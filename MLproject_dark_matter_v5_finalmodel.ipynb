{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook contains our final model which generated the best recall of 0.958 \n",
    "#and a high overall score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training images\n",
    "\n",
    "!wget https://alabama.box.com/s/isylwsjb5wphq0owgjl1hx12xad81w2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d Training_0.2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test images\n",
    "\n",
    "!wget https://alabama.box.com/s/254plk0zo7uez06gvn1kjbqfb0li2brf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d Test_0.2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3283,
     "status": "ok",
     "timestamp": 1619134434749,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "dUP5b4IfVW7_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import shutil\n",
    "import natsort\n",
    "import glob\n",
    "import numpy as np\n",
    "from numpy import save, load\n",
    "import os.path as path\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, load_model, save_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, LeakyReLU, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, precision_recall_curve, auc,recall_score\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import h5py\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from keras.backend import cast, greater, clip, floatx,epsilon\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, make_scorer, fbeta_score\n",
    "from matplotlib import pyplot\n",
    "from tensorflow import image\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1619134438186,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "CkUUiBUw6yG2"
   },
   "outputs": [],
   "source": [
    "len_dataset = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17930,
     "status": "ok",
     "timestamp": 1619134455961,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "DV6uwY9l_8qD",
    "outputId": "e091712e-cae4-4d16-ecd4-8d7f919ab67b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 75, 75, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = load('train_all.npy')\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 13899,
     "status": "ok",
     "timestamp": 1619134455962,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "3NwNkPvvcCmj"
   },
   "outputs": [],
   "source": [
    "train_images = train_images[0:len_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10813,
     "status": "ok",
     "timestamp": 1619134455962,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "u29B55qSb_XL",
    "outputId": "284acd27-d5d3-4829-8599-00ee43f4a941"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 75, 75, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "executionInfo": {
     "elapsed": 682,
     "status": "ok",
     "timestamp": 1619042031975,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "dWefBg_YwR75",
    "outputId": "bca28cb9-2db7-435b-b27b-bfbfbe89ed97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb2d5c42a50>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_image = train_images[0,:,:,0]\n",
    "pyplot.imshow(single_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1012,
     "status": "ok",
     "timestamp": 1619134472699,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "BTtGUbHe28uQ"
   },
   "outputs": [],
   "source": [
    "labels = load('labels_train_all.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1619134475272,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "jp6enWj1cToV"
   },
   "outputs": [],
   "source": [
    "labels = labels[:len_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1619134476427,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "tDs3xpcI7EGw",
    "outputId": "ffde9d94-7c82-42a6-d958-12554004daba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1619134480376,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "CcCJhuAcVgHS"
   },
   "outputs": [],
   "source": [
    "# Split into test and training sets\n",
    "\n",
    "n_images = train_images.shape[0]\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.8            \n",
    "\n",
    "# Split at the given index\n",
    "split_index = int(TRAIN_TEST_SPLIT * n_images)\n",
    "shuffled_indices = np.random.permutation(n_images)\n",
    "train_indices = shuffled_indices[0:split_index]\n",
    "test_indices = shuffled_indices[split_index:]\n",
    "\n",
    "# Split the images and the labels\n",
    "x_train = train_images[train_indices, :, :, :]\n",
    "y_train = labels[train_indices]\n",
    "x_val = train_images[test_indices, :, :, :]\n",
    "y_val = labels[test_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJ5SLR9nv4op"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVoYJWodoYFt"
   },
   "source": [
    "#Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1619134532035,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "0_i98Xe-14mG"
   },
   "outputs": [],
   "source": [
    "def create_model(activation='relu', kernel_size=3, kernel_initializer='TruncatedNormal', drop_rate=0.25, lr = 0.01): \n",
    "  shape = train_images.shape[1:]\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, activation=activation, kernel_size=kernel_size, padding='same', kernel_initializer=kernel_initializer, input_shape=shape))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Dropout(drop_rate))\n",
    "  model.add(Conv2D(64, activation=activation, kernel_size=kernel_size, padding='same', kernel_initializer=kernel_initializer))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Dropout(drop_rate))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, activation=activation, kernel_initializer=kernel_initializer))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer))\n",
    "  model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()], ver)\n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 603,
     "status": "ok",
     "timestamp": 1619134534703,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "bayTu3ep35Ou"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1.e-6)\n",
    "early_stopping_cb = EarlyStopping(monitor='loss', patience=5)\n",
    "callbacks = [reduce_lr, early_stopping_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1619055252627,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "8uUUKwxrA8_W"
   },
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3678671,
     "status": "ok",
     "timestamp": 1619058992027,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "BOg831SJDi7x",
    "outputId": "bff90243-332f-4834-84f2-2ce954a7d20c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.7172 - accuracy: 0.7037 - precision_304: 0.6945 - recall_304: 0.6852 - val_loss: 318.2298 - val_accuracy: 0.5142 - val_precision_304: 0.5142 - val_recall_304: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4680 - accuracy: 0.7750 - precision_304: 0.7702 - recall_304: 0.7809 - val_loss: 42.9151 - val_accuracy: 0.5142 - val_precision_304: 0.5142 - val_recall_304: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4492 - accuracy: 0.7922 - precision_304: 0.7883 - recall_304: 0.7853 - val_loss: 15.4475 - val_accuracy: 0.5142 - val_precision_304: 0.5142 - val_recall_304: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4477 - accuracy: 0.7940 - precision_304: 0.7974 - recall_304: 0.7909 - val_loss: 2.1348 - val_accuracy: 0.4992 - val_precision_304: 0.9000 - val_recall_304: 0.0292\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3937 - accuracy: 0.8209 - precision_304: 0.8067 - recall_304: 0.8321 - val_loss: 9.6927 - val_accuracy: 0.4858 - val_precision_304: 0.0000e+00 - val_recall_304: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4048 - accuracy: 0.8153 - precision_304: 0.7966 - recall_304: 0.8319 - val_loss: 2.2010 - val_accuracy: 0.4925 - val_precision_304: 0.5034 - val_recall_304: 0.9514\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4020 - accuracy: 0.8183 - precision_304: 0.8000 - recall_304: 0.8433 - val_loss: 2.2827 - val_accuracy: 0.5142 - val_precision_304: 0.5142 - val_recall_304: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3664 - accuracy: 0.8309 - precision_304: 0.8211 - recall_304: 0.8450 - val_loss: 8.3012 - val_accuracy: 0.4858 - val_precision_304: 0.0000e+00 - val_recall_304: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3628 - accuracy: 0.8287 - precision_304: 0.8238 - recall_304: 0.8306 - val_loss: 0.3952 - val_accuracy: 0.8275 - val_precision_304: 0.7962 - val_recall_304: 0.8930\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3565 - accuracy: 0.8358 - precision_304: 0.8260 - recall_304: 0.8509 - val_loss: 0.7280 - val_accuracy: 0.7142 - val_precision_304: 0.9308 - val_recall_304: 0.4797\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3947 - accuracy: 0.8136 - precision_304: 0.8094 - recall_304: 0.8155 - val_loss: 0.5335 - val_accuracy: 0.7533 - val_precision_304: 0.8905 - val_recall_304: 0.5932\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3640 - accuracy: 0.8335 - precision_304: 0.8186 - recall_304: 0.8525 - val_loss: 0.6961 - val_accuracy: 0.7283 - val_precision_304: 0.9292 - val_recall_304: 0.5105\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3578 - accuracy: 0.8300 - precision_304: 0.8209 - recall_304: 0.8453 - val_loss: 0.4329 - val_accuracy: 0.8008 - val_precision_304: 0.8765 - val_recall_304: 0.7131\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3446 - accuracy: 0.8432 - precision_304: 0.8342 - recall_304: 0.8574 - val_loss: 0.3994 - val_accuracy: 0.8117 - val_precision_304: 0.8510 - val_recall_304: 0.7682\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3538 - accuracy: 0.8416 - precision_304: 0.8282 - recall_304: 0.8540 - val_loss: 0.3810 - val_accuracy: 0.8275 - val_precision_304: 0.8328 - val_recall_304: 0.8314\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3675 - accuracy: 0.8275 - precision_304: 0.8245 - recall_304: 0.8342 - val_loss: 0.3793 - val_accuracy: 0.8358 - val_precision_304: 0.8221 - val_recall_304: 0.8687\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3584 - accuracy: 0.8383 - precision_304: 0.8261 - recall_304: 0.8575 - val_loss: 0.3822 - val_accuracy: 0.8258 - val_precision_304: 0.8322 - val_recall_304: 0.8282\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3715 - accuracy: 0.8338 - precision_304: 0.8178 - recall_304: 0.8547 - val_loss: 0.3804 - val_accuracy: 0.8333 - val_precision_304: 0.8347 - val_recall_304: 0.8428\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3491 - accuracy: 0.8461 - precision_304: 0.8404 - recall_304: 0.8537 - val_loss: 0.3793 - val_accuracy: 0.8375 - val_precision_304: 0.8256 - val_recall_304: 0.8671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu, AUC=0.918, Accuracy=0.831, f2=0.845, prec=0.816, rec=0.853, total=  22.2s\n",
      "[CV] lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 46ms/step - loss: 0.7212 - accuracy: 0.6914 - precision_305: 0.6932 - recall_305: 0.7005 - val_loss: 122.2625 - val_accuracy: 0.5142 - val_precision_305: 0.5142 - val_recall_305: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4725 - accuracy: 0.7711 - precision_305: 0.7852 - recall_305: 0.7348 - val_loss: 18.8644 - val_accuracy: 0.5142 - val_precision_305: 0.5142 - val_recall_305: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4190 - accuracy: 0.8027 - precision_305: 0.7843 - recall_305: 0.8331 - val_loss: 2.4818 - val_accuracy: 0.5142 - val_precision_305: 0.5142 - val_recall_305: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3983 - accuracy: 0.8194 - precision_305: 0.7977 - recall_305: 0.8462 - val_loss: 1.7586 - val_accuracy: 0.5133 - val_precision_305: 0.5138 - val_recall_305: 0.9984\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3976 - accuracy: 0.8093 - precision_305: 0.8085 - recall_305: 0.8154 - val_loss: 62.3176 - val_accuracy: 0.4858 - val_precision_305: 0.0000e+00 - val_recall_305: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4025 - accuracy: 0.8192 - precision_305: 0.7975 - recall_305: 0.8650 - val_loss: 50.2239 - val_accuracy: 0.4858 - val_precision_305: 0.0000e+00 - val_recall_305: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3743 - accuracy: 0.8259 - precision_305: 0.8168 - recall_305: 0.8432 - val_loss: 68.3142 - val_accuracy: 0.4858 - val_precision_305: 0.0000e+00 - val_recall_305: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3552 - accuracy: 0.8385 - precision_305: 0.8287 - recall_305: 0.8511 - val_loss: 6.0924 - val_accuracy: 0.4858 - val_precision_305: 0.0000e+00 - val_recall_305: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3439 - accuracy: 0.8429 - precision_305: 0.8181 - recall_305: 0.8793 - val_loss: 27.2727 - val_accuracy: 0.4858 - val_precision_305: 0.0000e+00 - val_recall_305: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3390 - accuracy: 0.8530 - precision_305: 0.8353 - recall_305: 0.8733 - val_loss: 37.3316 - val_accuracy: 0.4858 - val_precision_305: 0.0000e+00 - val_recall_305: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3496 - accuracy: 0.8403 - precision_305: 0.8137 - recall_305: 0.8707 - val_loss: 24.0650 - val_accuracy: 0.4858 - val_precision_305: 0.0000e+00 - val_recall_305: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3346 - accuracy: 0.8427 - precision_305: 0.8277 - recall_305: 0.8616 - val_loss: 7.2612 - val_accuracy: 0.4858 - val_precision_305: 0.0000e+00 - val_recall_305: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3411 - accuracy: 0.8516 - precision_305: 0.8459 - recall_305: 0.8616 - val_loss: 4.2379 - val_accuracy: 0.4858 - val_precision_305: 0.0000e+00 - val_recall_305: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3436 - accuracy: 0.8450 - precision_305: 0.8286 - recall_305: 0.8684 - val_loss: 2.4052 - val_accuracy: 0.4858 - val_precision_305: 0.0000e+00 - val_recall_305: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3495 - accuracy: 0.8450 - precision_305: 0.8323 - recall_305: 0.8608 - val_loss: 1.5219 - val_accuracy: 0.4958 - val_precision_305: 1.0000 - val_recall_305: 0.0194\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3452 - accuracy: 0.8388 - precision_305: 0.8192 - recall_305: 0.8639 - val_loss: 1.0039 - val_accuracy: 0.5750 - val_precision_305: 0.9908 - val_recall_305: 0.1750\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3330 - accuracy: 0.8532 - precision_305: 0.8335 - recall_305: 0.8761 - val_loss: 0.6967 - val_accuracy: 0.6842 - val_precision_305: 0.9474 - val_recall_305: 0.4084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   41.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu, AUC=0.896, Accuracy=0.691, f2=0.457, prec=0.933, rec=0.406, total=  19.6s\n",
      "[CV] lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.8058 - accuracy: 0.6796 - precision_306: 0.6761 - recall_306: 0.6700 - val_loss: 179.7512 - val_accuracy: 0.5142 - val_precision_306: 0.5142 - val_recall_306: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.5012 - accuracy: 0.7442 - precision_306: 0.7697 - recall_306: 0.6994 - val_loss: 31.8712 - val_accuracy: 0.5142 - val_precision_306: 0.5142 - val_recall_306: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4581 - accuracy: 0.7794 - precision_306: 0.7760 - recall_306: 0.7751 - val_loss: 4.7094 - val_accuracy: 0.5142 - val_precision_306: 0.5142 - val_recall_306: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4391 - accuracy: 0.7968 - precision_306: 0.8055 - recall_306: 0.7785 - val_loss: 1.0988 - val_accuracy: 0.4992 - val_precision_306: 0.5635 - val_recall_306: 0.1151\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4079 - accuracy: 0.8199 - precision_306: 0.8115 - recall_306: 0.8424 - val_loss: 1.4626 - val_accuracy: 0.4883 - val_precision_306: 0.6667 - val_recall_306: 0.0097\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4146 - accuracy: 0.8071 - precision_306: 0.8175 - recall_306: 0.7857 - val_loss: 17.2124 - val_accuracy: 0.4858 - val_precision_306: 0.0000e+00 - val_recall_306: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3783 - accuracy: 0.8296 - precision_306: 0.8347 - recall_306: 0.8300 - val_loss: 29.5743 - val_accuracy: 0.4858 - val_precision_306: 0.0000e+00 - val_recall_306: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3681 - accuracy: 0.8349 - precision_306: 0.8279 - recall_306: 0.8429 - val_loss: 34.5081 - val_accuracy: 0.4858 - val_precision_306: 0.0000e+00 - val_recall_306: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3908 - accuracy: 0.8334 - precision_306: 0.8191 - recall_306: 0.8448 - val_loss: 66.6623 - val_accuracy: 0.4858 - val_precision_306: 0.0000e+00 - val_recall_306: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3769 - accuracy: 0.8312 - precision_306: 0.8215 - recall_306: 0.8445 - val_loss: 12.2770 - val_accuracy: 0.4858 - val_precision_306: 0.0000e+00 - val_recall_306: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3626 - accuracy: 0.8280 - precision_306: 0.8323 - recall_306: 0.8256 - val_loss: 9.3558 - val_accuracy: 0.4858 - val_precision_306: 0.0000e+00 - val_recall_306: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3860 - accuracy: 0.8237 - precision_306: 0.8179 - recall_306: 0.8325 - val_loss: 8.0704 - val_accuracy: 0.4858 - val_precision_306: 0.0000e+00 - val_recall_306: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3729 - accuracy: 0.8213 - precision_306: 0.8138 - recall_306: 0.8255 - val_loss: 4.1071 - val_accuracy: 0.4867 - val_precision_306: 1.0000 - val_recall_306: 0.0016\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3692 - accuracy: 0.8356 - precision_306: 0.8280 - recall_306: 0.8481 - val_loss: 2.3001 - val_accuracy: 0.5025 - val_precision_306: 1.0000 - val_recall_306: 0.0324\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3912 - accuracy: 0.8162 - precision_306: 0.8080 - recall_306: 0.8307 - val_loss: 1.3732 - val_accuracy: 0.5642 - val_precision_306: 0.9700 - val_recall_306: 0.1572\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3780 - accuracy: 0.8279 - precision_306: 0.8222 - recall_306: 0.8335 - val_loss: 0.9122 - val_accuracy: 0.6442 - val_precision_306: 0.9358 - val_recall_306: 0.3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu, AUC=0.905, Accuracy=0.646, f2=0.356, prec=0.932, rec=0.309, total=  18.5s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.25, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 2s 42ms/step - loss: 0.5414 - accuracy: 0.7233 - precision_307: 0.7160 - recall_307: 0.7166 - val_loss: 33.9500 - val_accuracy: 0.5142 - val_precision_307: 0.5142 - val_recall_307: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4373 - accuracy: 0.7912 - precision_307: 0.7806 - recall_307: 0.8114 - val_loss: 32.1353 - val_accuracy: 0.5142 - val_precision_307: 0.5142 - val_recall_307: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4238 - accuracy: 0.7999 - precision_307: 0.7971 - recall_307: 0.7966 - val_loss: 11.4312 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4006 - accuracy: 0.8216 - precision_307: 0.8211 - recall_307: 0.8219 - val_loss: 10.4186 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3973 - accuracy: 0.8196 - precision_307: 0.8024 - recall_307: 0.8426 - val_loss: 36.2173 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3646 - accuracy: 0.8297 - precision_307: 0.8345 - recall_307: 0.8248 - val_loss: 4.0652 - val_accuracy: 0.4867 - val_precision_307: 1.0000 - val_recall_307: 0.0016\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3473 - accuracy: 0.8436 - precision_307: 0.8324 - recall_307: 0.8533 - val_loss: 15.0933 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3439 - accuracy: 0.8441 - precision_307: 0.8256 - recall_307: 0.8687 - val_loss: 23.7779 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3021 - accuracy: 0.8682 - precision_307: 0.8577 - recall_307: 0.8801 - val_loss: 55.9583 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2810 - accuracy: 0.8814 - precision_307: 0.8783 - recall_307: 0.8847 - val_loss: 74.3703 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2550 - accuracy: 0.8872 - precision_307: 0.8838 - recall_307: 0.8945 - val_loss: 49.1507 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2574 - accuracy: 0.8942 - precision_307: 0.8899 - recall_307: 0.8998 - val_loss: 59.8143 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2506 - accuracy: 0.8875 - precision_307: 0.8831 - recall_307: 0.8924 - val_loss: 55.6137 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2446 - accuracy: 0.8963 - precision_307: 0.8943 - recall_307: 0.8992 - val_loss: 45.2575 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2486 - accuracy: 0.8965 - precision_307: 0.8792 - recall_307: 0.9088 - val_loss: 32.0074 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2544 - accuracy: 0.8887 - precision_307: 0.8883 - recall_307: 0.8925 - val_loss: 20.7829 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2459 - accuracy: 0.8987 - precision_307: 0.8882 - recall_307: 0.9085 - val_loss: 13.0748 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2496 - accuracy: 0.8854 - precision_307: 0.8698 - recall_307: 0.9017 - val_loss: 8.7929 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2442 - accuracy: 0.8952 - precision_307: 0.8819 - recall_307: 0.9062 - val_loss: 6.5036 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2548 - accuracy: 0.8898 - precision_307: 0.8729 - recall_307: 0.9047 - val_loss: 5.0108 - val_accuracy: 0.4858 - val_precision_307: 0.0000e+00 - val_recall_307: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.25, batch_size=100, activation=elu, AUC=0.907, Accuracy=0.503, f2=0.000, prec=0.000, rec=0.000, total=  22.2s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.25, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.5648 - accuracy: 0.6903 - precision_308: 0.6819 - recall_308: 0.6891 - val_loss: 16.0196 - val_accuracy: 0.5142 - val_precision_308: 0.5142 - val_recall_308: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4047 - accuracy: 0.8136 - precision_308: 0.8031 - recall_308: 0.8269 - val_loss: 6.1826 - val_accuracy: 0.4858 - val_precision_308: 0.0000e+00 - val_recall_308: 0.0000e+00\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3607 - accuracy: 0.8406 - precision_308: 0.8280 - recall_308: 0.8560 - val_loss: 38.5396 - val_accuracy: 0.4858 - val_precision_308: 0.0000e+00 - val_recall_308: 0.0000e+00\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3849 - accuracy: 0.8281 - precision_308: 0.8110 - recall_308: 0.8549 - val_loss: 30.0966 - val_accuracy: 0.5142 - val_precision_308: 0.5142 - val_recall_308: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3296 - accuracy: 0.8488 - precision_308: 0.8329 - recall_308: 0.8715 - val_loss: 11.1267 - val_accuracy: 0.5142 - val_precision_308: 0.5142 - val_recall_308: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3283 - accuracy: 0.8566 - precision_308: 0.8373 - recall_308: 0.8850 - val_loss: 13.5916 - val_accuracy: 0.5142 - val_precision_308: 0.5142 - val_recall_308: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3315 - accuracy: 0.8494 - precision_308: 0.8529 - recall_308: 0.8514 - val_loss: 6.7108 - val_accuracy: 0.5142 - val_precision_308: 0.5142 - val_recall_308: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2915 - accuracy: 0.8699 - precision_308: 0.8546 - recall_308: 0.8921 - val_loss: 2.1260 - val_accuracy: 0.5158 - val_precision_308: 0.5150 - val_recall_308: 1.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2979 - accuracy: 0.8743 - precision_308: 0.8711 - recall_308: 0.8808 - val_loss: 0.4022 - val_accuracy: 0.8175 - val_precision_308: 0.8516 - val_recall_308: 0.7812\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3091 - accuracy: 0.8563 - precision_308: 0.8432 - recall_308: 0.8756 - val_loss: 4.4866 - val_accuracy: 0.4858 - val_precision_308: 0.0000e+00 - val_recall_308: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3023 - accuracy: 0.8658 - precision_308: 0.8632 - recall_308: 0.8713 - val_loss: 0.3672 - val_accuracy: 0.8350 - val_precision_308: 0.8363 - val_recall_308: 0.8444\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2958 - accuracy: 0.8663 - precision_308: 0.8678 - recall_308: 0.8667 - val_loss: 2.6202 - val_accuracy: 0.4858 - val_precision_308: 0.0000e+00 - val_recall_308: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2821 - accuracy: 0.8777 - precision_308: 0.8722 - recall_308: 0.8872 - val_loss: 5.2733 - val_accuracy: 0.4858 - val_precision_308: 0.0000e+00 - val_recall_308: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2856 - accuracy: 0.8867 - precision_308: 0.8846 - recall_308: 0.8925 - val_loss: 2.9824 - val_accuracy: 0.4858 - val_precision_308: 0.0000e+00 - val_recall_308: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2692 - accuracy: 0.8817 - precision_308: 0.8787 - recall_308: 0.8854 - val_loss: 2.2118 - val_accuracy: 0.4900 - val_precision_308: 1.0000 - val_recall_308: 0.0081\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2841 - accuracy: 0.8784 - precision_308: 0.8679 - recall_308: 0.8888 - val_loss: 1.4851 - val_accuracy: 0.5383 - val_precision_308: 0.9701 - val_recall_308: 0.1053\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2859 - accuracy: 0.8772 - precision_308: 0.8708 - recall_308: 0.8862 - val_loss: 1.0760 - val_accuracy: 0.6142 - val_precision_308: 0.9695 - val_recall_308: 0.2577\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2825 - accuracy: 0.8735 - precision_308: 0.8733 - recall_308: 0.8748 - val_loss: 0.7378 - val_accuracy: 0.7008 - val_precision_308: 0.9388 - val_recall_308: 0.4473\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2909 - accuracy: 0.8725 - precision_308: 0.8561 - recall_308: 0.8884 - val_loss: 0.5446 - val_accuracy: 0.7592 - val_precision_308: 0.9271 - val_recall_308: 0.5770\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2840 - accuracy: 0.8875 - precision_308: 0.8761 - recall_308: 0.8995 - val_loss: 0.4721 - val_accuracy: 0.7817 - val_precision_308: 0.9080 - val_recall_308: 0.6402\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2863 - accuracy: 0.8738 - precision_308: 0.8552 - recall_308: 0.8956 - val_loss: 0.4191 - val_accuracy: 0.8025 - val_precision_308: 0.8862 - val_recall_308: 0.7066\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2886 - accuracy: 0.8719 - precision_308: 0.8577 - recall_308: 0.8889 - val_loss: 0.3896 - val_accuracy: 0.8200 - val_precision_308: 0.8762 - val_recall_308: 0.7569\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2651 - accuracy: 0.8908 - precision_308: 0.8838 - recall_308: 0.9004 - val_loss: 0.3739 - val_accuracy: 0.8292 - val_precision_308: 0.8576 - val_recall_308: 0.8006\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2814 - accuracy: 0.8760 - precision_308: 0.8740 - recall_308: 0.8807 - val_loss: 0.3678 - val_accuracy: 0.8383 - val_precision_308: 0.8473 - val_recall_308: 0.8363\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2996 - accuracy: 0.8679 - precision_308: 0.8583 - recall_308: 0.8758 - val_loss: 0.3654 - val_accuracy: 0.8383 - val_precision_308: 0.8417 - val_recall_308: 0.8444\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2861 - accuracy: 0.8755 - precision_308: 0.8610 - recall_308: 0.8911 - val_loss: 0.3645 - val_accuracy: 0.8383 - val_precision_308: 0.8384 - val_recall_308: 0.8493\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2869 - accuracy: 0.8735 - precision_308: 0.8649 - recall_308: 0.8822 - val_loss: 0.3639 - val_accuracy: 0.8392 - val_precision_308: 0.8333 - val_recall_308: 0.8590\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2927 - accuracy: 0.8651 - precision_308: 0.8513 - recall_308: 0.8810 - val_loss: 0.3640 - val_accuracy: 0.8375 - val_precision_308: 0.8339 - val_recall_308: 0.8541\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2824 - accuracy: 0.8752 - precision_308: 0.8669 - recall_308: 0.8825 - val_loss: 0.3641 - val_accuracy: 0.8392 - val_precision_308: 0.8376 - val_recall_308: 0.8525\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2885 - accuracy: 0.8769 - precision_308: 0.8694 - recall_308: 0.8839 - val_loss: 0.3641 - val_accuracy: 0.8392 - val_precision_308: 0.8365 - val_recall_308: 0.8541\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2827 - accuracy: 0.8741 - precision_308: 0.8630 - recall_308: 0.8839 - val_loss: 0.3641 - val_accuracy: 0.8367 - val_precision_308: 0.8274 - val_recall_308: 0.8622\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2871 - accuracy: 0.8708 - precision_308: 0.8586 - recall_308: 0.8780 - val_loss: 0.3641 - val_accuracy: 0.8367 - val_precision_308: 0.8274 - val_recall_308: 0.8622\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2938 - accuracy: 0.8699 - precision_308: 0.8792 - recall_308: 0.8681 - val_loss: 0.3641 - val_accuracy: 0.8375 - val_precision_308: 0.8287 - val_recall_308: 0.8622\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2705 - accuracy: 0.8838 - precision_308: 0.8803 - recall_308: 0.8927 - val_loss: 0.3642 - val_accuracy: 0.8375 - val_precision_308: 0.8276 - val_recall_308: 0.8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.25, batch_size=100, activation=elu, AUC=0.896, Accuracy=0.807, f2=0.827, prec=0.788, rec=0.838, total=  37.1s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.25, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.5329 - accuracy: 0.7228 - precision_309: 0.7226 - recall_309: 0.7241 - val_loss: 16.9933 - val_accuracy: 0.4858 - val_precision_309: 0.0000e+00 - val_recall_309: 0.0000e+00\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4285 - accuracy: 0.8031 - precision_309: 0.7848 - recall_309: 0.8254 - val_loss: 18.1590 - val_accuracy: 0.4858 - val_precision_309: 0.0000e+00 - val_recall_309: 0.0000e+00\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4043 - accuracy: 0.8192 - precision_309: 0.8021 - recall_309: 0.8351 - val_loss: 0.6491 - val_accuracy: 0.7033 - val_precision_309: 0.6364 - val_recall_309: 0.9870\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3807 - accuracy: 0.8256 - precision_309: 0.8124 - recall_309: 0.8350 - val_loss: 9.6386 - val_accuracy: 0.5142 - val_precision_309: 0.5142 - val_recall_309: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3643 - accuracy: 0.8400 - precision_309: 0.8272 - recall_309: 0.8562 - val_loss: 25.2264 - val_accuracy: 0.4858 - val_precision_309: 0.0000e+00 - val_recall_309: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3616 - accuracy: 0.8319 - precision_309: 0.8493 - recall_309: 0.8153 - val_loss: 0.5642 - val_accuracy: 0.7292 - val_precision_309: 0.6659 - val_recall_309: 0.9498\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3095 - accuracy: 0.8620 - precision_309: 0.8606 - recall_309: 0.8692 - val_loss: 2.8954 - val_accuracy: 0.4858 - val_precision_309: 0.0000e+00 - val_recall_309: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2947 - accuracy: 0.8693 - precision_309: 0.8584 - recall_309: 0.8802 - val_loss: 2.8907 - val_accuracy: 0.4858 - val_precision_309: 0.0000e+00 - val_recall_309: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2867 - accuracy: 0.8828 - precision_309: 0.8698 - recall_309: 0.8981 - val_loss: 4.9438 - val_accuracy: 0.4858 - val_precision_309: 0.0000e+00 - val_recall_309: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2730 - accuracy: 0.8810 - precision_309: 0.8781 - recall_309: 0.8896 - val_loss: 13.2717 - val_accuracy: 0.4858 - val_precision_309: 0.0000e+00 - val_recall_309: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2598 - accuracy: 0.8866 - precision_309: 0.8752 - recall_309: 0.8986 - val_loss: 6.5780 - val_accuracy: 0.4858 - val_precision_309: 0.0000e+00 - val_recall_309: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2703 - accuracy: 0.8920 - precision_309: 0.8918 - recall_309: 0.8925 - val_loss: 3.5513 - val_accuracy: 0.4858 - val_precision_309: 0.0000e+00 - val_recall_309: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2586 - accuracy: 0.8963 - precision_309: 0.8856 - recall_309: 0.9061 - val_loss: 2.1260 - val_accuracy: 0.4917 - val_precision_309: 1.0000 - val_recall_309: 0.0113\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2464 - accuracy: 0.8988 - precision_309: 0.8805 - recall_309: 0.9134 - val_loss: 1.5112 - val_accuracy: 0.5192 - val_precision_309: 0.9762 - val_recall_309: 0.0665\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2691 - accuracy: 0.8871 - precision_309: 0.8647 - recall_309: 0.9065 - val_loss: 0.9830 - val_accuracy: 0.6100 - val_precision_309: 0.9806 - val_recall_309: 0.2464\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2661 - accuracy: 0.8873 - precision_309: 0.8897 - recall_309: 0.8914 - val_loss: 0.6713 - val_accuracy: 0.7108 - val_precision_309: 0.9441 - val_recall_309: 0.4652\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2564 - accuracy: 0.8933 - precision_309: 0.8902 - recall_309: 0.8949 - val_loss: 0.5138 - val_accuracy: 0.7508 - val_precision_309: 0.8897 - val_recall_309: 0.5883\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2568 - accuracy: 0.8882 - precision_309: 0.8810 - recall_309: 0.8931 - val_loss: 0.4339 - val_accuracy: 0.7917 - val_precision_309: 0.8737 - val_recall_309: 0.6953\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2488 - accuracy: 0.8952 - precision_309: 0.8921 - recall_309: 0.8970 - val_loss: 0.3958 - val_accuracy: 0.8275 - val_precision_309: 0.8727 - val_recall_309: 0.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.25, batch_size=100, activation=elu, AUC=0.910, Accuracy=0.815, f2=0.774, prec=0.854, rec=0.757, total=  21.4s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=relu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 4s 177ms/step - loss: 0.8671 - accuracy: 0.6310 - precision_310: 0.6162 - recall_310: 0.6208 - val_loss: 168.6884 - val_accuracy: 0.5142 - val_precision_310: 0.5142 - val_recall_310: 1.0000\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.5188 - accuracy: 0.7548 - precision_310: 0.7489 - recall_310: 0.7745 - val_loss: 83.8754 - val_accuracy: 0.5142 - val_precision_310: 0.5142 - val_recall_310: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4686 - accuracy: 0.7801 - precision_310: 0.7631 - recall_310: 0.8058 - val_loss: 56.3477 - val_accuracy: 0.5142 - val_precision_310: 0.5142 - val_recall_310: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4618 - accuracy: 0.7781 - precision_310: 0.7688 - recall_310: 0.7895 - val_loss: 23.9641 - val_accuracy: 0.5142 - val_precision_310: 0.5142 - val_recall_310: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4392 - accuracy: 0.7922 - precision_310: 0.7789 - recall_310: 0.8155 - val_loss: 1.9320 - val_accuracy: 0.4858 - val_precision_310: 0.0000e+00 - val_recall_310: 0.0000e+00\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4286 - accuracy: 0.7945 - precision_310: 0.7950 - recall_310: 0.8038 - val_loss: 18.0530 - val_accuracy: 0.4858 - val_precision_310: 0.0000e+00 - val_recall_310: 0.0000e+00\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.4218 - accuracy: 0.8125 - precision_310: 0.8142 - recall_310: 0.8076 - val_loss: 13.7637 - val_accuracy: 0.4858 - val_precision_310: 0.0000e+00 - val_recall_310: 0.0000e+00\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.4185 - accuracy: 0.8093 - precision_310: 0.7947 - recall_310: 0.8325 - val_loss: 7.3516 - val_accuracy: 0.4858 - val_precision_310: 0.0000e+00 - val_recall_310: 0.0000e+00\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.4232 - accuracy: 0.8114 - precision_310: 0.8100 - recall_310: 0.8190 - val_loss: 6.0175 - val_accuracy: 0.4858 - val_precision_310: 0.0000e+00 - val_recall_310: 0.0000e+00\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.4037 - accuracy: 0.8220 - precision_310: 0.8051 - recall_310: 0.8421 - val_loss: 4.3287 - val_accuracy: 0.4858 - val_precision_310: 0.0000e+00 - val_recall_310: 0.0000e+00\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3986 - accuracy: 0.8120 - precision_310: 0.7915 - recall_310: 0.8399 - val_loss: 3.0845 - val_accuracy: 0.4858 - val_precision_310: 0.0000e+00 - val_recall_310: 0.0000e+00\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4045 - accuracy: 0.8145 - precision_310: 0.8120 - recall_310: 0.8203 - val_loss: 2.2076 - val_accuracy: 0.4858 - val_precision_310: 0.0000e+00 - val_recall_310: 0.0000e+00\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4055 - accuracy: 0.8108 - precision_310: 0.8073 - recall_310: 0.8194 - val_loss: 1.5720 - val_accuracy: 0.4858 - val_precision_310: 0.0000e+00 - val_recall_310: 0.0000e+00\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4130 - accuracy: 0.8014 - precision_310: 0.8007 - recall_310: 0.8061 - val_loss: 1.1572 - val_accuracy: 0.4850 - val_precision_310: 0.4444 - val_recall_310: 0.0065\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4052 - accuracy: 0.8154 - precision_310: 0.8116 - recall_310: 0.8235 - val_loss: 0.9274 - val_accuracy: 0.4708 - val_precision_310: 0.4062 - val_recall_310: 0.0632\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4020 - accuracy: 0.8113 - precision_310: 0.7930 - recall_310: 0.8250 - val_loss: 0.8192 - val_accuracy: 0.4708 - val_precision_310: 0.4795 - val_recall_310: 0.3420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=relu, AUC=0.417, Accuracy=0.469, f2=0.339, prec=0.452, rec=0.319, total=  17.2s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=relu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 2s 116ms/step - loss: 0.8578 - accuracy: 0.6398 - precision_311: 0.6300 - recall_311: 0.6419 - val_loss: 58.3088 - val_accuracy: 0.5142 - val_precision_311: 0.5142 - val_recall_311: 1.0000\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4880 - accuracy: 0.7678 - precision_311: 0.7601 - recall_311: 0.7740 - val_loss: 66.5749 - val_accuracy: 0.5142 - val_precision_311: 0.5142 - val_recall_311: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4467 - accuracy: 0.7943 - precision_311: 0.7810 - recall_311: 0.8225 - val_loss: 50.0212 - val_accuracy: 0.5142 - val_precision_311: 0.5142 - val_recall_311: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4383 - accuracy: 0.8006 - precision_311: 0.7880 - recall_311: 0.8092 - val_loss: 25.9876 - val_accuracy: 0.5142 - val_precision_311: 0.5142 - val_recall_311: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4104 - accuracy: 0.8124 - precision_311: 0.7954 - recall_311: 0.8321 - val_loss: 13.1476 - val_accuracy: 0.5142 - val_precision_311: 0.5142 - val_recall_311: 1.0000\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4104 - accuracy: 0.8185 - precision_311: 0.8067 - recall_311: 0.8349 - val_loss: 8.5109 - val_accuracy: 0.5142 - val_precision_311: 0.5142 - val_recall_311: 1.0000\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3971 - accuracy: 0.8174 - precision_311: 0.8118 - recall_311: 0.8270 - val_loss: 2.1627 - val_accuracy: 0.5142 - val_precision_311: 0.5142 - val_recall_311: 1.0000\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3960 - accuracy: 0.8178 - precision_311: 0.8095 - recall_311: 0.8324 - val_loss: 0.8556 - val_accuracy: 0.4667 - val_precision_311: 0.4896 - val_recall_311: 0.8817\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3881 - accuracy: 0.8285 - precision_311: 0.8225 - recall_311: 0.8316 - val_loss: 0.8135 - val_accuracy: 0.4342 - val_precision_311: 0.4706 - val_recall_311: 0.8039\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3697 - accuracy: 0.8341 - precision_311: 0.8121 - recall_311: 0.8630 - val_loss: 0.9468 - val_accuracy: 0.4858 - val_precision_311: 0.5000 - val_recall_311: 0.9368\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3815 - accuracy: 0.8198 - precision_311: 0.8163 - recall_311: 0.8325 - val_loss: 2.0686 - val_accuracy: 0.5142 - val_precision_311: 0.5142 - val_recall_311: 1.0000\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3835 - accuracy: 0.8244 - precision_311: 0.8249 - recall_311: 0.8333 - val_loss: 2.2186 - val_accuracy: 0.5142 - val_precision_311: 0.5142 - val_recall_311: 1.0000\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3731 - accuracy: 0.8303 - precision_311: 0.8136 - recall_311: 0.8477 - val_loss: 1.6463 - val_accuracy: 0.5092 - val_precision_311: 0.5117 - val_recall_311: 0.9887\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3631 - accuracy: 0.8359 - precision_311: 0.8192 - recall_311: 0.8558 - val_loss: 1.6648 - val_accuracy: 0.5108 - val_precision_311: 0.5126 - val_recall_311: 0.9919\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3528 - accuracy: 0.8425 - precision_311: 0.8281 - recall_311: 0.8630 - val_loss: 0.9513 - val_accuracy: 0.5367 - val_precision_311: 0.5260 - val_recall_311: 1.0000\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3607 - accuracy: 0.8342 - precision_311: 0.8166 - recall_311: 0.8558 - val_loss: 1.1404 - val_accuracy: 0.5192 - val_precision_311: 0.5168 - val_recall_311: 1.0000\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3520 - accuracy: 0.8489 - precision_311: 0.8426 - recall_311: 0.8624 - val_loss: 1.2971 - val_accuracy: 0.5175 - val_precision_311: 0.5159 - val_recall_311: 1.0000\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3778 - accuracy: 0.8384 - precision_311: 0.8208 - recall_311: 0.8609 - val_loss: 1.2848 - val_accuracy: 0.5175 - val_precision_311: 0.5159 - val_recall_311: 1.0000\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3793 - accuracy: 0.8226 - precision_311: 0.8101 - recall_311: 0.8409 - val_loss: 1.2516 - val_accuracy: 0.5175 - val_precision_311: 0.5159 - val_recall_311: 1.0000\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3737 - accuracy: 0.8276 - precision_311: 0.8219 - recall_311: 0.8371 - val_loss: 1.1979 - val_accuracy: 0.5225 - val_precision_311: 0.5185 - val_recall_311: 1.0000\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3599 - accuracy: 0.8353 - precision_311: 0.8148 - recall_311: 0.8541 - val_loss: 1.1441 - val_accuracy: 0.5292 - val_precision_311: 0.5220 - val_recall_311: 1.0000\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3495 - accuracy: 0.8437 - precision_311: 0.8272 - recall_311: 0.8666 - val_loss: 1.0840 - val_accuracy: 0.5358 - val_precision_311: 0.5256 - val_recall_311: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=relu, AUC=0.829, Accuracy=0.522, f2=0.838, prec=0.509, rec=0.999, total=  20.4s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=relu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 3s 117ms/step - loss: 0.8649 - accuracy: 0.6265 - precision_312: 0.6221 - recall_312: 0.6226 - val_loss: 120.3740 - val_accuracy: 0.5142 - val_precision_312: 0.5142 - val_recall_312: 1.0000\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.5219 - accuracy: 0.7477 - precision_312: 0.7607 - recall_312: 0.7357 - val_loss: 78.5787 - val_accuracy: 0.5142 - val_precision_312: 0.5142 - val_recall_312: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4978 - accuracy: 0.7511 - precision_312: 0.7517 - recall_312: 0.7626 - val_loss: 28.3048 - val_accuracy: 0.5142 - val_precision_312: 0.5142 - val_recall_312: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4806 - accuracy: 0.7684 - precision_312: 0.7795 - recall_312: 0.7397 - val_loss: 5.3578 - val_accuracy: 0.5142 - val_precision_312: 0.5142 - val_recall_312: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.4535 - accuracy: 0.7891 - precision_312: 0.7806 - recall_312: 0.8034 - val_loss: 9.2689 - val_accuracy: 0.4858 - val_precision_312: 0.0000e+00 - val_recall_312: 0.0000e+00\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4374 - accuracy: 0.8009 - precision_312: 0.7852 - recall_312: 0.8128 - val_loss: 12.0437 - val_accuracy: 0.4858 - val_precision_312: 0.0000e+00 - val_recall_312: 0.0000e+00\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4045 - accuracy: 0.8205 - precision_312: 0.8060 - recall_312: 0.8412 - val_loss: 8.3857 - val_accuracy: 0.4858 - val_precision_312: 0.0000e+00 - val_recall_312: 0.0000e+00\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4078 - accuracy: 0.8048 - precision_312: 0.7951 - recall_312: 0.8181 - val_loss: 5.9090 - val_accuracy: 0.4858 - val_precision_312: 0.0000e+00 - val_recall_312: 0.0000e+00\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4091 - accuracy: 0.8075 - precision_312: 0.8004 - recall_312: 0.8168 - val_loss: 4.3231 - val_accuracy: 0.4858 - val_precision_312: 0.0000e+00 - val_recall_312: 0.0000e+00\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4154 - accuracy: 0.8050 - precision_312: 0.7914 - recall_312: 0.8189 - val_loss: 3.1051 - val_accuracy: 0.4858 - val_precision_312: 0.0000e+00 - val_recall_312: 0.0000e+00\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4158 - accuracy: 0.8064 - precision_312: 0.8026 - recall_312: 0.8124 - val_loss: 2.3027 - val_accuracy: 0.4858 - val_precision_312: 0.0000e+00 - val_recall_312: 0.0000e+00\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3968 - accuracy: 0.8229 - precision_312: 0.8107 - recall_312: 0.8420 - val_loss: 1.5268 - val_accuracy: 0.4858 - val_precision_312: 0.0000e+00 - val_recall_312: 0.0000e+00\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4117 - accuracy: 0.8210 - precision_312: 0.8031 - recall_312: 0.8395 - val_loss: 1.1468 - val_accuracy: 0.4833 - val_precision_312: 0.4211 - val_recall_312: 0.0130\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4192 - accuracy: 0.8166 - precision_312: 0.8005 - recall_312: 0.8337 - val_loss: 0.9281 - val_accuracy: 0.4300 - val_precision_312: 0.4062 - val_recall_312: 0.2350\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3993 - accuracy: 0.8158 - precision_312: 0.8116 - recall_312: 0.8252 - val_loss: 0.9093 - val_accuracy: 0.3433 - val_precision_312: 0.3978 - val_recall_312: 0.5397\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4068 - accuracy: 0.8062 - precision_312: 0.7974 - recall_312: 0.8204 - val_loss: 1.0011 - val_accuracy: 0.4242 - val_precision_312: 0.4643 - val_recall_312: 0.7796\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4134 - accuracy: 0.8134 - precision_312: 0.7972 - recall_312: 0.8279 - val_loss: 1.1060 - val_accuracy: 0.4850 - val_precision_312: 0.4996 - val_recall_312: 0.9254\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4157 - accuracy: 0.8131 - precision_312: 0.8005 - recall_312: 0.8317 - val_loss: 1.1752 - val_accuracy: 0.5108 - val_precision_312: 0.5126 - val_recall_312: 0.9919\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4057 - accuracy: 0.8161 - precision_312: 0.8093 - recall_312: 0.8299 - val_loss: 1.2003 - val_accuracy: 0.5142 - val_precision_312: 0.5142 - val_recall_312: 1.0000\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4018 - accuracy: 0.8129 - precision_312: 0.8004 - recall_312: 0.8270 - val_loss: 1.2136 - val_accuracy: 0.5142 - val_precision_312: 0.5142 - val_recall_312: 1.0000\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4127 - accuracy: 0.8081 - precision_312: 0.8006 - recall_312: 0.8217 - val_loss: 1.2169 - val_accuracy: 0.5158 - val_precision_312: 0.5150 - val_recall_312: 1.0000\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4064 - accuracy: 0.8060 - precision_312: 0.8048 - recall_312: 0.8102 - val_loss: 1.1999 - val_accuracy: 0.5158 - val_precision_312: 0.5150 - val_recall_312: 1.0000\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4006 - accuracy: 0.8208 - precision_312: 0.8056 - recall_312: 0.8401 - val_loss: 1.1640 - val_accuracy: 0.5158 - val_precision_312: 0.5150 - val_recall_312: 1.0000\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4178 - accuracy: 0.8139 - precision_312: 0.8091 - recall_312: 0.8199 - val_loss: 1.1197 - val_accuracy: 0.5175 - val_precision_312: 0.5159 - val_recall_312: 1.0000\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4054 - accuracy: 0.8082 - precision_312: 0.7904 - recall_312: 0.8239 - val_loss: 1.0644 - val_accuracy: 0.5200 - val_precision_312: 0.5172 - val_recall_312: 1.0000\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4143 - accuracy: 0.8069 - precision_312: 0.7910 - recall_312: 0.8187 - val_loss: 1.0054 - val_accuracy: 0.5292 - val_precision_312: 0.5220 - val_recall_312: 1.0000\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4073 - accuracy: 0.8095 - precision_312: 0.7932 - recall_312: 0.8274 - val_loss: 0.9449 - val_accuracy: 0.5400 - val_precision_312: 0.5278 - val_recall_312: 1.0000\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4024 - accuracy: 0.8223 - precision_312: 0.8072 - recall_312: 0.8375 - val_loss: 0.8855 - val_accuracy: 0.5575 - val_precision_312: 0.5375 - val_recall_312: 1.0000\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4128 - accuracy: 0.8055 - precision_312: 0.7907 - recall_312: 0.8212 - val_loss: 0.8329 - val_accuracy: 0.5817 - val_precision_312: 0.5514 - val_recall_312: 1.0000\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4048 - accuracy: 0.8139 - precision_312: 0.7976 - recall_312: 0.8329 - val_loss: 0.7814 - val_accuracy: 0.6008 - val_precision_312: 0.5630 - val_recall_312: 1.0000\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4137 - accuracy: 0.8079 - precision_312: 0.7917 - recall_312: 0.8265 - val_loss: 0.7375 - val_accuracy: 0.6200 - val_precision_312: 0.5750 - val_recall_312: 1.0000\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4115 - accuracy: 0.8182 - precision_312: 0.8110 - recall_312: 0.8271 - val_loss: 0.7001 - val_accuracy: 0.6392 - val_precision_312: 0.5876 - val_recall_312: 1.0000\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.4081 - accuracy: 0.8186 - precision_312: 0.8063 - recall_312: 0.8348 - val_loss: 0.6647 - val_accuracy: 0.6617 - val_precision_312: 0.6033 - val_recall_312: 0.9984\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4248 - accuracy: 0.8074 - precision_312: 0.7978 - recall_312: 0.8215 - val_loss: 0.6371 - val_accuracy: 0.6708 - val_precision_312: 0.6106 - val_recall_312: 0.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=relu, AUC=0.899, Accuracy=0.679, f2=0.880, prec=0.608, rec=0.990, total=  30.8s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=200, activation=elu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 78ms/step - loss: 0.7529 - accuracy: 0.6670 - precision_313: 0.6640 - recall_313: 0.6763 - val_loss: 12.4605 - val_accuracy: 0.5142 - val_precision_313: 0.5142 - val_recall_313: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4748 - accuracy: 0.7751 - precision_313: 0.7742 - recall_313: 0.7826 - val_loss: 13.2998 - val_accuracy: 0.5142 - val_precision_313: 0.5142 - val_recall_313: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4202 - accuracy: 0.7987 - precision_313: 0.7927 - recall_313: 0.8095 - val_loss: 0.6260 - val_accuracy: 0.6267 - val_precision_313: 0.9333 - val_recall_313: 0.2950\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3951 - accuracy: 0.8159 - precision_313: 0.8033 - recall_313: 0.8267 - val_loss: 12.2320 - val_accuracy: 0.5142 - val_precision_313: 0.5142 - val_recall_313: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3922 - accuracy: 0.8222 - precision_313: 0.8135 - recall_313: 0.8322 - val_loss: 10.4499 - val_accuracy: 0.5142 - val_precision_313: 0.5142 - val_recall_313: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3799 - accuracy: 0.8219 - precision_313: 0.8058 - recall_313: 0.8420 - val_loss: 8.7993 - val_accuracy: 0.5142 - val_precision_313: 0.5142 - val_recall_313: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3743 - accuracy: 0.8249 - precision_313: 0.8197 - recall_313: 0.8340 - val_loss: 5.7343 - val_accuracy: 0.5142 - val_precision_313: 0.5142 - val_recall_313: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3584 - accuracy: 0.8282 - precision_313: 0.8183 - recall_313: 0.8419 - val_loss: 4.7617 - val_accuracy: 0.5142 - val_precision_313: 0.5142 - val_recall_313: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3547 - accuracy: 0.8361 - precision_313: 0.8302 - recall_313: 0.8470 - val_loss: 4.3840 - val_accuracy: 0.5142 - val_precision_313: 0.5142 - val_recall_313: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3491 - accuracy: 0.8432 - precision_313: 0.8316 - recall_313: 0.8594 - val_loss: 4.0690 - val_accuracy: 0.5142 - val_precision_313: 0.5142 - val_recall_313: 1.0000\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3517 - accuracy: 0.8413 - precision_313: 0.8295 - recall_313: 0.8589 - val_loss: 3.9860 - val_accuracy: 0.5142 - val_precision_313: 0.5142 - val_recall_313: 1.0000\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3506 - accuracy: 0.8375 - precision_313: 0.8244 - recall_313: 0.8534 - val_loss: 3.7296 - val_accuracy: 0.5150 - val_precision_313: 0.5146 - val_recall_313: 1.0000\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3515 - accuracy: 0.8330 - precision_313: 0.8162 - recall_313: 0.8519 - val_loss: 3.2022 - val_accuracy: 0.5175 - val_precision_313: 0.5159 - val_recall_313: 1.0000\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3504 - accuracy: 0.8399 - precision_313: 0.8345 - recall_313: 0.8400 - val_loss: 2.6256 - val_accuracy: 0.5283 - val_precision_313: 0.5216 - val_recall_313: 1.0000\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3550 - accuracy: 0.8432 - precision_313: 0.8435 - recall_313: 0.8473 - val_loss: 2.0712 - val_accuracy: 0.5492 - val_precision_313: 0.5328 - val_recall_313: 1.0000\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3421 - accuracy: 0.8505 - precision_313: 0.8487 - recall_313: 0.8591 - val_loss: 1.6049 - val_accuracy: 0.5825 - val_precision_313: 0.5519 - val_recall_313: 1.0000\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3784 - accuracy: 0.8245 - precision_313: 0.8197 - recall_313: 0.8319 - val_loss: 1.2571 - val_accuracy: 0.6133 - val_precision_313: 0.5708 - val_recall_313: 1.0000\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3536 - accuracy: 0.8368 - precision_313: 0.8210 - recall_313: 0.8544 - val_loss: 1.0069 - val_accuracy: 0.6408 - val_precision_313: 0.5889 - val_recall_313: 0.9984\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3633 - accuracy: 0.8322 - precision_313: 0.8188 - recall_313: 0.8512 - val_loss: 0.8294 - val_accuracy: 0.6733 - val_precision_313: 0.6117 - val_recall_313: 0.9984\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3632 - accuracy: 0.8315 - precision_313: 0.8273 - recall_313: 0.8355 - val_loss: 0.7054 - val_accuracy: 0.6992 - val_precision_313: 0.6314 - val_recall_313: 0.9968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=200, activation=elu, AUC=0.914, Accuracy=0.734, f2=0.896, prec=0.654, rec=0.987, total=  18.6s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=200, activation=elu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 79ms/step - loss: 0.6401 - accuracy: 0.6871 - precision_314: 0.6881 - recall_314: 0.6800 - val_loss: 20.4185 - val_accuracy: 0.5142 - val_precision_314: 0.5142 - val_recall_314: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4409 - accuracy: 0.7915 - precision_314: 0.7692 - recall_314: 0.8272 - val_loss: 4.3152 - val_accuracy: 0.5142 - val_precision_314: 0.5142 - val_recall_314: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4091 - accuracy: 0.8075 - precision_314: 0.7997 - recall_314: 0.8207 - val_loss: 7.8852 - val_accuracy: 0.5142 - val_precision_314: 0.5142 - val_recall_314: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3690 - accuracy: 0.8328 - precision_314: 0.8308 - recall_314: 0.8415 - val_loss: 5.9776 - val_accuracy: 0.5142 - val_precision_314: 0.5142 - val_recall_314: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3564 - accuracy: 0.8388 - precision_314: 0.8303 - recall_314: 0.8533 - val_loss: 1.4830 - val_accuracy: 0.5142 - val_precision_314: 0.5142 - val_recall_314: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.3462 - accuracy: 0.8454 - precision_314: 0.8366 - recall_314: 0.8544 - val_loss: 4.5469 - val_accuracy: 0.4858 - val_precision_314: 0.0000e+00 - val_recall_314: 0.0000e+00\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3399 - accuracy: 0.8446 - precision_314: 0.8346 - recall_314: 0.8527 - val_loss: 6.5036 - val_accuracy: 0.4858 - val_precision_314: 0.0000e+00 - val_recall_314: 0.0000e+00\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3348 - accuracy: 0.8467 - precision_314: 0.8318 - recall_314: 0.8595 - val_loss: 6.2466 - val_accuracy: 0.4858 - val_precision_314: 0.0000e+00 - val_recall_314: 0.0000e+00\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3313 - accuracy: 0.8533 - precision_314: 0.8523 - recall_314: 0.8573 - val_loss: 6.1180 - val_accuracy: 0.4858 - val_precision_314: 0.0000e+00 - val_recall_314: 0.0000e+00\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3417 - accuracy: 0.8414 - precision_314: 0.8187 - recall_314: 0.8646 - val_loss: 5.6540 - val_accuracy: 0.4858 - val_precision_314: 0.0000e+00 - val_recall_314: 0.0000e+00\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.3351 - accuracy: 0.8469 - precision_314: 0.8189 - recall_314: 0.8792 - val_loss: 5.1084 - val_accuracy: 0.4858 - val_precision_314: 0.0000e+00 - val_recall_314: 0.0000e+00\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.3271 - accuracy: 0.8586 - precision_314: 0.8537 - recall_314: 0.8670 - val_loss: 4.0344 - val_accuracy: 0.4858 - val_precision_314: 0.0000e+00 - val_recall_314: 0.0000e+00\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3273 - accuracy: 0.8564 - precision_314: 0.8549 - recall_314: 0.8578 - val_loss: 3.1049 - val_accuracy: 0.4858 - val_precision_314: 0.0000e+00 - val_recall_314: 0.0000e+00\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3204 - accuracy: 0.8556 - precision_314: 0.8587 - recall_314: 0.8589 - val_loss: 2.3442 - val_accuracy: 0.4858 - val_precision_314: 0.0000e+00 - val_recall_314: 0.0000e+00\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3379 - accuracy: 0.8547 - precision_314: 0.8329 - recall_314: 0.8764 - val_loss: 1.7695 - val_accuracy: 0.4858 - val_precision_314: 0.0000e+00 - val_recall_314: 0.0000e+00\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3501 - accuracy: 0.8316 - precision_314: 0.8274 - recall_314: 0.8442 - val_loss: 1.3269 - val_accuracy: 0.4958 - val_precision_314: 1.0000 - val_recall_314: 0.0194\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.3375 - accuracy: 0.8375 - precision_314: 0.8383 - recall_314: 0.8402 - val_loss: 1.0031 - val_accuracy: 0.5333 - val_precision_314: 0.9831 - val_recall_314: 0.0940\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3396 - accuracy: 0.8483 - precision_314: 0.8386 - recall_314: 0.8551 - val_loss: 0.7792 - val_accuracy: 0.6083 - val_precision_314: 0.9682 - val_recall_314: 0.2464\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3395 - accuracy: 0.8489 - precision_314: 0.8316 - recall_314: 0.8654 - val_loss: 0.6211 - val_accuracy: 0.6808 - val_precision_314: 0.9466 - val_recall_314: 0.4019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=200, activation=elu, AUC=0.893, Accuracy=0.675, f2=0.419, prec=0.942, rec=0.368, total=  17.6s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=200, activation=elu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 78ms/step - loss: 0.7006 - accuracy: 0.6703 - precision_315: 0.6620 - recall_315: 0.6611 - val_loss: 15.0292 - val_accuracy: 0.5142 - val_precision_315: 0.5142 - val_recall_315: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4637 - accuracy: 0.7792 - precision_315: 0.7826 - recall_315: 0.7802 - val_loss: 9.9228 - val_accuracy: 0.5142 - val_precision_315: 0.5142 - val_recall_315: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4230 - accuracy: 0.8028 - precision_315: 0.8040 - recall_315: 0.8057 - val_loss: 3.3723 - val_accuracy: 0.5142 - val_precision_315: 0.5142 - val_recall_315: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3900 - accuracy: 0.8153 - precision_315: 0.8092 - recall_315: 0.8239 - val_loss: 6.7703 - val_accuracy: 0.5142 - val_precision_315: 0.5142 - val_recall_315: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3740 - accuracy: 0.8284 - precision_315: 0.8203 - recall_315: 0.8299 - val_loss: 0.9264 - val_accuracy: 0.5300 - val_precision_315: 0.5224 - val_recall_315: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3644 - accuracy: 0.8363 - precision_315: 0.8319 - recall_315: 0.8400 - val_loss: 4.7002 - val_accuracy: 0.5142 - val_precision_315: 0.5142 - val_recall_315: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3704 - accuracy: 0.8373 - precision_315: 0.8315 - recall_315: 0.8466 - val_loss: 7.2911 - val_accuracy: 0.4858 - val_precision_315: 0.0000e+00 - val_recall_315: 0.0000e+00\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3423 - accuracy: 0.8386 - precision_315: 0.8352 - recall_315: 0.8410 - val_loss: 5.0068 - val_accuracy: 0.4858 - val_precision_315: 0.0000e+00 - val_recall_315: 0.0000e+00\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3275 - accuracy: 0.8581 - precision_315: 0.8463 - recall_315: 0.8690 - val_loss: 5.0226 - val_accuracy: 0.4858 - val_precision_315: 0.0000e+00 - val_recall_315: 0.0000e+00\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3519 - accuracy: 0.8421 - precision_315: 0.8449 - recall_315: 0.8431 - val_loss: 7.4010 - val_accuracy: 0.4858 - val_precision_315: 0.0000e+00 - val_recall_315: 0.0000e+00\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3192 - accuracy: 0.8539 - precision_315: 0.8380 - recall_315: 0.8758 - val_loss: 6.0270 - val_accuracy: 0.4858 - val_precision_315: 0.0000e+00 - val_recall_315: 0.0000e+00\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.3323 - accuracy: 0.8462 - precision_315: 0.8383 - recall_315: 0.8581 - val_loss: 4.5814 - val_accuracy: 0.4858 - val_precision_315: 0.0000e+00 - val_recall_315: 0.0000e+00\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.3213 - accuracy: 0.8620 - precision_315: 0.8579 - recall_315: 0.8698 - val_loss: 3.5855 - val_accuracy: 0.4858 - val_precision_315: 0.0000e+00 - val_recall_315: 0.0000e+00\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3378 - accuracy: 0.8479 - precision_315: 0.8317 - recall_315: 0.8636 - val_loss: 2.9297 - val_accuracy: 0.4858 - val_precision_315: 0.0000e+00 - val_recall_315: 0.0000e+00\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.3123 - accuracy: 0.8657 - precision_315: 0.8461 - recall_315: 0.8834 - val_loss: 2.4045 - val_accuracy: 0.4858 - val_precision_315: 0.0000e+00 - val_recall_315: 0.0000e+00\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3414 - accuracy: 0.8467 - precision_315: 0.8376 - recall_315: 0.8592 - val_loss: 1.9140 - val_accuracy: 0.4925 - val_precision_315: 1.0000 - val_recall_315: 0.0130\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3277 - accuracy: 0.8584 - precision_315: 0.8469 - recall_315: 0.8687 - val_loss: 1.5244 - val_accuracy: 0.5192 - val_precision_315: 0.9762 - val_recall_315: 0.0665\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.3315 - accuracy: 0.8480 - precision_315: 0.8453 - recall_315: 0.8521 - val_loss: 1.2332 - val_accuracy: 0.5533 - val_precision_315: 0.9765 - val_recall_315: 0.1345\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3330 - accuracy: 0.8481 - precision_315: 0.8441 - recall_315: 0.8568 - val_loss: 1.0062 - val_accuracy: 0.6033 - val_precision_315: 0.9669 - val_recall_315: 0.2366\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3195 - accuracy: 0.8619 - precision_315: 0.8346 - recall_315: 0.8842 - val_loss: 0.8331 - val_accuracy: 0.6533 - val_precision_315: 0.9427 - val_recall_315: 0.3468\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3374 - accuracy: 0.8541 - precision_315: 0.8440 - recall_315: 0.8660 - val_loss: 0.7112 - val_accuracy: 0.6950 - val_precision_315: 0.9373 - val_recall_315: 0.4360\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3323 - accuracy: 0.8568 - precision_315: 0.8507 - recall_315: 0.8627 - val_loss: 0.6203 - val_accuracy: 0.7267 - val_precision_315: 0.9366 - val_recall_315: 0.5024\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3269 - accuracy: 0.8615 - precision_315: 0.8474 - recall_315: 0.8776 - val_loss: 0.5548 - val_accuracy: 0.7408 - val_precision_315: 0.9158 - val_recall_315: 0.5462\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3210 - accuracy: 0.8708 - precision_315: 0.8669 - recall_315: 0.8806 - val_loss: 0.5021 - val_accuracy: 0.7567 - val_precision_315: 0.9052 - val_recall_315: 0.5883\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3244 - accuracy: 0.8533 - precision_315: 0.8432 - recall_315: 0.8665 - val_loss: 0.4644 - val_accuracy: 0.7717 - val_precision_315: 0.8924 - val_recall_315: 0.6321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=200, activation=elu, AUC=0.913, Accuracy=0.782, f2=0.670, prec=0.903, rec=0.630, total=  22.5s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 4s 65ms/step - loss: 0.7491 - accuracy: 0.6651 - precision_316: 0.6625 - recall_316: 0.6727 - val_loss: 130.2360 - val_accuracy: 0.5142 - val_precision_316: 0.5142 - val_recall_316: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4667 - accuracy: 0.7758 - precision_316: 0.7542 - recall_316: 0.8171 - val_loss: 19.5870 - val_accuracy: 0.5142 - val_precision_316: 0.5142 - val_recall_316: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4594 - accuracy: 0.7821 - precision_316: 0.7717 - recall_316: 0.8064 - val_loss: 7.0332 - val_accuracy: 0.5142 - val_precision_316: 0.5142 - val_recall_316: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4400 - accuracy: 0.7926 - precision_316: 0.8030 - recall_316: 0.7784 - val_loss: 1.5072 - val_accuracy: 0.5142 - val_precision_316: 0.5142 - val_recall_316: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4135 - accuracy: 0.8121 - precision_316: 0.8045 - recall_316: 0.8206 - val_loss: 1.1037 - val_accuracy: 0.5142 - val_precision_316: 0.5142 - val_recall_316: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3995 - accuracy: 0.8178 - precision_316: 0.8092 - recall_316: 0.8261 - val_loss: 0.8592 - val_accuracy: 0.5117 - val_precision_316: 0.5130 - val_recall_316: 0.9903\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3928 - accuracy: 0.8145 - precision_316: 0.8059 - recall_316: 0.8288 - val_loss: 0.7797 - val_accuracy: 0.4717 - val_precision_316: 0.4718 - val_recall_316: 0.2301\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4263 - accuracy: 0.8048 - precision_316: 0.7874 - recall_316: 0.8286 - val_loss: 3.2522 - val_accuracy: 0.4858 - val_precision_316: 0.0000e+00 - val_recall_316: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4126 - accuracy: 0.8130 - precision_316: 0.7827 - recall_316: 0.8431 - val_loss: 1.7273 - val_accuracy: 0.5142 - val_precision_316: 0.5142 - val_recall_316: 1.0000\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3686 - accuracy: 0.8370 - precision_316: 0.8117 - recall_316: 0.8791 - val_loss: 7.5892 - val_accuracy: 0.3800 - val_precision_316: 0.2756 - val_recall_316: 0.1264\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3714 - accuracy: 0.8312 - precision_316: 0.8209 - recall_316: 0.8482 - val_loss: 42.4234 - val_accuracy: 0.5142 - val_precision_316: 0.5142 - val_recall_316: 1.0000\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3675 - accuracy: 0.8340 - precision_316: 0.8282 - recall_316: 0.8374 - val_loss: 2.4365 - val_accuracy: 0.4858 - val_precision_316: 0.0000e+00 - val_recall_316: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3811 - accuracy: 0.8177 - precision_316: 0.8035 - recall_316: 0.8370 - val_loss: 4.1383 - val_accuracy: 0.4858 - val_precision_316: 0.0000e+00 - val_recall_316: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3828 - accuracy: 0.8244 - precision_316: 0.8070 - recall_316: 0.8476 - val_loss: 3.3484 - val_accuracy: 0.4858 - val_precision_316: 0.0000e+00 - val_recall_316: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3715 - accuracy: 0.8385 - precision_316: 0.8315 - recall_316: 0.8502 - val_loss: 2.1869 - val_accuracy: 0.4958 - val_precision_316: 1.0000 - val_recall_316: 0.0194\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3932 - accuracy: 0.8134 - precision_316: 0.8027 - recall_316: 0.8273 - val_loss: 1.3737 - val_accuracy: 0.5650 - val_precision_316: 0.9798 - val_recall_316: 0.1572\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3687 - accuracy: 0.8351 - precision_316: 0.8149 - recall_316: 0.8590 - val_loss: 0.9442 - val_accuracy: 0.6275 - val_precision_316: 0.9293 - val_recall_316: 0.2982\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3662 - accuracy: 0.8295 - precision_316: 0.8180 - recall_316: 0.8449 - val_loss: 0.6868 - val_accuracy: 0.7025 - val_precision_316: 0.9305 - val_recall_316: 0.4554\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3898 - accuracy: 0.8185 - precision_316: 0.7848 - recall_316: 0.8535 - val_loss: 0.5386 - val_accuracy: 0.7508 - val_precision_316: 0.9119 - val_recall_316: 0.5705\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3807 - accuracy: 0.8194 - precision_316: 0.8165 - recall_316: 0.8290 - val_loss: 0.4577 - val_accuracy: 0.7775 - val_precision_316: 0.8855 - val_recall_316: 0.6515\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3703 - accuracy: 0.8257 - precision_316: 0.8066 - recall_316: 0.8460 - val_loss: 0.4184 - val_accuracy: 0.7933 - val_precision_316: 0.8683 - val_recall_316: 0.7050\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3800 - accuracy: 0.8295 - precision_316: 0.8203 - recall_316: 0.8491 - val_loss: 0.3862 - val_accuracy: 0.8242 - val_precision_316: 0.8524 - val_recall_316: 0.7958\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3697 - accuracy: 0.8309 - precision_316: 0.8206 - recall_316: 0.8437 - val_loss: 0.3784 - val_accuracy: 0.8383 - val_precision_316: 0.8395 - val_recall_316: 0.8476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=gelu, AUC=0.917, Accuracy=0.830, f2=0.830, prec=0.828, rec=0.830, total=  31.5s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 52ms/step - loss: 0.6985 - accuracy: 0.6773 - precision_317: 0.6707 - recall_317: 0.6664 - val_loss: 243.4944 - val_accuracy: 0.5142 - val_precision_317: 0.5142 - val_recall_317: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4934 - accuracy: 0.7676 - precision_317: 0.7684 - recall_317: 0.7714 - val_loss: 56.5917 - val_accuracy: 0.5142 - val_precision_317: 0.5142 - val_recall_317: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4395 - accuracy: 0.7960 - precision_317: 0.8018 - recall_317: 0.7955 - val_loss: 17.4526 - val_accuracy: 0.5142 - val_precision_317: 0.5142 - val_recall_317: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4355 - accuracy: 0.7971 - precision_317: 0.7925 - recall_317: 0.7900 - val_loss: 2.9664 - val_accuracy: 0.5142 - val_precision_317: 0.5142 - val_recall_317: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4104 - accuracy: 0.8053 - precision_317: 0.7929 - recall_317: 0.8189 - val_loss: 1.0109 - val_accuracy: 0.5992 - val_precision_317: 0.9359 - val_recall_317: 0.2366\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3900 - accuracy: 0.8264 - precision_317: 0.8053 - recall_317: 0.8608 - val_loss: 1.1848 - val_accuracy: 0.6117 - val_precision_317: 0.9415 - val_recall_317: 0.2609\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3959 - accuracy: 0.8278 - precision_317: 0.8172 - recall_317: 0.8294 - val_loss: 84.3672 - val_accuracy: 0.4858 - val_precision_317: 0.0000e+00 - val_recall_317: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3774 - accuracy: 0.8242 - precision_317: 0.7940 - recall_317: 0.8625 - val_loss: 40.4743 - val_accuracy: 0.4858 - val_precision_317: 0.0000e+00 - val_recall_317: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3760 - accuracy: 0.8387 - precision_317: 0.8152 - recall_317: 0.8677 - val_loss: 104.2687 - val_accuracy: 0.4858 - val_precision_317: 0.0000e+00 - val_recall_317: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3712 - accuracy: 0.8298 - precision_317: 0.8194 - recall_317: 0.8454 - val_loss: 48.8599 - val_accuracy: 0.4858 - val_precision_317: 0.0000e+00 - val_recall_317: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3819 - accuracy: 0.8227 - precision_317: 0.7908 - recall_317: 0.8609 - val_loss: 58.0377 - val_accuracy: 0.4858 - val_precision_317: 0.0000e+00 - val_recall_317: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3511 - accuracy: 0.8442 - precision_317: 0.8395 - recall_317: 0.8501 - val_loss: 38.2741 - val_accuracy: 0.4858 - val_precision_317: 0.0000e+00 - val_recall_317: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3778 - accuracy: 0.8236 - precision_317: 0.8204 - recall_317: 0.8404 - val_loss: 14.7942 - val_accuracy: 0.4858 - val_precision_317: 0.0000e+00 - val_recall_317: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3566 - accuracy: 0.8379 - precision_317: 0.8241 - recall_317: 0.8573 - val_loss: 6.3500 - val_accuracy: 0.4858 - val_precision_317: 0.0000e+00 - val_recall_317: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3660 - accuracy: 0.8356 - precision_317: 0.8132 - recall_317: 0.8593 - val_loss: 4.0254 - val_accuracy: 0.4858 - val_precision_317: 0.0000e+00 - val_recall_317: 0.0000e+00\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3693 - accuracy: 0.8294 - precision_317: 0.8195 - recall_317: 0.8464 - val_loss: 2.4744 - val_accuracy: 0.4950 - val_precision_317: 1.0000 - val_recall_317: 0.0178\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3614 - accuracy: 0.8328 - precision_317: 0.8097 - recall_317: 0.8653 - val_loss: 1.5223 - val_accuracy: 0.5642 - val_precision_317: 0.9700 - val_recall_317: 0.1572\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3530 - accuracy: 0.8347 - precision_317: 0.8122 - recall_317: 0.8656 - val_loss: 0.9865 - val_accuracy: 0.6425 - val_precision_317: 0.9273 - val_recall_317: 0.3306\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3539 - accuracy: 0.8508 - precision_317: 0.8431 - recall_317: 0.8636 - val_loss: 0.7006 - val_accuracy: 0.7150 - val_precision_317: 0.9231 - val_recall_317: 0.4862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=gelu, AUC=0.886, Accuracy=0.706, f2=0.507, prec=0.901, rec=0.457, total=  26.1s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 50ms/step - loss: 0.7492 - accuracy: 0.6792 - precision_318: 0.6811 - recall_318: 0.6718 - val_loss: 187.1317 - val_accuracy: 0.5142 - val_precision_318: 0.5142 - val_recall_318: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.4929 - accuracy: 0.7531 - precision_318: 0.7313 - recall_318: 0.7800 - val_loss: 36.4344 - val_accuracy: 0.5142 - val_precision_318: 0.5142 - val_recall_318: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4452 - accuracy: 0.7939 - precision_318: 0.7712 - recall_318: 0.8380 - val_loss: 7.7603 - val_accuracy: 0.5142 - val_precision_318: 0.5142 - val_recall_318: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4504 - accuracy: 0.7888 - precision_318: 0.7857 - recall_318: 0.7837 - val_loss: 1.4216 - val_accuracy: 0.5158 - val_precision_318: 0.5150 - val_recall_318: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4275 - accuracy: 0.8027 - precision_318: 0.7912 - recall_318: 0.8144 - val_loss: 19.0237 - val_accuracy: 0.4858 - val_precision_318: 0.0000e+00 - val_recall_318: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4098 - accuracy: 0.8044 - precision_318: 0.7951 - recall_318: 0.8177 - val_loss: 1.3699 - val_accuracy: 0.5792 - val_precision_318: 0.9375 - val_recall_318: 0.1945\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4135 - accuracy: 0.8100 - precision_318: 0.8044 - recall_318: 0.8276 - val_loss: 40.4919 - val_accuracy: 0.5142 - val_precision_318: 0.5142 - val_recall_318: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4034 - accuracy: 0.8227 - precision_318: 0.8272 - recall_318: 0.8271 - val_loss: 14.8012 - val_accuracy: 0.4858 - val_precision_318: 0.0000e+00 - val_recall_318: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3944 - accuracy: 0.8126 - precision_318: 0.8129 - recall_318: 0.8181 - val_loss: 19.5196 - val_accuracy: 0.3783 - val_precision_318: 0.4212 - val_recall_318: 0.5592\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3875 - accuracy: 0.8185 - precision_318: 0.8072 - recall_318: 0.8370 - val_loss: 32.5146 - val_accuracy: 0.4433 - val_precision_318: 0.4761 - val_recall_318: 0.8250\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3718 - accuracy: 0.8266 - precision_318: 0.8221 - recall_318: 0.8353 - val_loss: 47.0451 - val_accuracy: 0.4733 - val_precision_318: 0.4934 - val_recall_318: 0.9076\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3611 - accuracy: 0.8364 - precision_318: 0.8396 - recall_318: 0.8396 - val_loss: 28.0988 - val_accuracy: 0.3550 - val_precision_318: 0.3979 - val_recall_318: 0.4959\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3508 - accuracy: 0.8423 - precision_318: 0.8464 - recall_318: 0.8490 - val_loss: 25.4833 - val_accuracy: 0.3425 - val_precision_318: 0.3622 - val_recall_318: 0.3663\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3627 - accuracy: 0.8336 - precision_318: 0.8218 - recall_318: 0.8494 - val_loss: 21.1416 - val_accuracy: 0.3458 - val_precision_318: 0.3333 - val_recall_318: 0.2723\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3570 - accuracy: 0.8381 - precision_318: 0.8171 - recall_318: 0.8639 - val_loss: 9.4276 - val_accuracy: 0.4408 - val_precision_318: 0.3071 - val_recall_318: 0.0697\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3633 - accuracy: 0.8315 - precision_318: 0.8273 - recall_318: 0.8416 - val_loss: 4.5511 - val_accuracy: 0.4817 - val_precision_318: 0.1429 - val_recall_318: 0.0016\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3692 - accuracy: 0.8322 - precision_318: 0.8364 - recall_318: 0.8328 - val_loss: 2.8663 - val_accuracy: 0.5100 - val_precision_318: 1.0000 - val_recall_318: 0.0470\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3790 - accuracy: 0.8245 - precision_318: 0.8131 - recall_318: 0.8389 - val_loss: 1.8322 - val_accuracy: 0.5600 - val_precision_318: 0.9785 - val_recall_318: 0.1475\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3714 - accuracy: 0.8356 - precision_318: 0.8191 - recall_318: 0.8557 - val_loss: 1.2155 - val_accuracy: 0.6217 - val_precision_318: 0.9553 - val_recall_318: 0.2771\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3541 - accuracy: 0.8461 - precision_318: 0.8283 - recall_318: 0.8667 - val_loss: 0.8517 - val_accuracy: 0.6892 - val_precision_318: 0.9388 - val_recall_318: 0.4230\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3703 - accuracy: 0.8380 - precision_318: 0.8271 - recall_318: 0.8487 - val_loss: 0.6347 - val_accuracy: 0.7333 - val_precision_318: 0.9160 - val_recall_318: 0.5300\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3661 - accuracy: 0.8320 - precision_318: 0.8257 - recall_318: 0.8445 - val_loss: 0.5172 - val_accuracy: 0.7625 - val_precision_318: 0.8934 - val_recall_318: 0.6110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=gelu, AUC=0.910, Accuracy=0.771, f2=0.650, prec=0.898, rec=0.608, total=  29.5s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 52ms/step - loss: 0.7173 - accuracy: 0.6693 - precision_319: 0.6781 - recall_319: 0.6547 - val_loss: 483.1552 - val_accuracy: 0.5142 - val_precision_319: 0.5142 - val_recall_319: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4891 - accuracy: 0.7708 - precision_319: 0.7853 - recall_319: 0.7477 - val_loss: 82.0010 - val_accuracy: 0.5142 - val_precision_319: 0.5142 - val_recall_319: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4839 - accuracy: 0.7664 - precision_319: 0.7629 - recall_319: 0.7614 - val_loss: 10.7864 - val_accuracy: 0.5142 - val_precision_319: 0.5142 - val_recall_319: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4441 - accuracy: 0.7940 - precision_319: 0.7996 - recall_319: 0.7879 - val_loss: 1.0500 - val_accuracy: 0.4858 - val_precision_319: 0.5000 - val_recall_319: 0.9190\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4187 - accuracy: 0.8121 - precision_319: 0.7916 - recall_319: 0.8356 - val_loss: 11.0204 - val_accuracy: 0.4858 - val_precision_319: 0.0000e+00 - val_recall_319: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4176 - accuracy: 0.8021 - precision_319: 0.7966 - recall_319: 0.8170 - val_loss: 1.9582 - val_accuracy: 0.4858 - val_precision_319: 0.0000e+00 - val_recall_319: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4127 - accuracy: 0.8159 - precision_319: 0.8250 - recall_319: 0.7979 - val_loss: 0.8731 - val_accuracy: 0.3900 - val_precision_319: 0.4200 - val_recall_319: 0.4895\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3985 - accuracy: 0.8194 - precision_319: 0.8128 - recall_319: 0.8269 - val_loss: 1.1759 - val_accuracy: 0.4275 - val_precision_319: 0.4667 - val_recall_319: 0.7942\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3779 - accuracy: 0.8283 - precision_319: 0.8165 - recall_319: 0.8436 - val_loss: 1.3115 - val_accuracy: 0.3908 - val_precision_319: 0.4423 - val_recall_319: 0.7083\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3819 - accuracy: 0.8268 - precision_319: 0.8124 - recall_319: 0.8404 - val_loss: 0.7789 - val_accuracy: 0.5958 - val_precision_319: 0.9286 - val_recall_319: 0.2318\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3885 - accuracy: 0.8099 - precision_319: 0.7841 - recall_319: 0.8309 - val_loss: 0.4684 - val_accuracy: 0.7625 - val_precision_319: 0.8593 - val_recall_319: 0.6434\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4076 - accuracy: 0.8103 - precision_319: 0.8025 - recall_319: 0.8161 - val_loss: 1.8597 - val_accuracy: 0.5167 - val_precision_319: 0.9744 - val_recall_319: 0.0616\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3726 - accuracy: 0.8249 - precision_319: 0.8071 - recall_319: 0.8484 - val_loss: 1.5202 - val_accuracy: 0.5542 - val_precision_319: 0.9767 - val_recall_319: 0.1361\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4066 - accuracy: 0.8086 - precision_319: 0.7916 - recall_319: 0.8197 - val_loss: 1.7027 - val_accuracy: 0.5500 - val_precision_319: 0.9873 - val_recall_319: 0.1264\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3801 - accuracy: 0.8289 - precision_319: 0.8222 - recall_319: 0.8373 - val_loss: 1.0158 - val_accuracy: 0.6292 - val_precision_319: 0.9216 - val_recall_319: 0.3047\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3879 - accuracy: 0.8156 - precision_319: 0.8007 - recall_319: 0.8330 - val_loss: 0.7675 - val_accuracy: 0.6908 - val_precision_319: 0.9271 - val_recall_319: 0.4327\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3872 - accuracy: 0.8204 - precision_319: 0.8213 - recall_319: 0.8334 - val_loss: 0.5472 - val_accuracy: 0.7500 - val_precision_319: 0.8914 - val_recall_319: 0.5851\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4108 - accuracy: 0.8115 - precision_319: 0.8156 - recall_319: 0.8171 - val_loss: 0.4542 - val_accuracy: 0.7800 - val_precision_319: 0.8654 - val_recall_319: 0.6775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu, AUC=0.911, Accuracy=0.806, f2=0.736, prec=0.879, rec=0.707, total=  24.7s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 66ms/step - loss: 0.7450 - accuracy: 0.6800 - precision_320: 0.6724 - recall_320: 0.6765 - val_loss: 165.6685 - val_accuracy: 0.5142 - val_precision_320: 0.5142 - val_recall_320: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4613 - accuracy: 0.7815 - precision_320: 0.7826 - recall_320: 0.7929 - val_loss: 35.6551 - val_accuracy: 0.5142 - val_precision_320: 0.5142 - val_recall_320: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4399 - accuracy: 0.7955 - precision_320: 0.7877 - recall_320: 0.8006 - val_loss: 14.7075 - val_accuracy: 0.5142 - val_precision_320: 0.5142 - val_recall_320: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4182 - accuracy: 0.8057 - precision_320: 0.8035 - recall_320: 0.8078 - val_loss: 7.8666 - val_accuracy: 0.5142 - val_precision_320: 0.5142 - val_recall_320: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4093 - accuracy: 0.8162 - precision_320: 0.7989 - recall_320: 0.8330 - val_loss: 3.8086 - val_accuracy: 0.5142 - val_precision_320: 0.5142 - val_recall_320: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3945 - accuracy: 0.8244 - precision_320: 0.8152 - recall_320: 0.8354 - val_loss: 0.7154 - val_accuracy: 0.5625 - val_precision_320: 0.5441 - val_recall_320: 0.9206\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3982 - accuracy: 0.8152 - precision_320: 0.8317 - recall_320: 0.8000 - val_loss: 306.4410 - val_accuracy: 0.4858 - val_precision_320: 0.0000e+00 - val_recall_320: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4042 - accuracy: 0.8149 - precision_320: 0.8211 - recall_320: 0.8134 - val_loss: 23.4543 - val_accuracy: 0.4858 - val_precision_320: 0.0000e+00 - val_recall_320: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4002 - accuracy: 0.8188 - precision_320: 0.8387 - recall_320: 0.7794 - val_loss: 3.8535 - val_accuracy: 0.4858 - val_precision_320: 0.0000e+00 - val_recall_320: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3900 - accuracy: 0.8194 - precision_320: 0.8133 - recall_320: 0.8383 - val_loss: 2.8990 - val_accuracy: 0.4858 - val_precision_320: 0.0000e+00 - val_recall_320: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3592 - accuracy: 0.8364 - precision_320: 0.8162 - recall_320: 0.8580 - val_loss: 10.7380 - val_accuracy: 0.4858 - val_precision_320: 0.0000e+00 - val_recall_320: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3713 - accuracy: 0.8324 - precision_320: 0.8065 - recall_320: 0.8607 - val_loss: 2.6084 - val_accuracy: 0.4858 - val_precision_320: 0.0000e+00 - val_recall_320: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3584 - accuracy: 0.8337 - precision_320: 0.8083 - recall_320: 0.8654 - val_loss: 2.3216 - val_accuracy: 0.4942 - val_precision_320: 1.0000 - val_recall_320: 0.0162\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3581 - accuracy: 0.8372 - precision_320: 0.8237 - recall_320: 0.8590 - val_loss: 2.5261 - val_accuracy: 0.5000 - val_precision_320: 1.0000 - val_recall_320: 0.0276\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3599 - accuracy: 0.8365 - precision_320: 0.8199 - recall_320: 0.8569 - val_loss: 1.7442 - val_accuracy: 0.5567 - val_precision_320: 0.9885 - val_recall_320: 0.1394\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3680 - accuracy: 0.8228 - precision_320: 0.7949 - recall_320: 0.8465 - val_loss: 1.2147 - val_accuracy: 0.6142 - val_precision_320: 0.9639 - val_recall_320: 0.2593\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3541 - accuracy: 0.8393 - precision_320: 0.8309 - recall_320: 0.8532 - val_loss: 0.8319 - val_accuracy: 0.6850 - val_precision_320: 0.9377 - val_recall_320: 0.4149\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3556 - accuracy: 0.8377 - precision_320: 0.8196 - recall_320: 0.8560 - val_loss: 0.6129 - val_accuracy: 0.7342 - val_precision_320: 0.9093 - val_recall_320: 0.5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu, AUC=0.890, Accuracy=0.735, f2=0.576, prec=0.894, rec=0.529, total=  25.1s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 54ms/step - loss: 0.7152 - accuracy: 0.6634 - precision_321: 0.6531 - recall_321: 0.6623 - val_loss: 233.6480 - val_accuracy: 0.5142 - val_precision_321: 0.5142 - val_recall_321: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4879 - accuracy: 0.7584 - precision_321: 0.7580 - recall_321: 0.7473 - val_loss: 57.8876 - val_accuracy: 0.5142 - val_precision_321: 0.5142 - val_recall_321: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4820 - accuracy: 0.7664 - precision_321: 0.7485 - recall_321: 0.7922 - val_loss: 16.1610 - val_accuracy: 0.5142 - val_precision_321: 0.5142 - val_recall_321: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4535 - accuracy: 0.7917 - precision_321: 0.7859 - recall_321: 0.7880 - val_loss: 2.8769 - val_accuracy: 0.5142 - val_precision_321: 0.5142 - val_recall_321: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4458 - accuracy: 0.7893 - precision_321: 0.7671 - recall_321: 0.8070 - val_loss: 2.1157 - val_accuracy: 0.4892 - val_precision_321: 1.0000 - val_recall_321: 0.0065\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4191 - accuracy: 0.8112 - precision_321: 0.7892 - recall_321: 0.8421 - val_loss: 112.5622 - val_accuracy: 0.4858 - val_precision_321: 0.0000e+00 - val_recall_321: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4245 - accuracy: 0.8121 - precision_321: 0.7952 - recall_321: 0.8194 - val_loss: 773.2461 - val_accuracy: 0.4858 - val_precision_321: 0.0000e+00 - val_recall_321: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4067 - accuracy: 0.8140 - precision_321: 0.8011 - recall_321: 0.8326 - val_loss: 290.6129 - val_accuracy: 0.4858 - val_precision_321: 0.0000e+00 - val_recall_321: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.3946 - accuracy: 0.8170 - precision_321: 0.8092 - recall_321: 0.8288 - val_loss: 318.0686 - val_accuracy: 0.4858 - val_precision_321: 0.0000e+00 - val_recall_321: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3677 - accuracy: 0.8381 - precision_321: 0.8285 - recall_321: 0.8528 - val_loss: 291.1032 - val_accuracy: 0.4858 - val_precision_321: 0.0000e+00 - val_recall_321: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3779 - accuracy: 0.8314 - precision_321: 0.8181 - recall_321: 0.8482 - val_loss: 188.2348 - val_accuracy: 0.4858 - val_precision_321: 0.0000e+00 - val_recall_321: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3647 - accuracy: 0.8377 - precision_321: 0.8235 - recall_321: 0.8616 - val_loss: 40.7057 - val_accuracy: 0.4858 - val_precision_321: 0.0000e+00 - val_recall_321: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3759 - accuracy: 0.8401 - precision_321: 0.8395 - recall_321: 0.8530 - val_loss: 19.2840 - val_accuracy: 0.4858 - val_precision_321: 0.0000e+00 - val_recall_321: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3813 - accuracy: 0.8269 - precision_321: 0.8088 - recall_321: 0.8523 - val_loss: 9.0531 - val_accuracy: 0.4858 - val_precision_321: 0.0000e+00 - val_recall_321: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3761 - accuracy: 0.8340 - precision_321: 0.8170 - recall_321: 0.8481 - val_loss: 5.8683 - val_accuracy: 0.4858 - val_precision_321: 0.0000e+00 - val_recall_321: 0.0000e+00\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3840 - accuracy: 0.8285 - precision_321: 0.8254 - recall_321: 0.8408 - val_loss: 3.8692 - val_accuracy: 0.4925 - val_precision_321: 1.0000 - val_recall_321: 0.0130\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3902 - accuracy: 0.8166 - precision_321: 0.7971 - recall_321: 0.8329 - val_loss: 2.5593 - val_accuracy: 0.5233 - val_precision_321: 1.0000 - val_recall_321: 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu, AUC=0.896, Accuracy=0.529, f2=0.070, prec=0.918, rec=0.057, total=  23.6s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 4s 189ms/step - loss: 0.7293 - accuracy: 0.6412 - precision_322: 0.6364 - recall_322: 0.6512 - val_loss: 1.2362 - val_accuracy: 0.4858 - val_precision_322: 0.0000e+00 - val_recall_322: 0.0000e+00\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.6320 - accuracy: 0.7258 - precision_322: 0.7335 - recall_322: 0.7077 - val_loss: 3.7775 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.5153 - accuracy: 0.7535 - precision_322: 0.7431 - recall_322: 0.7676 - val_loss: 8.5033 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4459 - accuracy: 0.7980 - precision_322: 0.7916 - recall_322: 0.8046 - val_loss: 5.9391 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4516 - accuracy: 0.7911 - precision_322: 0.7813 - recall_322: 0.7974 - val_loss: 4.5904 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4222 - accuracy: 0.8118 - precision_322: 0.8197 - recall_322: 0.8013 - val_loss: 3.7420 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4373 - accuracy: 0.7996 - precision_322: 0.7887 - recall_322: 0.8095 - val_loss: 3.1341 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4434 - accuracy: 0.7871 - precision_322: 0.7898 - recall_322: 0.7802 - val_loss: 2.7067 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4444 - accuracy: 0.7947 - precision_322: 0.7942 - recall_322: 0.7877 - val_loss: 2.3768 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.4272 - accuracy: 0.7996 - precision_322: 0.7893 - recall_322: 0.8074 - val_loss: 2.1120 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4500 - accuracy: 0.7908 - precision_322: 0.7884 - recall_322: 0.7897 - val_loss: 1.8968 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4318 - accuracy: 0.7950 - precision_322: 0.8045 - recall_322: 0.7855 - val_loss: 1.7313 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4346 - accuracy: 0.8081 - precision_322: 0.8071 - recall_322: 0.8055 - val_loss: 1.6325 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4313 - accuracy: 0.8050 - precision_322: 0.8060 - recall_322: 0.8076 - val_loss: 1.5869 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4108 - accuracy: 0.8055 - precision_322: 0.8001 - recall_322: 0.8018 - val_loss: 1.5870 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4424 - accuracy: 0.7997 - precision_322: 0.7903 - recall_322: 0.8050 - val_loss: 1.6094 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4418 - accuracy: 0.7908 - precision_322: 0.7891 - recall_322: 0.7839 - val_loss: 1.6316 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4416 - accuracy: 0.7929 - precision_322: 0.7897 - recall_322: 0.7993 - val_loss: 1.6363 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.4318 - accuracy: 0.7992 - precision_322: 0.7867 - recall_322: 0.8083 - val_loss: 1.6235 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4259 - accuracy: 0.8016 - precision_322: 0.7875 - recall_322: 0.8148 - val_loss: 1.5844 - val_accuracy: 0.5142 - val_precision_322: 0.5142 - val_recall_322: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu, AUC=0.835, Accuracy=0.497, f2=0.832, prec=0.497, rec=1.000, total=  26.7s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 3s 151ms/step - loss: 0.7364 - accuracy: 0.6370 - precision_323: 0.6354 - recall_323: 0.6469 - val_loss: 0.6585 - val_accuracy: 0.6283 - val_precision_323: 0.8869 - val_recall_323: 0.3177\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.5688 - accuracy: 0.7450 - precision_323: 0.7396 - recall_323: 0.7613 - val_loss: 14.8499 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4983 - accuracy: 0.7757 - precision_323: 0.7749 - recall_323: 0.7804 - val_loss: 15.2362 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4523 - accuracy: 0.7813 - precision_323: 0.7784 - recall_323: 0.7931 - val_loss: 10.0367 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4469 - accuracy: 0.7851 - precision_323: 0.7788 - recall_323: 0.7872 - val_loss: 7.4401 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4314 - accuracy: 0.8094 - precision_323: 0.8083 - recall_323: 0.8152 - val_loss: 5.8765 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4425 - accuracy: 0.7900 - precision_323: 0.7879 - recall_323: 0.7977 - val_loss: 4.8148 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.4101 - accuracy: 0.8141 - precision_323: 0.8083 - recall_323: 0.8230 - val_loss: 4.0513 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4400 - accuracy: 0.7899 - precision_323: 0.7905 - recall_323: 0.7948 - val_loss: 3.4823 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4477 - accuracy: 0.7893 - precision_323: 0.7765 - recall_323: 0.8004 - val_loss: 3.0403 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4265 - accuracy: 0.8017 - precision_323: 0.7903 - recall_323: 0.8159 - val_loss: 2.6905 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4234 - accuracy: 0.8033 - precision_323: 0.7855 - recall_323: 0.8216 - val_loss: 2.4139 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4388 - accuracy: 0.7925 - precision_323: 0.7622 - recall_323: 0.8221 - val_loss: 2.1861 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4270 - accuracy: 0.8008 - precision_323: 0.7956 - recall_323: 0.8053 - val_loss: 2.0077 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4321 - accuracy: 0.8056 - precision_323: 0.8146 - recall_323: 0.8077 - val_loss: 1.8615 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4340 - accuracy: 0.7971 - precision_323: 0.7934 - recall_323: 0.8023 - val_loss: 1.7422 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4319 - accuracy: 0.7975 - precision_323: 0.7945 - recall_323: 0.7991 - val_loss: 1.6436 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4197 - accuracy: 0.8042 - precision_323: 0.7952 - recall_323: 0.8192 - val_loss: 1.5638 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4169 - accuracy: 0.8026 - precision_323: 0.7915 - recall_323: 0.8162 - val_loss: 1.4952 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4201 - accuracy: 0.7945 - precision_323: 0.8008 - recall_323: 0.7944 - val_loss: 1.4378 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4237 - accuracy: 0.8094 - precision_323: 0.7936 - recall_323: 0.8272 - val_loss: 1.3817 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4249 - accuracy: 0.7996 - precision_323: 0.7919 - recall_323: 0.8067 - val_loss: 1.3216 - val_accuracy: 0.5142 - val_precision_323: 0.5142 - val_recall_323: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu, AUC=0.829, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  28.1s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 4s 151ms/step - loss: 0.7868 - accuracy: 0.6340 - precision_324: 0.6224 - recall_324: 0.6436 - val_loss: 0.5367 - val_accuracy: 0.7300 - val_precision_324: 0.6767 - val_recall_324: 0.9092\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.6869 - accuracy: 0.7180 - precision_324: 0.7049 - recall_324: 0.7320 - val_loss: 5.9865 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.5867 - accuracy: 0.7410 - precision_324: 0.7468 - recall_324: 0.7329 - val_loss: 6.9608 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.5011 - accuracy: 0.7694 - precision_324: 0.7669 - recall_324: 0.7689 - val_loss: 5.9404 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4792 - accuracy: 0.7633 - precision_324: 0.7594 - recall_324: 0.7678 - val_loss: 5.3582 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.5001 - accuracy: 0.7563 - precision_324: 0.7468 - recall_324: 0.7639 - val_loss: 4.4921 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4734 - accuracy: 0.7827 - precision_324: 0.7726 - recall_324: 0.7915 - val_loss: 3.8472 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4653 - accuracy: 0.7736 - precision_324: 0.7632 - recall_324: 0.7802 - val_loss: 3.2904 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4478 - accuracy: 0.7929 - precision_324: 0.7815 - recall_324: 0.8010 - val_loss: 2.8527 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4554 - accuracy: 0.7857 - precision_324: 0.7884 - recall_324: 0.7777 - val_loss: 2.5146 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.4657 - accuracy: 0.7655 - precision_324: 0.7713 - recall_324: 0.7595 - val_loss: 2.2324 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4583 - accuracy: 0.7698 - precision_324: 0.7724 - recall_324: 0.7721 - val_loss: 2.0001 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4856 - accuracy: 0.7728 - precision_324: 0.7618 - recall_324: 0.7828 - val_loss: 1.8030 - val_accuracy: 0.5142 - val_precision_324: 0.5142 - val_recall_324: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu, AUC=0.859, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  18.0s\n",
      "[CV] lr=0.001, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=200, activation=relu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 76ms/step - loss: 0.6838 - accuracy: 0.6657 - precision_325: 0.6625 - recall_325: 0.6620 - val_loss: 1.7714 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4744 - accuracy: 0.7714 - precision_325: 0.7649 - recall_325: 0.7913 - val_loss: 7.3501 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4487 - accuracy: 0.7841 - precision_325: 0.7724 - recall_325: 0.7882 - val_loss: 10.7024 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4008 - accuracy: 0.8089 - precision_325: 0.7960 - recall_325: 0.8246 - val_loss: 8.6354 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3838 - accuracy: 0.8308 - precision_325: 0.8228 - recall_325: 0.8412 - val_loss: 7.0117 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3754 - accuracy: 0.8314 - precision_325: 0.8271 - recall_325: 0.8350 - val_loss: 5.7976 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3805 - accuracy: 0.8319 - precision_325: 0.8269 - recall_325: 0.8355 - val_loss: 4.9461 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3621 - accuracy: 0.8364 - precision_325: 0.8291 - recall_325: 0.8427 - val_loss: 4.3313 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3765 - accuracy: 0.8250 - precision_325: 0.8138 - recall_325: 0.8367 - val_loss: 3.8231 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3878 - accuracy: 0.8282 - precision_325: 0.8254 - recall_325: 0.8338 - val_loss: 3.4267 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3650 - accuracy: 0.8342 - precision_325: 0.8137 - recall_325: 0.8550 - val_loss: 3.0932 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3694 - accuracy: 0.8331 - precision_325: 0.8367 - recall_325: 0.8404 - val_loss: 2.8041 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3707 - accuracy: 0.8308 - precision_325: 0.8298 - recall_325: 0.8296 - val_loss: 2.5472 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3884 - accuracy: 0.8231 - precision_325: 0.8146 - recall_325: 0.8354 - val_loss: 2.3085 - val_accuracy: 0.5142 - val_precision_325: 0.5142 - val_recall_325: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=200, activation=relu, AUC=0.877, Accuracy=0.497, f2=0.832, prec=0.497, rec=1.000, total=  12.9s\n",
      "[CV] lr=0.001, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=200, activation=relu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 74ms/step - loss: 0.6956 - accuracy: 0.6944 - precision_326: 0.6995 - recall_326: 0.7007 - val_loss: 11.0269 - val_accuracy: 0.5142 - val_precision_326: 0.5142 - val_recall_326: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4637 - accuracy: 0.7893 - precision_326: 0.7835 - recall_326: 0.7928 - val_loss: 18.1529 - val_accuracy: 0.5142 - val_precision_326: 0.5142 - val_recall_326: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4063 - accuracy: 0.8182 - precision_326: 0.8240 - recall_326: 0.8100 - val_loss: 17.4702 - val_accuracy: 0.5142 - val_precision_326: 0.5142 - val_recall_326: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3968 - accuracy: 0.8171 - precision_326: 0.8106 - recall_326: 0.8266 - val_loss: 12.8138 - val_accuracy: 0.5142 - val_precision_326: 0.5142 - val_recall_326: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3626 - accuracy: 0.8422 - precision_326: 0.8379 - recall_326: 0.8364 - val_loss: 10.0238 - val_accuracy: 0.5142 - val_precision_326: 0.5142 - val_recall_326: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3852 - accuracy: 0.8208 - precision_326: 0.8232 - recall_326: 0.8228 - val_loss: 7.3387 - val_accuracy: 0.5142 - val_precision_326: 0.5142 - val_recall_326: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3511 - accuracy: 0.8333 - precision_326: 0.8192 - recall_326: 0.8441 - val_loss: 5.8805 - val_accuracy: 0.5142 - val_precision_326: 0.5142 - val_recall_326: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3719 - accuracy: 0.8240 - precision_326: 0.8146 - recall_326: 0.8284 - val_loss: 5.3921 - val_accuracy: 0.5142 - val_precision_326: 0.5142 - val_recall_326: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3446 - accuracy: 0.8472 - precision_326: 0.8387 - recall_326: 0.8595 - val_loss: 4.3907 - val_accuracy: 0.5142 - val_precision_326: 0.5142 - val_recall_326: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3539 - accuracy: 0.8434 - precision_326: 0.8326 - recall_326: 0.8505 - val_loss: 3.4226 - val_accuracy: 0.5142 - val_precision_326: 0.5142 - val_recall_326: 1.0000\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3333 - accuracy: 0.8510 - precision_326: 0.8536 - recall_326: 0.8499 - val_loss: 1.6606 - val_accuracy: 0.5142 - val_precision_326: 0.5142 - val_recall_326: 1.0000\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3449 - accuracy: 0.8427 - precision_326: 0.8271 - recall_326: 0.8543 - val_loss: 0.4995 - val_accuracy: 0.7608 - val_precision_326: 0.6910 - val_recall_326: 0.9676\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3184 - accuracy: 0.8570 - precision_326: 0.8463 - recall_326: 0.8705 - val_loss: 1.0768 - val_accuracy: 0.5100 - val_precision_326: 0.9677 - val_recall_326: 0.0486\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3145 - accuracy: 0.8698 - precision_326: 0.8625 - recall_326: 0.8791 - val_loss: 1.9280 - val_accuracy: 0.4858 - val_precision_326: 0.0000e+00 - val_recall_326: 0.0000e+00\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3097 - accuracy: 0.8722 - precision_326: 0.8707 - recall_326: 0.8796 - val_loss: 1.7761 - val_accuracy: 0.4858 - val_precision_326: 0.0000e+00 - val_recall_326: 0.0000e+00\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3249 - accuracy: 0.8524 - precision_326: 0.8564 - recall_326: 0.8520 - val_loss: 1.0812 - val_accuracy: 0.5142 - val_precision_326: 0.9722 - val_recall_326: 0.0567\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3251 - accuracy: 0.8591 - precision_326: 0.8553 - recall_326: 0.8640 - val_loss: 0.9575 - val_accuracy: 0.5458 - val_precision_326: 0.9737 - val_recall_326: 0.1199\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3102 - accuracy: 0.8617 - precision_326: 0.8629 - recall_326: 0.8646 - val_loss: 0.8608 - val_accuracy: 0.5758 - val_precision_326: 0.9576 - val_recall_326: 0.1831\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.2998 - accuracy: 0.8682 - precision_326: 0.8631 - recall_326: 0.8738 - val_loss: 0.7762 - val_accuracy: 0.6142 - val_precision_326: 0.9326 - val_recall_326: 0.2690\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3041 - accuracy: 0.8723 - precision_326: 0.8581 - recall_326: 0.8828 - val_loss: 0.7062 - val_accuracy: 0.6542 - val_precision_326: 0.9430 - val_recall_326: 0.3485\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3122 - accuracy: 0.8595 - precision_326: 0.8442 - recall_326: 0.8749 - val_loss: 0.6516 - val_accuracy: 0.6892 - val_precision_326: 0.9420 - val_recall_326: 0.4214\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3052 - accuracy: 0.8600 - precision_326: 0.8742 - recall_326: 0.8501 - val_loss: 0.6081 - val_accuracy: 0.7042 - val_precision_326: 0.9309 - val_recall_326: 0.4587\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.2943 - accuracy: 0.8732 - precision_326: 0.8650 - recall_326: 0.8762 - val_loss: 0.5678 - val_accuracy: 0.7242 - val_precision_326: 0.9181 - val_recall_326: 0.5089\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.2974 - accuracy: 0.8697 - precision_326: 0.8640 - recall_326: 0.8793 - val_loss: 0.5287 - val_accuracy: 0.7458 - val_precision_326: 0.9105 - val_recall_326: 0.5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=200, activation=relu, AUC=0.883, Accuracy=0.748, f2=0.600, prec=0.898, rec=0.554, total=  20.8s\n",
      "[CV] lr=0.001, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=200, activation=relu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 76ms/step - loss: 0.7285 - accuracy: 0.6687 - precision_327: 0.6622 - recall_327: 0.6770 - val_loss: 12.1772 - val_accuracy: 0.5142 - val_precision_327: 0.5142 - val_recall_327: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4936 - accuracy: 0.7700 - precision_327: 0.7635 - recall_327: 0.7783 - val_loss: 17.9760 - val_accuracy: 0.5142 - val_precision_327: 0.5142 - val_recall_327: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4276 - accuracy: 0.8003 - precision_327: 0.7892 - recall_327: 0.8107 - val_loss: 12.3893 - val_accuracy: 0.5142 - val_precision_327: 0.5142 - val_recall_327: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3911 - accuracy: 0.8242 - precision_327: 0.8193 - recall_327: 0.8288 - val_loss: 8.9018 - val_accuracy: 0.5142 - val_precision_327: 0.5142 - val_recall_327: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3776 - accuracy: 0.8289 - precision_327: 0.8168 - recall_327: 0.8320 - val_loss: 6.9002 - val_accuracy: 0.5142 - val_precision_327: 0.5142 - val_recall_327: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3756 - accuracy: 0.8282 - precision_327: 0.8337 - recall_327: 0.8225 - val_loss: 5.7915 - val_accuracy: 0.5142 - val_precision_327: 0.5142 - val_recall_327: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3610 - accuracy: 0.8321 - precision_327: 0.8231 - recall_327: 0.8383 - val_loss: 4.4312 - val_accuracy: 0.5142 - val_precision_327: 0.5142 - val_recall_327: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3505 - accuracy: 0.8442 - precision_327: 0.8419 - recall_327: 0.8468 - val_loss: 2.9708 - val_accuracy: 0.5142 - val_precision_327: 0.5142 - val_recall_327: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3472 - accuracy: 0.8429 - precision_327: 0.8331 - recall_327: 0.8541 - val_loss: 2.6851 - val_accuracy: 0.5142 - val_precision_327: 0.5142 - val_recall_327: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3215 - accuracy: 0.8552 - precision_327: 0.8665 - recall_327: 0.8462 - val_loss: 0.5702 - val_accuracy: 0.6825 - val_precision_327: 0.6190 - val_recall_327: 0.9951\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3390 - accuracy: 0.8381 - precision_327: 0.8345 - recall_327: 0.8417 - val_loss: 0.4367 - val_accuracy: 0.8142 - val_precision_327: 0.8481 - val_recall_327: 0.7780\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3261 - accuracy: 0.8554 - precision_327: 0.8512 - recall_327: 0.8621 - val_loss: 1.2374 - val_accuracy: 0.5000 - val_precision_327: 0.9474 - val_recall_327: 0.0292\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3177 - accuracy: 0.8499 - precision_327: 0.8346 - recall_327: 0.8640 - val_loss: 2.3912 - val_accuracy: 0.4858 - val_precision_327: 0.0000e+00 - val_recall_327: 0.0000e+00\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3250 - accuracy: 0.8623 - precision_327: 0.8535 - recall_327: 0.8689 - val_loss: 2.4642 - val_accuracy: 0.4883 - val_precision_327: 1.0000 - val_recall_327: 0.0049\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3158 - accuracy: 0.8619 - precision_327: 0.8579 - recall_327: 0.8679 - val_loss: 2.5152 - val_accuracy: 0.4875 - val_precision_327: 1.0000 - val_recall_327: 0.0032\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.2977 - accuracy: 0.8739 - precision_327: 0.8687 - recall_327: 0.8817 - val_loss: 2.0090 - val_accuracy: 0.4950 - val_precision_327: 1.0000 - val_recall_327: 0.0178\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3004 - accuracy: 0.8730 - precision_327: 0.8770 - recall_327: 0.8678 - val_loss: 1.6377 - val_accuracy: 0.5042 - val_precision_327: 0.9231 - val_recall_327: 0.0389\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3005 - accuracy: 0.8770 - precision_327: 0.8843 - recall_327: 0.8728 - val_loss: 1.3068 - val_accuracy: 0.5258 - val_precision_327: 0.9286 - val_recall_327: 0.0843\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3041 - accuracy: 0.8638 - precision_327: 0.8699 - recall_327: 0.8560 - val_loss: 1.0406 - val_accuracy: 0.5683 - val_precision_327: 0.9541 - val_recall_327: 0.1686\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3001 - accuracy: 0.8660 - precision_327: 0.8522 - recall_327: 0.8768 - val_loss: 0.8456 - val_accuracy: 0.6133 - val_precision_327: 0.9180 - val_recall_327: 0.2723\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.2908 - accuracy: 0.8836 - precision_327: 0.8818 - recall_327: 0.8847 - val_loss: 0.7070 - val_accuracy: 0.6608 - val_precision_327: 0.9339 - val_recall_327: 0.3663\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3128 - accuracy: 0.8646 - precision_327: 0.8509 - recall_327: 0.8760 - val_loss: 0.6112 - val_accuracy: 0.6908 - val_precision_327: 0.9046 - val_recall_327: 0.4457\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3065 - accuracy: 0.8571 - precision_327: 0.8524 - recall_327: 0.8646 - val_loss: 0.5436 - val_accuracy: 0.7267 - val_precision_327: 0.9003 - val_recall_327: 0.5267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=200, activation=relu, AUC=0.897, Accuracy=0.738, f2=0.578, prec=0.901, rec=0.530, total=  19.9s\n",
      "[CV] lr=0.01, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=50, activation=gelu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 29ms/step - loss: 0.5614 - accuracy: 0.6958 - precision_328: 0.6896 - recall_328: 0.6980 - val_loss: 55.4516 - val_accuracy: 0.5142 - val_precision_328: 0.5142 - val_recall_328: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.4635 - accuracy: 0.7845 - precision_328: 0.7691 - recall_328: 0.8044 - val_loss: 19.8335 - val_accuracy: 0.5142 - val_precision_328: 0.5142 - val_recall_328: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.4331 - accuracy: 0.7979 - precision_328: 0.7780 - recall_328: 0.8098 - val_loss: 11.3014 - val_accuracy: 0.5142 - val_precision_328: 0.5142 - val_recall_328: 1.0000\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.4480 - accuracy: 0.7820 - precision_328: 0.7687 - recall_328: 0.8048 - val_loss: 49.4182 - val_accuracy: 0.4858 - val_precision_328: 0.0000e+00 - val_recall_328: 0.0000e+00\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.4011 - accuracy: 0.8126 - precision_328: 0.8087 - recall_328: 0.8061 - val_loss: 367.7563 - val_accuracy: 0.4858 - val_precision_328: 0.0000e+00 - val_recall_328: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3858 - accuracy: 0.8128 - precision_328: 0.7971 - recall_328: 0.8379 - val_loss: 286.2710 - val_accuracy: 0.4858 - val_precision_328: 0.0000e+00 - val_recall_328: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3800 - accuracy: 0.8194 - precision_328: 0.8130 - recall_328: 0.8196 - val_loss: 27.3657 - val_accuracy: 0.4867 - val_precision_328: 1.0000 - val_recall_328: 0.0016\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3516 - accuracy: 0.8408 - precision_328: 0.8494 - recall_328: 0.8355 - val_loss: 16.2543 - val_accuracy: 0.5950 - val_precision_328: 0.9396 - val_recall_328: 0.2269\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3555 - accuracy: 0.8373 - precision_328: 0.8145 - recall_328: 0.8497 - val_loss: 65.8672 - val_accuracy: 0.4858 - val_precision_328: 0.0000e+00 - val_recall_328: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3439 - accuracy: 0.8415 - precision_328: 0.8378 - recall_328: 0.8454 - val_loss: 14.7941 - val_accuracy: 0.6700 - val_precision_328: 0.8647 - val_recall_328: 0.4246\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3447 - accuracy: 0.8454 - precision_328: 0.8219 - recall_328: 0.8663 - val_loss: 3.5520 - val_accuracy: 0.7033 - val_precision_328: 0.7157 - val_recall_328: 0.7018\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3376 - accuracy: 0.8368 - precision_328: 0.8284 - recall_328: 0.8472 - val_loss: 2.7637 - val_accuracy: 0.6233 - val_precision_328: 0.6914 - val_recall_328: 0.4830\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3475 - accuracy: 0.8439 - precision_328: 0.8400 - recall_328: 0.8472 - val_loss: 2.3457 - val_accuracy: 0.6100 - val_precision_328: 0.6886 - val_recall_328: 0.4408\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3371 - accuracy: 0.8444 - precision_328: 0.8474 - recall_328: 0.8451 - val_loss: 1.9328 - val_accuracy: 0.6158 - val_precision_328: 0.7281 - val_recall_328: 0.4036\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3450 - accuracy: 0.8456 - precision_328: 0.8317 - recall_328: 0.8655 - val_loss: 1.3534 - val_accuracy: 0.5567 - val_precision_328: 0.8761 - val_recall_328: 0.1605\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3505 - accuracy: 0.8328 - precision_328: 0.8191 - recall_328: 0.8516 - val_loss: 1.2863 - val_accuracy: 0.5450 - val_precision_328: 0.9733 - val_recall_328: 0.1183\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3432 - accuracy: 0.8421 - precision_328: 0.8325 - recall_328: 0.8548 - val_loss: 0.5727 - val_accuracy: 0.7433 - val_precision_328: 0.9120 - val_recall_328: 0.5543\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3373 - accuracy: 0.8553 - precision_328: 0.8439 - recall_328: 0.8682 - val_loss: 0.6595 - val_accuracy: 0.7017 - val_precision_328: 0.9302 - val_recall_328: 0.4538\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3350 - accuracy: 0.8473 - precision_328: 0.8376 - recall_328: 0.8581 - val_loss: 0.4261 - val_accuracy: 0.8050 - val_precision_328: 0.8593 - val_recall_328: 0.7423\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3411 - accuracy: 0.8435 - precision_328: 0.8266 - recall_328: 0.8609 - val_loss: 0.5048 - val_accuracy: 0.7683 - val_precision_328: 0.8988 - val_recall_328: 0.6191\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3442 - accuracy: 0.8487 - precision_328: 0.8473 - recall_328: 0.8512 - val_loss: 1.4195 - val_accuracy: 0.5208 - val_precision_328: 0.9565 - val_recall_328: 0.0713\n",
      "Epoch 22/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3278 - accuracy: 0.8454 - precision_328: 0.8405 - recall_328: 0.8522 - val_loss: 0.7071 - val_accuracy: 0.6850 - val_precision_328: 0.9476 - val_recall_328: 0.4100\n",
      "Epoch 23/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3584 - accuracy: 0.8429 - precision_328: 0.8458 - recall_328: 0.8479 - val_loss: 0.5612 - val_accuracy: 0.7425 - val_precision_328: 0.9231 - val_recall_328: 0.5446\n",
      "Epoch 24/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3465 - accuracy: 0.8364 - precision_328: 0.8378 - recall_328: 0.8377 - val_loss: 0.4233 - val_accuracy: 0.7967 - val_precision_328: 0.8753 - val_recall_328: 0.7050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=50, activation=gelu, AUC=0.917, Accuracy=0.816, f2=0.750, prec=0.886, rec=0.722, total=  37.1s\n",
      "[CV] lr=0.01, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=50, activation=gelu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 28ms/step - loss: 0.5498 - accuracy: 0.7268 - precision_329: 0.7212 - recall_329: 0.7289 - val_loss: 135.2341 - val_accuracy: 0.5142 - val_precision_329: 0.5142 - val_recall_329: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 0.4227 - accuracy: 0.7967 - precision_329: 0.7894 - recall_329: 0.8114 - val_loss: 80.6599 - val_accuracy: 0.5142 - val_precision_329: 0.5142 - val_recall_329: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 0.4270 - accuracy: 0.8021 - precision_329: 0.7858 - recall_329: 0.8047 - val_loss: 4.8342 - val_accuracy: 0.4867 - val_precision_329: 1.0000 - val_recall_329: 0.0016\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3904 - accuracy: 0.8179 - precision_329: 0.7934 - recall_329: 0.8416 - val_loss: 14.6937 - val_accuracy: 0.5142 - val_precision_329: 0.5142 - val_recall_329: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3723 - accuracy: 0.8319 - precision_329: 0.8275 - recall_329: 0.8506 - val_loss: 27.1536 - val_accuracy: 0.4858 - val_precision_329: 0.0000e+00 - val_recall_329: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3593 - accuracy: 0.8402 - precision_329: 0.8356 - recall_329: 0.8351 - val_loss: 15.4001 - val_accuracy: 0.4858 - val_precision_329: 0.0000e+00 - val_recall_329: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3275 - accuracy: 0.8626 - precision_329: 0.8594 - recall_329: 0.8739 - val_loss: 23.8300 - val_accuracy: 0.4858 - val_precision_329: 0.0000e+00 - val_recall_329: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3286 - accuracy: 0.8581 - precision_329: 0.8611 - recall_329: 0.8535 - val_loss: 14.4384 - val_accuracy: 0.4858 - val_precision_329: 0.0000e+00 - val_recall_329: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3156 - accuracy: 0.8569 - precision_329: 0.8528 - recall_329: 0.8630 - val_loss: 9.7707 - val_accuracy: 0.4858 - val_precision_329: 0.0000e+00 - val_recall_329: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3124 - accuracy: 0.8614 - precision_329: 0.8417 - recall_329: 0.8774 - val_loss: 3.7356 - val_accuracy: 0.4842 - val_precision_329: 0.0000e+00 - val_recall_329: 0.0000e+00\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3131 - accuracy: 0.8619 - precision_329: 0.8564 - recall_329: 0.8671 - val_loss: 3.3613 - val_accuracy: 0.4325 - val_precision_329: 0.0152 - val_recall_329: 0.0016\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3043 - accuracy: 0.8689 - precision_329: 0.8624 - recall_329: 0.8790 - val_loss: 2.0796 - val_accuracy: 0.4633 - val_precision_329: 0.1538 - val_recall_329: 0.0097\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3035 - accuracy: 0.8635 - precision_329: 0.8476 - recall_329: 0.8798 - val_loss: 1.2781 - val_accuracy: 0.5308 - val_precision_329: 0.9355 - val_recall_329: 0.0940\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 0.3042 - accuracy: 0.8683 - precision_329: 0.8593 - recall_329: 0.8807 - val_loss: 1.5902 - val_accuracy: 0.5017 - val_precision_329: 0.7568 - val_recall_329: 0.0454\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3194 - accuracy: 0.8511 - precision_329: 0.8548 - recall_329: 0.8549 - val_loss: 1.3565 - val_accuracy: 0.5183 - val_precision_329: 0.8095 - val_recall_329: 0.0827\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3122 - accuracy: 0.8645 - precision_329: 0.8676 - recall_329: 0.8601 - val_loss: 0.8193 - val_accuracy: 0.6608 - val_precision_329: 0.9487 - val_recall_329: 0.3598\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3099 - accuracy: 0.8578 - precision_329: 0.8564 - recall_329: 0.8557 - val_loss: 0.5847 - val_accuracy: 0.7300 - val_precision_329: 0.9271 - val_recall_329: 0.5154\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3141 - accuracy: 0.8662 - precision_329: 0.8553 - recall_329: 0.8772 - val_loss: 0.5718 - val_accuracy: 0.7308 - val_precision_329: 0.9224 - val_recall_329: 0.5203\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 0.2946 - accuracy: 0.8717 - precision_329: 0.8661 - recall_329: 0.8785 - val_loss: 0.5117 - val_accuracy: 0.7592 - val_precision_329: 0.9121 - val_recall_329: 0.5883\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3044 - accuracy: 0.8674 - precision_329: 0.8579 - recall_329: 0.8834 - val_loss: 0.5360 - val_accuracy: 0.7508 - val_precision_329: 0.9141 - val_recall_329: 0.5689\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 0.3078 - accuracy: 0.8670 - precision_329: 0.8698 - recall_329: 0.8693 - val_loss: 0.4548 - val_accuracy: 0.7900 - val_precision_329: 0.9083 - val_recall_329: 0.6580\n",
      "Epoch 22/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.2953 - accuracy: 0.8747 - precision_329: 0.8496 - recall_329: 0.8962 - val_loss: 0.4068 - val_accuracy: 0.8175 - val_precision_329: 0.8872 - val_recall_329: 0.7391\n",
      "Epoch 23/500\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 0.3132 - accuracy: 0.8556 - precision_329: 0.8436 - recall_329: 0.8702 - val_loss: 0.3767 - val_accuracy: 0.8233 - val_precision_329: 0.8450 - val_recall_329: 0.8039\n",
      "Epoch 24/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.2962 - accuracy: 0.8665 - precision_329: 0.8619 - recall_329: 0.8748 - val_loss: 0.4109 - val_accuracy: 0.8167 - val_precision_329: 0.8885 - val_recall_329: 0.7358\n",
      "Epoch 25/500\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 0.3144 - accuracy: 0.8600 - precision_329: 0.8389 - recall_329: 0.8817 - val_loss: 0.4030 - val_accuracy: 0.8217 - val_precision_329: 0.8824 - val_recall_329: 0.7536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=50, activation=gelu, AUC=0.900, Accuracy=0.803, f2=0.756, prec=0.847, rec=0.737, total=  38.3s\n",
      "[CV] lr=0.01, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=50, activation=gelu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 29ms/step - loss: 0.5436 - accuracy: 0.7147 - precision_330: 0.7171 - recall_330: 0.7004 - val_loss: 53.5022 - val_accuracy: 0.5142 - val_precision_330: 0.5142 - val_recall_330: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.4448 - accuracy: 0.7870 - precision_330: 0.7706 - recall_330: 0.8057 - val_loss: 7.4151 - val_accuracy: 0.5142 - val_precision_330: 0.5142 - val_recall_330: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.4225 - accuracy: 0.7955 - precision_330: 0.7695 - recall_330: 0.8217 - val_loss: 1.3816 - val_accuracy: 0.5142 - val_precision_330: 0.5142 - val_recall_330: 1.0000\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.4280 - accuracy: 0.7894 - precision_330: 0.7803 - recall_330: 0.8071 - val_loss: 14.0690 - val_accuracy: 0.5142 - val_precision_330: 0.5142 - val_recall_330: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.4013 - accuracy: 0.8153 - precision_330: 0.8173 - recall_330: 0.8133 - val_loss: 5.9344 - val_accuracy: 0.5142 - val_precision_330: 0.5142 - val_recall_330: 1.0000\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 0.3869 - accuracy: 0.8236 - precision_330: 0.8100 - recall_330: 0.8240 - val_loss: 3.8752 - val_accuracy: 0.5142 - val_precision_330: 0.5142 - val_recall_330: 1.0000\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 0.3584 - accuracy: 0.8414 - precision_330: 0.8274 - recall_330: 0.8655 - val_loss: 3.9376 - val_accuracy: 0.5092 - val_precision_330: 1.0000 - val_recall_330: 0.0454\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 0.3651 - accuracy: 0.8359 - precision_330: 0.8367 - recall_330: 0.8359 - val_loss: 5.1943 - val_accuracy: 0.4875 - val_precision_330: 1.0000 - val_recall_330: 0.0032\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3467 - accuracy: 0.8406 - precision_330: 0.8255 - recall_330: 0.8583 - val_loss: 5.1519 - val_accuracy: 0.4908 - val_precision_330: 0.8750 - val_recall_330: 0.0113\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3501 - accuracy: 0.8421 - precision_330: 0.8371 - recall_330: 0.8469 - val_loss: 2.9665 - val_accuracy: 0.4975 - val_precision_330: 0.9375 - val_recall_330: 0.0243\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3492 - accuracy: 0.8422 - precision_330: 0.8414 - recall_330: 0.8468 - val_loss: 0.5054 - val_accuracy: 0.7558 - val_precision_330: 0.8971 - val_recall_330: 0.5932\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3532 - accuracy: 0.8421 - precision_330: 0.8288 - recall_330: 0.8514 - val_loss: 0.4447 - val_accuracy: 0.7825 - val_precision_330: 0.8618 - val_recall_330: 0.6872\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3457 - accuracy: 0.8467 - precision_330: 0.8296 - recall_330: 0.8594 - val_loss: 0.3998 - val_accuracy: 0.8142 - val_precision_330: 0.8635 - val_recall_330: 0.7585\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3431 - accuracy: 0.8456 - precision_330: 0.8385 - recall_330: 0.8553 - val_loss: 0.3856 - val_accuracy: 0.8183 - val_precision_330: 0.8595 - val_recall_330: 0.7731\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3300 - accuracy: 0.8572 - precision_330: 0.8534 - recall_330: 0.8681 - val_loss: 0.3812 - val_accuracy: 0.8333 - val_precision_330: 0.8304 - val_recall_330: 0.8493\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3441 - accuracy: 0.8449 - precision_330: 0.8377 - recall_330: 0.8526 - val_loss: 0.3869 - val_accuracy: 0.8267 - val_precision_330: 0.7968 - val_recall_330: 0.8898\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3519 - accuracy: 0.8469 - precision_330: 0.8305 - recall_330: 0.8582 - val_loss: 0.3848 - val_accuracy: 0.8267 - val_precision_330: 0.8103 - val_recall_330: 0.8655\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3314 - accuracy: 0.8557 - precision_330: 0.8498 - recall_330: 0.8645 - val_loss: 0.3969 - val_accuracy: 0.8250 - val_precision_330: 0.7838 - val_recall_330: 0.9109\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3463 - accuracy: 0.8436 - precision_330: 0.8366 - recall_330: 0.8577 - val_loss: 0.3929 - val_accuracy: 0.8308 - val_precision_330: 0.7907 - val_recall_330: 0.9125\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3512 - accuracy: 0.8482 - precision_330: 0.8209 - recall_330: 0.8641 - val_loss: 0.3846 - val_accuracy: 0.8275 - val_precision_330: 0.7954 - val_recall_330: 0.8947\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3432 - accuracy: 0.8461 - precision_330: 0.8334 - recall_330: 0.8598 - val_loss: 0.3803 - val_accuracy: 0.8300 - val_precision_330: 0.8015 - val_recall_330: 0.8898\n",
      "Epoch 22/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3291 - accuracy: 0.8605 - precision_330: 0.8501 - recall_330: 0.8730 - val_loss: 0.3797 - val_accuracy: 0.8283 - val_precision_330: 0.8009 - val_recall_330: 0.8865\n",
      "Epoch 23/500\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.3297 - accuracy: 0.8504 - precision_330: 0.8524 - recall_330: 0.8460 - val_loss: 0.3810 - val_accuracy: 0.8292 - val_precision_330: 0.7994 - val_recall_330: 0.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=50, activation=gelu, AUC=0.908, Accuracy=0.821, f2=0.864, prec=0.782, rec=0.888, total=  35.5s\n",
      "[CV] lr=0.005, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 3s 151ms/step - loss: 0.6971 - accuracy: 0.6499 - precision_331: 0.6613 - recall_331: 0.6566 - val_loss: 0.5776 - val_accuracy: 0.7542 - val_precision_331: 0.7361 - val_recall_331: 0.8136\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4996 - accuracy: 0.7621 - precision_331: 0.7629 - recall_331: 0.7625 - val_loss: 32.0584 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4664 - accuracy: 0.7813 - precision_331: 0.7939 - recall_331: 0.7714 - val_loss: 18.7793 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4417 - accuracy: 0.7936 - precision_331: 0.7791 - recall_331: 0.8087 - val_loss: 10.6961 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.4378 - accuracy: 0.7957 - precision_331: 0.7921 - recall_331: 0.8018 - val_loss: 6.9539 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4125 - accuracy: 0.8178 - precision_331: 0.8073 - recall_331: 0.8299 - val_loss: 5.7035 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4225 - accuracy: 0.8097 - precision_331: 0.8068 - recall_331: 0.8128 - val_loss: 4.8807 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4250 - accuracy: 0.8004 - precision_331: 0.8010 - recall_331: 0.8068 - val_loss: 4.2917 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4396 - accuracy: 0.7923 - precision_331: 0.7676 - recall_331: 0.8155 - val_loss: 3.8231 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4248 - accuracy: 0.8020 - precision_331: 0.7858 - recall_331: 0.8179 - val_loss: 3.4825 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4220 - accuracy: 0.8094 - precision_331: 0.8152 - recall_331: 0.8066 - val_loss: 3.2033 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4097 - accuracy: 0.8119 - precision_331: 0.8015 - recall_331: 0.8200 - val_loss: 2.9842 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4183 - accuracy: 0.8017 - precision_331: 0.7842 - recall_331: 0.8244 - val_loss: 2.8107 - val_accuracy: 0.5142 - val_precision_331: 0.5142 - val_recall_331: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu, AUC=0.702, Accuracy=0.497, f2=0.832, prec=0.497, rec=1.000, total=  17.7s\n",
      "[CV] lr=0.005, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 4s 189ms/step - loss: 0.7009 - accuracy: 0.6528 - precision_332: 0.6575 - recall_332: 0.6280 - val_loss: 84.3388 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4820 - accuracy: 0.7683 - precision_332: 0.7543 - recall_332: 0.7865 - val_loss: 69.4641 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4315 - accuracy: 0.8006 - precision_332: 0.7818 - recall_332: 0.8145 - val_loss: 56.8772 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4134 - accuracy: 0.8099 - precision_332: 0.7986 - recall_332: 0.8209 - val_loss: 37.2033 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4121 - accuracy: 0.8150 - precision_332: 0.8011 - recall_332: 0.8438 - val_loss: 21.3857 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4018 - accuracy: 0.8191 - precision_332: 0.8111 - recall_332: 0.8256 - val_loss: 12.1241 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3898 - accuracy: 0.8196 - precision_332: 0.7910 - recall_332: 0.8513 - val_loss: 10.7608 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3820 - accuracy: 0.8278 - precision_332: 0.8084 - recall_332: 0.8482 - val_loss: 2.1933 - val_accuracy: 0.4850 - val_precision_332: 0.0000e+00 - val_recall_332: 0.0000e+00\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.3835 - accuracy: 0.8211 - precision_332: 0.7954 - recall_332: 0.8567 - val_loss: 16.6187 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3617 - accuracy: 0.8341 - precision_332: 0.8140 - recall_332: 0.8607 - val_loss: 15.0572 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3646 - accuracy: 0.8242 - precision_332: 0.8094 - recall_332: 0.8450 - val_loss: 11.5450 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3586 - accuracy: 0.8331 - precision_332: 0.8169 - recall_332: 0.8540 - val_loss: 8.0712 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3434 - accuracy: 0.8475 - precision_332: 0.8317 - recall_332: 0.8631 - val_loss: 7.1903 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3453 - accuracy: 0.8344 - precision_332: 0.8077 - recall_332: 0.8622 - val_loss: 6.5665 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3476 - accuracy: 0.8461 - precision_332: 0.8331 - recall_332: 0.8644 - val_loss: 5.8019 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3502 - accuracy: 0.8345 - precision_332: 0.8190 - recall_332: 0.8517 - val_loss: 4.9537 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.3452 - accuracy: 0.8529 - precision_332: 0.8384 - recall_332: 0.8698 - val_loss: 4.4475 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3574 - accuracy: 0.8355 - precision_332: 0.8380 - recall_332: 0.8412 - val_loss: 4.0376 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3471 - accuracy: 0.8404 - precision_332: 0.8288 - recall_332: 0.8546 - val_loss: 3.6547 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3564 - accuracy: 0.8296 - precision_332: 0.8266 - recall_332: 0.8382 - val_loss: 3.2878 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.3487 - accuracy: 0.8361 - precision_332: 0.8284 - recall_332: 0.8530 - val_loss: 2.9504 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3423 - accuracy: 0.8389 - precision_332: 0.8199 - recall_332: 0.8635 - val_loss: 2.6315 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3648 - accuracy: 0.8308 - precision_332: 0.8281 - recall_332: 0.8373 - val_loss: 2.3432 - val_accuracy: 0.5142 - val_precision_332: 0.5142 - val_recall_332: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu, AUC=0.802, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  29.5s\n",
      "[CV] lr=0.005, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 3s 148ms/step - loss: 0.7507 - accuracy: 0.6482 - precision_333: 0.6517 - recall_333: 0.6485 - val_loss: 93.7852 - val_accuracy: 0.5142 - val_precision_333: 0.5142 - val_recall_333: 1.0000\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.5012 - accuracy: 0.7576 - precision_333: 0.7586 - recall_333: 0.7391 - val_loss: 63.0082 - val_accuracy: 0.5142 - val_precision_333: 0.5142 - val_recall_333: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4657 - accuracy: 0.7688 - precision_333: 0.7608 - recall_333: 0.7822 - val_loss: 50.3570 - val_accuracy: 0.5142 - val_precision_333: 0.5142 - val_recall_333: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4328 - accuracy: 0.7996 - precision_333: 0.7869 - recall_333: 0.8103 - val_loss: 28.7366 - val_accuracy: 0.5142 - val_precision_333: 0.5142 - val_recall_333: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4251 - accuracy: 0.8085 - precision_333: 0.8028 - recall_333: 0.8181 - val_loss: 15.5938 - val_accuracy: 0.5142 - val_precision_333: 0.5142 - val_recall_333: 1.0000\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4202 - accuracy: 0.8069 - precision_333: 0.7981 - recall_333: 0.8204 - val_loss: 13.0005 - val_accuracy: 0.5142 - val_precision_333: 0.5142 - val_recall_333: 1.0000\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4053 - accuracy: 0.8083 - precision_333: 0.7949 - recall_333: 0.8232 - val_loss: 9.7156 - val_accuracy: 0.5142 - val_precision_333: 0.5142 - val_recall_333: 1.0000\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4031 - accuracy: 0.8220 - precision_333: 0.8014 - recall_333: 0.8500 - val_loss: 4.0584 - val_accuracy: 0.5142 - val_precision_333: 0.5142 - val_recall_333: 1.0000\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4033 - accuracy: 0.8153 - precision_333: 0.8150 - recall_333: 0.8142 - val_loss: 11.1406 - val_accuracy: 0.5142 - val_precision_333: 0.5142 - val_recall_333: 1.0000\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4037 - accuracy: 0.8124 - precision_333: 0.7952 - recall_333: 0.8314 - val_loss: 2.1474 - val_accuracy: 0.5050 - val_precision_333: 0.9259 - val_recall_333: 0.0405\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.3946 - accuracy: 0.8203 - precision_333: 0.7914 - recall_333: 0.8556 - val_loss: 7.8970 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3856 - accuracy: 0.8301 - precision_333: 0.8164 - recall_333: 0.8470 - val_loss: 19.9411 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3823 - accuracy: 0.8295 - precision_333: 0.8088 - recall_333: 0.8576 - val_loss: 23.0969 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3728 - accuracy: 0.8346 - precision_333: 0.8170 - recall_333: 0.8633 - val_loss: 16.5591 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.3658 - accuracy: 0.8413 - precision_333: 0.8233 - recall_333: 0.8670 - val_loss: 19.7334 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3633 - accuracy: 0.8375 - precision_333: 0.8143 - recall_333: 0.8685 - val_loss: 24.0732 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3638 - accuracy: 0.8345 - precision_333: 0.8227 - recall_333: 0.8543 - val_loss: 20.0717 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3675 - accuracy: 0.8413 - precision_333: 0.8192 - recall_333: 0.8729 - val_loss: 17.0416 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3532 - accuracy: 0.8397 - precision_333: 0.8131 - recall_333: 0.8748 - val_loss: 14.3300 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3381 - accuracy: 0.8510 - precision_333: 0.8375 - recall_333: 0.8734 - val_loss: 12.0980 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3642 - accuracy: 0.8353 - precision_333: 0.8176 - recall_333: 0.8632 - val_loss: 10.1576 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3674 - accuracy: 0.8279 - precision_333: 0.8115 - recall_333: 0.8549 - val_loss: 8.5354 - val_accuracy: 0.4858 - val_precision_333: 0.0000e+00 - val_recall_333: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=300, activation=gelu, AUC=0.879, Accuracy=0.504, f2=0.000, prec=0.000, rec=0.000, total=  27.9s\n",
      "[CV] lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 191ms/step - loss: 0.8520 - accuracy: 0.6093 - precision_334: 0.6165 - recall_334: 0.6027 - val_loss: 925.2260 - val_accuracy: 0.5142 - val_precision_334: 0.5142 - val_recall_334: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.5025 - accuracy: 0.7565 - precision_334: 0.7658 - recall_334: 0.7492 - val_loss: 869.1456 - val_accuracy: 0.5142 - val_precision_334: 0.5142 - val_recall_334: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4806 - accuracy: 0.7656 - precision_334: 0.7693 - recall_334: 0.7604 - val_loss: 499.3118 - val_accuracy: 0.5142 - val_precision_334: 0.5142 - val_recall_334: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.4503 - accuracy: 0.7949 - precision_334: 0.7937 - recall_334: 0.8008 - val_loss: 237.5896 - val_accuracy: 0.5142 - val_precision_334: 0.5142 - val_recall_334: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4385 - accuracy: 0.8000 - precision_334: 0.7900 - recall_334: 0.8135 - val_loss: 89.1980 - val_accuracy: 0.5142 - val_precision_334: 0.5142 - val_recall_334: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.4156 - accuracy: 0.8149 - precision_334: 0.8226 - recall_334: 0.8130 - val_loss: 24.6066 - val_accuracy: 0.5142 - val_precision_334: 0.5142 - val_recall_334: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4102 - accuracy: 0.8047 - precision_334: 0.7973 - recall_334: 0.8062 - val_loss: 16.3429 - val_accuracy: 0.5142 - val_precision_334: 0.5142 - val_recall_334: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.4268 - accuracy: 0.8027 - precision_334: 0.8064 - recall_334: 0.8066 - val_loss: 30.8430 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4084 - accuracy: 0.8070 - precision_334: 0.8010 - recall_334: 0.8142 - val_loss: 45.6770 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4117 - accuracy: 0.8031 - precision_334: 0.8015 - recall_334: 0.8112 - val_loss: 21.6193 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3898 - accuracy: 0.8201 - precision_334: 0.8095 - recall_334: 0.8379 - val_loss: 14.0528 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3885 - accuracy: 0.8285 - precision_334: 0.8161 - recall_334: 0.8384 - val_loss: 15.6247 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3762 - accuracy: 0.8228 - precision_334: 0.8113 - recall_334: 0.8407 - val_loss: 12.4295 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3828 - accuracy: 0.8226 - precision_334: 0.8129 - recall_334: 0.8386 - val_loss: 19.8656 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3810 - accuracy: 0.8165 - precision_334: 0.8159 - recall_334: 0.8131 - val_loss: 21.0949 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3611 - accuracy: 0.8378 - precision_334: 0.8242 - recall_334: 0.8533 - val_loss: 19.0753 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3686 - accuracy: 0.8361 - precision_334: 0.8271 - recall_334: 0.8439 - val_loss: 14.9484 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3746 - accuracy: 0.8228 - precision_334: 0.8113 - recall_334: 0.8340 - val_loss: 10.5377 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3884 - accuracy: 0.8189 - precision_334: 0.8123 - recall_334: 0.8265 - val_loss: 8.0365 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3791 - accuracy: 0.8257 - precision_334: 0.8225 - recall_334: 0.8298 - val_loss: 6.6239 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3702 - accuracy: 0.8248 - precision_334: 0.7970 - recall_334: 0.8524 - val_loss: 5.5553 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3733 - accuracy: 0.8265 - precision_334: 0.8273 - recall_334: 0.8300 - val_loss: 4.6927 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3662 - accuracy: 0.8329 - precision_334: 0.8259 - recall_334: 0.8409 - val_loss: 4.0443 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3615 - accuracy: 0.8262 - precision_334: 0.8100 - recall_334: 0.8445 - val_loss: 3.6319 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3698 - accuracy: 0.8345 - precision_334: 0.8063 - recall_334: 0.8611 - val_loss: 3.4759 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3713 - accuracy: 0.8329 - precision_334: 0.8205 - recall_334: 0.8510 - val_loss: 2.9958 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.3641 - accuracy: 0.8321 - precision_334: 0.8207 - recall_334: 0.8496 - val_loss: 2.4665 - val_accuracy: 0.4858 - val_precision_334: 0.0000e+00 - val_recall_334: 0.0000e+00\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3741 - accuracy: 0.8214 - precision_334: 0.8081 - recall_334: 0.8384 - val_loss: 1.7018 - val_accuracy: 0.4892 - val_precision_334: 1.0000 - val_recall_334: 0.0065\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3784 - accuracy: 0.8224 - precision_334: 0.8077 - recall_334: 0.8406 - val_loss: 1.1909 - val_accuracy: 0.5075 - val_precision_334: 0.9333 - val_recall_334: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=gelu, AUC=0.890, Accuracy=0.530, f2=0.067, prec=1.000, rec=0.054, total=  33.1s\n",
      "[CV] lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 192ms/step - loss: 0.8567 - accuracy: 0.6342 - precision_335: 0.6407 - recall_335: 0.6226 - val_loss: 910.0059 - val_accuracy: 0.5142 - val_precision_335: 0.5142 - val_recall_335: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.4968 - accuracy: 0.7718 - precision_335: 0.7439 - recall_335: 0.8161 - val_loss: 658.2333 - val_accuracy: 0.5142 - val_precision_335: 0.5142 - val_recall_335: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4678 - accuracy: 0.7739 - precision_335: 0.7992 - recall_335: 0.7328 - val_loss: 423.5605 - val_accuracy: 0.5142 - val_precision_335: 0.5142 - val_recall_335: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.4626 - accuracy: 0.7753 - precision_335: 0.7687 - recall_335: 0.7825 - val_loss: 210.9538 - val_accuracy: 0.5142 - val_precision_335: 0.5142 - val_recall_335: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4276 - accuracy: 0.7994 - precision_335: 0.8011 - recall_335: 0.8099 - val_loss: 120.3265 - val_accuracy: 0.5142 - val_precision_335: 0.5142 - val_recall_335: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.4341 - accuracy: 0.7987 - precision_335: 0.7987 - recall_335: 0.7914 - val_loss: 51.3489 - val_accuracy: 0.5142 - val_precision_335: 0.5142 - val_recall_335: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3959 - accuracy: 0.8138 - precision_335: 0.8080 - recall_335: 0.8274 - val_loss: 28.6900 - val_accuracy: 0.5142 - val_precision_335: 0.5142 - val_recall_335: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4051 - accuracy: 0.8167 - precision_335: 0.8010 - recall_335: 0.8474 - val_loss: 14.9930 - val_accuracy: 0.5142 - val_precision_335: 0.5142 - val_recall_335: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3968 - accuracy: 0.8185 - precision_335: 0.8238 - recall_335: 0.8177 - val_loss: 13.0149 - val_accuracy: 0.5142 - val_precision_335: 0.5142 - val_recall_335: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3693 - accuracy: 0.8331 - precision_335: 0.8105 - recall_335: 0.8636 - val_loss: 0.9457 - val_accuracy: 0.5458 - val_precision_335: 0.5359 - val_recall_335: 0.8720\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3697 - accuracy: 0.8319 - precision_335: 0.8165 - recall_335: 0.8587 - val_loss: 5.3463 - val_accuracy: 0.4858 - val_precision_335: 0.0000e+00 - val_recall_335: 0.0000e+00\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3800 - accuracy: 0.8233 - precision_335: 0.8192 - recall_335: 0.8309 - val_loss: 6.8771 - val_accuracy: 0.4858 - val_precision_335: 0.0000e+00 - val_recall_335: 0.0000e+00\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3684 - accuracy: 0.8340 - precision_335: 0.8202 - recall_335: 0.8517 - val_loss: 19.4094 - val_accuracy: 0.4858 - val_precision_335: 0.0000e+00 - val_recall_335: 0.0000e+00\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.3454 - accuracy: 0.8434 - precision_335: 0.8273 - recall_335: 0.8705 - val_loss: 3.3838 - val_accuracy: 0.4858 - val_precision_335: 0.0000e+00 - val_recall_335: 0.0000e+00\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3401 - accuracy: 0.8480 - precision_335: 0.8280 - recall_335: 0.8804 - val_loss: 3.2117 - val_accuracy: 0.4858 - val_precision_335: 0.0000e+00 - val_recall_335: 0.0000e+00\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3576 - accuracy: 0.8375 - precision_335: 0.8194 - recall_335: 0.8612 - val_loss: 4.8846 - val_accuracy: 0.4858 - val_precision_335: 0.0000e+00 - val_recall_335: 0.0000e+00\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3536 - accuracy: 0.8298 - precision_335: 0.8108 - recall_335: 0.8513 - val_loss: 4.4151 - val_accuracy: 0.4858 - val_precision_335: 0.0000e+00 - val_recall_335: 0.0000e+00\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3550 - accuracy: 0.8351 - precision_335: 0.8076 - recall_335: 0.8651 - val_loss: 3.6317 - val_accuracy: 0.4858 - val_precision_335: 0.0000e+00 - val_recall_335: 0.0000e+00\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3333 - accuracy: 0.8498 - precision_335: 0.8424 - recall_335: 0.8639 - val_loss: 3.0116 - val_accuracy: 0.4858 - val_precision_335: 0.0000e+00 - val_recall_335: 0.0000e+00\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3479 - accuracy: 0.8393 - precision_335: 0.8168 - recall_335: 0.8671 - val_loss: 2.4991 - val_accuracy: 0.4858 - val_precision_335: 0.0000e+00 - val_recall_335: 0.0000e+00\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3455 - accuracy: 0.8424 - precision_335: 0.8298 - recall_335: 0.8614 - val_loss: 2.0676 - val_accuracy: 0.4867 - val_precision_335: 1.0000 - val_recall_335: 0.0016\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3456 - accuracy: 0.8468 - precision_335: 0.8246 - recall_335: 0.8795 - val_loss: 1.7122 - val_accuracy: 0.4883 - val_precision_335: 1.0000 - val_recall_335: 0.0049\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3461 - accuracy: 0.8527 - precision_335: 0.8320 - recall_335: 0.8830 - val_loss: 1.4207 - val_accuracy: 0.4917 - val_precision_335: 1.0000 - val_recall_335: 0.0113\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.3342 - accuracy: 0.8501 - precision_335: 0.8338 - recall_335: 0.8754 - val_loss: 1.1837 - val_accuracy: 0.5017 - val_precision_335: 0.9130 - val_recall_335: 0.0340\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3455 - accuracy: 0.8467 - precision_335: 0.8284 - recall_335: 0.8721 - val_loss: 0.9960 - val_accuracy: 0.5275 - val_precision_335: 0.9167 - val_recall_335: 0.0891\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3439 - accuracy: 0.8412 - precision_335: 0.8222 - recall_335: 0.8637 - val_loss: 0.8540 - val_accuracy: 0.5417 - val_precision_335: 0.9136 - val_recall_335: 0.1199\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3487 - accuracy: 0.8437 - precision_335: 0.8165 - recall_335: 0.8797 - val_loss: 0.7468 - val_accuracy: 0.5783 - val_precision_335: 0.8776 - val_recall_335: 0.2091\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.3432 - accuracy: 0.8436 - precision_335: 0.8272 - recall_335: 0.8652 - val_loss: 0.6669 - val_accuracy: 0.6200 - val_precision_335: 0.8966 - val_recall_335: 0.2950\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.3454 - accuracy: 0.8392 - precision_335: 0.8180 - recall_335: 0.8701 - val_loss: 0.6083 - val_accuracy: 0.6467 - val_precision_335: 0.8587 - val_recall_335: 0.3744\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3457 - accuracy: 0.8408 - precision_335: 0.8063 - recall_335: 0.8816 - val_loss: 0.5644 - val_accuracy: 0.6750 - val_precision_335: 0.8328 - val_recall_335: 0.4603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=gelu, AUC=0.831, Accuracy=0.687, f2=0.506, prec=0.834, rec=0.461, total=  33.6s\n",
      "[CV] lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 200ms/step - loss: 1.0067 - accuracy: 0.6002 - precision_336: 0.5943 - recall_336: 0.5823 - val_loss: 775.8750 - val_accuracy: 0.5142 - val_precision_336: 0.5142 - val_recall_336: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.5142 - accuracy: 0.7571 - precision_336: 0.7370 - recall_336: 0.7953 - val_loss: 476.4071 - val_accuracy: 0.5142 - val_precision_336: 0.5142 - val_recall_336: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4911 - accuracy: 0.7593 - precision_336: 0.7711 - recall_336: 0.7450 - val_loss: 334.8008 - val_accuracy: 0.5142 - val_precision_336: 0.5142 - val_recall_336: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4569 - accuracy: 0.7864 - precision_336: 0.8079 - recall_336: 0.7638 - val_loss: 161.7284 - val_accuracy: 0.5142 - val_precision_336: 0.5142 - val_recall_336: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.4574 - accuracy: 0.7806 - precision_336: 0.7812 - recall_336: 0.7841 - val_loss: 89.6065 - val_accuracy: 0.5142 - val_precision_336: 0.5142 - val_recall_336: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4261 - accuracy: 0.8009 - precision_336: 0.7947 - recall_336: 0.8088 - val_loss: 23.8966 - val_accuracy: 0.5142 - val_precision_336: 0.5142 - val_recall_336: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4327 - accuracy: 0.8114 - precision_336: 0.8096 - recall_336: 0.8124 - val_loss: 5.0278 - val_accuracy: 0.5142 - val_precision_336: 0.5142 - val_recall_336: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.4269 - accuracy: 0.8063 - precision_336: 0.7964 - recall_336: 0.8064 - val_loss: 2.2278 - val_accuracy: 0.3692 - val_precision_336: 0.4257 - val_recall_336: 0.6499\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4056 - accuracy: 0.8159 - precision_336: 0.8094 - recall_336: 0.8312 - val_loss: 4.2162 - val_accuracy: 0.4833 - val_precision_336: 0.3333 - val_recall_336: 0.0049\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4019 - accuracy: 0.8169 - precision_336: 0.8092 - recall_336: 0.8250 - val_loss: 5.1129 - val_accuracy: 0.4858 - val_precision_336: 0.5000 - val_recall_336: 0.0016\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3883 - accuracy: 0.8230 - precision_336: 0.8170 - recall_336: 0.8283 - val_loss: 2.0214 - val_accuracy: 0.3442 - val_precision_336: 0.3935 - val_recall_336: 0.5089\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 134ms/step - loss: 0.3968 - accuracy: 0.8242 - precision_336: 0.8250 - recall_336: 0.8250 - val_loss: 2.3244 - val_accuracy: 0.4308 - val_precision_336: 0.4689 - val_recall_336: 0.8071\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3845 - accuracy: 0.8342 - precision_336: 0.8295 - recall_336: 0.8410 - val_loss: 2.6282 - val_accuracy: 0.4742 - val_precision_336: 0.4939 - val_recall_336: 0.9125\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3749 - accuracy: 0.8348 - precision_336: 0.8319 - recall_336: 0.8427 - val_loss: 2.7643 - val_accuracy: 0.4942 - val_precision_336: 0.5043 - val_recall_336: 0.9562\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3855 - accuracy: 0.8299 - precision_336: 0.8215 - recall_336: 0.8408 - val_loss: 2.7533 - val_accuracy: 0.4967 - val_precision_336: 0.5055 - val_recall_336: 0.9611\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3863 - accuracy: 0.8142 - precision_336: 0.8009 - recall_336: 0.8300 - val_loss: 2.9026 - val_accuracy: 0.5100 - val_precision_336: 0.5122 - val_recall_336: 0.9870\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3780 - accuracy: 0.8365 - precision_336: 0.8390 - recall_336: 0.8385 - val_loss: 3.0908 - val_accuracy: 0.5125 - val_precision_336: 0.5134 - val_recall_336: 0.9951\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3819 - accuracy: 0.8257 - precision_336: 0.8066 - recall_336: 0.8429 - val_loss: 3.1623 - val_accuracy: 0.5125 - val_precision_336: 0.5134 - val_recall_336: 0.9968\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3826 - accuracy: 0.8273 - precision_336: 0.8211 - recall_336: 0.8402 - val_loss: 3.2147 - val_accuracy: 0.5133 - val_precision_336: 0.5138 - val_recall_336: 0.9984\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3884 - accuracy: 0.8261 - precision_336: 0.8170 - recall_336: 0.8356 - val_loss: 3.2464 - val_accuracy: 0.5133 - val_precision_336: 0.5138 - val_recall_336: 0.9984\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3826 - accuracy: 0.8278 - precision_336: 0.8164 - recall_336: 0.8429 - val_loss: 3.2624 - val_accuracy: 0.5142 - val_precision_336: 0.5142 - val_recall_336: 1.0000\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3870 - accuracy: 0.8288 - precision_336: 0.8222 - recall_336: 0.8384 - val_loss: 3.2655 - val_accuracy: 0.5142 - val_precision_336: 0.5142 - val_recall_336: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=gelu, AUC=0.260, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  25.7s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=300, activation=elu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 3s 116ms/step - loss: 0.8853 - accuracy: 0.6859 - precision_337: 0.6803 - recall_337: 0.7050 - val_loss: 29.6504 - val_accuracy: 0.5142 - val_precision_337: 0.5142 - val_recall_337: 1.0000\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.4480 - accuracy: 0.7860 - precision_337: 0.8016 - recall_337: 0.7725 - val_loss: 6.5132 - val_accuracy: 0.5142 - val_precision_337: 0.5142 - val_recall_337: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.4203 - accuracy: 0.8142 - precision_337: 0.8127 - recall_337: 0.8070 - val_loss: 17.2559 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3900 - accuracy: 0.8190 - precision_337: 0.8029 - recall_337: 0.8405 - val_loss: 14.8945 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3867 - accuracy: 0.8221 - precision_337: 0.8139 - recall_337: 0.8271 - val_loss: 2.7162 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3685 - accuracy: 0.8289 - precision_337: 0.8108 - recall_337: 0.8521 - val_loss: 7.5132 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3625 - accuracy: 0.8330 - precision_337: 0.8226 - recall_337: 0.8452 - val_loss: 8.7953 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3540 - accuracy: 0.8379 - precision_337: 0.8209 - recall_337: 0.8577 - val_loss: 7.6634 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3482 - accuracy: 0.8438 - precision_337: 0.8401 - recall_337: 0.8511 - val_loss: 5.4849 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3479 - accuracy: 0.8463 - precision_337: 0.8304 - recall_337: 0.8621 - val_loss: 4.6468 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3416 - accuracy: 0.8394 - precision_337: 0.8220 - recall_337: 0.8557 - val_loss: 3.8924 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3369 - accuracy: 0.8477 - precision_337: 0.8379 - recall_337: 0.8592 - val_loss: 3.2322 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3453 - accuracy: 0.8459 - precision_337: 0.8253 - recall_337: 0.8722 - val_loss: 2.6785 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3425 - accuracy: 0.8449 - precision_337: 0.8326 - recall_337: 0.8599 - val_loss: 2.2865 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3466 - accuracy: 0.8519 - precision_337: 0.8408 - recall_337: 0.8651 - val_loss: 1.9273 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3506 - accuracy: 0.8467 - precision_337: 0.8358 - recall_337: 0.8632 - val_loss: 1.6143 - val_accuracy: 0.4858 - val_precision_337: 0.0000e+00 - val_recall_337: 0.0000e+00\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3479 - accuracy: 0.8441 - precision_337: 0.8319 - recall_337: 0.8598 - val_loss: 1.3459 - val_accuracy: 0.4875 - val_precision_337: 1.0000 - val_recall_337: 0.0032\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3475 - accuracy: 0.8418 - precision_337: 0.8309 - recall_337: 0.8534 - val_loss: 1.0548 - val_accuracy: 0.4983 - val_precision_337: 1.0000 - val_recall_337: 0.0243\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3506 - accuracy: 0.8368 - precision_337: 0.8330 - recall_337: 0.8475 - val_loss: 0.8656 - val_accuracy: 0.5275 - val_precision_337: 0.9630 - val_recall_337: 0.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=300, activation=elu, AUC=0.915, Accuracy=0.553, f2=0.123, prec=1.000, rec=0.101, total=  17.5s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=300, activation=elu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 3s 116ms/step - loss: 0.8266 - accuracy: 0.6813 - precision_338: 0.6724 - recall_338: 0.6945 - val_loss: 38.9899 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.4269 - accuracy: 0.8115 - precision_338: 0.8179 - recall_338: 0.8006 - val_loss: 26.1650 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3933 - accuracy: 0.8204 - precision_338: 0.8128 - recall_338: 0.8310 - val_loss: 3.7407 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3601 - accuracy: 0.8386 - precision_338: 0.8297 - recall_338: 0.8547 - val_loss: 9.9630 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3504 - accuracy: 0.8395 - precision_338: 0.8417 - recall_338: 0.8377 - val_loss: 10.7555 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3235 - accuracy: 0.8491 - precision_338: 0.8405 - recall_338: 0.8584 - val_loss: 6.5821 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.3147 - accuracy: 0.8593 - precision_338: 0.8457 - recall_338: 0.8824 - val_loss: 3.8227 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3091 - accuracy: 0.8636 - precision_338: 0.8565 - recall_338: 0.8738 - val_loss: 2.9968 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2912 - accuracy: 0.8744 - precision_338: 0.8713 - recall_338: 0.8831 - val_loss: 2.6193 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3129 - accuracy: 0.8595 - precision_338: 0.8465 - recall_338: 0.8751 - val_loss: 2.3769 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.3094 - accuracy: 0.8581 - precision_338: 0.8526 - recall_338: 0.8704 - val_loss: 1.9254 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.2836 - accuracy: 0.8870 - precision_338: 0.8739 - recall_338: 0.8994 - val_loss: 1.3256 - val_accuracy: 0.5142 - val_precision_338: 0.5142 - val_recall_338: 1.0000\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.2965 - accuracy: 0.8676 - precision_338: 0.8539 - recall_338: 0.8865 - val_loss: 0.6046 - val_accuracy: 0.6550 - val_precision_338: 0.6070 - val_recall_338: 0.9335\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.2868 - accuracy: 0.8779 - precision_338: 0.8590 - recall_338: 0.8988 - val_loss: 0.5541 - val_accuracy: 0.7375 - val_precision_338: 0.7182 - val_recall_338: 0.8055\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2876 - accuracy: 0.8767 - precision_338: 0.8611 - recall_338: 0.8983 - val_loss: 0.5673 - val_accuracy: 0.7017 - val_precision_338: 0.6480 - val_recall_338: 0.9190\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.2922 - accuracy: 0.8738 - precision_338: 0.8611 - recall_338: 0.8905 - val_loss: 0.7909 - val_accuracy: 0.5492 - val_precision_338: 0.5328 - val_recall_338: 1.0000\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.2894 - accuracy: 0.8751 - precision_338: 0.8660 - recall_338: 0.8861 - val_loss: 0.7008 - val_accuracy: 0.5858 - val_precision_338: 0.5540 - val_recall_338: 0.9984\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.2925 - accuracy: 0.8816 - precision_338: 0.8725 - recall_338: 0.8927 - val_loss: 0.6601 - val_accuracy: 0.6058 - val_precision_338: 0.5662 - val_recall_338: 0.9984\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2849 - accuracy: 0.8815 - precision_338: 0.8729 - recall_338: 0.8946 - val_loss: 0.6666 - val_accuracy: 0.6050 - val_precision_338: 0.5657 - val_recall_338: 0.9984\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3096 - accuracy: 0.8653 - precision_338: 0.8500 - recall_338: 0.8850 - val_loss: 0.6468 - val_accuracy: 0.6200 - val_precision_338: 0.5752 - val_recall_338: 0.9984\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2907 - accuracy: 0.8730 - precision_338: 0.8599 - recall_338: 0.8850 - val_loss: 0.6402 - val_accuracy: 0.6292 - val_precision_338: 0.5811 - val_recall_338: 0.9984\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.2799 - accuracy: 0.8811 - precision_338: 0.8618 - recall_338: 0.9044 - val_loss: 0.6322 - val_accuracy: 0.6358 - val_precision_338: 0.5857 - val_recall_338: 0.9968\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2877 - accuracy: 0.8757 - precision_338: 0.8670 - recall_338: 0.8893 - val_loss: 0.6282 - val_accuracy: 0.6408 - val_precision_338: 0.5889 - val_recall_338: 0.9984\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2861 - accuracy: 0.8709 - precision_338: 0.8610 - recall_338: 0.8821 - val_loss: 0.6272 - val_accuracy: 0.6475 - val_precision_338: 0.5934 - val_recall_338: 0.9984\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.2639 - accuracy: 0.8917 - precision_338: 0.8812 - recall_338: 0.9058 - val_loss: 0.6266 - val_accuracy: 0.6508 - val_precision_338: 0.5957 - val_recall_338: 0.9984\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2773 - accuracy: 0.8805 - precision_338: 0.8585 - recall_338: 0.9026 - val_loss: 0.6278 - val_accuracy: 0.6558 - val_precision_338: 0.5992 - val_recall_338: 0.9984\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.2906 - accuracy: 0.8747 - precision_338: 0.8610 - recall_338: 0.8918 - val_loss: 0.6272 - val_accuracy: 0.6617 - val_precision_338: 0.6033 - val_recall_338: 0.9984\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.2796 - accuracy: 0.8773 - precision_338: 0.8663 - recall_338: 0.8957 - val_loss: 0.6271 - val_accuracy: 0.6633 - val_precision_338: 0.6045 - val_recall_338: 0.9984\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.2934 - accuracy: 0.8706 - precision_338: 0.8671 - recall_338: 0.8785 - val_loss: 0.6258 - val_accuracy: 0.6675 - val_precision_338: 0.6075 - val_recall_338: 0.9984\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2854 - accuracy: 0.8758 - precision_338: 0.8649 - recall_338: 0.8883 - val_loss: 0.6193 - val_accuracy: 0.6808 - val_precision_338: 0.6172 - val_recall_338: 0.9984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=300, activation=elu, AUC=0.880, Accuracy=0.677, f2=0.876, prec=0.608, rec=0.985, total=  26.0s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=300, activation=elu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 3s 115ms/step - loss: 0.8741 - accuracy: 0.6528 - precision_339: 0.6448 - recall_339: 0.6741 - val_loss: 41.1928 - val_accuracy: 0.5142 - val_precision_339: 0.5142 - val_recall_339: 1.0000\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.4406 - accuracy: 0.7875 - precision_339: 0.7839 - recall_339: 0.7739 - val_loss: 12.0541 - val_accuracy: 0.5142 - val_precision_339: 0.5142 - val_recall_339: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.4052 - accuracy: 0.8067 - precision_339: 0.7920 - recall_339: 0.8291 - val_loss: 7.8108 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3857 - accuracy: 0.8229 - precision_339: 0.8252 - recall_339: 0.8289 - val_loss: 14.2628 - val_accuracy: 0.5142 - val_precision_339: 0.5142 - val_recall_339: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3525 - accuracy: 0.8470 - precision_339: 0.8286 - recall_339: 0.8675 - val_loss: 6.3576 - val_accuracy: 0.5142 - val_precision_339: 0.5142 - val_recall_339: 1.0000\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3485 - accuracy: 0.8414 - precision_339: 0.8258 - recall_339: 0.8587 - val_loss: 7.7968 - val_accuracy: 0.5142 - val_precision_339: 0.5142 - val_recall_339: 1.0000\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3220 - accuracy: 0.8627 - precision_339: 0.8635 - recall_339: 0.8650 - val_loss: 11.1779 - val_accuracy: 0.5142 - val_precision_339: 0.5142 - val_recall_339: 1.0000\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3145 - accuracy: 0.8612 - precision_339: 0.8612 - recall_339: 0.8661 - val_loss: 8.4456 - val_accuracy: 0.5142 - val_precision_339: 0.5142 - val_recall_339: 1.0000\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.2985 - accuracy: 0.8779 - precision_339: 0.8585 - recall_339: 0.8956 - val_loss: 3.5419 - val_accuracy: 0.5142 - val_precision_339: 0.5142 - val_recall_339: 1.0000\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.3018 - accuracy: 0.8648 - precision_339: 0.8539 - recall_339: 0.8796 - val_loss: 1.6902 - val_accuracy: 0.4883 - val_precision_339: 1.0000 - val_recall_339: 0.0049\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2801 - accuracy: 0.8730 - precision_339: 0.8685 - recall_339: 0.8816 - val_loss: 0.9187 - val_accuracy: 0.5458 - val_precision_339: 0.9500 - val_recall_339: 0.1232\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2717 - accuracy: 0.8832 - precision_339: 0.8777 - recall_339: 0.8886 - val_loss: 0.6533 - val_accuracy: 0.6317 - val_precision_339: 0.9353 - val_recall_339: 0.3047\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2639 - accuracy: 0.8914 - precision_339: 0.8847 - recall_339: 0.8978 - val_loss: 5.6210 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.2486 - accuracy: 0.8941 - precision_339: 0.8845 - recall_339: 0.9053 - val_loss: 9.1766 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.2360 - accuracy: 0.8975 - precision_339: 0.9025 - recall_339: 0.8928 - val_loss: 9.4916 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.2465 - accuracy: 0.8950 - precision_339: 0.8882 - recall_339: 0.8990 - val_loss: 9.2000 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.2379 - accuracy: 0.8988 - precision_339: 0.8879 - recall_339: 0.9097 - val_loss: 8.2445 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2387 - accuracy: 0.9047 - precision_339: 0.9003 - recall_339: 0.9069 - val_loss: 7.6232 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.2415 - accuracy: 0.8933 - precision_339: 0.8912 - recall_339: 0.8951 - val_loss: 6.9100 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2468 - accuracy: 0.8950 - precision_339: 0.8986 - recall_339: 0.8930 - val_loss: 6.2935 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2487 - accuracy: 0.9009 - precision_339: 0.9032 - recall_339: 0.9000 - val_loss: 5.6942 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2475 - accuracy: 0.8925 - precision_339: 0.8721 - recall_339: 0.9095 - val_loss: 5.1494 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.2259 - accuracy: 0.9060 - precision_339: 0.9015 - recall_339: 0.9121 - val_loss: 4.6435 - val_accuracy: 0.4858 - val_precision_339: 0.0000e+00 - val_recall_339: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=300, activation=elu, AUC=0.900, Accuracy=0.504, f2=0.000, prec=0.000, rec=0.000, total=  20.6s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 58ms/step - loss: 0.6456 - accuracy: 0.6984 - precision_340: 0.6940 - recall_340: 0.6920 - val_loss: 159.4507 - val_accuracy: 0.5142 - val_precision_340: 0.5142 - val_recall_340: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4700 - accuracy: 0.7756 - precision_340: 0.7740 - recall_340: 0.7746 - val_loss: 22.8873 - val_accuracy: 0.5142 - val_precision_340: 0.5142 - val_recall_340: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4317 - accuracy: 0.8105 - precision_340: 0.7982 - recall_340: 0.8269 - val_loss: 9.6447 - val_accuracy: 0.5142 - val_precision_340: 0.5142 - val_recall_340: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4412 - accuracy: 0.7983 - precision_340: 0.8009 - recall_340: 0.7995 - val_loss: 7.4741 - val_accuracy: 0.5142 - val_precision_340: 0.5142 - val_recall_340: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4179 - accuracy: 0.8070 - precision_340: 0.7958 - recall_340: 0.8265 - val_loss: 1.8501 - val_accuracy: 0.5133 - val_precision_340: 0.5138 - val_recall_340: 0.9984\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4150 - accuracy: 0.8093 - precision_340: 0.7984 - recall_340: 0.8245 - val_loss: 130.2495 - val_accuracy: 0.4858 - val_precision_340: 0.0000e+00 - val_recall_340: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4020 - accuracy: 0.8120 - precision_340: 0.8007 - recall_340: 0.8224 - val_loss: 62.7520 - val_accuracy: 0.5142 - val_precision_340: 0.5142 - val_recall_340: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3972 - accuracy: 0.8190 - precision_340: 0.7971 - recall_340: 0.8475 - val_loss: 91.2726 - val_accuracy: 0.5142 - val_precision_340: 0.5142 - val_recall_340: 1.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3907 - accuracy: 0.8315 - precision_340: 0.8226 - recall_340: 0.8530 - val_loss: 112.6732 - val_accuracy: 0.5142 - val_precision_340: 0.5142 - val_recall_340: 1.0000\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3821 - accuracy: 0.8237 - precision_340: 0.8175 - recall_340: 0.8287 - val_loss: 120.3825 - val_accuracy: 0.5142 - val_precision_340: 0.5142 - val_recall_340: 1.0000\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3845 - accuracy: 0.8264 - precision_340: 0.8217 - recall_340: 0.8333 - val_loss: 131.0730 - val_accuracy: 0.5142 - val_precision_340: 0.5142 - val_recall_340: 1.0000\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3867 - accuracy: 0.8215 - precision_340: 0.8204 - recall_340: 0.8249 - val_loss: 137.6184 - val_accuracy: 0.5158 - val_precision_340: 0.5150 - val_recall_340: 1.0000\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3884 - accuracy: 0.8273 - precision_340: 0.8150 - recall_340: 0.8453 - val_loss: 123.8015 - val_accuracy: 0.5258 - val_precision_340: 0.5203 - val_recall_340: 0.9984\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3917 - accuracy: 0.8114 - precision_340: 0.7879 - recall_340: 0.8382 - val_loss: 116.0108 - val_accuracy: 0.5292 - val_precision_340: 0.5223 - val_recall_340: 0.9870\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3831 - accuracy: 0.8251 - precision_340: 0.8110 - recall_340: 0.8407 - val_loss: 101.3648 - val_accuracy: 0.5158 - val_precision_340: 0.5157 - val_recall_340: 0.9562\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3897 - accuracy: 0.8133 - precision_340: 0.7988 - recall_340: 0.8372 - val_loss: 80.9862 - val_accuracy: 0.5008 - val_precision_340: 0.5080 - val_recall_340: 0.9254\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3828 - accuracy: 0.8232 - precision_340: 0.8173 - recall_340: 0.8319 - val_loss: 57.7225 - val_accuracy: 0.4967 - val_precision_340: 0.5060 - val_recall_340: 0.8947\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3811 - accuracy: 0.8280 - precision_340: 0.8105 - recall_340: 0.8454 - val_loss: 31.9269 - val_accuracy: 0.5042 - val_precision_340: 0.5126 - val_recall_340: 0.7277\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3788 - accuracy: 0.8230 - precision_340: 0.8055 - recall_340: 0.8476 - val_loss: 25.6799 - val_accuracy: 0.4942 - val_precision_340: 0.5111 - val_recall_340: 0.3744\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3959 - accuracy: 0.8172 - precision_340: 0.8136 - recall_340: 0.8264 - val_loss: 19.7293 - val_accuracy: 0.4692 - val_precision_340: 0.4342 - val_recall_340: 0.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu, AUC=0.678, Accuracy=0.480, f2=0.100, prec=0.392, rec=0.084, total=  22.4s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.6845 - accuracy: 0.6774 - precision_341: 0.6736 - recall_341: 0.6685 - val_loss: 58.9277 - val_accuracy: 0.5142 - val_precision_341: 0.5142 - val_recall_341: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4633 - accuracy: 0.7830 - precision_341: 0.7850 - recall_341: 0.7805 - val_loss: 24.1254 - val_accuracy: 0.5142 - val_precision_341: 0.5142 - val_recall_341: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4259 - accuracy: 0.8019 - precision_341: 0.7938 - recall_341: 0.8065 - val_loss: 18.3912 - val_accuracy: 0.4858 - val_precision_341: 0.0000e+00 - val_recall_341: 0.0000e+00\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4077 - accuracy: 0.8120 - precision_341: 0.8086 - recall_341: 0.8105 - val_loss: 15.5811 - val_accuracy: 0.4858 - val_precision_341: 0.0000e+00 - val_recall_341: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3997 - accuracy: 0.8211 - precision_341: 0.8211 - recall_341: 0.8187 - val_loss: 7.9470 - val_accuracy: 0.5142 - val_precision_341: 0.5142 - val_recall_341: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4047 - accuracy: 0.8202 - precision_341: 0.8030 - recall_341: 0.8340 - val_loss: 4.2977 - val_accuracy: 0.5142 - val_precision_341: 0.5142 - val_recall_341: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3904 - accuracy: 0.8181 - precision_341: 0.7970 - recall_341: 0.8420 - val_loss: 4.8813 - val_accuracy: 0.5142 - val_precision_341: 0.5142 - val_recall_341: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3762 - accuracy: 0.8286 - precision_341: 0.8201 - recall_341: 0.8442 - val_loss: 3.2666 - val_accuracy: 0.4867 - val_precision_341: 1.0000 - val_recall_341: 0.0016\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3937 - accuracy: 0.8124 - precision_341: 0.8029 - recall_341: 0.8263 - val_loss: 7.7172 - val_accuracy: 0.5142 - val_precision_341: 0.5142 - val_recall_341: 1.0000\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3820 - accuracy: 0.8242 - precision_341: 0.8143 - recall_341: 0.8369 - val_loss: 54.9805 - val_accuracy: 0.4858 - val_precision_341: 0.0000e+00 - val_recall_341: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3622 - accuracy: 0.8316 - precision_341: 0.8198 - recall_341: 0.8457 - val_loss: 27.2399 - val_accuracy: 0.3408 - val_precision_341: 0.0693 - val_recall_341: 0.0227\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3579 - accuracy: 0.8305 - precision_341: 0.8145 - recall_341: 0.8539 - val_loss: 7.2622 - val_accuracy: 0.3917 - val_precision_341: 0.0407 - val_recall_341: 0.0081\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3480 - accuracy: 0.8355 - precision_341: 0.8385 - recall_341: 0.8390 - val_loss: 0.4585 - val_accuracy: 0.7633 - val_precision_341: 0.8692 - val_recall_341: 0.6353\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3461 - accuracy: 0.8432 - precision_341: 0.8398 - recall_341: 0.8558 - val_loss: 0.9778 - val_accuracy: 0.5275 - val_precision_341: 0.9310 - val_recall_341: 0.0875\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3418 - accuracy: 0.8489 - precision_341: 0.8452 - recall_341: 0.8583 - val_loss: 0.8000 - val_accuracy: 0.5750 - val_precision_341: 0.9735 - val_recall_341: 0.1783\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3411 - accuracy: 0.8460 - precision_341: 0.8403 - recall_341: 0.8493 - val_loss: 0.6117 - val_accuracy: 0.6925 - val_precision_341: 0.9397 - val_recall_341: 0.4295\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3555 - accuracy: 0.8395 - precision_341: 0.8382 - recall_341: 0.8447 - val_loss: 0.7526 - val_accuracy: 0.6433 - val_precision_341: 0.9522 - val_recall_341: 0.3225\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3530 - accuracy: 0.8388 - precision_341: 0.8324 - recall_341: 0.8443 - val_loss: 0.6375 - val_accuracy: 0.6883 - val_precision_341: 0.9418 - val_recall_341: 0.4198\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3663 - accuracy: 0.8259 - precision_341: 0.8190 - recall_341: 0.8383 - val_loss: 0.5307 - val_accuracy: 0.7317 - val_precision_341: 0.9132 - val_recall_341: 0.5284\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3408 - accuracy: 0.8542 - precision_341: 0.8599 - recall_341: 0.8583 - val_loss: 0.4641 - val_accuracy: 0.7725 - val_precision_341: 0.8981 - val_recall_341: 0.6288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu, AUC=0.893, Accuracy=0.766, f2=0.647, prec=0.887, rec=0.606, total=  22.0s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.7196 - accuracy: 0.6804 - precision_342: 0.6867 - recall_342: 0.6853 - val_loss: 38.9634 - val_accuracy: 0.5142 - val_precision_342: 0.5142 - val_recall_342: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4559 - accuracy: 0.7856 - precision_342: 0.7866 - recall_342: 0.7786 - val_loss: 7.5224 - val_accuracy: 0.5142 - val_precision_342: 0.5142 - val_recall_342: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4487 - accuracy: 0.7914 - precision_342: 0.7896 - recall_342: 0.7949 - val_loss: 4.3102 - val_accuracy: 0.5142 - val_precision_342: 0.5142 - val_recall_342: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4423 - accuracy: 0.8000 - precision_342: 0.7934 - recall_342: 0.8155 - val_loss: 3.4314 - val_accuracy: 0.5142 - val_precision_342: 0.5142 - val_recall_342: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4253 - accuracy: 0.7931 - precision_342: 0.7929 - recall_342: 0.7999 - val_loss: 3.6202 - val_accuracy: 0.5142 - val_precision_342: 0.5142 - val_recall_342: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4121 - accuracy: 0.8109 - precision_342: 0.8035 - recall_342: 0.8159 - val_loss: 0.9574 - val_accuracy: 0.3058 - val_precision_342: 0.3286 - val_recall_342: 0.3355\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4041 - accuracy: 0.8095 - precision_342: 0.7999 - recall_342: 0.8207 - val_loss: 2.3617 - val_accuracy: 0.4867 - val_precision_342: 1.0000 - val_recall_342: 0.0016\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4371 - accuracy: 0.8032 - precision_342: 0.7878 - recall_342: 0.8147 - val_loss: 1.0001 - val_accuracy: 0.5142 - val_precision_342: 0.5142 - val_recall_342: 1.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3955 - accuracy: 0.8128 - precision_342: 0.7977 - recall_342: 0.8206 - val_loss: 0.8774 - val_accuracy: 0.4758 - val_precision_342: 0.4946 - val_recall_342: 0.8930\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3912 - accuracy: 0.8227 - precision_342: 0.8014 - recall_342: 0.8462 - val_loss: 1.5664 - val_accuracy: 0.4883 - val_precision_342: 1.0000 - val_recall_342: 0.0049\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3697 - accuracy: 0.8408 - precision_342: 0.8294 - recall_342: 0.8614 - val_loss: 2.5044 - val_accuracy: 0.4858 - val_precision_342: 0.0000e+00 - val_recall_342: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3735 - accuracy: 0.8343 - precision_342: 0.8170 - recall_342: 0.8508 - val_loss: 4.7814 - val_accuracy: 0.4858 - val_precision_342: 0.0000e+00 - val_recall_342: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3684 - accuracy: 0.8329 - precision_342: 0.8137 - recall_342: 0.8596 - val_loss: 4.4789 - val_accuracy: 0.4858 - val_precision_342: 0.0000e+00 - val_recall_342: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3544 - accuracy: 0.8331 - precision_342: 0.8311 - recall_342: 0.8423 - val_loss: 4.0045 - val_accuracy: 0.4858 - val_precision_342: 0.0000e+00 - val_recall_342: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3705 - accuracy: 0.8228 - precision_342: 0.8218 - recall_342: 0.8278 - val_loss: 3.0923 - val_accuracy: 0.4867 - val_precision_342: 1.0000 - val_recall_342: 0.0016\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3647 - accuracy: 0.8364 - precision_342: 0.8193 - recall_342: 0.8544 - val_loss: 2.1447 - val_accuracy: 0.4975 - val_precision_342: 1.0000 - val_recall_342: 0.0227\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3826 - accuracy: 0.8153 - precision_342: 0.8056 - recall_342: 0.8294 - val_loss: 1.5251 - val_accuracy: 0.5183 - val_precision_342: 0.9756 - val_recall_342: 0.0648\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3572 - accuracy: 0.8390 - precision_342: 0.8294 - recall_342: 0.8450 - val_loss: 1.1164 - val_accuracy: 0.5692 - val_precision_342: 0.9808 - val_recall_342: 0.1653\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3711 - accuracy: 0.8241 - precision_342: 0.8141 - recall_342: 0.8383 - val_loss: 0.8399 - val_accuracy: 0.6392 - val_precision_342: 0.9742 - val_recall_342: 0.3063\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3695 - accuracy: 0.8411 - precision_342: 0.8314 - recall_342: 0.8511 - val_loss: 0.6573 - val_accuracy: 0.6900 - val_precision_342: 0.9329 - val_recall_342: 0.4279\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3833 - accuracy: 0.8205 - precision_342: 0.8003 - recall_342: 0.8447 - val_loss: 0.5332 - val_accuracy: 0.7425 - val_precision_342: 0.9254 - val_recall_342: 0.5429\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3685 - accuracy: 0.8293 - precision_342: 0.8125 - recall_342: 0.8433 - val_loss: 0.4645 - val_accuracy: 0.7592 - val_precision_342: 0.9000 - val_recall_342: 0.5981\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3720 - accuracy: 0.8325 - precision_342: 0.8412 - recall_342: 0.8320 - val_loss: 0.4239 - val_accuracy: 0.7767 - val_precision_342: 0.8737 - val_recall_342: 0.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu, AUC=0.913, Accuracy=0.806, f2=0.726, prec=0.892, rec=0.694, total=  24.6s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 46ms/step - loss: 0.6894 - accuracy: 0.6967 - precision_343: 0.6907 - recall_343: 0.7043 - val_loss: 11.6439 - val_accuracy: 0.5142 - val_precision_343: 0.5142 - val_recall_343: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4490 - accuracy: 0.8005 - precision_343: 0.8064 - recall_343: 0.7855 - val_loss: 5.1050 - val_accuracy: 0.5142 - val_precision_343: 0.5142 - val_recall_343: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4056 - accuracy: 0.8164 - precision_343: 0.8004 - recall_343: 0.8293 - val_loss: 0.6363 - val_accuracy: 0.5992 - val_precision_343: 0.9359 - val_recall_343: 0.2366\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3552 - accuracy: 0.8455 - precision_343: 0.8331 - recall_343: 0.8559 - val_loss: 20.6477 - val_accuracy: 0.4858 - val_precision_343: 0.0000e+00 - val_recall_343: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3432 - accuracy: 0.8368 - precision_343: 0.8401 - recall_343: 0.8354 - val_loss: 0.9898 - val_accuracy: 0.5167 - val_precision_343: 0.5155 - val_recall_343: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3068 - accuracy: 0.8647 - precision_343: 0.8583 - recall_343: 0.8705 - val_loss: 15.2779 - val_accuracy: 0.4858 - val_precision_343: 0.0000e+00 - val_recall_343: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2588 - accuracy: 0.8935 - precision_343: 0.8963 - recall_343: 0.8878 - val_loss: 26.6482 - val_accuracy: 0.4858 - val_precision_343: 0.0000e+00 - val_recall_343: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.2325 - accuracy: 0.9049 - precision_343: 0.9003 - recall_343: 0.9125 - val_loss: 15.2332 - val_accuracy: 0.4858 - val_precision_343: 0.0000e+00 - val_recall_343: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2149 - accuracy: 0.9145 - precision_343: 0.9060 - recall_343: 0.9226 - val_loss: 11.7661 - val_accuracy: 0.4858 - val_precision_343: 0.0000e+00 - val_recall_343: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2131 - accuracy: 0.9167 - precision_343: 0.9076 - recall_343: 0.9245 - val_loss: 10.4444 - val_accuracy: 0.4858 - val_precision_343: 0.0000e+00 - val_recall_343: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2027 - accuracy: 0.9245 - precision_343: 0.9319 - recall_343: 0.9179 - val_loss: 7.2410 - val_accuracy: 0.4858 - val_precision_343: 0.0000e+00 - val_recall_343: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2159 - accuracy: 0.9177 - precision_343: 0.9061 - recall_343: 0.9258 - val_loss: 5.0718 - val_accuracy: 0.4858 - val_precision_343: 0.0000e+00 - val_recall_343: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2046 - accuracy: 0.9262 - precision_343: 0.9302 - recall_343: 0.9222 - val_loss: 3.7870 - val_accuracy: 0.4858 - val_precision_343: 0.0000e+00 - val_recall_343: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2118 - accuracy: 0.9186 - precision_343: 0.9106 - recall_343: 0.9222 - val_loss: 2.8684 - val_accuracy: 0.4867 - val_precision_343: 1.0000 - val_recall_343: 0.0016\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2086 - accuracy: 0.9234 - precision_343: 0.9238 - recall_343: 0.9216 - val_loss: 1.9974 - val_accuracy: 0.5008 - val_precision_343: 1.0000 - val_recall_343: 0.0292\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2199 - accuracy: 0.9130 - precision_343: 0.9095 - recall_343: 0.9150 - val_loss: 1.4100 - val_accuracy: 0.5408 - val_precision_343: 0.9714 - val_recall_343: 0.1102\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2022 - accuracy: 0.9254 - precision_343: 0.9261 - recall_343: 0.9254 - val_loss: 1.0410 - val_accuracy: 0.6042 - val_precision_343: 0.9610 - val_recall_343: 0.2399\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2185 - accuracy: 0.9154 - precision_343: 0.9114 - recall_343: 0.9168 - val_loss: 0.8216 - val_accuracy: 0.6583 - val_precision_343: 0.9295 - val_recall_343: 0.3630\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2123 - accuracy: 0.9195 - precision_343: 0.9111 - recall_343: 0.9233 - val_loss: 0.6427 - val_accuracy: 0.7200 - val_precision_343: 0.9120 - val_recall_343: 0.5041\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2072 - accuracy: 0.9237 - precision_343: 0.9238 - recall_343: 0.9250 - val_loss: 0.5505 - val_accuracy: 0.7533 - val_precision_343: 0.8849 - val_recall_343: 0.5981\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2029 - accuracy: 0.9186 - precision_343: 0.9097 - recall_343: 0.9252 - val_loss: 0.5112 - val_accuracy: 0.7725 - val_precision_343: 0.8739 - val_recall_343: 0.6515\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2030 - accuracy: 0.9243 - precision_343: 0.9211 - recall_343: 0.9276 - val_loss: 0.4732 - val_accuracy: 0.7917 - val_precision_343: 0.8707 - val_recall_343: 0.6985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=100, activation=elu, AUC=0.905, Accuracy=0.780, f2=0.688, prec=0.871, rec=0.654, total=  24.9s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.6694 - accuracy: 0.7031 - precision_344: 0.7064 - recall_344: 0.7085 - val_loss: 12.9074 - val_accuracy: 0.5142 - val_precision_344: 0.5142 - val_recall_344: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4175 - accuracy: 0.8056 - precision_344: 0.7931 - recall_344: 0.8306 - val_loss: 3.1571 - val_accuracy: 0.5142 - val_precision_344: 0.5142 - val_recall_344: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3836 - accuracy: 0.8186 - precision_344: 0.8056 - recall_344: 0.8304 - val_loss: 4.0082 - val_accuracy: 0.4858 - val_precision_344: 0.0000e+00 - val_recall_344: 0.0000e+00\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3285 - accuracy: 0.8481 - precision_344: 0.8275 - recall_344: 0.8681 - val_loss: 7.9826 - val_accuracy: 0.5142 - val_precision_344: 0.5142 - val_recall_344: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3143 - accuracy: 0.8586 - precision_344: 0.8380 - recall_344: 0.8823 - val_loss: 14.6670 - val_accuracy: 0.4858 - val_precision_344: 0.0000e+00 - val_recall_344: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2929 - accuracy: 0.8780 - precision_344: 0.8673 - recall_344: 0.8938 - val_loss: 21.6596 - val_accuracy: 0.4858 - val_precision_344: 0.0000e+00 - val_recall_344: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2511 - accuracy: 0.9009 - precision_344: 0.8983 - recall_344: 0.9072 - val_loss: 26.1869 - val_accuracy: 0.4858 - val_precision_344: 0.0000e+00 - val_recall_344: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2618 - accuracy: 0.8851 - precision_344: 0.8970 - recall_344: 0.8796 - val_loss: 18.7514 - val_accuracy: 0.4858 - val_precision_344: 0.0000e+00 - val_recall_344: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2387 - accuracy: 0.9020 - precision_344: 0.8944 - recall_344: 0.9073 - val_loss: 13.2423 - val_accuracy: 0.4858 - val_precision_344: 0.0000e+00 - val_recall_344: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2471 - accuracy: 0.8885 - precision_344: 0.8821 - recall_344: 0.8923 - val_loss: 6.2088 - val_accuracy: 0.4858 - val_precision_344: 0.0000e+00 - val_recall_344: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2490 - accuracy: 0.9007 - precision_344: 0.8968 - recall_344: 0.9026 - val_loss: 4.3498 - val_accuracy: 0.4858 - val_precision_344: 0.0000e+00 - val_recall_344: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2412 - accuracy: 0.9030 - precision_344: 0.9005 - recall_344: 0.9103 - val_loss: 2.8820 - val_accuracy: 0.4858 - val_precision_344: 0.0000e+00 - val_recall_344: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2421 - accuracy: 0.8926 - precision_344: 0.8911 - recall_344: 0.8975 - val_loss: 1.8041 - val_accuracy: 0.4992 - val_precision_344: 1.0000 - val_recall_344: 0.0259\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2530 - accuracy: 0.8897 - precision_344: 0.8866 - recall_344: 0.8954 - val_loss: 1.1374 - val_accuracy: 0.5700 - val_precision_344: 0.9550 - val_recall_344: 0.1718\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2414 - accuracy: 0.9019 - precision_344: 0.9174 - recall_344: 0.8872 - val_loss: 0.7125 - val_accuracy: 0.6783 - val_precision_344: 0.9358 - val_recall_344: 0.4019\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2489 - accuracy: 0.8977 - precision_344: 0.8969 - recall_344: 0.8959 - val_loss: 0.6114 - val_accuracy: 0.7242 - val_precision_344: 0.9281 - val_recall_344: 0.5024\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2327 - accuracy: 0.9052 - precision_344: 0.9016 - recall_344: 0.9081 - val_loss: 0.5242 - val_accuracy: 0.7625 - val_precision_344: 0.9150 - val_recall_344: 0.5932\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2123 - accuracy: 0.9154 - precision_344: 0.9039 - recall_344: 0.9258 - val_loss: 0.4521 - val_accuracy: 0.7933 - val_precision_344: 0.8968 - val_recall_344: 0.6759\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2345 - accuracy: 0.9068 - precision_344: 0.9047 - recall_344: 0.9056 - val_loss: 0.4036 - val_accuracy: 0.8217 - val_precision_344: 0.8592 - val_recall_344: 0.7812\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2267 - accuracy: 0.9035 - precision_344: 0.9058 - recall_344: 0.8995 - val_loss: 0.3948 - val_accuracy: 0.8250 - val_precision_344: 0.8479 - val_recall_344: 0.8039\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2434 - accuracy: 0.8997 - precision_344: 0.8951 - recall_344: 0.9015 - val_loss: 0.3936 - val_accuracy: 0.8267 - val_precision_344: 0.8403 - val_recall_344: 0.8185\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2436 - accuracy: 0.9043 - precision_344: 0.8929 - recall_344: 0.9121 - val_loss: 0.3924 - val_accuracy: 0.8317 - val_precision_344: 0.8257 - val_recall_344: 0.8525\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2375 - accuracy: 0.9019 - precision_344: 0.8973 - recall_344: 0.9064 - val_loss: 0.3940 - val_accuracy: 0.8267 - val_precision_344: 0.8151 - val_recall_344: 0.8574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=100, activation=elu, AUC=0.884, Accuracy=0.794, f2=0.810, prec=0.778, rec=0.819, total=  25.8s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 46ms/step - loss: 0.7930 - accuracy: 0.6693 - precision_345: 0.6748 - recall_345: 0.6643 - val_loss: 18.6851 - val_accuracy: 0.5142 - val_precision_345: 0.5142 - val_recall_345: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4617 - accuracy: 0.7775 - precision_345: 0.7697 - recall_345: 0.7850 - val_loss: 4.5075 - val_accuracy: 0.5142 - val_precision_345: 0.5142 - val_recall_345: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4158 - accuracy: 0.8106 - precision_345: 0.8051 - recall_345: 0.8154 - val_loss: 3.8143 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3820 - accuracy: 0.8159 - precision_345: 0.7919 - recall_345: 0.8507 - val_loss: 11.2304 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3492 - accuracy: 0.8448 - precision_345: 0.8424 - recall_345: 0.8467 - val_loss: 32.8433 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3232 - accuracy: 0.8556 - precision_345: 0.8396 - recall_345: 0.8730 - val_loss: 28.0115 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3031 - accuracy: 0.8684 - precision_345: 0.8667 - recall_345: 0.8668 - val_loss: 16.3911 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2736 - accuracy: 0.8845 - precision_345: 0.8680 - recall_345: 0.8997 - val_loss: 19.7933 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2675 - accuracy: 0.8854 - precision_345: 0.8885 - recall_345: 0.8785 - val_loss: 18.0445 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.2573 - accuracy: 0.8917 - precision_345: 0.9024 - recall_345: 0.8821 - val_loss: 15.3407 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2384 - accuracy: 0.8986 - precision_345: 0.8984 - recall_345: 0.9006 - val_loss: 11.6485 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2605 - accuracy: 0.8915 - precision_345: 0.8900 - recall_345: 0.8913 - val_loss: 8.1110 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2610 - accuracy: 0.8872 - precision_345: 0.8878 - recall_345: 0.8840 - val_loss: 5.6081 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.2536 - accuracy: 0.8930 - precision_345: 0.8817 - recall_345: 0.9034 - val_loss: 4.0600 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2516 - accuracy: 0.8905 - precision_345: 0.8900 - recall_345: 0.8860 - val_loss: 3.2066 - val_accuracy: 0.4858 - val_precision_345: 0.0000e+00 - val_recall_345: 0.0000e+00\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2388 - accuracy: 0.8985 - precision_345: 0.9068 - recall_345: 0.8913 - val_loss: 2.4140 - val_accuracy: 0.4875 - val_precision_345: 1.0000 - val_recall_345: 0.0032\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2556 - accuracy: 0.8926 - precision_345: 0.8937 - recall_345: 0.8851 - val_loss: 1.8453 - val_accuracy: 0.5000 - val_precision_345: 1.0000 - val_recall_345: 0.0276\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2298 - accuracy: 0.9057 - precision_345: 0.9044 - recall_345: 0.9074 - val_loss: 1.4474 - val_accuracy: 0.5275 - val_precision_345: 0.9808 - val_recall_345: 0.0827\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.2546 - accuracy: 0.8862 - precision_345: 0.8644 - recall_345: 0.9070 - val_loss: 1.0275 - val_accuracy: 0.6025 - val_precision_345: 0.9667 - val_recall_345: 0.2350\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2405 - accuracy: 0.9020 - precision_345: 0.9107 - recall_345: 0.8934 - val_loss: 0.7486 - val_accuracy: 0.6733 - val_precision_345: 0.9310 - val_recall_345: 0.3938\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2419 - accuracy: 0.9032 - precision_345: 0.8998 - recall_345: 0.9055 - val_loss: 0.6508 - val_accuracy: 0.7092 - val_precision_345: 0.9268 - val_recall_345: 0.4716\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2424 - accuracy: 0.9005 - precision_345: 0.8962 - recall_345: 0.8999 - val_loss: 0.6211 - val_accuracy: 0.7192 - val_precision_345: 0.9142 - val_recall_345: 0.5008\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2416 - accuracy: 0.8974 - precision_345: 0.8979 - recall_345: 0.8939 - val_loss: 0.5532 - val_accuracy: 0.7425 - val_precision_345: 0.8929 - val_recall_345: 0.5673\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2428 - accuracy: 0.8971 - precision_345: 0.8952 - recall_345: 0.8990 - val_loss: 0.5190 - val_accuracy: 0.7617 - val_precision_345: 0.8894 - val_recall_345: 0.6126\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2520 - accuracy: 0.8969 - precision_345: 0.8964 - recall_345: 0.8945 - val_loss: 0.4306 - val_accuracy: 0.8025 - val_precision_345: 0.8585 - val_recall_345: 0.7374\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2404 - accuracy: 0.9003 - precision_345: 0.9085 - recall_345: 0.8912 - val_loss: 0.4279 - val_accuracy: 0.8050 - val_precision_345: 0.8593 - val_recall_345: 0.7423\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2489 - accuracy: 0.8914 - precision_345: 0.8953 - recall_345: 0.8847 - val_loss: 0.4586 - val_accuracy: 0.7892 - val_precision_345: 0.8730 - val_recall_345: 0.6904\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2669 - accuracy: 0.8948 - precision_345: 0.8976 - recall_345: 0.8906 - val_loss: 0.4334 - val_accuracy: 0.7992 - val_precision_345: 0.8574 - val_recall_345: 0.7310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=100, activation=elu, AUC=0.894, Accuracy=0.792, f2=0.745, prec=0.835, rec=0.725, total=  31.4s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 26ms/step - loss: 0.7140 - accuracy: 0.7042 - precision_346: 0.7021 - recall_346: 0.7084 - val_loss: 41.9137 - val_accuracy: 0.4858 - val_precision_346: 0.0000e+00 - val_recall_346: 0.0000e+00\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4519 - accuracy: 0.7938 - precision_346: 0.7954 - recall_346: 0.7845 - val_loss: 81.5438 - val_accuracy: 0.4858 - val_precision_346: 0.0000e+00 - val_recall_346: 0.0000e+00\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4326 - accuracy: 0.8066 - precision_346: 0.8031 - recall_346: 0.8180 - val_loss: 257.4890 - val_accuracy: 0.4858 - val_precision_346: 0.0000e+00 - val_recall_346: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4194 - accuracy: 0.8103 - precision_346: 0.7947 - recall_346: 0.8268 - val_loss: 0.6819 - val_accuracy: 0.5858 - val_precision_346: 0.9478 - val_recall_346: 0.2058\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4129 - accuracy: 0.8100 - precision_346: 0.8017 - recall_346: 0.8159 - val_loss: 67.8053 - val_accuracy: 0.4858 - val_precision_346: 0.0000e+00 - val_recall_346: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4129 - accuracy: 0.8128 - precision_346: 0.8021 - recall_346: 0.8224 - val_loss: 42.1041 - val_accuracy: 0.5142 - val_precision_346: 0.5142 - val_recall_346: 1.0000\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3869 - accuracy: 0.8234 - precision_346: 0.8177 - recall_346: 0.8406 - val_loss: 1.5775 - val_accuracy: 0.5492 - val_precision_346: 1.0000 - val_recall_346: 0.1232\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3882 - accuracy: 0.8123 - precision_346: 0.8036 - recall_346: 0.8109 - val_loss: 3.8200 - val_accuracy: 0.6708 - val_precision_346: 0.6101 - val_recall_346: 0.9968\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3865 - accuracy: 0.8269 - precision_346: 0.8060 - recall_346: 0.8536 - val_loss: 0.6042 - val_accuracy: 0.7358 - val_precision_346: 0.9032 - val_recall_346: 0.5446\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3731 - accuracy: 0.8331 - precision_346: 0.8186 - recall_346: 0.8544 - val_loss: 1.4442 - val_accuracy: 0.5892 - val_precision_346: 0.9627 - val_recall_346: 0.2091\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3642 - accuracy: 0.8388 - precision_346: 0.8310 - recall_346: 0.8500 - val_loss: 0.8119 - val_accuracy: 0.6958 - val_precision_346: 0.9286 - val_recall_346: 0.4425\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3741 - accuracy: 0.8292 - precision_346: 0.8247 - recall_346: 0.8418 - val_loss: 0.4799 - val_accuracy: 0.7725 - val_precision_346: 0.8691 - val_recall_346: 0.6564\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3683 - accuracy: 0.8290 - precision_346: 0.8180 - recall_346: 0.8422 - val_loss: 0.4342 - val_accuracy: 0.7942 - val_precision_346: 0.8627 - val_recall_346: 0.7131\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3759 - accuracy: 0.8189 - precision_346: 0.8089 - recall_346: 0.8327 - val_loss: 0.4184 - val_accuracy: 0.8050 - val_precision_346: 0.8593 - val_recall_346: 0.7423\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3849 - accuracy: 0.8260 - precision_346: 0.8231 - recall_346: 0.8378 - val_loss: 0.3854 - val_accuracy: 0.8367 - val_precision_346: 0.8243 - val_recall_346: 0.8671\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.3768 - accuracy: 0.8238 - precision_346: 0.8107 - recall_346: 0.8357 - val_loss: 0.3921 - val_accuracy: 0.8308 - val_precision_346: 0.7991 - val_recall_346: 0.8963\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3615 - accuracy: 0.8309 - precision_346: 0.8273 - recall_346: 0.8410 - val_loss: 0.3908 - val_accuracy: 0.8308 - val_precision_346: 0.7991 - val_recall_346: 0.8963\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3726 - accuracy: 0.8264 - precision_346: 0.8207 - recall_346: 0.8377 - val_loss: 0.3889 - val_accuracy: 0.8358 - val_precision_346: 0.8079 - val_recall_346: 0.8930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=50, activation=elu, AUC=0.917, Accuracy=0.833, f2=0.865, prec=0.802, rec=0.882, total=  24.7s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 26ms/step - loss: 0.6892 - accuracy: 0.7082 - precision_347: 0.7049 - recall_347: 0.7108 - val_loss: 12.4214 - val_accuracy: 0.5142 - val_precision_347: 0.5142 - val_recall_347: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4519 - accuracy: 0.7912 - precision_347: 0.7888 - recall_347: 0.7987 - val_loss: 47.0261 - val_accuracy: 0.4858 - val_precision_347: 0.0000e+00 - val_recall_347: 0.0000e+00\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4150 - accuracy: 0.8040 - precision_347: 0.7932 - recall_347: 0.8064 - val_loss: 26.7156 - val_accuracy: 0.4858 - val_precision_347: 0.0000e+00 - val_recall_347: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4080 - accuracy: 0.8034 - precision_347: 0.7887 - recall_347: 0.8294 - val_loss: 66.6837 - val_accuracy: 0.4858 - val_precision_347: 0.0000e+00 - val_recall_347: 0.0000e+00\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3876 - accuracy: 0.8205 - precision_347: 0.7973 - recall_347: 0.8554 - val_loss: 217.5020 - val_accuracy: 0.4858 - val_precision_347: 0.0000e+00 - val_recall_347: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3723 - accuracy: 0.8197 - precision_347: 0.8231 - recall_347: 0.8182 - val_loss: 32.1972 - val_accuracy: 0.4858 - val_precision_347: 0.0000e+00 - val_recall_347: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3718 - accuracy: 0.8309 - precision_347: 0.8226 - recall_347: 0.8444 - val_loss: 17.3253 - val_accuracy: 0.4858 - val_precision_347: 0.0000e+00 - val_recall_347: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3640 - accuracy: 0.8406 - precision_347: 0.8357 - recall_347: 0.8546 - val_loss: 4.9959 - val_accuracy: 0.4858 - val_precision_347: 0.0000e+00 - val_recall_347: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3698 - accuracy: 0.8355 - precision_347: 0.8102 - recall_347: 0.8683 - val_loss: 2.8305 - val_accuracy: 0.4867 - val_precision_347: 1.0000 - val_recall_347: 0.0016\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3679 - accuracy: 0.8339 - precision_347: 0.8096 - recall_347: 0.8586 - val_loss: 2.4600 - val_accuracy: 0.4875 - val_precision_347: 1.0000 - val_recall_347: 0.0032\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3463 - accuracy: 0.8521 - precision_347: 0.8409 - recall_347: 0.8649 - val_loss: 1.3984 - val_accuracy: 0.5142 - val_precision_347: 0.9722 - val_recall_347: 0.0567\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3357 - accuracy: 0.8524 - precision_347: 0.8332 - recall_347: 0.8814 - val_loss: 0.6311 - val_accuracy: 0.7125 - val_precision_347: 0.9250 - val_recall_347: 0.4797\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3570 - accuracy: 0.8373 - precision_347: 0.8329 - recall_347: 0.8519 - val_loss: 0.6478 - val_accuracy: 0.6917 - val_precision_347: 0.9273 - val_recall_347: 0.4344\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3326 - accuracy: 0.8564 - precision_347: 0.8461 - recall_347: 0.8753 - val_loss: 0.4720 - val_accuracy: 0.7767 - val_precision_347: 0.8939 - val_recall_347: 0.6418\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3468 - accuracy: 0.8434 - precision_347: 0.8254 - recall_347: 0.8606 - val_loss: 0.4376 - val_accuracy: 0.8100 - val_precision_347: 0.7478 - val_recall_347: 0.9514\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3405 - accuracy: 0.8520 - precision_347: 0.8445 - recall_347: 0.8649 - val_loss: 0.3806 - val_accuracy: 0.8333 - val_precision_347: 0.8154 - val_recall_347: 0.8736\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3471 - accuracy: 0.8420 - precision_347: 0.8250 - recall_347: 0.8622 - val_loss: 0.5221 - val_accuracy: 0.7600 - val_precision_347: 0.9042 - val_recall_347: 0.5964\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3613 - accuracy: 0.8334 - precision_347: 0.8284 - recall_347: 0.8469 - val_loss: 0.6652 - val_accuracy: 0.7100 - val_precision_347: 0.9297 - val_recall_347: 0.4716\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3655 - accuracy: 0.8372 - precision_347: 0.8301 - recall_347: 0.8408 - val_loss: 0.4164 - val_accuracy: 0.7992 - val_precision_347: 0.8658 - val_recall_347: 0.7212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=50, activation=elu, AUC=0.892, Accuracy=0.797, f2=0.737, prec=0.855, rec=0.713, total=  25.7s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 26ms/step - loss: 0.7126 - accuracy: 0.7087 - precision_348: 0.7134 - recall_348: 0.6936 - val_loss: 72.6366 - val_accuracy: 0.5142 - val_precision_348: 0.5142 - val_recall_348: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4778 - accuracy: 0.7670 - precision_348: 0.7503 - recall_348: 0.7816 - val_loss: 43.5628 - val_accuracy: 0.5142 - val_precision_348: 0.5142 - val_recall_348: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4464 - accuracy: 0.7898 - precision_348: 0.7794 - recall_348: 0.7963 - val_loss: 10.1413 - val_accuracy: 0.4858 - val_precision_348: 0.0000e+00 - val_recall_348: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4255 - accuracy: 0.7874 - precision_348: 0.7863 - recall_348: 0.7860 - val_loss: 10.4407 - val_accuracy: 0.5142 - val_precision_348: 0.5142 - val_recall_348: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4022 - accuracy: 0.8155 - precision_348: 0.7907 - recall_348: 0.8431 - val_loss: 73.1512 - val_accuracy: 0.4858 - val_precision_348: 0.0000e+00 - val_recall_348: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3722 - accuracy: 0.8263 - precision_348: 0.8085 - recall_348: 0.8645 - val_loss: 44.5464 - val_accuracy: 0.5142 - val_precision_348: 0.5142 - val_recall_348: 1.0000\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3616 - accuracy: 0.8414 - precision_348: 0.8347 - recall_348: 0.8430 - val_loss: 3.5799 - val_accuracy: 0.6983 - val_precision_348: 0.6620 - val_recall_348: 0.8444\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3601 - accuracy: 0.8362 - precision_348: 0.8214 - recall_348: 0.8583 - val_loss: 27.5022 - val_accuracy: 0.4858 - val_precision_348: 0.0000e+00 - val_recall_348: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3446 - accuracy: 0.8388 - precision_348: 0.8367 - recall_348: 0.8440 - val_loss: 156.7740 - val_accuracy: 0.4858 - val_precision_348: 0.0000e+00 - val_recall_348: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.3524 - accuracy: 0.8325 - precision_348: 0.8328 - recall_348: 0.8255 - val_loss: 9.5818 - val_accuracy: 0.6250 - val_precision_348: 0.6299 - val_recall_348: 0.6564\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3234 - accuracy: 0.8488 - precision_348: 0.8449 - recall_348: 0.8487 - val_loss: 48.4481 - val_accuracy: 0.5125 - val_precision_348: 0.5134 - val_recall_348: 0.9951\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3307 - accuracy: 0.8624 - precision_348: 0.8611 - recall_348: 0.8601 - val_loss: 43.2995 - val_accuracy: 0.5092 - val_precision_348: 0.5118 - val_recall_348: 0.9870\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3338 - accuracy: 0.8501 - precision_348: 0.8220 - recall_348: 0.8755 - val_loss: 17.0649 - val_accuracy: 0.4708 - val_precision_348: 0.4895 - val_recall_348: 0.6823\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3232 - accuracy: 0.8558 - precision_348: 0.8564 - recall_348: 0.8560 - val_loss: 2.2387 - val_accuracy: 0.4950 - val_precision_348: 0.5821 - val_recall_348: 0.0632\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3069 - accuracy: 0.8642 - precision_348: 0.8645 - recall_348: 0.8611 - val_loss: 1.1093 - val_accuracy: 0.5525 - val_precision_348: 0.9651 - val_recall_348: 0.1345\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2991 - accuracy: 0.8724 - precision_348: 0.8751 - recall_348: 0.8693 - val_loss: 0.8500 - val_accuracy: 0.6333 - val_precision_348: 0.9585 - val_recall_348: 0.2998\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3256 - accuracy: 0.8585 - precision_348: 0.8680 - recall_348: 0.8534 - val_loss: 0.5863 - val_accuracy: 0.7392 - val_precision_348: 0.9343 - val_recall_348: 0.5300\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3237 - accuracy: 0.8532 - precision_348: 0.8616 - recall_348: 0.8492 - val_loss: 0.5233 - val_accuracy: 0.7583 - val_precision_348: 0.9160 - val_recall_348: 0.5835\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3151 - accuracy: 0.8592 - precision_348: 0.8647 - recall_348: 0.8512 - val_loss: 0.4337 - val_accuracy: 0.7958 - val_precision_348: 0.8843 - val_recall_348: 0.6937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=50, activation=elu, AUC=0.905, Accuracy=0.796, f2=0.721, prec=0.871, rec=0.691, total=  25.6s\n",
      "[CV] lr=0.01, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 30ms/step - loss: 0.6947 - accuracy: 0.7087 - precision_349: 0.6953 - recall_349: 0.7039 - val_loss: 23.7276 - val_accuracy: 0.5142 - val_precision_349: 0.5142 - val_recall_349: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4478 - accuracy: 0.7827 - precision_349: 0.7623 - recall_349: 0.8074 - val_loss: 2.8870 - val_accuracy: 0.4858 - val_precision_349: 0.0000e+00 - val_recall_349: 0.0000e+00\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.4117 - accuracy: 0.8107 - precision_349: 0.7997 - recall_349: 0.8208 - val_loss: 80.3427 - val_accuracy: 0.4858 - val_precision_349: 0.0000e+00 - val_recall_349: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.3917 - accuracy: 0.8226 - precision_349: 0.8021 - recall_349: 0.8425 - val_loss: 75.7444 - val_accuracy: 0.4858 - val_precision_349: 0.0000e+00 - val_recall_349: 0.0000e+00\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3630 - accuracy: 0.8446 - precision_349: 0.8325 - recall_349: 0.8602 - val_loss: 59.5223 - val_accuracy: 0.4858 - val_precision_349: 0.0000e+00 - val_recall_349: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3480 - accuracy: 0.8501 - precision_349: 0.8457 - recall_349: 0.8615 - val_loss: 138.1466 - val_accuracy: 0.4858 - val_precision_349: 0.0000e+00 - val_recall_349: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3368 - accuracy: 0.8510 - precision_349: 0.8466 - recall_349: 0.8616 - val_loss: 134.9017 - val_accuracy: 0.4858 - val_precision_349: 0.0000e+00 - val_recall_349: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3259 - accuracy: 0.8550 - precision_349: 0.8549 - recall_349: 0.8603 - val_loss: 80.3364 - val_accuracy: 0.4858 - val_precision_349: 0.0000e+00 - val_recall_349: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3301 - accuracy: 0.8525 - precision_349: 0.8474 - recall_349: 0.8625 - val_loss: 40.8393 - val_accuracy: 0.4858 - val_precision_349: 0.0000e+00 - val_recall_349: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3199 - accuracy: 0.8668 - precision_349: 0.8478 - recall_349: 0.8865 - val_loss: 12.8464 - val_accuracy: 0.4858 - val_precision_349: 0.0000e+00 - val_recall_349: 0.0000e+00\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3148 - accuracy: 0.8599 - precision_349: 0.8590 - recall_349: 0.8590 - val_loss: 3.8849 - val_accuracy: 0.4858 - val_precision_349: 0.0000e+00 - val_recall_349: 0.0000e+00\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3272 - accuracy: 0.8524 - precision_349: 0.8540 - recall_349: 0.8473 - val_loss: 1.7482 - val_accuracy: 0.5058 - val_precision_349: 1.0000 - val_recall_349: 0.0389\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3224 - accuracy: 0.8510 - precision_349: 0.8629 - recall_349: 0.8426 - val_loss: 0.7092 - val_accuracy: 0.6933 - val_precision_349: 0.9628 - val_recall_349: 0.4198\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3217 - accuracy: 0.8514 - precision_349: 0.8573 - recall_349: 0.8511 - val_loss: 0.3846 - val_accuracy: 0.8125 - val_precision_349: 0.8564 - val_recall_349: 0.7634\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3253 - accuracy: 0.8533 - precision_349: 0.8576 - recall_349: 0.8437 - val_loss: 0.3724 - val_accuracy: 0.8383 - val_precision_349: 0.8180 - val_recall_349: 0.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=elu, AUC=0.922, Accuracy=0.841, f2=0.860, prec=0.821, rec=0.870, total=  19.1s\n",
      "[CV] lr=0.01, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 24ms/step - loss: 0.6195 - accuracy: 0.7485 - precision_350: 0.7385 - recall_350: 0.7574 - val_loss: 6.2316 - val_accuracy: 0.5142 - val_precision_350: 0.5142 - val_recall_350: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4042 - accuracy: 0.8155 - precision_350: 0.7963 - recall_350: 0.8276 - val_loss: 2.5833 - val_accuracy: 0.5142 - val_precision_350: 0.5142 - val_recall_350: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3744 - accuracy: 0.8278 - precision_350: 0.8106 - recall_350: 0.8501 - val_loss: 124.0477 - val_accuracy: 0.4858 - val_precision_350: 0.0000e+00 - val_recall_350: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3791 - accuracy: 0.8164 - precision_350: 0.8191 - recall_350: 0.8201 - val_loss: 2.2293 - val_accuracy: 0.5142 - val_precision_350: 0.5142 - val_recall_350: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3737 - accuracy: 0.8323 - precision_350: 0.8229 - recall_350: 0.8400 - val_loss: 1.3448 - val_accuracy: 0.4883 - val_precision_350: 1.0000 - val_recall_350: 0.0049\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3646 - accuracy: 0.8296 - precision_350: 0.8340 - recall_350: 0.8327 - val_loss: 0.5707 - val_accuracy: 0.7550 - val_precision_350: 0.6850 - val_recall_350: 0.9692\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3584 - accuracy: 0.8421 - precision_350: 0.8259 - recall_350: 0.8586 - val_loss: 13.8665 - val_accuracy: 0.4858 - val_precision_350: 0.0000e+00 - val_recall_350: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3329 - accuracy: 0.8544 - precision_350: 0.8488 - recall_350: 0.8621 - val_loss: 3.8200 - val_accuracy: 0.6750 - val_precision_350: 0.6181 - val_recall_350: 0.9627\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3139 - accuracy: 0.8696 - precision_350: 0.8638 - recall_350: 0.8746 - val_loss: 18.2929 - val_accuracy: 0.4858 - val_precision_350: 0.0000e+00 - val_recall_350: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2750 - accuracy: 0.8842 - precision_350: 0.8693 - recall_350: 0.8992 - val_loss: 33.9150 - val_accuracy: 0.4858 - val_precision_350: 0.0000e+00 - val_recall_350: 0.0000e+00\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2755 - accuracy: 0.8907 - precision_350: 0.8856 - recall_350: 0.8986 - val_loss: 8.6744 - val_accuracy: 0.4858 - val_precision_350: 0.0000e+00 - val_recall_350: 0.0000e+00\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2550 - accuracy: 0.8918 - precision_350: 0.8829 - recall_350: 0.9021 - val_loss: 13.4047 - val_accuracy: 0.4833 - val_precision_350: 0.4211 - val_recall_350: 0.0130\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2691 - accuracy: 0.8942 - precision_350: 0.8749 - recall_350: 0.9137 - val_loss: 3.7311 - val_accuracy: 0.4883 - val_precision_350: 1.0000 - val_recall_350: 0.0049\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2572 - accuracy: 0.8879 - precision_350: 0.8886 - recall_350: 0.8903 - val_loss: 1.6895 - val_accuracy: 0.5542 - val_precision_350: 0.9881 - val_recall_350: 0.1345\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2472 - accuracy: 0.8919 - precision_350: 0.8897 - recall_350: 0.8964 - val_loss: 0.9422 - val_accuracy: 0.6692 - val_precision_350: 0.9661 - val_recall_350: 0.3695\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2575 - accuracy: 0.8908 - precision_350: 0.8790 - recall_350: 0.9029 - val_loss: 0.6443 - val_accuracy: 0.7300 - val_precision_350: 0.9271 - val_recall_350: 0.5154\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2477 - accuracy: 0.9032 - precision_350: 0.8893 - recall_350: 0.9207 - val_loss: 0.4440 - val_accuracy: 0.7992 - val_precision_350: 0.8983 - val_recall_350: 0.6872\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2486 - accuracy: 0.9010 - precision_350: 0.9002 - recall_350: 0.9056 - val_loss: 0.3816 - val_accuracy: 0.8275 - val_precision_350: 0.8584 - val_recall_350: 0.7958\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2632 - accuracy: 0.8917 - precision_350: 0.8970 - recall_350: 0.8936 - val_loss: 0.3717 - val_accuracy: 0.8375 - val_precision_350: 0.8328 - val_recall_350: 0.8558\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2522 - accuracy: 0.8965 - precision_350: 0.8944 - recall_350: 0.8993 - val_loss: 0.3753 - val_accuracy: 0.8367 - val_precision_350: 0.8194 - val_recall_350: 0.8752\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2534 - accuracy: 0.8943 - precision_350: 0.8747 - recall_350: 0.9134 - val_loss: 0.3792 - val_accuracy: 0.8383 - val_precision_350: 0.8124 - val_recall_350: 0.8914\n",
      "Epoch 22/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2685 - accuracy: 0.8909 - precision_350: 0.8851 - recall_350: 0.8963 - val_loss: 0.3813 - val_accuracy: 0.8383 - val_precision_350: 0.8106 - val_recall_350: 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=elu, AUC=0.895, Accuracy=0.804, f2=0.846, prec=0.767, rec=0.869, total=  26.9s\n",
      "[CV] lr=0.01, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 24ms/step - loss: 0.6127 - accuracy: 0.7175 - precision_351: 0.7080 - recall_351: 0.7272 - val_loss: 2.0608 - val_accuracy: 0.5142 - val_precision_351: 0.5142 - val_recall_351: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4454 - accuracy: 0.7922 - precision_351: 0.7814 - recall_351: 0.8090 - val_loss: 9.4694 - val_accuracy: 0.4858 - val_precision_351: 0.0000e+00 - val_recall_351: 0.0000e+00\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4077 - accuracy: 0.8119 - precision_351: 0.8150 - recall_351: 0.8113 - val_loss: 20.0391 - val_accuracy: 0.4858 - val_precision_351: 0.0000e+00 - val_recall_351: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3835 - accuracy: 0.8199 - precision_351: 0.8207 - recall_351: 0.8203 - val_loss: 1.5289 - val_accuracy: 0.5142 - val_precision_351: 0.5142 - val_recall_351: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3633 - accuracy: 0.8380 - precision_351: 0.8314 - recall_351: 0.8431 - val_loss: 8.9566 - val_accuracy: 0.4858 - val_precision_351: 0.0000e+00 - val_recall_351: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3588 - accuracy: 0.8373 - precision_351: 0.8246 - recall_351: 0.8540 - val_loss: 20.8181 - val_accuracy: 0.5717 - val_precision_351: 0.8931 - val_recall_351: 0.1896\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3572 - accuracy: 0.8370 - precision_351: 0.8301 - recall_351: 0.8397 - val_loss: 286.4727 - val_accuracy: 0.4858 - val_precision_351: 0.0000e+00 - val_recall_351: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3409 - accuracy: 0.8469 - precision_351: 0.8282 - recall_351: 0.8576 - val_loss: 170.2676 - val_accuracy: 0.4892 - val_precision_351: 1.0000 - val_recall_351: 0.0065\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3394 - accuracy: 0.8480 - precision_351: 0.8382 - recall_351: 0.8587 - val_loss: 5.3835 - val_accuracy: 0.4508 - val_precision_351: 0.3220 - val_recall_351: 0.0616\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3412 - accuracy: 0.8534 - precision_351: 0.8535 - recall_351: 0.8600 - val_loss: 0.7698 - val_accuracy: 0.6900 - val_precision_351: 0.9422 - val_recall_351: 0.4230\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3191 - accuracy: 0.8582 - precision_351: 0.8536 - recall_351: 0.8653 - val_loss: 0.3913 - val_accuracy: 0.8333 - val_precision_351: 0.8009 - val_recall_351: 0.8995\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3419 - accuracy: 0.8528 - precision_351: 0.8388 - recall_351: 0.8713 - val_loss: 0.4083 - val_accuracy: 0.8250 - val_precision_351: 0.7746 - val_recall_351: 0.9303\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3191 - accuracy: 0.8595 - precision_351: 0.8580 - recall_351: 0.8625 - val_loss: 0.8118 - val_accuracy: 0.6592 - val_precision_351: 0.6014 - val_recall_351: 1.0000\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3237 - accuracy: 0.8423 - precision_351: 0.8393 - recall_351: 0.8464 - val_loss: 0.7198 - val_accuracy: 0.6908 - val_precision_351: 0.6245 - val_recall_351: 1.0000\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3171 - accuracy: 0.8542 - precision_351: 0.8382 - recall_351: 0.8677 - val_loss: 0.5134 - val_accuracy: 0.7742 - val_precision_351: 0.7016 - val_recall_351: 0.9757\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3320 - accuracy: 0.8442 - precision_351: 0.8457 - recall_351: 0.8478 - val_loss: 0.4558 - val_accuracy: 0.7950 - val_precision_351: 0.7265 - val_recall_351: 0.9643\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3101 - accuracy: 0.8720 - precision_351: 0.8704 - recall_351: 0.8780 - val_loss: 0.4333 - val_accuracy: 0.8117 - val_precision_351: 0.7465 - val_recall_351: 0.9595\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3307 - accuracy: 0.8498 - precision_351: 0.8480 - recall_351: 0.8532 - val_loss: 0.4173 - val_accuracy: 0.8225 - val_precision_351: 0.7610 - val_recall_351: 0.9546\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3216 - accuracy: 0.8586 - precision_351: 0.8566 - recall_351: 0.8655 - val_loss: 0.4115 - val_accuracy: 0.8208 - val_precision_351: 0.7617 - val_recall_351: 0.9481\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3243 - accuracy: 0.8557 - precision_351: 0.8588 - recall_351: 0.8578 - val_loss: 0.4077 - val_accuracy: 0.8225 - val_precision_351: 0.7651 - val_recall_351: 0.9449\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3305 - accuracy: 0.8551 - precision_351: 0.8556 - recall_351: 0.8530 - val_loss: 0.4034 - val_accuracy: 0.8250 - val_precision_351: 0.7688 - val_recall_351: 0.9433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=elu, AUC=0.905, Accuracy=0.806, f2=0.881, prec=0.747, rec=0.922, total=  25.6s\n",
      "[CV] lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 47ms/step - loss: 0.7449 - accuracy: 0.6651 - precision_352: 0.6621 - recall_352: 0.6552 - val_loss: 15.7028 - val_accuracy: 0.5142 - val_precision_352: 0.5142 - val_recall_352: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4748 - accuracy: 0.7749 - precision_352: 0.7614 - recall_352: 0.7987 - val_loss: 11.8262 - val_accuracy: 0.5142 - val_precision_352: 0.5142 - val_recall_352: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4718 - accuracy: 0.7731 - precision_352: 0.7707 - recall_352: 0.7648 - val_loss: 2.2659 - val_accuracy: 0.5142 - val_precision_352: 0.5142 - val_recall_352: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4142 - accuracy: 0.8096 - precision_352: 0.8019 - recall_352: 0.8070 - val_loss: 2.2115 - val_accuracy: 0.5142 - val_precision_352: 0.5142 - val_recall_352: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4325 - accuracy: 0.8013 - precision_352: 0.7813 - recall_352: 0.8332 - val_loss: 7.4296 - val_accuracy: 0.4858 - val_precision_352: 0.0000e+00 - val_recall_352: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4293 - accuracy: 0.7851 - precision_352: 0.7567 - recall_352: 0.8111 - val_loss: 3.5550 - val_accuracy: 0.5017 - val_precision_352: 0.5408 - val_recall_352: 0.2042\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3974 - accuracy: 0.8185 - precision_352: 0.7982 - recall_352: 0.8511 - val_loss: 13.1590 - val_accuracy: 0.4750 - val_precision_352: 0.0667 - val_recall_352: 0.0016\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3955 - accuracy: 0.8218 - precision_352: 0.8147 - recall_352: 0.8365 - val_loss: 5.9087 - val_accuracy: 0.4850 - val_precision_352: 0.0000e+00 - val_recall_352: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3853 - accuracy: 0.8162 - precision_352: 0.7901 - recall_352: 0.8497 - val_loss: 6.3500 - val_accuracy: 0.4525 - val_precision_352: 0.4379 - val_recall_352: 0.2285\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3826 - accuracy: 0.8177 - precision_352: 0.8136 - recall_352: 0.8263 - val_loss: 5.7058 - val_accuracy: 0.4825 - val_precision_352: 0.0000e+00 - val_recall_352: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3863 - accuracy: 0.8272 - precision_352: 0.8117 - recall_352: 0.8380 - val_loss: 5.1847 - val_accuracy: 0.4825 - val_precision_352: 0.0000e+00 - val_recall_352: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3859 - accuracy: 0.8356 - precision_352: 0.8193 - recall_352: 0.8518 - val_loss: 4.4710 - val_accuracy: 0.4842 - val_precision_352: 0.0000e+00 - val_recall_352: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3708 - accuracy: 0.8312 - precision_352: 0.8071 - recall_352: 0.8591 - val_loss: 3.2576 - val_accuracy: 0.4858 - val_precision_352: 0.0000e+00 - val_recall_352: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3792 - accuracy: 0.8239 - precision_352: 0.8185 - recall_352: 0.8357 - val_loss: 2.5057 - val_accuracy: 0.4858 - val_precision_352: 0.0000e+00 - val_recall_352: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3747 - accuracy: 0.8249 - precision_352: 0.8147 - recall_352: 0.8407 - val_loss: 1.6861 - val_accuracy: 0.4917 - val_precision_352: 1.0000 - val_recall_352: 0.0113\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3908 - accuracy: 0.8214 - precision_352: 0.8011 - recall_352: 0.8443 - val_loss: 1.1137 - val_accuracy: 0.5550 - val_precision_352: 0.9663 - val_recall_352: 0.1394\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3510 - accuracy: 0.8467 - precision_352: 0.8375 - recall_352: 0.8580 - val_loss: 0.7770 - val_accuracy: 0.6408 - val_precision_352: 0.9429 - val_recall_352: 0.3209\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3614 - accuracy: 0.8311 - precision_352: 0.8185 - recall_352: 0.8467 - val_loss: 0.5783 - val_accuracy: 0.7308 - val_precision_352: 0.9324 - val_recall_352: 0.5138\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3909 - accuracy: 0.8149 - precision_352: 0.7948 - recall_352: 0.8354 - val_loss: 0.4687 - val_accuracy: 0.7725 - val_precision_352: 0.8909 - val_recall_352: 0.6353\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3871 - accuracy: 0.8221 - precision_352: 0.8141 - recall_352: 0.8326 - val_loss: 0.4136 - val_accuracy: 0.7917 - val_precision_352: 0.8619 - val_recall_352: 0.7083\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3938 - accuracy: 0.8156 - precision_352: 0.8040 - recall_352: 0.8369 - val_loss: 0.3903 - val_accuracy: 0.8183 - val_precision_352: 0.8446 - val_recall_352: 0.7925\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3859 - accuracy: 0.8173 - precision_352: 0.7884 - recall_352: 0.8499 - val_loss: 0.3887 - val_accuracy: 0.8333 - val_precision_352: 0.8283 - val_recall_352: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu, AUC=0.916, Accuracy=0.838, f2=0.846, prec=0.827, rec=0.852, total=  24.6s\n",
      "[CV] lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.7111 - accuracy: 0.6983 - precision_353: 0.6963 - recall_353: 0.7071 - val_loss: 51.2821 - val_accuracy: 0.5142 - val_precision_353: 0.5142 - val_recall_353: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4474 - accuracy: 0.7893 - precision_353: 0.7863 - recall_353: 0.7787 - val_loss: 9.5340 - val_accuracy: 0.5142 - val_precision_353: 0.5142 - val_recall_353: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4214 - accuracy: 0.8074 - precision_353: 0.8027 - recall_353: 0.8086 - val_loss: 3.0033 - val_accuracy: 0.5142 - val_precision_353: 0.5142 - val_recall_353: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3783 - accuracy: 0.8335 - precision_353: 0.8191 - recall_353: 0.8494 - val_loss: 2.7590 - val_accuracy: 0.5142 - val_precision_353: 0.5142 - val_recall_353: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4040 - accuracy: 0.8183 - precision_353: 0.8045 - recall_353: 0.8307 - val_loss: 2.6924 - val_accuracy: 0.4858 - val_precision_353: 0.0000e+00 - val_recall_353: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3919 - accuracy: 0.8163 - precision_353: 0.7972 - recall_353: 0.8355 - val_loss: 0.9679 - val_accuracy: 0.6267 - val_precision_353: 0.9378 - val_recall_353: 0.2934\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3763 - accuracy: 0.8356 - precision_353: 0.8375 - recall_353: 0.8408 - val_loss: 2.4113 - val_accuracy: 0.5142 - val_precision_353: 0.5142 - val_recall_353: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3850 - accuracy: 0.8188 - precision_353: 0.8165 - recall_353: 0.8199 - val_loss: 2.3116 - val_accuracy: 0.5142 - val_precision_353: 0.5142 - val_recall_353: 1.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3921 - accuracy: 0.8177 - precision_353: 0.7898 - recall_353: 0.8509 - val_loss: 2.1650 - val_accuracy: 0.5158 - val_precision_353: 0.5150 - val_recall_353: 1.0000\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3692 - accuracy: 0.8303 - precision_353: 0.8157 - recall_353: 0.8399 - val_loss: 7.9323 - val_accuracy: 0.4858 - val_precision_353: 0.0000e+00 - val_recall_353: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3530 - accuracy: 0.8434 - precision_353: 0.8332 - recall_353: 0.8663 - val_loss: 0.4081 - val_accuracy: 0.8250 - val_precision_353: 0.8024 - val_recall_353: 0.8752\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3432 - accuracy: 0.8374 - precision_353: 0.8367 - recall_353: 0.8433 - val_loss: 0.3831 - val_accuracy: 0.8317 - val_precision_353: 0.8309 - val_recall_353: 0.8444\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3583 - accuracy: 0.8401 - precision_353: 0.8439 - recall_353: 0.8427 - val_loss: 0.4065 - val_accuracy: 0.8000 - val_precision_353: 0.8689 - val_recall_353: 0.7196\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3396 - accuracy: 0.8434 - precision_353: 0.8275 - recall_353: 0.8584 - val_loss: 0.7199 - val_accuracy: 0.7300 - val_precision_353: 0.9322 - val_recall_353: 0.5122\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3403 - accuracy: 0.8449 - precision_353: 0.8202 - recall_353: 0.8698 - val_loss: 0.4093 - val_accuracy: 0.8150 - val_precision_353: 0.8365 - val_recall_353: 0.7958\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3383 - accuracy: 0.8490 - precision_353: 0.8483 - recall_353: 0.8530 - val_loss: 0.4236 - val_accuracy: 0.8200 - val_precision_353: 0.7670 - val_recall_353: 0.9335\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3522 - accuracy: 0.8330 - precision_353: 0.8212 - recall_353: 0.8472 - val_loss: 0.4707 - val_accuracy: 0.7942 - val_precision_353: 0.7267 - val_recall_353: 0.9611\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3404 - accuracy: 0.8428 - precision_353: 0.8220 - recall_353: 0.8693 - val_loss: 0.4813 - val_accuracy: 0.7900 - val_precision_353: 0.7191 - val_recall_353: 0.9708\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3401 - accuracy: 0.8400 - precision_353: 0.8385 - recall_353: 0.8446 - val_loss: 0.4845 - val_accuracy: 0.7842 - val_precision_353: 0.7131 - val_recall_353: 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu, AUC=0.899, Accuracy=0.771, f2=0.888, prec=0.696, rec=0.953, total=  21.7s\n",
      "[CV] lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.7726 - accuracy: 0.6847 - precision_354: 0.6756 - recall_354: 0.6876 - val_loss: 26.3220 - val_accuracy: 0.5142 - val_precision_354: 0.5142 - val_recall_354: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4751 - accuracy: 0.7758 - precision_354: 0.7648 - recall_354: 0.7846 - val_loss: 11.1987 - val_accuracy: 0.5142 - val_precision_354: 0.5142 - val_recall_354: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4374 - accuracy: 0.8013 - precision_354: 0.7901 - recall_354: 0.8112 - val_loss: 4.7187 - val_accuracy: 0.5142 - val_precision_354: 0.5142 - val_recall_354: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4248 - accuracy: 0.7971 - precision_354: 0.7932 - recall_354: 0.8053 - val_loss: 3.2106 - val_accuracy: 0.5142 - val_precision_354: 0.5142 - val_recall_354: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4171 - accuracy: 0.7992 - precision_354: 0.8011 - recall_354: 0.7919 - val_loss: 2.6266 - val_accuracy: 0.4942 - val_precision_354: 1.0000 - val_recall_354: 0.0162\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4010 - accuracy: 0.8123 - precision_354: 0.8100 - recall_354: 0.8191 - val_loss: 15.7494 - val_accuracy: 0.4858 - val_precision_354: 0.0000e+00 - val_recall_354: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4143 - accuracy: 0.8053 - precision_354: 0.7904 - recall_354: 0.8241 - val_loss: 22.7037 - val_accuracy: 0.4858 - val_precision_354: 0.0000e+00 - val_recall_354: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4025 - accuracy: 0.8128 - precision_354: 0.8030 - recall_354: 0.8254 - val_loss: 4.6478 - val_accuracy: 0.4858 - val_precision_354: 0.0000e+00 - val_recall_354: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3901 - accuracy: 0.8199 - precision_354: 0.8041 - recall_354: 0.8395 - val_loss: 14.1005 - val_accuracy: 0.4858 - val_precision_354: 0.0000e+00 - val_recall_354: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3857 - accuracy: 0.8174 - precision_354: 0.8140 - recall_354: 0.8345 - val_loss: 6.8182 - val_accuracy: 0.4858 - val_precision_354: 0.0000e+00 - val_recall_354: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3593 - accuracy: 0.8411 - precision_354: 0.8343 - recall_354: 0.8544 - val_loss: 3.7758 - val_accuracy: 0.4858 - val_precision_354: 0.0000e+00 - val_recall_354: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3685 - accuracy: 0.8251 - precision_354: 0.8004 - recall_354: 0.8578 - val_loss: 3.4221 - val_accuracy: 0.4892 - val_precision_354: 1.0000 - val_recall_354: 0.0065\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3656 - accuracy: 0.8354 - precision_354: 0.8180 - recall_354: 0.8628 - val_loss: 1.8637 - val_accuracy: 0.5258 - val_precision_354: 0.9800 - val_recall_354: 0.0794\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3641 - accuracy: 0.8333 - precision_354: 0.8208 - recall_354: 0.8467 - val_loss: 1.4702 - val_accuracy: 0.5642 - val_precision_354: 0.9796 - val_recall_354: 0.1556\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3530 - accuracy: 0.8338 - precision_354: 0.8081 - recall_354: 0.8642 - val_loss: 0.6071 - val_accuracy: 0.7367 - val_precision_354: 0.9216 - val_recall_354: 0.5332\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3719 - accuracy: 0.8325 - precision_354: 0.8210 - recall_354: 0.8422 - val_loss: 0.3965 - val_accuracy: 0.8100 - val_precision_354: 0.8517 - val_recall_354: 0.7634\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3622 - accuracy: 0.8308 - precision_354: 0.8170 - recall_354: 0.8574 - val_loss: 0.3866 - val_accuracy: 0.8267 - val_precision_354: 0.8437 - val_recall_354: 0.8136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu, AUC=0.910, Accuracy=0.834, f2=0.823, prec=0.842, rec=0.819, total=  20.0s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 157ms/step - loss: 0.8827 - accuracy: 0.6064 - precision_355: 0.6157 - recall_355: 0.6034 - val_loss: 80.3007 - val_accuracy: 0.5142 - val_precision_355: 0.5142 - val_recall_355: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4883 - accuracy: 0.7637 - precision_355: 0.7660 - recall_355: 0.7765 - val_loss: 119.7460 - val_accuracy: 0.5142 - val_precision_355: 0.5142 - val_recall_355: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4644 - accuracy: 0.7795 - precision_355: 0.7830 - recall_355: 0.7621 - val_loss: 70.8379 - val_accuracy: 0.5142 - val_precision_355: 0.5142 - val_recall_355: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4581 - accuracy: 0.7847 - precision_355: 0.7703 - recall_355: 0.8029 - val_loss: 43.2050 - val_accuracy: 0.5142 - val_precision_355: 0.5142 - val_recall_355: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.4266 - accuracy: 0.8010 - precision_355: 0.7928 - recall_355: 0.8097 - val_loss: 37.1670 - val_accuracy: 0.5142 - val_precision_355: 0.5142 - val_recall_355: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.4263 - accuracy: 0.8076 - precision_355: 0.8018 - recall_355: 0.8082 - val_loss: 23.1071 - val_accuracy: 0.5142 - val_precision_355: 0.5142 - val_recall_355: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4069 - accuracy: 0.8143 - precision_355: 0.8099 - recall_355: 0.8228 - val_loss: 18.6828 - val_accuracy: 0.5142 - val_precision_355: 0.5142 - val_recall_355: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4071 - accuracy: 0.8147 - precision_355: 0.8142 - recall_355: 0.8100 - val_loss: 6.2881 - val_accuracy: 0.5142 - val_precision_355: 0.5142 - val_recall_355: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.3897 - accuracy: 0.8200 - precision_355: 0.8075 - recall_355: 0.8330 - val_loss: 8.8657 - val_accuracy: 0.5142 - val_precision_355: 0.5142 - val_recall_355: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3872 - accuracy: 0.8266 - precision_355: 0.8074 - recall_355: 0.8507 - val_loss: 38.0406 - val_accuracy: 0.4858 - val_precision_355: 0.0000e+00 - val_recall_355: 0.0000e+00\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3782 - accuracy: 0.8251 - precision_355: 0.8089 - recall_355: 0.8479 - val_loss: 34.4558 - val_accuracy: 0.4858 - val_precision_355: 0.0000e+00 - val_recall_355: 0.0000e+00\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3757 - accuracy: 0.8333 - precision_355: 0.8240 - recall_355: 0.8469 - val_loss: 29.0194 - val_accuracy: 0.4858 - val_precision_355: 0.0000e+00 - val_recall_355: 0.0000e+00\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3611 - accuracy: 0.8281 - precision_355: 0.8080 - recall_355: 0.8524 - val_loss: 19.3436 - val_accuracy: 0.4858 - val_precision_355: 0.0000e+00 - val_recall_355: 0.0000e+00\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3875 - accuracy: 0.8164 - precision_355: 0.7943 - recall_355: 0.8486 - val_loss: 18.2462 - val_accuracy: 0.4858 - val_precision_355: 0.0000e+00 - val_recall_355: 0.0000e+00\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3735 - accuracy: 0.8346 - precision_355: 0.8218 - recall_355: 0.8527 - val_loss: 16.5552 - val_accuracy: 0.4858 - val_precision_355: 0.0000e+00 - val_recall_355: 0.0000e+00\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3696 - accuracy: 0.8278 - precision_355: 0.8147 - recall_355: 0.8474 - val_loss: 14.6836 - val_accuracy: 0.4858 - val_precision_355: 0.0000e+00 - val_recall_355: 0.0000e+00\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3655 - accuracy: 0.8302 - precision_355: 0.8264 - recall_355: 0.8405 - val_loss: 12.1826 - val_accuracy: 0.4858 - val_precision_355: 0.0000e+00 - val_recall_355: 0.0000e+00\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3757 - accuracy: 0.8218 - precision_355: 0.8051 - recall_355: 0.8417 - val_loss: 10.0693 - val_accuracy: 0.4858 - val_precision_355: 0.0000e+00 - val_recall_355: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=relu, AUC=0.870, Accuracy=0.503, f2=0.000, prec=0.000, rec=0.000, total=  17.3s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 161ms/step - loss: 0.7580 - accuracy: 0.6180 - precision_356: 0.6057 - recall_356: 0.6116 - val_loss: 48.5405 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4694 - accuracy: 0.7728 - precision_356: 0.7598 - recall_356: 0.7900 - val_loss: 77.6139 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4564 - accuracy: 0.7757 - precision_356: 0.7559 - recall_356: 0.7948 - val_loss: 67.1231 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4525 - accuracy: 0.7906 - precision_356: 0.7777 - recall_356: 0.8129 - val_loss: 43.5663 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4386 - accuracy: 0.7913 - precision_356: 0.7727 - recall_356: 0.8080 - val_loss: 26.8892 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4274 - accuracy: 0.7964 - precision_356: 0.7807 - recall_356: 0.8183 - val_loss: 17.4695 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4247 - accuracy: 0.7964 - precision_356: 0.7761 - recall_356: 0.8246 - val_loss: 11.2453 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4064 - accuracy: 0.8118 - precision_356: 0.8015 - recall_356: 0.8341 - val_loss: 6.7634 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3961 - accuracy: 0.8170 - precision_356: 0.8006 - recall_356: 0.8497 - val_loss: 3.0448 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4087 - accuracy: 0.8082 - precision_356: 0.7954 - recall_356: 0.8264 - val_loss: 1.2010 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3995 - accuracy: 0.8122 - precision_356: 0.7948 - recall_356: 0.8364 - val_loss: 0.8933 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3807 - accuracy: 0.8248 - precision_356: 0.8175 - recall_356: 0.8338 - val_loss: 0.6949 - val_accuracy: 0.5383 - val_precision_356: 0.6615 - val_recall_356: 0.2091\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.3691 - accuracy: 0.8330 - precision_356: 0.8133 - recall_356: 0.8451 - val_loss: 0.7762 - val_accuracy: 0.5142 - val_precision_356: 0.5143 - val_recall_356: 0.9935\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.3890 - accuracy: 0.8217 - precision_356: 0.8033 - recall_356: 0.8419 - val_loss: 1.9483 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3796 - accuracy: 0.8301 - precision_356: 0.8162 - recall_356: 0.8515 - val_loss: 1.8909 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3827 - accuracy: 0.8230 - precision_356: 0.8097 - recall_356: 0.8413 - val_loss: 1.3948 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3737 - accuracy: 0.8321 - precision_356: 0.8144 - recall_356: 0.8563 - val_loss: 1.3466 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3789 - accuracy: 0.8315 - precision_356: 0.8235 - recall_356: 0.8456 - val_loss: 1.2615 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.3727 - accuracy: 0.8230 - precision_356: 0.8019 - recall_356: 0.8473 - val_loss: 1.3063 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3692 - accuracy: 0.8286 - precision_356: 0.8162 - recall_356: 0.8465 - val_loss: 1.3158 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3710 - accuracy: 0.8274 - precision_356: 0.8118 - recall_356: 0.8482 - val_loss: 1.3458 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3740 - accuracy: 0.8277 - precision_356: 0.8178 - recall_356: 0.8400 - val_loss: 1.3704 - val_accuracy: 0.5142 - val_precision_356: 0.5142 - val_recall_356: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=relu, AUC=0.721, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  19.5s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 162ms/step - loss: 0.8617 - accuracy: 0.6219 - precision_357: 0.6181 - recall_357: 0.6202 - val_loss: 24.2376 - val_accuracy: 0.5142 - val_precision_357: 0.5142 - val_recall_357: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4996 - accuracy: 0.7577 - precision_357: 0.7628 - recall_357: 0.7476 - val_loss: 79.7199 - val_accuracy: 0.5142 - val_precision_357: 0.5142 - val_recall_357: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4710 - accuracy: 0.7725 - precision_357: 0.7675 - recall_357: 0.7724 - val_loss: 66.1549 - val_accuracy: 0.5142 - val_precision_357: 0.5142 - val_recall_357: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4702 - accuracy: 0.7688 - precision_357: 0.7714 - recall_357: 0.7717 - val_loss: 35.3567 - val_accuracy: 0.5142 - val_precision_357: 0.5142 - val_recall_357: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4709 - accuracy: 0.7685 - precision_357: 0.7661 - recall_357: 0.7723 - val_loss: 21.2364 - val_accuracy: 0.5142 - val_precision_357: 0.5142 - val_recall_357: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4538 - accuracy: 0.7801 - precision_357: 0.7781 - recall_357: 0.7898 - val_loss: 13.6531 - val_accuracy: 0.5142 - val_precision_357: 0.5142 - val_recall_357: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4433 - accuracy: 0.7882 - precision_357: 0.7699 - recall_357: 0.7994 - val_loss: 9.5900 - val_accuracy: 0.5142 - val_precision_357: 0.5142 - val_recall_357: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4274 - accuracy: 0.7930 - precision_357: 0.7820 - recall_357: 0.8040 - val_loss: 6.1835 - val_accuracy: 0.5142 - val_precision_357: 0.5142 - val_recall_357: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4167 - accuracy: 0.8072 - precision_357: 0.7928 - recall_357: 0.8238 - val_loss: 4.0897 - val_accuracy: 0.5142 - val_precision_357: 0.5142 - val_recall_357: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.4151 - accuracy: 0.8133 - precision_357: 0.8078 - recall_357: 0.8259 - val_loss: 2.3240 - val_accuracy: 0.5142 - val_precision_357: 0.5142 - val_recall_357: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4187 - accuracy: 0.8083 - precision_357: 0.8012 - recall_357: 0.8238 - val_loss: 1.5424 - val_accuracy: 0.5142 - val_precision_357: 0.5142 - val_recall_357: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4039 - accuracy: 0.8135 - precision_357: 0.8065 - recall_357: 0.8253 - val_loss: 0.6915 - val_accuracy: 0.5258 - val_precision_357: 0.5202 - val_recall_357: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3972 - accuracy: 0.8192 - precision_357: 0.8070 - recall_357: 0.8320 - val_loss: 0.6263 - val_accuracy: 0.7067 - val_precision_357: 0.6542 - val_recall_357: 0.9109\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3958 - accuracy: 0.8247 - precision_357: 0.8125 - recall_357: 0.8408 - val_loss: 0.8447 - val_accuracy: 0.4867 - val_precision_357: 1.0000 - val_recall_357: 0.0016\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.3880 - accuracy: 0.8207 - precision_357: 0.8126 - recall_357: 0.8339 - val_loss: 3.1557 - val_accuracy: 0.4858 - val_precision_357: 0.0000e+00 - val_recall_357: 0.0000e+00\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3796 - accuracy: 0.8258 - precision_357: 0.8049 - recall_357: 0.8466 - val_loss: 1.9434 - val_accuracy: 0.4858 - val_precision_357: 0.0000e+00 - val_recall_357: 0.0000e+00\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3785 - accuracy: 0.8300 - precision_357: 0.8162 - recall_357: 0.8487 - val_loss: 3.1094 - val_accuracy: 0.4858 - val_precision_357: 0.0000e+00 - val_recall_357: 0.0000e+00\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3843 - accuracy: 0.8228 - precision_357: 0.8151 - recall_357: 0.8306 - val_loss: 2.6780 - val_accuracy: 0.4858 - val_precision_357: 0.0000e+00 - val_recall_357: 0.0000e+00\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3830 - accuracy: 0.8250 - precision_357: 0.8089 - recall_357: 0.8501 - val_loss: 1.9371 - val_accuracy: 0.4858 - val_precision_357: 0.0000e+00 - val_recall_357: 0.0000e+00\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3870 - accuracy: 0.8222 - precision_357: 0.8030 - recall_357: 0.8476 - val_loss: 1.7247 - val_accuracy: 0.4858 - val_precision_357: 0.0000e+00 - val_recall_357: 0.0000e+00\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3894 - accuracy: 0.8157 - precision_357: 0.7998 - recall_357: 0.8422 - val_loss: 1.5463 - val_accuracy: 0.4858 - val_precision_357: 0.0000e+00 - val_recall_357: 0.0000e+00\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3824 - accuracy: 0.8295 - precision_357: 0.8219 - recall_357: 0.8429 - val_loss: 1.3668 - val_accuracy: 0.4858 - val_precision_357: 0.0000e+00 - val_recall_357: 0.0000e+00\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3832 - accuracy: 0.8253 - precision_357: 0.8073 - recall_357: 0.8499 - val_loss: 1.1920 - val_accuracy: 0.4858 - val_precision_357: 0.0000e+00 - val_recall_357: 0.0000e+00\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3847 - accuracy: 0.8256 - precision_357: 0.8040 - recall_357: 0.8495 - val_loss: 1.0356 - val_accuracy: 0.4867 - val_precision_357: 1.0000 - val_recall_357: 0.0016\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3908 - accuracy: 0.8277 - precision_357: 0.8083 - recall_357: 0.8524 - val_loss: 0.9073 - val_accuracy: 0.4867 - val_precision_357: 0.6667 - val_recall_357: 0.0032\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3870 - accuracy: 0.8175 - precision_357: 0.7942 - recall_357: 0.8453 - val_loss: 0.8048 - val_accuracy: 0.5067 - val_precision_357: 0.9032 - val_recall_357: 0.0454\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3958 - accuracy: 0.8204 - precision_357: 0.8046 - recall_357: 0.8404 - val_loss: 0.7243 - val_accuracy: 0.5367 - val_precision_357: 0.8861 - val_recall_357: 0.1135\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3773 - accuracy: 0.8329 - precision_357: 0.8139 - recall_357: 0.8594 - val_loss: 0.6632 - val_accuracy: 0.5900 - val_precision_357: 0.9195 - val_recall_357: 0.2220\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3820 - accuracy: 0.8236 - precision_357: 0.8062 - recall_357: 0.8463 - val_loss: 0.6183 - val_accuracy: 0.6308 - val_precision_357: 0.8919 - val_recall_357: 0.3209\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3848 - accuracy: 0.8272 - precision_357: 0.8201 - recall_357: 0.8375 - val_loss: 0.5836 - val_accuracy: 0.6575 - val_precision_357: 0.8366 - val_recall_357: 0.4149\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3903 - accuracy: 0.8223 - precision_357: 0.8048 - recall_357: 0.8469 - val_loss: 0.5569 - val_accuracy: 0.6958 - val_precision_357: 0.8214 - val_recall_357: 0.5219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.2, batch_size=400, activation=relu, AUC=0.853, Accuracy=0.718, f2=0.575, prec=0.839, rec=0.533, total=  26.5s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.7290 - accuracy: 0.6762 - precision_358: 0.6703 - recall_358: 0.6708 - val_loss: 118.9009 - val_accuracy: 0.5142 - val_precision_358: 0.5142 - val_recall_358: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4707 - accuracy: 0.7804 - precision_358: 0.7724 - recall_358: 0.7820 - val_loss: 45.9794 - val_accuracy: 0.5142 - val_precision_358: 0.5142 - val_recall_358: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4601 - accuracy: 0.7826 - precision_358: 0.7728 - recall_358: 0.7978 - val_loss: 8.4185 - val_accuracy: 0.5142 - val_precision_358: 0.5142 - val_recall_358: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4395 - accuracy: 0.8016 - precision_358: 0.7945 - recall_358: 0.8208 - val_loss: 5.8006 - val_accuracy: 0.5142 - val_precision_358: 0.5142 - val_recall_358: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4330 - accuracy: 0.7995 - precision_358: 0.8110 - recall_358: 0.7857 - val_loss: 2.0078 - val_accuracy: 0.4875 - val_precision_358: 1.0000 - val_recall_358: 0.0032\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4088 - accuracy: 0.8183 - precision_358: 0.8217 - recall_358: 0.8108 - val_loss: 4.8864 - val_accuracy: 0.4858 - val_precision_358: 0.0000e+00 - val_recall_358: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3938 - accuracy: 0.8140 - precision_358: 0.8053 - recall_358: 0.8177 - val_loss: 12.6227 - val_accuracy: 0.4833 - val_precision_358: 0.4986 - val_recall_358: 0.8914\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3983 - accuracy: 0.8166 - precision_358: 0.8161 - recall_358: 0.8094 - val_loss: 14.0225 - val_accuracy: 0.4808 - val_precision_358: 0.2000 - val_recall_358: 0.0032\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3823 - accuracy: 0.8275 - precision_358: 0.8124 - recall_358: 0.8443 - val_loss: 8.6956 - val_accuracy: 0.4858 - val_precision_358: 0.0000e+00 - val_recall_358: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3825 - accuracy: 0.8230 - precision_358: 0.7962 - recall_358: 0.8563 - val_loss: 12.9836 - val_accuracy: 0.4750 - val_precision_358: 0.0000e+00 - val_recall_358: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3857 - accuracy: 0.8298 - precision_358: 0.8258 - recall_358: 0.8429 - val_loss: 11.6892 - val_accuracy: 0.4858 - val_precision_358: 0.0000e+00 - val_recall_358: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3809 - accuracy: 0.8264 - precision_358: 0.8143 - recall_358: 0.8486 - val_loss: 8.7767 - val_accuracy: 0.4858 - val_precision_358: 0.0000e+00 - val_recall_358: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3807 - accuracy: 0.8281 - precision_358: 0.8118 - recall_358: 0.8460 - val_loss: 6.8149 - val_accuracy: 0.4858 - val_precision_358: 0.0000e+00 - val_recall_358: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3809 - accuracy: 0.8282 - precision_358: 0.8125 - recall_358: 0.8541 - val_loss: 4.7400 - val_accuracy: 0.4858 - val_precision_358: 0.0000e+00 - val_recall_358: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3921 - accuracy: 0.8159 - precision_358: 0.8082 - recall_358: 0.8342 - val_loss: 3.2329 - val_accuracy: 0.4908 - val_precision_358: 1.0000 - val_recall_358: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu, AUC=0.885, Accuracy=0.506, f2=0.006, prec=1.000, rec=0.005, total=  17.4s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.6435 - accuracy: 0.7041 - precision_359: 0.6969 - recall_359: 0.6973 - val_loss: 202.4154 - val_accuracy: 0.5142 - val_precision_359: 0.5142 - val_recall_359: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4595 - accuracy: 0.7843 - precision_359: 0.7871 - recall_359: 0.7914 - val_loss: 24.5456 - val_accuracy: 0.5142 - val_precision_359: 0.5142 - val_recall_359: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4214 - accuracy: 0.7963 - precision_359: 0.7948 - recall_359: 0.7968 - val_loss: 5.4863 - val_accuracy: 0.5142 - val_precision_359: 0.5142 - val_recall_359: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4266 - accuracy: 0.8089 - precision_359: 0.8057 - recall_359: 0.8138 - val_loss: 1.0840 - val_accuracy: 0.4858 - val_precision_359: 0.0000e+00 - val_recall_359: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4037 - accuracy: 0.8144 - precision_359: 0.8011 - recall_359: 0.8321 - val_loss: 2.2739 - val_accuracy: 0.5142 - val_precision_359: 0.5142 - val_recall_359: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3783 - accuracy: 0.8301 - precision_359: 0.8098 - recall_359: 0.8550 - val_loss: 1.2443 - val_accuracy: 0.4900 - val_precision_359: 1.0000 - val_recall_359: 0.0081\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3737 - accuracy: 0.8257 - precision_359: 0.8130 - recall_359: 0.8440 - val_loss: 16.8396 - val_accuracy: 0.4858 - val_precision_359: 0.0000e+00 - val_recall_359: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3688 - accuracy: 0.8326 - precision_359: 0.8164 - recall_359: 0.8488 - val_loss: 25.7664 - val_accuracy: 0.4858 - val_precision_359: 0.0000e+00 - val_recall_359: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3554 - accuracy: 0.8373 - precision_359: 0.8193 - recall_359: 0.8564 - val_loss: 33.7791 - val_accuracy: 0.4858 - val_precision_359: 0.0000e+00 - val_recall_359: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3429 - accuracy: 0.8413 - precision_359: 0.8272 - recall_359: 0.8679 - val_loss: 15.8938 - val_accuracy: 0.4858 - val_precision_359: 0.0000e+00 - val_recall_359: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3514 - accuracy: 0.8401 - precision_359: 0.8226 - recall_359: 0.8684 - val_loss: 10.5755 - val_accuracy: 0.4858 - val_precision_359: 0.0000e+00 - val_recall_359: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3542 - accuracy: 0.8412 - precision_359: 0.8257 - recall_359: 0.8612 - val_loss: 8.5522 - val_accuracy: 0.4858 - val_precision_359: 0.0000e+00 - val_recall_359: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3562 - accuracy: 0.8377 - precision_359: 0.8182 - recall_359: 0.8644 - val_loss: 6.1229 - val_accuracy: 0.4858 - val_precision_359: 0.0000e+00 - val_recall_359: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3551 - accuracy: 0.8403 - precision_359: 0.8296 - recall_359: 0.8584 - val_loss: 4.7341 - val_accuracy: 0.4858 - val_precision_359: 0.0000e+00 - val_recall_359: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3476 - accuracy: 0.8414 - precision_359: 0.8200 - recall_359: 0.8626 - val_loss: 3.4214 - val_accuracy: 0.4858 - val_precision_359: 0.0000e+00 - val_recall_359: 0.0000e+00\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3638 - accuracy: 0.8272 - precision_359: 0.8186 - recall_359: 0.8393 - val_loss: 2.3847 - val_accuracy: 0.4875 - val_precision_359: 1.0000 - val_recall_359: 0.0032\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3510 - accuracy: 0.8383 - precision_359: 0.8250 - recall_359: 0.8561 - val_loss: 1.6337 - val_accuracy: 0.4967 - val_precision_359: 1.0000 - val_recall_359: 0.0211\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3417 - accuracy: 0.8374 - precision_359: 0.8182 - recall_359: 0.8600 - val_loss: 1.1206 - val_accuracy: 0.5633 - val_precision_359: 0.9794 - val_recall_359: 0.1540\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3507 - accuracy: 0.8382 - precision_359: 0.8105 - recall_359: 0.8666 - val_loss: 0.7922 - val_accuracy: 0.6533 - val_precision_359: 0.9507 - val_recall_359: 0.3436\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3491 - accuracy: 0.8425 - precision_359: 0.8217 - recall_359: 0.8702 - val_loss: 0.6052 - val_accuracy: 0.7158 - val_precision_359: 0.9233 - val_recall_359: 0.4878\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3501 - accuracy: 0.8388 - precision_359: 0.8279 - recall_359: 0.8579 - val_loss: 0.4922 - val_accuracy: 0.7650 - val_precision_359: 0.9056 - val_recall_359: 0.6062\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3555 - accuracy: 0.8354 - precision_359: 0.8212 - recall_359: 0.8484 - val_loss: 0.4336 - val_accuracy: 0.7958 - val_precision_359: 0.8827 - val_recall_359: 0.6953\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3399 - accuracy: 0.8444 - precision_359: 0.8298 - recall_359: 0.8663 - val_loss: 0.3990 - val_accuracy: 0.8133 - val_precision_359: 0.8646 - val_recall_359: 0.7553\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3612 - accuracy: 0.8302 - precision_359: 0.8189 - recall_359: 0.8475 - val_loss: 0.3824 - val_accuracy: 0.8192 - val_precision_359: 0.8497 - val_recall_359: 0.7877\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3426 - accuracy: 0.8472 - precision_359: 0.8435 - recall_359: 0.8584 - val_loss: 0.3755 - val_accuracy: 0.8275 - val_precision_359: 0.8383 - val_recall_359: 0.8233\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3497 - accuracy: 0.8390 - precision_359: 0.8290 - recall_359: 0.8557 - val_loss: 0.3727 - val_accuracy: 0.8292 - val_precision_359: 0.8270 - val_recall_359: 0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu, AUC=0.896, Accuracy=0.813, f2=0.827, prec=0.798, rec=0.835, total=  27.8s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.7261 - accuracy: 0.6826 - precision_360: 0.6888 - recall_360: 0.6866 - val_loss: 77.4975 - val_accuracy: 0.5142 - val_precision_360: 0.5142 - val_recall_360: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4668 - accuracy: 0.7761 - precision_360: 0.7886 - recall_360: 0.7691 - val_loss: 2.5047 - val_accuracy: 0.5142 - val_precision_360: 0.5142 - val_recall_360: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4327 - accuracy: 0.8030 - precision_360: 0.7989 - recall_360: 0.8061 - val_loss: 1.4218 - val_accuracy: 0.5142 - val_precision_360: 0.5142 - val_recall_360: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4219 - accuracy: 0.8078 - precision_360: 0.8012 - recall_360: 0.8157 - val_loss: 6.9312 - val_accuracy: 0.4858 - val_precision_360: 0.0000e+00 - val_recall_360: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4000 - accuracy: 0.8143 - precision_360: 0.7980 - recall_360: 0.8365 - val_loss: 3.5202 - val_accuracy: 0.4858 - val_precision_360: 0.0000e+00 - val_recall_360: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4058 - accuracy: 0.8086 - precision_360: 0.8000 - recall_360: 0.8218 - val_loss: 19.4256 - val_accuracy: 0.4817 - val_precision_360: 0.4074 - val_recall_360: 0.0178\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4014 - accuracy: 0.8293 - precision_360: 0.8118 - recall_360: 0.8478 - val_loss: 25.8172 - val_accuracy: 0.4783 - val_precision_360: 0.2857 - val_recall_360: 0.0097\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3728 - accuracy: 0.8297 - precision_360: 0.8139 - recall_360: 0.8543 - val_loss: 20.4131 - val_accuracy: 0.4850 - val_precision_360: 0.4964 - val_recall_360: 0.1118\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3615 - accuracy: 0.8428 - precision_360: 0.8316 - recall_360: 0.8639 - val_loss: 15.1434 - val_accuracy: 0.5075 - val_precision_360: 0.6806 - val_recall_360: 0.0794\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3586 - accuracy: 0.8384 - precision_360: 0.8257 - recall_360: 0.8590 - val_loss: 16.4693 - val_accuracy: 0.5125 - val_precision_360: 0.7051 - val_recall_360: 0.0891\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3573 - accuracy: 0.8332 - precision_360: 0.8065 - recall_360: 0.8664 - val_loss: 18.0784 - val_accuracy: 0.4958 - val_precision_360: 0.6364 - val_recall_360: 0.0454\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3616 - accuracy: 0.8345 - precision_360: 0.8334 - recall_360: 0.8407 - val_loss: 8.1239 - val_accuracy: 0.4925 - val_precision_360: 0.8333 - val_recall_360: 0.0162\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3646 - accuracy: 0.8337 - precision_360: 0.8265 - recall_360: 0.8460 - val_loss: 4.9084 - val_accuracy: 0.4883 - val_precision_360: 1.0000 - val_recall_360: 0.0049\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3595 - accuracy: 0.8484 - precision_360: 0.8273 - recall_360: 0.8745 - val_loss: 3.3436 - val_accuracy: 0.4883 - val_precision_360: 1.0000 - val_recall_360: 0.0049\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3692 - accuracy: 0.8287 - precision_360: 0.8068 - recall_360: 0.8500 - val_loss: 2.3990 - val_accuracy: 0.4933 - val_precision_360: 1.0000 - val_recall_360: 0.0146\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3560 - accuracy: 0.8367 - precision_360: 0.8263 - recall_360: 0.8511 - val_loss: 1.6982 - val_accuracy: 0.5242 - val_precision_360: 0.9792 - val_recall_360: 0.0762\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3544 - accuracy: 0.8376 - precision_360: 0.8243 - recall_360: 0.8561 - val_loss: 1.1936 - val_accuracy: 0.5850 - val_precision_360: 0.9685 - val_recall_360: 0.1994\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3522 - accuracy: 0.8362 - precision_360: 0.8207 - recall_360: 0.8581 - val_loss: 0.8735 - val_accuracy: 0.6533 - val_precision_360: 0.9548 - val_recall_360: 0.3420\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3597 - accuracy: 0.8332 - precision_360: 0.7996 - recall_360: 0.8703 - val_loss: 0.6662 - val_accuracy: 0.7075 - val_precision_360: 0.9346 - val_recall_360: 0.4635\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3700 - accuracy: 0.8221 - precision_360: 0.8090 - recall_360: 0.8399 - val_loss: 0.5296 - val_accuracy: 0.7467 - val_precision_360: 0.9003 - val_recall_360: 0.5705\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3551 - accuracy: 0.8387 - precision_360: 0.8261 - recall_360: 0.8544 - val_loss: 0.4579 - val_accuracy: 0.7733 - val_precision_360: 0.8894 - val_recall_360: 0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu, AUC=0.910, Accuracy=0.790, f2=0.694, prec=0.891, rec=0.657, total=  22.8s\n",
      "[CV] lr=0.001, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 2s 41ms/step - loss: 0.8432 - accuracy: 0.6444 - precision_361: 0.6535 - recall_361: 0.6536 - val_loss: 6.7144 - val_accuracy: 0.5142 - val_precision_361: 0.5142 - val_recall_361: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5201 - accuracy: 0.7557 - precision_361: 0.7538 - recall_361: 0.7576 - val_loss: 9.6551 - val_accuracy: 0.5142 - val_precision_361: 0.5142 - val_recall_361: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.4700 - accuracy: 0.7824 - precision_361: 0.7858 - recall_361: 0.7742 - val_loss: 9.0036 - val_accuracy: 0.5142 - val_precision_361: 0.5142 - val_recall_361: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4511 - accuracy: 0.7931 - precision_361: 0.7875 - recall_361: 0.7983 - val_loss: 12.8752 - val_accuracy: 0.5142 - val_precision_361: 0.5142 - val_recall_361: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4533 - accuracy: 0.7759 - precision_361: 0.7664 - recall_361: 0.7855 - val_loss: 13.4207 - val_accuracy: 0.5142 - val_precision_361: 0.5142 - val_recall_361: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4261 - accuracy: 0.8040 - precision_361: 0.7858 - recall_361: 0.8153 - val_loss: 13.4963 - val_accuracy: 0.5142 - val_precision_361: 0.5142 - val_recall_361: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4241 - accuracy: 0.8050 - precision_361: 0.7919 - recall_361: 0.8224 - val_loss: 12.2782 - val_accuracy: 0.5142 - val_precision_361: 0.5142 - val_recall_361: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4234 - accuracy: 0.8068 - precision_361: 0.8067 - recall_361: 0.8116 - val_loss: 10.0959 - val_accuracy: 0.5142 - val_precision_361: 0.5142 - val_recall_361: 1.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4423 - accuracy: 0.7906 - precision_361: 0.8004 - recall_361: 0.7835 - val_loss: 6.4882 - val_accuracy: 0.5150 - val_precision_361: 0.5146 - val_recall_361: 1.0000\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4172 - accuracy: 0.8138 - precision_361: 0.8070 - recall_361: 0.8163 - val_loss: 3.5251 - val_accuracy: 0.5475 - val_precision_361: 0.5319 - val_recall_361: 1.0000\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4289 - accuracy: 0.7988 - precision_361: 0.7968 - recall_361: 0.8035 - val_loss: 1.7301 - val_accuracy: 0.6267 - val_precision_361: 0.5798 - val_recall_361: 0.9951\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4326 - accuracy: 0.8064 - precision_361: 0.7900 - recall_361: 0.8264 - val_loss: 0.9552 - val_accuracy: 0.7108 - val_precision_361: 0.6461 - val_recall_361: 0.9676\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4201 - accuracy: 0.8023 - precision_361: 0.7920 - recall_361: 0.8104 - val_loss: 0.6269 - val_accuracy: 0.7517 - val_precision_361: 0.6981 - val_recall_361: 0.9109\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4405 - accuracy: 0.7921 - precision_361: 0.7697 - recall_361: 0.8083 - val_loss: 0.5095 - val_accuracy: 0.7825 - val_precision_361: 0.7507 - val_recall_361: 0.8639\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4133 - accuracy: 0.8090 - precision_361: 0.8090 - recall_361: 0.8087 - val_loss: 0.4664 - val_accuracy: 0.7900 - val_precision_361: 0.7865 - val_recall_361: 0.8120\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4122 - accuracy: 0.8099 - precision_361: 0.8166 - recall_361: 0.8062 - val_loss: 0.4521 - val_accuracy: 0.7933 - val_precision_361: 0.8070 - val_recall_361: 0.7861\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4226 - accuracy: 0.8106 - precision_361: 0.8180 - recall_361: 0.8054 - val_loss: 0.4469 - val_accuracy: 0.7917 - val_precision_361: 0.8126 - val_recall_361: 0.7731\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4288 - accuracy: 0.8009 - precision_361: 0.8130 - recall_361: 0.7946 - val_loss: 0.4423 - val_accuracy: 0.7967 - val_precision_361: 0.8083 - val_recall_361: 0.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu, AUC=0.891, Accuracy=0.804, f2=0.791, prec=0.815, rec=0.785, total=  18.8s\n",
      "[CV] lr=0.001, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 55ms/step - loss: 0.7484 - accuracy: 0.6752 - precision_362: 0.6690 - recall_362: 0.6873 - val_loss: 7.7749 - val_accuracy: 0.5142 - val_precision_362: 0.5142 - val_recall_362: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4874 - accuracy: 0.7805 - precision_362: 0.7854 - recall_362: 0.7742 - val_loss: 3.4833 - val_accuracy: 0.5142 - val_precision_362: 0.5142 - val_recall_362: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4286 - accuracy: 0.7992 - precision_362: 0.7869 - recall_362: 0.8200 - val_loss: 3.5440 - val_accuracy: 0.5142 - val_precision_362: 0.5142 - val_recall_362: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4373 - accuracy: 0.7931 - precision_362: 0.7846 - recall_362: 0.8116 - val_loss: 6.1618 - val_accuracy: 0.5142 - val_precision_362: 0.5142 - val_recall_362: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3895 - accuracy: 0.8167 - precision_362: 0.8016 - recall_362: 0.8404 - val_loss: 2.6628 - val_accuracy: 0.5367 - val_precision_362: 0.5260 - val_recall_362: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3879 - accuracy: 0.8122 - precision_362: 0.7920 - recall_362: 0.8449 - val_loss: 1.8193 - val_accuracy: 0.5883 - val_precision_362: 0.9128 - val_recall_362: 0.2204\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3717 - accuracy: 0.8313 - precision_362: 0.8182 - recall_362: 0.8561 - val_loss: 3.3463 - val_accuracy: 0.4883 - val_precision_362: 1.0000 - val_recall_362: 0.0049\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3786 - accuracy: 0.8281 - precision_362: 0.8182 - recall_362: 0.8404 - val_loss: 6.9682 - val_accuracy: 0.4858 - val_precision_362: 0.0000e+00 - val_recall_362: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3627 - accuracy: 0.8330 - precision_362: 0.8315 - recall_362: 0.8390 - val_loss: 6.6424 - val_accuracy: 0.4858 - val_precision_362: 0.0000e+00 - val_recall_362: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3735 - accuracy: 0.8320 - precision_362: 0.8318 - recall_362: 0.8381 - val_loss: 3.0209 - val_accuracy: 0.4858 - val_precision_362: 0.0000e+00 - val_recall_362: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.3717 - accuracy: 0.8355 - precision_362: 0.8194 - recall_362: 0.8586 - val_loss: 2.1814 - val_accuracy: 0.4875 - val_precision_362: 1.0000 - val_recall_362: 0.0032\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3716 - accuracy: 0.8221 - precision_362: 0.8061 - recall_362: 0.8396 - val_loss: 1.7061 - val_accuracy: 0.4908 - val_precision_362: 1.0000 - val_recall_362: 0.0097\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3569 - accuracy: 0.8335 - precision_362: 0.8279 - recall_362: 0.8479 - val_loss: 1.4206 - val_accuracy: 0.4942 - val_precision_362: 1.0000 - val_recall_362: 0.0162\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.3513 - accuracy: 0.8366 - precision_362: 0.8424 - recall_362: 0.8442 - val_loss: 0.9939 - val_accuracy: 0.5217 - val_precision_362: 0.9778 - val_recall_362: 0.0713\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.3559 - accuracy: 0.8351 - precision_362: 0.8332 - recall_362: 0.8459 - val_loss: 0.9468 - val_accuracy: 0.5400 - val_precision_362: 0.9851 - val_recall_362: 0.1070\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3741 - accuracy: 0.8280 - precision_362: 0.8211 - recall_362: 0.8461 - val_loss: 0.5881 - val_accuracy: 0.6900 - val_precision_362: 0.9391 - val_recall_362: 0.4246\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3697 - accuracy: 0.8400 - precision_362: 0.8307 - recall_362: 0.8528 - val_loss: 0.5226 - val_accuracy: 0.7300 - val_precision_362: 0.9322 - val_recall_362: 0.5122\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.3636 - accuracy: 0.8341 - precision_362: 0.8304 - recall_362: 0.8428 - val_loss: 0.5239 - val_accuracy: 0.7300 - val_precision_362: 0.9322 - val_recall_362: 0.5122\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3669 - accuracy: 0.8345 - precision_362: 0.8126 - recall_362: 0.8591 - val_loss: 0.4555 - val_accuracy: 0.7758 - val_precision_362: 0.9065 - val_recall_362: 0.6288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu, AUC=0.892, Accuracy=0.767, f2=0.657, prec=0.875, rec=0.618, total=  20.2s\n",
      "[CV] lr=0.001, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 43ms/step - loss: 0.7491 - accuracy: 0.6614 - precision_363: 0.6591 - recall_363: 0.6576 - val_loss: 7.5432 - val_accuracy: 0.5142 - val_precision_363: 0.5142 - val_recall_363: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4878 - accuracy: 0.7777 - precision_363: 0.7694 - recall_363: 0.7789 - val_loss: 4.0932 - val_accuracy: 0.5142 - val_precision_363: 0.5142 - val_recall_363: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.4537 - accuracy: 0.7778 - precision_363: 0.7607 - recall_363: 0.7918 - val_loss: 0.6011 - val_accuracy: 0.7408 - val_precision_363: 0.7452 - val_recall_363: 0.7536\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3972 - accuracy: 0.8234 - precision_363: 0.8257 - recall_363: 0.8303 - val_loss: 3.4018 - val_accuracy: 0.4858 - val_precision_363: 0.0000e+00 - val_recall_363: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3982 - accuracy: 0.8166 - precision_363: 0.8189 - recall_363: 0.8192 - val_loss: 3.8944 - val_accuracy: 0.4858 - val_precision_363: 0.0000e+00 - val_recall_363: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3948 - accuracy: 0.8282 - precision_363: 0.8190 - recall_363: 0.8287 - val_loss: 5.9524 - val_accuracy: 0.4858 - val_precision_363: 0.0000e+00 - val_recall_363: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.3731 - accuracy: 0.8285 - precision_363: 0.8143 - recall_363: 0.8450 - val_loss: 1.1301 - val_accuracy: 0.7558 - val_precision_363: 0.7842 - val_recall_363: 0.7245\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3742 - accuracy: 0.8303 - precision_363: 0.8171 - recall_363: 0.8503 - val_loss: 2.1152 - val_accuracy: 0.6567 - val_precision_363: 0.8782 - val_recall_363: 0.3857\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3648 - accuracy: 0.8455 - precision_363: 0.8463 - recall_363: 0.8540 - val_loss: 4.4317 - val_accuracy: 0.4858 - val_precision_363: 0.0000e+00 - val_recall_363: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3730 - accuracy: 0.8286 - precision_363: 0.8195 - recall_363: 0.8411 - val_loss: 3.2645 - val_accuracy: 0.4858 - val_precision_363: 0.0000e+00 - val_recall_363: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.3744 - accuracy: 0.8323 - precision_363: 0.8193 - recall_363: 0.8521 - val_loss: 2.2659 - val_accuracy: 0.4908 - val_precision_363: 1.0000 - val_recall_363: 0.0097\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3581 - accuracy: 0.8305 - precision_363: 0.8103 - recall_363: 0.8546 - val_loss: 1.5736 - val_accuracy: 0.5033 - val_precision_363: 1.0000 - val_recall_363: 0.0340\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3661 - accuracy: 0.8286 - precision_363: 0.8199 - recall_363: 0.8465 - val_loss: 1.1045 - val_accuracy: 0.5483 - val_precision_363: 0.9747 - val_recall_363: 0.1248\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3785 - accuracy: 0.8226 - precision_363: 0.8046 - recall_363: 0.8468 - val_loss: 0.8127 - val_accuracy: 0.6208 - val_precision_363: 0.9655 - val_recall_363: 0.2723\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3945 - accuracy: 0.8229 - precision_363: 0.8158 - recall_363: 0.8366 - val_loss: 0.5990 - val_accuracy: 0.7075 - val_precision_363: 0.9290 - val_recall_363: 0.4668\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3611 - accuracy: 0.8311 - precision_363: 0.8167 - recall_363: 0.8511 - val_loss: 0.4876 - val_accuracy: 0.7517 - val_precision_363: 0.8881 - val_recall_363: 0.5916\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3660 - accuracy: 0.8332 - precision_363: 0.8305 - recall_363: 0.8396 - val_loss: 0.4257 - val_accuracy: 0.7967 - val_precision_363: 0.8526 - val_recall_363: 0.7310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=7, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=elu, AUC=0.892, Accuracy=0.807, f2=0.755, prec=0.857, rec=0.733, total=  18.1s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.5, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 178ms/step - loss: 0.6169 - accuracy: 0.6359 - precision_364: 0.6326 - recall_364: 0.6510 - val_loss: 5.4553 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.5004 - accuracy: 0.7584 - precision_364: 0.7474 - recall_364: 0.7843 - val_loss: 11.6388 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.4516 - accuracy: 0.7886 - precision_364: 0.7777 - recall_364: 0.8070 - val_loss: 17.3998 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.4297 - accuracy: 0.8029 - precision_364: 0.7999 - recall_364: 0.8010 - val_loss: 11.7111 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.4167 - accuracy: 0.8028 - precision_364: 0.7918 - recall_364: 0.8077 - val_loss: 8.5633 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.4171 - accuracy: 0.8068 - precision_364: 0.7989 - recall_364: 0.8125 - val_loss: 6.5338 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.4234 - accuracy: 0.8054 - precision_364: 0.8110 - recall_364: 0.8053 - val_loss: 5.0300 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.4295 - accuracy: 0.7907 - precision_364: 0.7754 - recall_364: 0.8042 - val_loss: 3.8045 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4277 - accuracy: 0.8006 - precision_364: 0.7968 - recall_364: 0.8083 - val_loss: 2.8565 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.4111 - accuracy: 0.8170 - precision_364: 0.8127 - recall_364: 0.8195 - val_loss: 2.1784 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4130 - accuracy: 0.8061 - precision_364: 0.7988 - recall_364: 0.8180 - val_loss: 1.8581 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.4234 - accuracy: 0.8007 - precision_364: 0.8097 - recall_364: 0.7964 - val_loss: 1.7367 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.4023 - accuracy: 0.8161 - precision_364: 0.8135 - recall_364: 0.8203 - val_loss: 1.2605 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4029 - accuracy: 0.8149 - precision_364: 0.7985 - recall_364: 0.8296 - val_loss: 1.0859 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3989 - accuracy: 0.8114 - precision_364: 0.8023 - recall_364: 0.8278 - val_loss: 1.1795 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.4094 - accuracy: 0.8053 - precision_364: 0.7867 - recall_364: 0.8228 - val_loss: 1.0825 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4121 - accuracy: 0.8043 - precision_364: 0.7947 - recall_364: 0.8142 - val_loss: 0.8698 - val_accuracy: 0.5142 - val_precision_364: 0.5142 - val_recall_364: 1.0000\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.4046 - accuracy: 0.8135 - precision_364: 0.8130 - recall_364: 0.8154 - val_loss: 0.6385 - val_accuracy: 0.5750 - val_precision_364: 0.5476 - val_recall_364: 0.9984\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3980 - accuracy: 0.8130 - precision_364: 0.8113 - recall_364: 0.8209 - val_loss: 0.5501 - val_accuracy: 0.7492 - val_precision_364: 0.6881 - val_recall_364: 0.9368\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4049 - accuracy: 0.8214 - precision_364: 0.8158 - recall_364: 0.8290 - val_loss: 0.5387 - val_accuracy: 0.7808 - val_precision_364: 0.7425 - val_recall_364: 0.8784\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3957 - accuracy: 0.8136 - precision_364: 0.8003 - recall_364: 0.8241 - val_loss: 0.5449 - val_accuracy: 0.7442 - val_precision_364: 0.8370 - val_recall_364: 0.6240\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3909 - accuracy: 0.8214 - precision_364: 0.8144 - recall_364: 0.8284 - val_loss: 0.7383 - val_accuracy: 0.4983 - val_precision_364: 1.0000 - val_recall_364: 0.0243\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.3926 - accuracy: 0.8168 - precision_364: 0.8105 - recall_364: 0.8264 - val_loss: 0.7393 - val_accuracy: 0.4967 - val_precision_364: 1.0000 - val_recall_364: 0.0211\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3889 - accuracy: 0.8195 - precision_364: 0.8014 - recall_364: 0.8410 - val_loss: 0.6740 - val_accuracy: 0.5250 - val_precision_364: 0.9608 - val_recall_364: 0.0794\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3965 - accuracy: 0.8271 - precision_364: 0.8068 - recall_364: 0.8437 - val_loss: 0.6395 - val_accuracy: 0.5608 - val_precision_364: 0.9500 - val_recall_364: 0.1540\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4072 - accuracy: 0.8156 - precision_364: 0.8019 - recall_364: 0.8310 - val_loss: 0.6008 - val_accuracy: 0.6050 - val_precision_364: 0.9040 - val_recall_364: 0.2593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.5, batch_size=400, activation=gelu, AUC=0.888, Accuracy=0.642, f2=0.338, prec=0.963, rec=0.291, total=  27.7s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.5, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 186ms/step - loss: 0.5973 - accuracy: 0.6551 - precision_365: 0.6397 - recall_365: 0.6672 - val_loss: 0.6998 - val_accuracy: 0.5317 - val_precision_365: 0.5233 - val_recall_365: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4595 - accuracy: 0.7924 - precision_365: 0.7712 - recall_365: 0.8247 - val_loss: 0.6897 - val_accuracy: 0.5008 - val_precision_365: 0.6875 - val_recall_365: 0.0535\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4197 - accuracy: 0.7961 - precision_365: 0.8059 - recall_365: 0.7882 - val_loss: 0.7290 - val_accuracy: 0.5108 - val_precision_365: 0.5128 - val_recall_365: 0.9708\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3996 - accuracy: 0.8177 - precision_365: 0.8002 - recall_365: 0.8320 - val_loss: 2.2547 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3721 - accuracy: 0.8341 - precision_365: 0.8199 - recall_365: 0.8551 - val_loss: 2.3763 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.3729 - accuracy: 0.8333 - precision_365: 0.8222 - recall_365: 0.8477 - val_loss: 2.2490 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3786 - accuracy: 0.8208 - precision_365: 0.8089 - recall_365: 0.8351 - val_loss: 2.6256 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3702 - accuracy: 0.8350 - precision_365: 0.8372 - recall_365: 0.8328 - val_loss: 2.8809 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.3775 - accuracy: 0.8223 - precision_365: 0.8112 - recall_365: 0.8333 - val_loss: 3.0011 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3640 - accuracy: 0.8254 - precision_365: 0.8182 - recall_365: 0.8394 - val_loss: 3.0672 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3705 - accuracy: 0.8291 - precision_365: 0.8150 - recall_365: 0.8482 - val_loss: 3.0976 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3660 - accuracy: 0.8347 - precision_365: 0.8269 - recall_365: 0.8465 - val_loss: 3.1073 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3774 - accuracy: 0.8235 - precision_365: 0.8022 - recall_365: 0.8478 - val_loss: 3.1111 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3773 - accuracy: 0.8238 - precision_365: 0.8147 - recall_365: 0.8327 - val_loss: 3.2352 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3758 - accuracy: 0.8279 - precision_365: 0.8272 - recall_365: 0.8361 - val_loss: 3.3788 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3797 - accuracy: 0.8215 - precision_365: 0.8078 - recall_365: 0.8346 - val_loss: 3.4610 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3654 - accuracy: 0.8307 - precision_365: 0.8205 - recall_365: 0.8416 - val_loss: 3.4853 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3549 - accuracy: 0.8399 - precision_365: 0.8314 - recall_365: 0.8497 - val_loss: 3.4839 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.3536 - accuracy: 0.8433 - precision_365: 0.8360 - recall_365: 0.8566 - val_loss: 3.5009 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3708 - accuracy: 0.8298 - precision_365: 0.8065 - recall_365: 0.8533 - val_loss: 3.5593 - val_accuracy: 0.5142 - val_precision_365: 0.5142 - val_recall_365: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.5, batch_size=400, activation=gelu, AUC=0.393, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  21.5s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.5, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 185ms/step - loss: 0.6142 - accuracy: 0.6381 - precision_366: 0.6322 - recall_366: 0.6693 - val_loss: 28.6744 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.4894 - accuracy: 0.7637 - precision_366: 0.7573 - recall_366: 0.7727 - val_loss: 44.8201 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.4522 - accuracy: 0.7917 - precision_366: 0.7819 - recall_366: 0.7986 - val_loss: 38.7767 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4072 - accuracy: 0.8094 - precision_366: 0.8015 - recall_366: 0.8302 - val_loss: 27.0184 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4107 - accuracy: 0.8004 - precision_366: 0.7893 - recall_366: 0.8182 - val_loss: 20.0782 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.4090 - accuracy: 0.8048 - precision_366: 0.7997 - recall_366: 0.8078 - val_loss: 15.8805 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.4065 - accuracy: 0.8078 - precision_366: 0.7908 - recall_366: 0.8186 - val_loss: 12.2848 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3852 - accuracy: 0.8300 - precision_366: 0.8179 - recall_366: 0.8409 - val_loss: 10.3419 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3750 - accuracy: 0.8306 - precision_366: 0.8148 - recall_366: 0.8499 - val_loss: 8.4859 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3894 - accuracy: 0.8231 - precision_366: 0.8078 - recall_366: 0.8371 - val_loss: 7.0621 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3673 - accuracy: 0.8320 - precision_366: 0.8267 - recall_366: 0.8443 - val_loss: 4.3654 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3562 - accuracy: 0.8430 - precision_366: 0.8385 - recall_366: 0.8522 - val_loss: 4.6035 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3659 - accuracy: 0.8317 - precision_366: 0.8206 - recall_366: 0.8417 - val_loss: 5.0020 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3637 - accuracy: 0.8364 - precision_366: 0.8272 - recall_366: 0.8472 - val_loss: 4.2164 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3568 - accuracy: 0.8367 - precision_366: 0.8254 - recall_366: 0.8504 - val_loss: 3.3777 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3435 - accuracy: 0.8401 - precision_366: 0.8277 - recall_366: 0.8545 - val_loss: 2.7724 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3481 - accuracy: 0.8467 - precision_366: 0.8358 - recall_366: 0.8573 - val_loss: 2.0969 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3646 - accuracy: 0.8350 - precision_366: 0.8395 - recall_366: 0.8383 - val_loss: 1.6373 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3552 - accuracy: 0.8341 - precision_366: 0.8240 - recall_366: 0.8524 - val_loss: 1.3397 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3551 - accuracy: 0.8426 - precision_366: 0.8207 - recall_366: 0.8628 - val_loss: 1.0339 - val_accuracy: 0.5142 - val_precision_366: 0.5142 - val_recall_366: 1.0000\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3392 - accuracy: 0.8495 - precision_366: 0.8369 - recall_366: 0.8634 - val_loss: 0.7852 - val_accuracy: 0.6100 - val_precision_366: 0.5688 - val_recall_366: 0.9984\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3504 - accuracy: 0.8406 - precision_366: 0.8216 - recall_366: 0.8641 - val_loss: 0.6613 - val_accuracy: 0.6967 - val_precision_366: 0.6371 - val_recall_366: 0.9530\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3545 - accuracy: 0.8423 - precision_366: 0.8238 - recall_366: 0.8618 - val_loss: 0.5773 - val_accuracy: 0.7442 - val_precision_366: 0.6914 - val_recall_366: 0.9076\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3358 - accuracy: 0.8492 - precision_366: 0.8410 - recall_366: 0.8593 - val_loss: 0.5939 - val_accuracy: 0.7567 - val_precision_366: 0.7223 - val_recall_366: 0.8558\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3379 - accuracy: 0.8412 - precision_366: 0.8279 - recall_366: 0.8589 - val_loss: 0.6696 - val_accuracy: 0.7475 - val_precision_366: 0.6982 - val_recall_366: 0.8963\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3473 - accuracy: 0.8373 - precision_366: 0.8297 - recall_366: 0.8465 - val_loss: 0.7206 - val_accuracy: 0.7517 - val_precision_366: 0.7069 - val_recall_366: 0.8833\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3453 - accuracy: 0.8421 - precision_366: 0.8294 - recall_366: 0.8587 - val_loss: 0.7943 - val_accuracy: 0.7408 - val_precision_366: 0.6913 - val_recall_366: 0.8963\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3366 - accuracy: 0.8500 - precision_366: 0.8409 - recall_366: 0.8639 - val_loss: 0.8410 - val_accuracy: 0.7417 - val_precision_366: 0.6926 - val_recall_366: 0.8947\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3579 - accuracy: 0.8344 - precision_366: 0.8393 - recall_366: 0.8371 - val_loss: 0.8843 - val_accuracy: 0.7417 - val_precision_366: 0.6936 - val_recall_366: 0.8914\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3455 - accuracy: 0.8435 - precision_366: 0.8250 - recall_366: 0.8643 - val_loss: 0.9287 - val_accuracy: 0.7458 - val_precision_366: 0.6985 - val_recall_366: 0.8898\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3401 - accuracy: 0.8499 - precision_366: 0.8393 - recall_366: 0.8624 - val_loss: 0.9726 - val_accuracy: 0.7433 - val_precision_366: 0.6958 - val_recall_366: 0.8898\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3524 - accuracy: 0.8395 - precision_366: 0.8278 - recall_366: 0.8512 - val_loss: 1.0114 - val_accuracy: 0.7392 - val_precision_366: 0.6910 - val_recall_366: 0.8914\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3439 - accuracy: 0.8404 - precision_366: 0.8263 - recall_366: 0.8616 - val_loss: 1.0487 - val_accuracy: 0.7383 - val_precision_366: 0.6901 - val_recall_366: 0.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.5, batch_size=400, activation=gelu, AUC=0.837, Accuracy=0.738, f2=0.825, prec=0.686, rec=0.869, total=  34.5s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.25, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 180ms/step - loss: 0.7012 - accuracy: 0.6485 - precision_367: 0.6348 - recall_367: 0.6537 - val_loss: 0.8326 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.4602 - accuracy: 0.7822 - precision_367: 0.7643 - recall_367: 0.7968 - val_loss: 0.7300 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.4269 - accuracy: 0.7953 - precision_367: 0.7998 - recall_367: 0.7855 - val_loss: 4.2844 - val_accuracy: 0.4858 - val_precision_367: 0.0000e+00 - val_recall_367: 0.0000e+00\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.4146 - accuracy: 0.8065 - precision_367: 0.7979 - recall_367: 0.8174 - val_loss: 0.8451 - val_accuracy: 0.4367 - val_precision_367: 0.2748 - val_recall_367: 0.0583\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3861 - accuracy: 0.8266 - precision_367: 0.8220 - recall_367: 0.8328 - val_loss: 1.9852 - val_accuracy: 0.4858 - val_precision_367: 0.0000e+00 - val_recall_367: 0.0000e+00\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3813 - accuracy: 0.8225 - precision_367: 0.8092 - recall_367: 0.8405 - val_loss: 1.4213 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3770 - accuracy: 0.8284 - precision_367: 0.8195 - recall_367: 0.8363 - val_loss: 2.4140 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3694 - accuracy: 0.8314 - precision_367: 0.8232 - recall_367: 0.8448 - val_loss: 2.8670 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3779 - accuracy: 0.8294 - precision_367: 0.8155 - recall_367: 0.8473 - val_loss: 3.1662 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3474 - accuracy: 0.8408 - precision_367: 0.8298 - recall_367: 0.8556 - val_loss: 3.4659 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3735 - accuracy: 0.8251 - precision_367: 0.8188 - recall_367: 0.8349 - val_loss: 3.6657 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3685 - accuracy: 0.8240 - precision_367: 0.8067 - recall_367: 0.8392 - val_loss: 3.8180 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3666 - accuracy: 0.8327 - precision_367: 0.8289 - recall_367: 0.8388 - val_loss: 3.9501 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3714 - accuracy: 0.8239 - precision_367: 0.8274 - recall_367: 0.8238 - val_loss: 4.0629 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3746 - accuracy: 0.8317 - precision_367: 0.8177 - recall_367: 0.8463 - val_loss: 4.1560 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3647 - accuracy: 0.8296 - precision_367: 0.8167 - recall_367: 0.8451 - val_loss: 4.2327 - val_accuracy: 0.5142 - val_precision_367: 0.5142 - val_recall_367: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.25, batch_size=400, activation=gelu, AUC=0.417, Accuracy=0.497, f2=0.832, prec=0.497, rec=1.000, total=  17.8s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.25, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 185ms/step - loss: 0.7004 - accuracy: 0.6560 - precision_368: 0.6423 - recall_368: 0.6663 - val_loss: 8.4177 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4550 - accuracy: 0.7818 - precision_368: 0.7776 - recall_368: 0.7884 - val_loss: 19.1138 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3991 - accuracy: 0.8204 - precision_368: 0.8163 - recall_368: 0.8196 - val_loss: 23.2145 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.3673 - accuracy: 0.8272 - precision_368: 0.8141 - recall_368: 0.8499 - val_loss: 16.2482 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3606 - accuracy: 0.8432 - precision_368: 0.8247 - recall_368: 0.8631 - val_loss: 13.6546 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3650 - accuracy: 0.8313 - precision_368: 0.8239 - recall_368: 0.8359 - val_loss: 11.2753 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3776 - accuracy: 0.8242 - precision_368: 0.8138 - recall_368: 0.8356 - val_loss: 9.5139 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3709 - accuracy: 0.8318 - precision_368: 0.8268 - recall_368: 0.8409 - val_loss: 8.4305 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3733 - accuracy: 0.8306 - precision_368: 0.8040 - recall_368: 0.8601 - val_loss: 7.6010 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3476 - accuracy: 0.8445 - precision_368: 0.8395 - recall_368: 0.8520 - val_loss: 6.9712 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3674 - accuracy: 0.8309 - precision_368: 0.8248 - recall_368: 0.8409 - val_loss: 6.4588 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3605 - accuracy: 0.8393 - precision_368: 0.8203 - recall_368: 0.8610 - val_loss: 6.0588 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3553 - accuracy: 0.8437 - precision_368: 0.8404 - recall_368: 0.8539 - val_loss: 5.7486 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3695 - accuracy: 0.8302 - precision_368: 0.8140 - recall_368: 0.8483 - val_loss: 5.4446 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3582 - accuracy: 0.8422 - precision_368: 0.8388 - recall_368: 0.8526 - val_loss: 5.2177 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3696 - accuracy: 0.8259 - precision_368: 0.8087 - recall_368: 0.8461 - val_loss: 5.0031 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3629 - accuracy: 0.8314 - precision_368: 0.8199 - recall_368: 0.8505 - val_loss: 4.8096 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3490 - accuracy: 0.8427 - precision_368: 0.8253 - recall_368: 0.8634 - val_loss: 4.6439 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3508 - accuracy: 0.8412 - precision_368: 0.8246 - recall_368: 0.8621 - val_loss: 4.5103 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3587 - accuracy: 0.8314 - precision_368: 0.8087 - recall_368: 0.8557 - val_loss: 4.4861 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3649 - accuracy: 0.8323 - precision_368: 0.8208 - recall_368: 0.8451 - val_loss: 4.5226 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3603 - accuracy: 0.8369 - precision_368: 0.8291 - recall_368: 0.8438 - val_loss: 4.6580 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.3669 - accuracy: 0.8333 - precision_368: 0.8263 - recall_368: 0.8506 - val_loss: 4.5979 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3574 - accuracy: 0.8375 - precision_368: 0.8222 - recall_368: 0.8548 - val_loss: 4.5063 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3550 - accuracy: 0.8373 - precision_368: 0.8263 - recall_368: 0.8509 - val_loss: 4.3949 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3631 - accuracy: 0.8285 - precision_368: 0.8174 - recall_368: 0.8444 - val_loss: 4.2813 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3596 - accuracy: 0.8352 - precision_368: 0.8284 - recall_368: 0.8438 - val_loss: 4.1859 - val_accuracy: 0.5142 - val_precision_368: 0.5142 - val_recall_368: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.25, batch_size=400, activation=gelu, AUC=0.536, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  28.3s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.25, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 185ms/step - loss: 0.7333 - accuracy: 0.6529 - precision_369: 0.6510 - recall_369: 0.6649 - val_loss: 78.5717 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.4639 - accuracy: 0.7807 - precision_369: 0.7786 - recall_369: 0.7779 - val_loss: 76.8100 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.4385 - accuracy: 0.7914 - precision_369: 0.7935 - recall_369: 0.7901 - val_loss: 40.6645 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3920 - accuracy: 0.8177 - precision_369: 0.8191 - recall_369: 0.8199 - val_loss: 15.8088 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3825 - accuracy: 0.8206 - precision_369: 0.8156 - recall_369: 0.8251 - val_loss: 42.2274 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3649 - accuracy: 0.8351 - precision_369: 0.8316 - recall_369: 0.8403 - val_loss: 5.3330 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3452 - accuracy: 0.8470 - precision_369: 0.8355 - recall_369: 0.8544 - val_loss: 5.9638 - val_accuracy: 0.4858 - val_precision_369: 0.0000e+00 - val_recall_369: 0.0000e+00\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3394 - accuracy: 0.8509 - precision_369: 0.8390 - recall_369: 0.8628 - val_loss: 9.9793 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3302 - accuracy: 0.8501 - precision_369: 0.8297 - recall_369: 0.8742 - val_loss: 22.0192 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3306 - accuracy: 0.8486 - precision_369: 0.8470 - recall_369: 0.8529 - val_loss: 13.5381 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3185 - accuracy: 0.8624 - precision_369: 0.8517 - recall_369: 0.8769 - val_loss: 13.0239 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3060 - accuracy: 0.8650 - precision_369: 0.8490 - recall_369: 0.8829 - val_loss: 12.7968 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.2987 - accuracy: 0.8695 - precision_369: 0.8663 - recall_369: 0.8750 - val_loss: 11.2546 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.2931 - accuracy: 0.8779 - precision_369: 0.8742 - recall_369: 0.8838 - val_loss: 9.8402 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3075 - accuracy: 0.8580 - precision_369: 0.8526 - recall_369: 0.8676 - val_loss: 8.8909 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3048 - accuracy: 0.8649 - precision_369: 0.8613 - recall_369: 0.8738 - val_loss: 8.0522 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.2927 - accuracy: 0.8761 - precision_369: 0.8653 - recall_369: 0.8861 - val_loss: 7.3242 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.2936 - accuracy: 0.8707 - precision_369: 0.8634 - recall_369: 0.8822 - val_loss: 6.6609 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3048 - accuracy: 0.8635 - precision_369: 0.8470 - recall_369: 0.8825 - val_loss: 6.0454 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.2908 - accuracy: 0.8701 - precision_369: 0.8634 - recall_369: 0.8814 - val_loss: 5.4802 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.2915 - accuracy: 0.8697 - precision_369: 0.8573 - recall_369: 0.8813 - val_loss: 4.9672 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3077 - accuracy: 0.8610 - precision_369: 0.8545 - recall_369: 0.8714 - val_loss: 4.4903 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.3012 - accuracy: 0.8689 - precision_369: 0.8540 - recall_369: 0.8826 - val_loss: 4.0517 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3007 - accuracy: 0.8639 - precision_369: 0.8547 - recall_369: 0.8755 - val_loss: 3.6444 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3141 - accuracy: 0.8569 - precision_369: 0.8564 - recall_369: 0.8586 - val_loss: 3.2709 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.2931 - accuracy: 0.8686 - precision_369: 0.8736 - recall_369: 0.8705 - val_loss: 2.9249 - val_accuracy: 0.5142 - val_precision_369: 0.5142 - val_recall_369: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.25, batch_size=400, activation=gelu, AUC=0.893, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  27.3s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 25ms/step - loss: 0.6724 - accuracy: 0.7199 - precision_370: 0.7175 - recall_370: 0.7158 - val_loss: 20.1767 - val_accuracy: 0.5142 - val_precision_370: 0.5142 - val_recall_370: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4459 - accuracy: 0.7999 - precision_370: 0.7833 - recall_370: 0.8141 - val_loss: 142.5526 - val_accuracy: 0.4858 - val_precision_370: 0.0000e+00 - val_recall_370: 0.0000e+00\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4160 - accuracy: 0.8155 - precision_370: 0.7997 - recall_370: 0.8534 - val_loss: 13.3826 - val_accuracy: 0.5142 - val_precision_370: 0.5142 - val_recall_370: 1.0000\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3969 - accuracy: 0.8150 - precision_370: 0.8156 - recall_370: 0.8142 - val_loss: 35.5228 - val_accuracy: 0.5142 - val_precision_370: 0.5142 - val_recall_370: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3873 - accuracy: 0.8184 - precision_370: 0.8104 - recall_370: 0.8280 - val_loss: 7.5580 - val_accuracy: 0.5142 - val_precision_370: 0.5142 - val_recall_370: 1.0000\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3724 - accuracy: 0.8286 - precision_370: 0.8250 - recall_370: 0.8355 - val_loss: 0.8036 - val_accuracy: 0.6417 - val_precision_370: 0.8912 - val_recall_370: 0.3452\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3701 - accuracy: 0.8286 - precision_370: 0.8193 - recall_370: 0.8354 - val_loss: 204.5318 - val_accuracy: 0.4858 - val_precision_370: 0.0000e+00 - val_recall_370: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3617 - accuracy: 0.8417 - precision_370: 0.8356 - recall_370: 0.8499 - val_loss: 71.3793 - val_accuracy: 0.4858 - val_precision_370: 0.0000e+00 - val_recall_370: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3348 - accuracy: 0.8533 - precision_370: 0.8307 - recall_370: 0.8783 - val_loss: 145.3333 - val_accuracy: 0.4858 - val_precision_370: 0.0000e+00 - val_recall_370: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3053 - accuracy: 0.8797 - precision_370: 0.8667 - recall_370: 0.8998 - val_loss: 151.3951 - val_accuracy: 0.4858 - val_precision_370: 0.0000e+00 - val_recall_370: 0.0000e+00\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3021 - accuracy: 0.8626 - precision_370: 0.8408 - recall_370: 0.8848 - val_loss: 372.0351 - val_accuracy: 0.4858 - val_precision_370: 0.0000e+00 - val_recall_370: 0.0000e+00\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2618 - accuracy: 0.8863 - precision_370: 0.8866 - recall_370: 0.8892 - val_loss: 176.6679 - val_accuracy: 0.4858 - val_precision_370: 0.0000e+00 - val_recall_370: 0.0000e+00\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2639 - accuracy: 0.8858 - precision_370: 0.8720 - recall_370: 0.9010 - val_loss: 39.2244 - val_accuracy: 0.4858 - val_precision_370: 0.0000e+00 - val_recall_370: 0.0000e+00\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2539 - accuracy: 0.8920 - precision_370: 0.8864 - recall_370: 0.8935 - val_loss: 8.4793 - val_accuracy: 0.4858 - val_precision_370: 0.0000e+00 - val_recall_370: 0.0000e+00\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2707 - accuracy: 0.8793 - precision_370: 0.8792 - recall_370: 0.8774 - val_loss: 3.3471 - val_accuracy: 0.4875 - val_precision_370: 1.0000 - val_recall_370: 0.0032\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2586 - accuracy: 0.8918 - precision_370: 0.8775 - recall_370: 0.9046 - val_loss: 1.3558 - val_accuracy: 0.5867 - val_precision_370: 0.9764 - val_recall_370: 0.2010\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2504 - accuracy: 0.8985 - precision_370: 0.8929 - recall_370: 0.9042 - val_loss: 0.6787 - val_accuracy: 0.7258 - val_precision_370: 0.9364 - val_recall_370: 0.5008\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2538 - accuracy: 0.8891 - precision_370: 0.8798 - recall_370: 0.8950 - val_loss: 0.4557 - val_accuracy: 0.7858 - val_precision_370: 0.8689 - val_recall_370: 0.6872\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2569 - accuracy: 0.8923 - precision_370: 0.8900 - recall_370: 0.8940 - val_loss: 0.3935 - val_accuracy: 0.8283 - val_precision_370: 0.8513 - val_recall_370: 0.8071\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2611 - accuracy: 0.8845 - precision_370: 0.8767 - recall_370: 0.8871 - val_loss: 0.3845 - val_accuracy: 0.8375 - val_precision_370: 0.8403 - val_recall_370: 0.8444\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2677 - accuracy: 0.8802 - precision_370: 0.8548 - recall_370: 0.9094 - val_loss: 0.3856 - val_accuracy: 0.8317 - val_precision_370: 0.8227 - val_recall_370: 0.8574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu, AUC=0.915, Accuracy=0.835, f2=0.844, prec=0.824, rec=0.849, total=  27.4s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 26ms/step - loss: 0.5920 - accuracy: 0.7453 - precision_371: 0.7456 - recall_371: 0.7395 - val_loss: 13.2527 - val_accuracy: 0.5142 - val_precision_371: 0.5142 - val_recall_371: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4197 - accuracy: 0.8016 - precision_371: 0.7925 - recall_371: 0.8193 - val_loss: 4.0032 - val_accuracy: 0.5142 - val_precision_371: 0.5142 - val_recall_371: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4127 - accuracy: 0.8111 - precision_371: 0.8136 - recall_371: 0.8174 - val_loss: 48.1399 - val_accuracy: 0.4858 - val_precision_371: 0.0000e+00 - val_recall_371: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3852 - accuracy: 0.8152 - precision_371: 0.8144 - recall_371: 0.8214 - val_loss: 6.3326 - val_accuracy: 0.5142 - val_precision_371: 0.5142 - val_recall_371: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3448 - accuracy: 0.8462 - precision_371: 0.8424 - recall_371: 0.8516 - val_loss: 1.2152 - val_accuracy: 0.5983 - val_precision_371: 0.5614 - val_recall_371: 1.0000\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3333 - accuracy: 0.8574 - precision_371: 0.8486 - recall_371: 0.8714 - val_loss: 6.5338 - val_accuracy: 0.5142 - val_precision_371: 0.5142 - val_recall_371: 1.0000\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3198 - accuracy: 0.8584 - precision_371: 0.8501 - recall_371: 0.8674 - val_loss: 9.6463 - val_accuracy: 0.4858 - val_precision_371: 0.0000e+00 - val_recall_371: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3017 - accuracy: 0.8749 - precision_371: 0.8725 - recall_371: 0.8792 - val_loss: 8.4216 - val_accuracy: 0.4858 - val_precision_371: 0.0000e+00 - val_recall_371: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2907 - accuracy: 0.8793 - precision_371: 0.8650 - recall_371: 0.8881 - val_loss: 1.8528 - val_accuracy: 0.5542 - val_precision_371: 0.5356 - val_recall_371: 1.0000\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2928 - accuracy: 0.8783 - precision_371: 0.8660 - recall_371: 0.8954 - val_loss: 0.3766 - val_accuracy: 0.8258 - val_precision_371: 0.8322 - val_recall_371: 0.8282\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2967 - accuracy: 0.8706 - precision_371: 0.8520 - recall_371: 0.8880 - val_loss: 0.3957 - val_accuracy: 0.8175 - val_precision_371: 0.8528 - val_recall_371: 0.7796\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2939 - accuracy: 0.8758 - precision_371: 0.8883 - recall_371: 0.8717 - val_loss: 0.4102 - val_accuracy: 0.8233 - val_precision_371: 0.7809 - val_recall_371: 0.9125\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2852 - accuracy: 0.8761 - precision_371: 0.8610 - recall_371: 0.8899 - val_loss: 0.3652 - val_accuracy: 0.8300 - val_precision_371: 0.8242 - val_recall_371: 0.8509\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2821 - accuracy: 0.8832 - precision_371: 0.8712 - recall_371: 0.8962 - val_loss: 0.3690 - val_accuracy: 0.8275 - val_precision_371: 0.8042 - val_recall_371: 0.8784\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2918 - accuracy: 0.8748 - precision_371: 0.8666 - recall_371: 0.8865 - val_loss: 0.3673 - val_accuracy: 0.8333 - val_precision_371: 0.8107 - val_recall_371: 0.8817\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2814 - accuracy: 0.8804 - precision_371: 0.8674 - recall_371: 0.8975 - val_loss: 0.3668 - val_accuracy: 0.8333 - val_precision_371: 0.8107 - val_recall_371: 0.8817\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2716 - accuracy: 0.8917 - precision_371: 0.8729 - recall_371: 0.9102 - val_loss: 0.3699 - val_accuracy: 0.8258 - val_precision_371: 0.8000 - val_recall_371: 0.8817\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2903 - accuracy: 0.8732 - precision_371: 0.8691 - recall_371: 0.8765 - val_loss: 0.3704 - val_accuracy: 0.8258 - val_precision_371: 0.7991 - val_recall_371: 0.8833\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2839 - accuracy: 0.8740 - precision_371: 0.8685 - recall_371: 0.8768 - val_loss: 0.3723 - val_accuracy: 0.8275 - val_precision_371: 0.7997 - val_recall_371: 0.8865\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2931 - accuracy: 0.8753 - precision_371: 0.8710 - recall_371: 0.8834 - val_loss: 0.3708 - val_accuracy: 0.8275 - val_precision_371: 0.8006 - val_recall_371: 0.8849\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2838 - accuracy: 0.8909 - precision_371: 0.8841 - recall_371: 0.9030 - val_loss: 0.3737 - val_accuracy: 0.8300 - val_precision_371: 0.8006 - val_recall_371: 0.8914\n",
      "Epoch 22/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2824 - accuracy: 0.8817 - precision_371: 0.8746 - recall_371: 0.8929 - val_loss: 0.3720 - val_accuracy: 0.8267 - val_precision_371: 0.7994 - val_recall_371: 0.8849\n",
      "Epoch 23/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3045 - accuracy: 0.8654 - precision_371: 0.8310 - recall_371: 0.8983 - val_loss: 0.3724 - val_accuracy: 0.8283 - val_precision_371: 0.8000 - val_recall_371: 0.8882\n",
      "Epoch 24/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2837 - accuracy: 0.8783 - precision_371: 0.8728 - recall_371: 0.8825 - val_loss: 0.3716 - val_accuracy: 0.8275 - val_precision_371: 0.7997 - val_recall_371: 0.8865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu, AUC=0.891, Accuracy=0.807, f2=0.847, prec=0.771, rec=0.869, total=  31.6s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 26ms/step - loss: 0.7461 - accuracy: 0.7110 - precision_372: 0.7064 - recall_372: 0.7095 - val_loss: 12.4978 - val_accuracy: 0.5142 - val_precision_372: 0.5142 - val_recall_372: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4324 - accuracy: 0.8015 - precision_372: 0.8001 - recall_372: 0.7978 - val_loss: 9.3465 - val_accuracy: 0.5142 - val_precision_372: 0.5142 - val_recall_372: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4231 - accuracy: 0.8040 - precision_372: 0.7900 - recall_372: 0.8117 - val_loss: 214.1370 - val_accuracy: 0.4858 - val_precision_372: 0.0000e+00 - val_recall_372: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4023 - accuracy: 0.8138 - precision_372: 0.8037 - recall_372: 0.8350 - val_loss: 5.2968 - val_accuracy: 0.5142 - val_precision_372: 0.5142 - val_recall_372: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3759 - accuracy: 0.8244 - precision_372: 0.8195 - recall_372: 0.8250 - val_loss: 551.4768 - val_accuracy: 0.4858 - val_precision_372: 0.0000e+00 - val_recall_372: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3597 - accuracy: 0.8368 - precision_372: 0.8364 - recall_372: 0.8427 - val_loss: 99.7581 - val_accuracy: 0.4858 - val_precision_372: 0.0000e+00 - val_recall_372: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3696 - accuracy: 0.8307 - precision_372: 0.8358 - recall_372: 0.8293 - val_loss: 70.7131 - val_accuracy: 0.4858 - val_precision_372: 0.0000e+00 - val_recall_372: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3175 - accuracy: 0.8575 - precision_372: 0.8493 - recall_372: 0.8630 - val_loss: 104.4476 - val_accuracy: 0.4858 - val_precision_372: 0.0000e+00 - val_recall_372: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3080 - accuracy: 0.8632 - precision_372: 0.8618 - recall_372: 0.8666 - val_loss: 87.6239 - val_accuracy: 0.4858 - val_precision_372: 0.0000e+00 - val_recall_372: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2834 - accuracy: 0.8812 - precision_372: 0.8773 - recall_372: 0.8870 - val_loss: 2.7169 - val_accuracy: 0.4900 - val_precision_372: 1.0000 - val_recall_372: 0.0081\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2949 - accuracy: 0.8701 - precision_372: 0.8725 - recall_372: 0.8706 - val_loss: 36.9613 - val_accuracy: 0.4858 - val_precision_372: 0.0000e+00 - val_recall_372: 0.0000e+00\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2826 - accuracy: 0.8717 - precision_372: 0.8639 - recall_372: 0.8819 - val_loss: 0.6774 - val_accuracy: 0.7583 - val_precision_372: 0.6847 - val_recall_372: 0.9822\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2552 - accuracy: 0.8890 - precision_372: 0.8801 - recall_372: 0.8975 - val_loss: 3.2425 - val_accuracy: 0.4858 - val_precision_372: 0.0000e+00 - val_recall_372: 0.0000e+00\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2640 - accuracy: 0.8851 - precision_372: 0.8803 - recall_372: 0.8845 - val_loss: 7.9595 - val_accuracy: 0.5142 - val_precision_372: 0.5142 - val_recall_372: 1.0000\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2559 - accuracy: 0.8785 - precision_372: 0.8601 - recall_372: 0.9011 - val_loss: 0.6816 - val_accuracy: 0.7475 - val_precision_372: 0.6733 - val_recall_372: 0.9887\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2674 - accuracy: 0.8814 - precision_372: 0.8835 - recall_372: 0.8868 - val_loss: 1.3437 - val_accuracy: 0.5750 - val_precision_372: 0.9820 - val_recall_372: 0.1767\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2523 - accuracy: 0.8933 - precision_372: 0.8831 - recall_372: 0.9028 - val_loss: 0.5461 - val_accuracy: 0.7458 - val_precision_372: 0.8939 - val_recall_372: 0.5737\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2454 - accuracy: 0.8938 - precision_372: 0.8974 - recall_372: 0.8937 - val_loss: 0.4262 - val_accuracy: 0.7992 - val_precision_372: 0.8760 - val_recall_372: 0.7099\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2508 - accuracy: 0.8935 - precision_372: 0.8902 - recall_372: 0.8992 - val_loss: 0.4046 - val_accuracy: 0.8067 - val_precision_372: 0.8639 - val_recall_372: 0.7407\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2522 - accuracy: 0.8935 - precision_372: 0.9013 - recall_372: 0.8876 - val_loss: 0.4172 - val_accuracy: 0.7992 - val_precision_372: 0.8658 - val_recall_372: 0.7212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu, AUC=0.906, Accuracy=0.811, f2=0.751, prec=0.873, rec=0.725, total=  26.4s\n",
      "[CV] lr=0.01, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=200, activation=gelu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 3s 100ms/step - loss: 0.8729 - accuracy: 0.6692 - precision_373: 0.6664 - recall_373: 0.6717 - val_loss: 834.2474 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.4890 - accuracy: 0.7562 - precision_373: 0.7632 - recall_373: 0.7275 - val_loss: 347.7311 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.4481 - accuracy: 0.7934 - precision_373: 0.7943 - recall_373: 0.8033 - val_loss: 117.0838 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.4436 - accuracy: 0.7903 - precision_373: 0.7955 - recall_373: 0.7726 - val_loss: 63.2143 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.4287 - accuracy: 0.8017 - precision_373: 0.7961 - recall_373: 0.8078 - val_loss: 40.6049 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3894 - accuracy: 0.8255 - precision_373: 0.8253 - recall_373: 0.8244 - val_loss: 19.3389 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3907 - accuracy: 0.8190 - precision_373: 0.8207 - recall_373: 0.8148 - val_loss: 13.0155 - val_accuracy: 0.4858 - val_precision_373: 0.0000e+00 - val_recall_373: 0.0000e+00\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3788 - accuracy: 0.8175 - precision_373: 0.8152 - recall_373: 0.8184 - val_loss: 1.0108 - val_accuracy: 0.5317 - val_precision_373: 0.5461 - val_recall_373: 0.5284\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.4021 - accuracy: 0.8118 - precision_373: 0.8090 - recall_373: 0.8218 - val_loss: 0.7036 - val_accuracy: 0.6708 - val_precision_373: 0.8854 - val_recall_373: 0.4133\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3721 - accuracy: 0.8215 - precision_373: 0.8047 - recall_373: 0.8391 - val_loss: 2.9372 - val_accuracy: 0.5150 - val_precision_373: 0.5146 - val_recall_373: 1.0000\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3842 - accuracy: 0.8222 - precision_373: 0.8084 - recall_373: 0.8451 - val_loss: 40.6036 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3804 - accuracy: 0.8181 - precision_373: 0.8026 - recall_373: 0.8419 - val_loss: 33.1308 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3541 - accuracy: 0.8364 - precision_373: 0.8346 - recall_373: 0.8425 - val_loss: 21.7591 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3583 - accuracy: 0.8283 - precision_373: 0.8120 - recall_373: 0.8476 - val_loss: 15.9325 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3346 - accuracy: 0.8491 - precision_373: 0.8361 - recall_373: 0.8667 - val_loss: 12.1364 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3402 - accuracy: 0.8469 - precision_373: 0.8325 - recall_373: 0.8637 - val_loss: 9.5889 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3378 - accuracy: 0.8495 - precision_373: 0.8410 - recall_373: 0.8611 - val_loss: 7.7877 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3427 - accuracy: 0.8406 - precision_373: 0.8416 - recall_373: 0.8462 - val_loss: 6.4496 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3396 - accuracy: 0.8467 - precision_373: 0.8269 - recall_373: 0.8685 - val_loss: 5.2976 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3522 - accuracy: 0.8368 - precision_373: 0.8267 - recall_373: 0.8470 - val_loss: 4.4313 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3484 - accuracy: 0.8456 - precision_373: 0.8437 - recall_373: 0.8549 - val_loss: 3.6518 - val_accuracy: 0.5142 - val_precision_373: 0.5142 - val_recall_373: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=200, activation=gelu, AUC=0.872, Accuracy=0.497, f2=0.832, prec=0.497, rec=1.000, total=  26.1s\n",
      "[CV] lr=0.01, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=200, activation=gelu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 3s 100ms/step - loss: 0.6574 - accuracy: 0.6852 - precision_374: 0.6797 - recall_374: 0.6888 - val_loss: 700.1465 - val_accuracy: 0.5142 - val_precision_374: 0.5142 - val_recall_374: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.4710 - accuracy: 0.7780 - precision_374: 0.7687 - recall_374: 0.7906 - val_loss: 265.9870 - val_accuracy: 0.5142 - val_precision_374: 0.5142 - val_recall_374: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.4348 - accuracy: 0.7961 - precision_374: 0.7971 - recall_374: 0.8020 - val_loss: 119.0538 - val_accuracy: 0.5142 - val_precision_374: 0.5142 - val_recall_374: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.4266 - accuracy: 0.8068 - precision_374: 0.7956 - recall_374: 0.8101 - val_loss: 71.6662 - val_accuracy: 0.5142 - val_precision_374: 0.5142 - val_recall_374: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.4157 - accuracy: 0.8042 - precision_374: 0.7823 - recall_374: 0.8365 - val_loss: 49.4699 - val_accuracy: 0.5142 - val_precision_374: 0.5142 - val_recall_374: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3873 - accuracy: 0.8224 - precision_374: 0.8110 - recall_374: 0.8361 - val_loss: 26.1582 - val_accuracy: 0.5142 - val_precision_374: 0.5142 - val_recall_374: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3877 - accuracy: 0.8196 - precision_374: 0.8119 - recall_374: 0.8353 - val_loss: 17.8702 - val_accuracy: 0.4858 - val_precision_374: 0.0000e+00 - val_recall_374: 0.0000e+00\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3683 - accuracy: 0.8348 - precision_374: 0.8347 - recall_374: 0.8272 - val_loss: 46.5806 - val_accuracy: 0.5142 - val_precision_374: 0.5142 - val_recall_374: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3904 - accuracy: 0.8186 - precision_374: 0.8057 - recall_374: 0.8349 - val_loss: 60.3554 - val_accuracy: 0.5142 - val_precision_374: 0.5142 - val_recall_374: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3800 - accuracy: 0.8260 - precision_374: 0.8201 - recall_374: 0.8390 - val_loss: 26.6281 - val_accuracy: 0.5142 - val_precision_374: 0.5142 - val_recall_374: 1.0000\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3733 - accuracy: 0.8274 - precision_374: 0.8175 - recall_374: 0.8376 - val_loss: 9.9832 - val_accuracy: 0.5142 - val_precision_374: 0.5142 - val_recall_374: 1.0000\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3596 - accuracy: 0.8439 - precision_374: 0.8321 - recall_374: 0.8582 - val_loss: 0.8332 - val_accuracy: 0.5175 - val_precision_374: 0.5159 - val_recall_374: 1.0000\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.3597 - accuracy: 0.8270 - precision_374: 0.8213 - recall_374: 0.8339 - val_loss: 3.4085 - val_accuracy: 0.4858 - val_precision_374: 0.0000e+00 - val_recall_374: 0.0000e+00\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3546 - accuracy: 0.8389 - precision_374: 0.8171 - recall_374: 0.8612 - val_loss: 56.0998 - val_accuracy: 0.4858 - val_precision_374: 0.0000e+00 - val_recall_374: 0.0000e+00\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3494 - accuracy: 0.8416 - precision_374: 0.8206 - recall_374: 0.8716 - val_loss: 33.9121 - val_accuracy: 0.4858 - val_precision_374: 0.0000e+00 - val_recall_374: 0.0000e+00\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.3308 - accuracy: 0.8475 - precision_374: 0.8357 - recall_374: 0.8627 - val_loss: 40.2146 - val_accuracy: 0.4858 - val_precision_374: 0.0000e+00 - val_recall_374: 0.0000e+00\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3445 - accuracy: 0.8449 - precision_374: 0.8310 - recall_374: 0.8640 - val_loss: 43.1270 - val_accuracy: 0.4858 - val_precision_374: 0.0000e+00 - val_recall_374: 0.0000e+00\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3367 - accuracy: 0.8478 - precision_374: 0.8321 - recall_374: 0.8671 - val_loss: 43.9493 - val_accuracy: 0.4858 - val_precision_374: 0.0000e+00 - val_recall_374: 0.0000e+00\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3445 - accuracy: 0.8528 - precision_374: 0.8282 - recall_374: 0.8802 - val_loss: 42.9054 - val_accuracy: 0.4858 - val_precision_374: 0.0000e+00 - val_recall_374: 0.0000e+00\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.3539 - accuracy: 0.8434 - precision_374: 0.8245 - recall_374: 0.8668 - val_loss: 41.1988 - val_accuracy: 0.4858 - val_precision_374: 0.0000e+00 - val_recall_374: 0.0000e+00\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3409 - accuracy: 0.8392 - precision_374: 0.8273 - recall_374: 0.8536 - val_loss: 37.7319 - val_accuracy: 0.4858 - val_precision_374: 0.0000e+00 - val_recall_374: 0.0000e+00\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3181 - accuracy: 0.8583 - precision_374: 0.8390 - recall_374: 0.8805 - val_loss: 33.8455 - val_accuracy: 0.4858 - val_precision_374: 0.0000e+00 - val_recall_374: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=200, activation=gelu, AUC=0.794, Accuracy=0.504, f2=0.000, prec=0.000, rec=0.000, total=  27.2s\n",
      "[CV] lr=0.01, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=200, activation=gelu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 3s 103ms/step - loss: 0.7105 - accuracy: 0.6694 - precision_375: 0.6717 - recall_375: 0.6608 - val_loss: 536.0428 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.4558 - accuracy: 0.7921 - precision_375: 0.7876 - recall_375: 0.7972 - val_loss: 173.0986 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.4221 - accuracy: 0.8051 - precision_375: 0.7949 - recall_375: 0.8107 - val_loss: 70.8180 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.3976 - accuracy: 0.8211 - precision_375: 0.8126 - recall_375: 0.8395 - val_loss: 20.2093 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3989 - accuracy: 0.8198 - precision_375: 0.8174 - recall_375: 0.8312 - val_loss: 27.6315 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3894 - accuracy: 0.8248 - precision_375: 0.8268 - recall_375: 0.8198 - val_loss: 24.4451 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.3912 - accuracy: 0.8154 - precision_375: 0.7940 - recall_375: 0.8468 - val_loss: 13.3435 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3881 - accuracy: 0.8212 - precision_375: 0.8056 - recall_375: 0.8476 - val_loss: 6.7055 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3529 - accuracy: 0.8410 - precision_375: 0.8437 - recall_375: 0.8429 - val_loss: 9.8060 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3456 - accuracy: 0.8400 - precision_375: 0.8337 - recall_375: 0.8487 - val_loss: 7.8115 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3339 - accuracy: 0.8512 - precision_375: 0.8331 - recall_375: 0.8743 - val_loss: 5.1779 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3487 - accuracy: 0.8436 - precision_375: 0.8225 - recall_375: 0.8650 - val_loss: 3.0677 - val_accuracy: 0.5142 - val_precision_375: 0.5142 - val_recall_375: 1.0000\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3408 - accuracy: 0.8470 - precision_375: 0.8405 - recall_375: 0.8642 - val_loss: 1.7903 - val_accuracy: 0.5150 - val_precision_375: 0.5146 - val_recall_375: 1.0000\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3484 - accuracy: 0.8444 - precision_375: 0.8194 - recall_375: 0.8660 - val_loss: 1.1066 - val_accuracy: 0.5275 - val_precision_375: 0.5213 - val_recall_375: 0.9903\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3300 - accuracy: 0.8519 - precision_375: 0.8420 - recall_375: 0.8636 - val_loss: 1.8153 - val_accuracy: 0.4883 - val_precision_375: 1.0000 - val_recall_375: 0.0049\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3281 - accuracy: 0.8528 - precision_375: 0.8388 - recall_375: 0.8698 - val_loss: 2.1117 - val_accuracy: 0.4875 - val_precision_375: 1.0000 - val_recall_375: 0.0032\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.3257 - accuracy: 0.8529 - precision_375: 0.8349 - recall_375: 0.8773 - val_loss: 1.2137 - val_accuracy: 0.5033 - val_precision_375: 0.9565 - val_recall_375: 0.0357\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3423 - accuracy: 0.8466 - precision_375: 0.8318 - recall_375: 0.8623 - val_loss: 1.5627 - val_accuracy: 0.4917 - val_precision_375: 0.8889 - val_recall_375: 0.0130\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3381 - accuracy: 0.8476 - precision_375: 0.8302 - recall_375: 0.8607 - val_loss: 1.4043 - val_accuracy: 0.4975 - val_precision_375: 0.9375 - val_recall_375: 0.0243\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.3428 - accuracy: 0.8418 - precision_375: 0.8426 - recall_375: 0.8445 - val_loss: 1.2720 - val_accuracy: 0.5142 - val_precision_375: 0.9722 - val_recall_375: 0.0567\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3154 - accuracy: 0.8582 - precision_375: 0.8316 - recall_375: 0.8832 - val_loss: 1.0869 - val_accuracy: 0.5417 - val_precision_375: 0.9855 - val_recall_375: 0.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.2, batch_size=200, activation=gelu, AUC=0.911, Accuracy=0.556, f2=0.133, prec=0.956, rec=0.110, total=  26.5s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 51ms/step - loss: 0.7145 - accuracy: 0.7028 - precision_376: 0.7055 - recall_376: 0.6987 - val_loss: 49.0992 - val_accuracy: 0.5142 - val_precision_376: 0.5142 - val_recall_376: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4668 - accuracy: 0.7813 - precision_376: 0.7774 - recall_376: 0.7921 - val_loss: 19.0104 - val_accuracy: 0.5142 - val_precision_376: 0.5142 - val_recall_376: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4100 - accuracy: 0.8198 - precision_376: 0.8155 - recall_376: 0.8221 - val_loss: 6.7839 - val_accuracy: 0.5142 - val_precision_376: 0.5142 - val_recall_376: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4139 - accuracy: 0.8047 - precision_376: 0.7924 - recall_376: 0.8349 - val_loss: 9.8660 - val_accuracy: 0.4858 - val_precision_376: 0.0000e+00 - val_recall_376: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3879 - accuracy: 0.8164 - precision_376: 0.8088 - recall_376: 0.8353 - val_loss: 11.2231 - val_accuracy: 0.5142 - val_precision_376: 0.5142 - val_recall_376: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3922 - accuracy: 0.8136 - precision_376: 0.7959 - recall_376: 0.8304 - val_loss: 8.0674 - val_accuracy: 0.5142 - val_precision_376: 0.5142 - val_recall_376: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3489 - accuracy: 0.8450 - precision_376: 0.8375 - recall_376: 0.8586 - val_loss: 1.7137 - val_accuracy: 0.5350 - val_precision_376: 0.5251 - val_recall_376: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3713 - accuracy: 0.8351 - precision_376: 0.8290 - recall_376: 0.8485 - val_loss: 51.6973 - val_accuracy: 0.4858 - val_precision_376: 0.0000e+00 - val_recall_376: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3476 - accuracy: 0.8422 - precision_376: 0.8412 - recall_376: 0.8463 - val_loss: 52.6569 - val_accuracy: 0.4858 - val_precision_376: 0.0000e+00 - val_recall_376: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3368 - accuracy: 0.8464 - precision_376: 0.8365 - recall_376: 0.8598 - val_loss: 59.5426 - val_accuracy: 0.4858 - val_precision_376: 0.0000e+00 - val_recall_376: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3317 - accuracy: 0.8474 - precision_376: 0.8474 - recall_376: 0.8553 - val_loss: 58.3489 - val_accuracy: 0.4950 - val_precision_376: 1.0000 - val_recall_376: 0.0178\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3237 - accuracy: 0.8563 - precision_376: 0.8442 - recall_376: 0.8687 - val_loss: 41.1455 - val_accuracy: 0.4917 - val_precision_376: 1.0000 - val_recall_376: 0.0113\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3306 - accuracy: 0.8615 - precision_376: 0.8469 - recall_376: 0.8781 - val_loss: 22.0111 - val_accuracy: 0.4858 - val_precision_376: 0.0000e+00 - val_recall_376: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3226 - accuracy: 0.8599 - precision_376: 0.8378 - recall_376: 0.8852 - val_loss: 8.0917 - val_accuracy: 0.4867 - val_precision_376: 1.0000 - val_recall_376: 0.0016\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3538 - accuracy: 0.8372 - precision_376: 0.8373 - recall_376: 0.8358 - val_loss: 2.7667 - val_accuracy: 0.4958 - val_precision_376: 1.0000 - val_recall_376: 0.0194\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3353 - accuracy: 0.8444 - precision_376: 0.8329 - recall_376: 0.8610 - val_loss: 1.6830 - val_accuracy: 0.5350 - val_precision_376: 0.9683 - val_recall_376: 0.0989\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3434 - accuracy: 0.8454 - precision_376: 0.8280 - recall_376: 0.8672 - val_loss: 1.0972 - val_accuracy: 0.6217 - val_precision_376: 0.9711 - val_recall_376: 0.2723\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3248 - accuracy: 0.8550 - precision_376: 0.8452 - recall_376: 0.8663 - val_loss: 0.7740 - val_accuracy: 0.6942 - val_precision_376: 0.9371 - val_recall_376: 0.4344\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3219 - accuracy: 0.8507 - precision_376: 0.8275 - recall_376: 0.8756 - val_loss: 0.6072 - val_accuracy: 0.7333 - val_precision_376: 0.9114 - val_recall_376: 0.5332\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3399 - accuracy: 0.8494 - precision_376: 0.8485 - recall_376: 0.8580 - val_loss: 0.4768 - val_accuracy: 0.7767 - val_precision_376: 0.8957 - val_recall_376: 0.6402\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3260 - accuracy: 0.8555 - precision_376: 0.8429 - recall_376: 0.8742 - val_loss: 0.4309 - val_accuracy: 0.7958 - val_precision_376: 0.8811 - val_recall_376: 0.6969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu, AUC=0.920, Accuracy=0.808, f2=0.735, prec=0.886, rec=0.704, total=  28.2s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 52ms/step - loss: 0.6395 - accuracy: 0.7100 - precision_377: 0.7069 - recall_377: 0.7056 - val_loss: 20.1455 - val_accuracy: 0.5142 - val_precision_377: 0.5142 - val_recall_377: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4143 - accuracy: 0.8069 - precision_377: 0.7977 - recall_377: 0.8245 - val_loss: 1.9134 - val_accuracy: 0.5142 - val_precision_377: 0.5142 - val_recall_377: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3915 - accuracy: 0.8171 - precision_377: 0.8007 - recall_377: 0.8408 - val_loss: 17.9766 - val_accuracy: 0.5142 - val_precision_377: 0.5142 - val_recall_377: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3911 - accuracy: 0.8154 - precision_377: 0.7974 - recall_377: 0.8423 - val_loss: 5.7103 - val_accuracy: 0.5142 - val_precision_377: 0.5142 - val_recall_377: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3650 - accuracy: 0.8361 - precision_377: 0.8238 - recall_377: 0.8479 - val_loss: 1.5136 - val_accuracy: 0.5658 - val_precision_377: 0.9286 - val_recall_377: 0.1686\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3509 - accuracy: 0.8359 - precision_377: 0.8050 - recall_377: 0.8769 - val_loss: 7.4183 - val_accuracy: 0.5142 - val_precision_377: 0.5142 - val_recall_377: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.3502 - accuracy: 0.8437 - precision_377: 0.8234 - recall_377: 0.8716 - val_loss: 1.9310 - val_accuracy: 0.5092 - val_precision_377: 1.0000 - val_recall_377: 0.0454\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3304 - accuracy: 0.8633 - precision_377: 0.8493 - recall_377: 0.8858 - val_loss: 2.8878 - val_accuracy: 0.5000 - val_precision_377: 1.0000 - val_recall_377: 0.0276\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3334 - accuracy: 0.8543 - precision_377: 0.8415 - recall_377: 0.8734 - val_loss: 3.6497 - val_accuracy: 0.4883 - val_precision_377: 1.0000 - val_recall_377: 0.0049\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3334 - accuracy: 0.8542 - precision_377: 0.8404 - recall_377: 0.8710 - val_loss: 3.8702 - val_accuracy: 0.4867 - val_precision_377: 1.0000 - val_recall_377: 0.0016\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3424 - accuracy: 0.8456 - precision_377: 0.8308 - recall_377: 0.8602 - val_loss: 2.4931 - val_accuracy: 0.5025 - val_precision_377: 1.0000 - val_recall_377: 0.0324\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3656 - accuracy: 0.8362 - precision_377: 0.8171 - recall_377: 0.8608 - val_loss: 1.4890 - val_accuracy: 0.5617 - val_precision_377: 0.9691 - val_recall_377: 0.1524\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3418 - accuracy: 0.8470 - precision_377: 0.8236 - recall_377: 0.8708 - val_loss: 0.9956 - val_accuracy: 0.6350 - val_precision_377: 0.9543 - val_recall_377: 0.3047\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3351 - accuracy: 0.8458 - precision_377: 0.8246 - recall_377: 0.8717 - val_loss: 0.6911 - val_accuracy: 0.7075 - val_precision_377: 0.9318 - val_recall_377: 0.4652\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3415 - accuracy: 0.8465 - precision_377: 0.8390 - recall_377: 0.8548 - val_loss: 0.6037 - val_accuracy: 0.7292 - val_precision_377: 0.9294 - val_recall_377: 0.5122\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3237 - accuracy: 0.8648 - precision_377: 0.8505 - recall_377: 0.8872 - val_loss: 0.5650 - val_accuracy: 0.7425 - val_precision_377: 0.9231 - val_recall_377: 0.5446\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3424 - accuracy: 0.8403 - precision_377: 0.8229 - recall_377: 0.8660 - val_loss: 0.4682 - val_accuracy: 0.7833 - val_precision_377: 0.9066 - val_recall_377: 0.6451\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3362 - accuracy: 0.8448 - precision_377: 0.8183 - recall_377: 0.8734 - val_loss: 0.4191 - val_accuracy: 0.8025 - val_precision_377: 0.8770 - val_recall_377: 0.7164\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3391 - accuracy: 0.8414 - precision_377: 0.8265 - recall_377: 0.8576 - val_loss: 0.4110 - val_accuracy: 0.8075 - val_precision_377: 0.8770 - val_recall_377: 0.7277\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3307 - accuracy: 0.8487 - precision_377: 0.8274 - recall_377: 0.8732 - val_loss: 0.3936 - val_accuracy: 0.8167 - val_precision_377: 0.8642 - val_recall_377: 0.7634\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3448 - accuracy: 0.8534 - precision_377: 0.8300 - recall_377: 0.8847 - val_loss: 0.3756 - val_accuracy: 0.8250 - val_precision_377: 0.8420 - val_recall_377: 0.8120\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3489 - accuracy: 0.8393 - precision_377: 0.8296 - recall_377: 0.8540 - val_loss: 0.3703 - val_accuracy: 0.8292 - val_precision_377: 0.8344 - val_recall_377: 0.8331\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3375 - accuracy: 0.8509 - precision_377: 0.8268 - recall_377: 0.8745 - val_loss: 0.3690 - val_accuracy: 0.8308 - val_precision_377: 0.8339 - val_recall_377: 0.8379\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3395 - accuracy: 0.8439 - precision_377: 0.8153 - recall_377: 0.8778 - val_loss: 0.3768 - val_accuracy: 0.8242 - val_precision_377: 0.8441 - val_recall_377: 0.8071\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3358 - accuracy: 0.8536 - precision_377: 0.8483 - recall_377: 0.8644 - val_loss: 0.3840 - val_accuracy: 0.8208 - val_precision_377: 0.8539 - val_recall_377: 0.7861\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3303 - accuracy: 0.8445 - precision_377: 0.8317 - recall_377: 0.8627 - val_loss: 0.3711 - val_accuracy: 0.8283 - val_precision_377: 0.8363 - val_recall_377: 0.8282\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3276 - accuracy: 0.8577 - precision_377: 0.8325 - recall_377: 0.8861 - val_loss: 0.3680 - val_accuracy: 0.8300 - val_precision_377: 0.8273 - val_recall_377: 0.8460\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3109 - accuracy: 0.8714 - precision_377: 0.8601 - recall_377: 0.8885 - val_loss: 0.3682 - val_accuracy: 0.8383 - val_precision_377: 0.8219 - val_recall_377: 0.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu, AUC=0.899, Accuracy=0.812, f2=0.840, prec=0.787, rec=0.854, total=  36.8s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 50ms/step - loss: 0.6851 - accuracy: 0.6882 - precision_378: 0.6884 - recall_378: 0.6960 - val_loss: 64.1130 - val_accuracy: 0.5142 - val_precision_378: 0.5142 - val_recall_378: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.4488 - accuracy: 0.7892 - precision_378: 0.7770 - recall_378: 0.8006 - val_loss: 22.9612 - val_accuracy: 0.5142 - val_precision_378: 0.5142 - val_recall_378: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4244 - accuracy: 0.7979 - precision_378: 0.7823 - recall_378: 0.8113 - val_loss: 5.0939 - val_accuracy: 0.5142 - val_precision_378: 0.5142 - val_recall_378: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4012 - accuracy: 0.8164 - precision_378: 0.8158 - recall_378: 0.8265 - val_loss: 6.5738 - val_accuracy: 0.5142 - val_precision_378: 0.5142 - val_recall_378: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4005 - accuracy: 0.8160 - precision_378: 0.8217 - recall_378: 0.8144 - val_loss: 6.4188 - val_accuracy: 0.5142 - val_precision_378: 0.5142 - val_recall_378: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3703 - accuracy: 0.8289 - precision_378: 0.8286 - recall_378: 0.8244 - val_loss: 5.4511 - val_accuracy: 0.5142 - val_precision_378: 0.5142 - val_recall_378: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.3757 - accuracy: 0.8260 - precision_378: 0.8177 - recall_378: 0.8370 - val_loss: 8.7783 - val_accuracy: 0.4858 - val_precision_378: 0.0000e+00 - val_recall_378: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3574 - accuracy: 0.8478 - precision_378: 0.8539 - recall_378: 0.8430 - val_loss: 4.7156 - val_accuracy: 0.4858 - val_precision_378: 0.0000e+00 - val_recall_378: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3618 - accuracy: 0.8303 - precision_378: 0.8210 - recall_378: 0.8419 - val_loss: 2.7541 - val_accuracy: 0.4858 - val_precision_378: 0.0000e+00 - val_recall_378: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3529 - accuracy: 0.8421 - precision_378: 0.8311 - recall_378: 0.8537 - val_loss: 4.6629 - val_accuracy: 0.4858 - val_precision_378: 0.0000e+00 - val_recall_378: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3473 - accuracy: 0.8476 - precision_378: 0.8455 - recall_378: 0.8511 - val_loss: 4.6584 - val_accuracy: 0.4858 - val_precision_378: 0.0000e+00 - val_recall_378: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3481 - accuracy: 0.8400 - precision_378: 0.8331 - recall_378: 0.8528 - val_loss: 3.2449 - val_accuracy: 0.4858 - val_precision_378: 0.0000e+00 - val_recall_378: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3434 - accuracy: 0.8477 - precision_378: 0.8463 - recall_378: 0.8539 - val_loss: 2.3036 - val_accuracy: 0.4867 - val_precision_378: 1.0000 - val_recall_378: 0.0016\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3482 - accuracy: 0.8482 - precision_378: 0.8342 - recall_378: 0.8629 - val_loss: 0.8683 - val_accuracy: 0.6225 - val_precision_378: 0.9824 - val_recall_378: 0.2707\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3579 - accuracy: 0.8377 - precision_378: 0.8278 - recall_378: 0.8493 - val_loss: 2.3387 - val_accuracy: 0.4892 - val_precision_378: 1.0000 - val_recall_378: 0.0065\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3609 - accuracy: 0.8412 - precision_378: 0.8399 - recall_378: 0.8460 - val_loss: 2.0584 - val_accuracy: 0.4950 - val_precision_378: 1.0000 - val_recall_378: 0.0178\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3470 - accuracy: 0.8428 - precision_378: 0.8341 - recall_378: 0.8478 - val_loss: 1.3722 - val_accuracy: 0.5292 - val_precision_378: 0.9815 - val_recall_378: 0.0859\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3425 - accuracy: 0.8536 - precision_378: 0.8491 - recall_378: 0.8644 - val_loss: 0.9537 - val_accuracy: 0.6183 - val_precision_378: 0.9818 - val_recall_378: 0.2626\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3494 - accuracy: 0.8469 - precision_378: 0.8529 - recall_378: 0.8436 - val_loss: 0.6643 - val_accuracy: 0.6967 - val_precision_378: 0.9377 - val_recall_378: 0.4392\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3459 - accuracy: 0.8367 - precision_378: 0.8321 - recall_378: 0.8457 - val_loss: 0.5018 - val_accuracy: 0.7608 - val_precision_378: 0.9044 - val_recall_378: 0.5981\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3659 - accuracy: 0.8360 - precision_378: 0.8168 - recall_378: 0.8515 - val_loss: 0.4213 - val_accuracy: 0.7875 - val_precision_378: 0.8664 - val_recall_378: 0.6937\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3480 - accuracy: 0.8473 - precision_378: 0.8303 - recall_378: 0.8630 - val_loss: 0.4009 - val_accuracy: 0.8017 - val_precision_378: 0.8623 - val_recall_378: 0.7310\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3443 - accuracy: 0.8491 - precision_378: 0.8315 - recall_378: 0.8680 - val_loss: 0.3875 - val_accuracy: 0.8200 - val_precision_378: 0.8613 - val_recall_378: 0.7747\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3592 - accuracy: 0.8479 - precision_378: 0.8311 - recall_378: 0.8640 - val_loss: 0.3781 - val_accuracy: 0.8225 - val_precision_378: 0.8389 - val_recall_378: 0.8104\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3389 - accuracy: 0.8410 - precision_378: 0.8277 - recall_378: 0.8489 - val_loss: 0.3760 - val_accuracy: 0.8267 - val_precision_378: 0.8304 - val_recall_378: 0.8331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=gelu, AUC=0.908, Accuracy=0.824, f2=0.828, prec=0.817, rec=0.831, total=  33.5s\n",
      "[CV] lr=0.005, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 159ms/step - loss: 0.7957 - accuracy: 0.6343 - precision_379: 0.6356 - recall_379: 0.6124 - val_loss: 102.5854 - val_accuracy: 0.4858 - val_precision_379: 0.0000e+00 - val_recall_379: 0.0000e+00\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.5476 - accuracy: 0.7483 - precision_379: 0.7388 - recall_379: 0.7546 - val_loss: 88.8434 - val_accuracy: 0.4858 - val_precision_379: 0.0000e+00 - val_recall_379: 0.0000e+00\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.4887 - accuracy: 0.7658 - precision_379: 0.7615 - recall_379: 0.7698 - val_loss: 9.3980 - val_accuracy: 0.4858 - val_precision_379: 0.0000e+00 - val_recall_379: 0.0000e+00\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4749 - accuracy: 0.7796 - precision_379: 0.7624 - recall_379: 0.7992 - val_loss: 21.5778 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4643 - accuracy: 0.7738 - precision_379: 0.7749 - recall_379: 0.7696 - val_loss: 26.4792 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4287 - accuracy: 0.8054 - precision_379: 0.8012 - recall_379: 0.8199 - val_loss: 19.8032 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4308 - accuracy: 0.7975 - precision_379: 0.7905 - recall_379: 0.8101 - val_loss: 14.8338 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4331 - accuracy: 0.7973 - precision_379: 0.7927 - recall_379: 0.8100 - val_loss: 11.6908 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4235 - accuracy: 0.8013 - precision_379: 0.7930 - recall_379: 0.8118 - val_loss: 9.5298 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4349 - accuracy: 0.7963 - precision_379: 0.7837 - recall_379: 0.8167 - val_loss: 8.0038 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.4188 - accuracy: 0.7997 - precision_379: 0.7941 - recall_379: 0.8113 - val_loss: 6.8768 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4126 - accuracy: 0.8080 - precision_379: 0.7997 - recall_379: 0.8225 - val_loss: 6.0129 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4433 - accuracy: 0.7870 - precision_379: 0.7760 - recall_379: 0.8081 - val_loss: 5.3445 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4211 - accuracy: 0.8083 - precision_379: 0.7926 - recall_379: 0.8266 - val_loss: 4.7774 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4306 - accuracy: 0.8001 - precision_379: 0.7797 - recall_379: 0.8227 - val_loss: 4.3318 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4129 - accuracy: 0.8166 - precision_379: 0.7963 - recall_379: 0.8424 - val_loss: 3.9544 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4213 - accuracy: 0.8082 - precision_379: 0.7908 - recall_379: 0.8296 - val_loss: 3.6452 - val_accuracy: 0.5142 - val_precision_379: 0.5142 - val_recall_379: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=400, activation=relu, AUC=0.811, Accuracy=0.497, f2=0.832, prec=0.497, rec=1.000, total=  15.9s\n",
      "[CV] lr=0.005, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 159ms/step - loss: 0.8716 - accuracy: 0.6364 - precision_380: 0.6392 - recall_380: 0.6218 - val_loss: 35.8168 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.5367 - accuracy: 0.7480 - precision_380: 0.7520 - recall_380: 0.7357 - val_loss: 99.0940 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4664 - accuracy: 0.7753 - precision_380: 0.7740 - recall_380: 0.7853 - val_loss: 80.6565 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4558 - accuracy: 0.7869 - precision_380: 0.7788 - recall_380: 0.7899 - val_loss: 44.5168 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4621 - accuracy: 0.7867 - precision_380: 0.7860 - recall_380: 0.7877 - val_loss: 27.1541 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4515 - accuracy: 0.7805 - precision_380: 0.7626 - recall_380: 0.7969 - val_loss: 20.4857 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4242 - accuracy: 0.7986 - precision_380: 0.7859 - recall_380: 0.8066 - val_loss: 14.3586 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4167 - accuracy: 0.8117 - precision_380: 0.8023 - recall_380: 0.8217 - val_loss: 13.1166 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4061 - accuracy: 0.8207 - precision_380: 0.8034 - recall_380: 0.8404 - val_loss: 9.7566 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4022 - accuracy: 0.8137 - precision_380: 0.7996 - recall_380: 0.8332 - val_loss: 7.7825 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4045 - accuracy: 0.8019 - precision_380: 0.7982 - recall_380: 0.8153 - val_loss: 5.3934 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3932 - accuracy: 0.8173 - precision_380: 0.7958 - recall_380: 0.8496 - val_loss: 4.4525 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3819 - accuracy: 0.8246 - precision_380: 0.8159 - recall_380: 0.8385 - val_loss: 4.5730 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3846 - accuracy: 0.8226 - precision_380: 0.8103 - recall_380: 0.8386 - val_loss: 4.0602 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3990 - accuracy: 0.8105 - precision_380: 0.7944 - recall_380: 0.8283 - val_loss: 2.4218 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3809 - accuracy: 0.8257 - precision_380: 0.8112 - recall_380: 0.8445 - val_loss: 3.8501 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3836 - accuracy: 0.8234 - precision_380: 0.8125 - recall_380: 0.8399 - val_loss: 0.6899 - val_accuracy: 0.5258 - val_precision_380: 0.5263 - val_recall_380: 0.7780\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3833 - accuracy: 0.8300 - precision_380: 0.8221 - recall_380: 0.8386 - val_loss: 4.4315 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3745 - accuracy: 0.8243 - precision_380: 0.8099 - recall_380: 0.8366 - val_loss: 7.9400 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3820 - accuracy: 0.8197 - precision_380: 0.8034 - recall_380: 0.8365 - val_loss: 6.9658 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3692 - accuracy: 0.8250 - precision_380: 0.8117 - recall_380: 0.8460 - val_loss: 5.4930 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3664 - accuracy: 0.8281 - precision_380: 0.8099 - recall_380: 0.8470 - val_loss: 5.0202 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3746 - accuracy: 0.8362 - precision_380: 0.8181 - recall_380: 0.8558 - val_loss: 4.6008 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3710 - accuracy: 0.8253 - precision_380: 0.8096 - recall_380: 0.8463 - val_loss: 4.3249 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3816 - accuracy: 0.8248 - precision_380: 0.8115 - recall_380: 0.8429 - val_loss: 4.0578 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3810 - accuracy: 0.8166 - precision_380: 0.7962 - recall_380: 0.8378 - val_loss: 3.8376 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3700 - accuracy: 0.8395 - precision_380: 0.8236 - recall_380: 0.8549 - val_loss: 3.6303 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3719 - accuracy: 0.8382 - precision_380: 0.8252 - recall_380: 0.8550 - val_loss: 3.4364 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3694 - accuracy: 0.8321 - precision_380: 0.8147 - recall_380: 0.8540 - val_loss: 3.2497 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3684 - accuracy: 0.8342 - precision_380: 0.8174 - recall_380: 0.8541 - val_loss: 3.0717 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3723 - accuracy: 0.8253 - precision_380: 0.8250 - recall_380: 0.8354 - val_loss: 2.9010 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.3846 - accuracy: 0.8244 - precision_380: 0.8198 - recall_380: 0.8356 - val_loss: 2.7346 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3836 - accuracy: 0.8232 - precision_380: 0.8051 - recall_380: 0.8443 - val_loss: 2.5749 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n",
      "Epoch 34/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3638 - accuracy: 0.8330 - precision_380: 0.8136 - recall_380: 0.8632 - val_loss: 2.4174 - val_accuracy: 0.5142 - val_precision_380: 0.5142 - val_recall_380: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=400, activation=relu, AUC=0.876, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  28.9s\n",
      "[CV] lr=0.005, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 160ms/step - loss: 0.8676 - accuracy: 0.6289 - precision_381: 0.6315 - recall_381: 0.6302 - val_loss: 68.6395 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.5090 - accuracy: 0.7526 - precision_381: 0.7541 - recall_381: 0.7454 - val_loss: 84.9143 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4883 - accuracy: 0.7709 - precision_381: 0.7591 - recall_381: 0.7841 - val_loss: 73.2300 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4720 - accuracy: 0.7767 - precision_381: 0.7736 - recall_381: 0.7824 - val_loss: 48.8432 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4513 - accuracy: 0.7796 - precision_381: 0.7774 - recall_381: 0.7838 - val_loss: 36.1544 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4498 - accuracy: 0.7917 - precision_381: 0.7949 - recall_381: 0.7935 - val_loss: 27.1606 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4575 - accuracy: 0.7817 - precision_381: 0.7818 - recall_381: 0.7830 - val_loss: 22.0421 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4453 - accuracy: 0.7907 - precision_381: 0.7930 - recall_381: 0.7943 - val_loss: 17.4363 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4265 - accuracy: 0.7909 - precision_381: 0.7810 - recall_381: 0.8021 - val_loss: 12.8856 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4321 - accuracy: 0.8005 - precision_381: 0.7940 - recall_381: 0.8085 - val_loss: 9.4370 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4145 - accuracy: 0.8064 - precision_381: 0.7946 - recall_381: 0.8149 - val_loss: 7.0637 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4086 - accuracy: 0.8106 - precision_381: 0.8007 - recall_381: 0.8280 - val_loss: 5.7301 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4226 - accuracy: 0.8005 - precision_381: 0.7872 - recall_381: 0.8228 - val_loss: 4.6504 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.4212 - accuracy: 0.8080 - precision_381: 0.7908 - recall_381: 0.8246 - val_loss: 3.6022 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4259 - accuracy: 0.8062 - precision_381: 0.7963 - recall_381: 0.8146 - val_loss: 3.5227 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4149 - accuracy: 0.8056 - precision_381: 0.7877 - recall_381: 0.8249 - val_loss: 2.9328 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.4090 - accuracy: 0.8090 - precision_381: 0.7983 - recall_381: 0.8209 - val_loss: 3.0962 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3859 - accuracy: 0.8298 - precision_381: 0.8275 - recall_381: 0.8375 - val_loss: 3.0360 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.4091 - accuracy: 0.8118 - precision_381: 0.8012 - recall_381: 0.8280 - val_loss: 2.7767 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3883 - accuracy: 0.8188 - precision_381: 0.8102 - recall_381: 0.8313 - val_loss: 2.5612 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4006 - accuracy: 0.8242 - precision_381: 0.8128 - recall_381: 0.8424 - val_loss: 2.1599 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3956 - accuracy: 0.8278 - precision_381: 0.8104 - recall_381: 0.8470 - val_loss: 1.7577 - val_accuracy: 0.5142 - val_precision_381: 0.5142 - val_recall_381: 1.0000\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3815 - accuracy: 0.8286 - precision_381: 0.8130 - recall_381: 0.8435 - val_loss: 1.3607 - val_accuracy: 0.5117 - val_precision_381: 0.5129 - val_recall_381: 0.9951\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3849 - accuracy: 0.8213 - precision_381: 0.8097 - recall_381: 0.8387 - val_loss: 1.2101 - val_accuracy: 0.5042 - val_precision_381: 0.5093 - val_recall_381: 0.9757\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3853 - accuracy: 0.8323 - precision_381: 0.8117 - recall_381: 0.8591 - val_loss: 1.0249 - val_accuracy: 0.5108 - val_precision_381: 0.5126 - val_recall_381: 0.9887\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3898 - accuracy: 0.8204 - precision_381: 0.8064 - recall_381: 0.8347 - val_loss: 0.7986 - val_accuracy: 0.5150 - val_precision_381: 0.5149 - val_recall_381: 0.9773\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.3973 - accuracy: 0.8147 - precision_381: 0.8123 - recall_381: 0.8184 - val_loss: 0.7472 - val_accuracy: 0.5283 - val_precision_381: 0.5223 - val_recall_381: 0.9676\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3915 - accuracy: 0.8212 - precision_381: 0.8101 - recall_381: 0.8367 - val_loss: 0.8266 - val_accuracy: 0.5058 - val_precision_381: 0.5103 - val_recall_381: 0.9611\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.3849 - accuracy: 0.8196 - precision_381: 0.8089 - recall_381: 0.8338 - val_loss: 0.5964 - val_accuracy: 0.6950 - val_precision_381: 0.6755 - val_recall_381: 0.7828\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3871 - accuracy: 0.8171 - precision_381: 0.8097 - recall_381: 0.8336 - val_loss: 0.5823 - val_accuracy: 0.6508 - val_precision_381: 0.8867 - val_recall_381: 0.3679\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3886 - accuracy: 0.8216 - precision_381: 0.8061 - recall_381: 0.8375 - val_loss: 0.5491 - val_accuracy: 0.6950 - val_precision_381: 0.8792 - val_recall_381: 0.4716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=400, activation=relu, AUC=0.872, Accuracy=0.709, f2=0.530, prec=0.876, rec=0.482, total=  26.6s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.3, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 164ms/step - loss: 0.7888 - accuracy: 0.6068 - precision_382: 0.6010 - recall_382: 0.5824 - val_loss: 855.8006 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.5097 - accuracy: 0.7511 - precision_382: 0.7293 - recall_382: 0.7876 - val_loss: 720.1231 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4886 - accuracy: 0.7552 - precision_382: 0.7338 - recall_382: 0.7882 - val_loss: 338.9392 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4788 - accuracy: 0.7681 - precision_382: 0.7605 - recall_382: 0.7848 - val_loss: 160.4067 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4510 - accuracy: 0.7871 - precision_382: 0.7752 - recall_382: 0.8019 - val_loss: 66.4170 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4370 - accuracy: 0.7908 - precision_382: 0.7689 - recall_382: 0.8274 - val_loss: 56.9251 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4324 - accuracy: 0.8045 - precision_382: 0.7972 - recall_382: 0.8175 - val_loss: 36.8124 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4217 - accuracy: 0.8020 - precision_382: 0.7965 - recall_382: 0.8166 - val_loss: 9.9226 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4443 - accuracy: 0.7835 - precision_382: 0.7811 - recall_382: 0.7745 - val_loss: 16.3282 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4285 - accuracy: 0.8031 - precision_382: 0.7922 - recall_382: 0.8178 - val_loss: 28.6007 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4318 - accuracy: 0.7909 - precision_382: 0.7780 - recall_382: 0.8120 - val_loss: 18.7998 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4072 - accuracy: 0.8120 - precision_382: 0.7980 - recall_382: 0.8290 - val_loss: 12.0339 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.4012 - accuracy: 0.8124 - precision_382: 0.7976 - recall_382: 0.8290 - val_loss: 9.5122 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4058 - accuracy: 0.8095 - precision_382: 0.8040 - recall_382: 0.8196 - val_loss: 7.5916 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3961 - accuracy: 0.8228 - precision_382: 0.8166 - recall_382: 0.8307 - val_loss: 6.2507 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4070 - accuracy: 0.8191 - precision_382: 0.8019 - recall_382: 0.8409 - val_loss: 5.0084 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.4014 - accuracy: 0.8215 - precision_382: 0.8142 - recall_382: 0.8267 - val_loss: 4.0511 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4072 - accuracy: 0.8060 - precision_382: 0.7977 - recall_382: 0.8189 - val_loss: 3.2860 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3991 - accuracy: 0.8091 - precision_382: 0.8067 - recall_382: 0.8167 - val_loss: 2.5847 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4127 - accuracy: 0.8159 - precision_382: 0.8075 - recall_382: 0.8221 - val_loss: 1.9015 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4185 - accuracy: 0.8113 - precision_382: 0.8008 - recall_382: 0.8239 - val_loss: 1.3385 - val_accuracy: 0.5142 - val_precision_382: 0.5142 - val_recall_382: 1.0000\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3916 - accuracy: 0.8229 - precision_382: 0.8147 - recall_382: 0.8361 - val_loss: 0.9088 - val_accuracy: 0.5125 - val_precision_382: 0.5134 - val_recall_382: 0.9935\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3955 - accuracy: 0.8172 - precision_382: 0.8037 - recall_382: 0.8280 - val_loss: 0.7602 - val_accuracy: 0.5392 - val_precision_382: 0.5282 - val_recall_382: 0.9708\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3992 - accuracy: 0.8172 - precision_382: 0.8050 - recall_382: 0.8331 - val_loss: 0.7042 - val_accuracy: 0.5667 - val_precision_382: 0.5469 - val_recall_382: 0.9173\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3905 - accuracy: 0.8231 - precision_382: 0.8128 - recall_382: 0.8392 - val_loss: 0.6854 - val_accuracy: 0.5917 - val_precision_382: 0.5691 - val_recall_382: 0.8476\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3938 - accuracy: 0.8187 - precision_382: 0.8160 - recall_382: 0.8288 - val_loss: 0.6586 - val_accuracy: 0.6208 - val_precision_382: 0.6416 - val_recall_382: 0.5948\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3946 - accuracy: 0.8182 - precision_382: 0.8049 - recall_382: 0.8343 - val_loss: 0.6785 - val_accuracy: 0.5967 - val_precision_382: 0.7046 - val_recall_382: 0.3712\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4168 - accuracy: 0.8050 - precision_382: 0.7978 - recall_382: 0.8175 - val_loss: 0.7218 - val_accuracy: 0.5458 - val_precision_382: 0.7022 - val_recall_382: 0.2026\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4044 - accuracy: 0.8148 - precision_382: 0.7957 - recall_382: 0.8350 - val_loss: 0.7192 - val_accuracy: 0.5617 - val_precision_382: 0.7382 - val_recall_382: 0.2285\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.3986 - accuracy: 0.8168 - precision_382: 0.8051 - recall_382: 0.8303 - val_loss: 0.7194 - val_accuracy: 0.5725 - val_precision_382: 0.7857 - val_recall_382: 0.2318\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3916 - accuracy: 0.8132 - precision_382: 0.7936 - recall_382: 0.8384 - val_loss: 0.6949 - val_accuracy: 0.5992 - val_precision_382: 0.8091 - val_recall_382: 0.2885\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4004 - accuracy: 0.8099 - precision_382: 0.7873 - recall_382: 0.8364 - val_loss: 0.6726 - val_accuracy: 0.6200 - val_precision_382: 0.8207 - val_recall_382: 0.3339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.3, batch_size=400, activation=relu, AUC=0.812, Accuracy=0.623, f2=0.351, prec=0.822, rec=0.307, total=  27.4s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.3, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 164ms/step - loss: 0.7153 - accuracy: 0.6394 - precision_383: 0.6410 - recall_383: 0.6364 - val_loss: 510.2314 - val_accuracy: 0.5142 - val_precision_383: 0.5142 - val_recall_383: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.4948 - accuracy: 0.7626 - precision_383: 0.7610 - recall_383: 0.7606 - val_loss: 342.7238 - val_accuracy: 0.5142 - val_precision_383: 0.5142 - val_recall_383: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4619 - accuracy: 0.7810 - precision_383: 0.7684 - recall_383: 0.8112 - val_loss: 213.9387 - val_accuracy: 0.5142 - val_precision_383: 0.5142 - val_recall_383: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4628 - accuracy: 0.7787 - precision_383: 0.7735 - recall_383: 0.7913 - val_loss: 114.5894 - val_accuracy: 0.5142 - val_precision_383: 0.5142 - val_recall_383: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4291 - accuracy: 0.8013 - precision_383: 0.7830 - recall_383: 0.8268 - val_loss: 60.2523 - val_accuracy: 0.5142 - val_precision_383: 0.5142 - val_recall_383: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4208 - accuracy: 0.8061 - precision_383: 0.7941 - recall_383: 0.8227 - val_loss: 15.6475 - val_accuracy: 0.5142 - val_precision_383: 0.5142 - val_recall_383: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4088 - accuracy: 0.8122 - precision_383: 0.8007 - recall_383: 0.8143 - val_loss: 1.9307 - val_accuracy: 0.5142 - val_precision_383: 0.5142 - val_recall_383: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4026 - accuracy: 0.8104 - precision_383: 0.7924 - recall_383: 0.8412 - val_loss: 7.2311 - val_accuracy: 0.4858 - val_precision_383: 0.0000e+00 - val_recall_383: 0.0000e+00\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3979 - accuracy: 0.8139 - precision_383: 0.7964 - recall_383: 0.8340 - val_loss: 14.2349 - val_accuracy: 0.4858 - val_precision_383: 0.0000e+00 - val_recall_383: 0.0000e+00\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3875 - accuracy: 0.8209 - precision_383: 0.8199 - recall_383: 0.8204 - val_loss: 11.6753 - val_accuracy: 0.4858 - val_precision_383: 0.0000e+00 - val_recall_383: 0.0000e+00\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3723 - accuracy: 0.8320 - precision_383: 0.8097 - recall_383: 0.8629 - val_loss: 9.8439 - val_accuracy: 0.4858 - val_precision_383: 0.0000e+00 - val_recall_383: 0.0000e+00\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.3636 - accuracy: 0.8349 - precision_383: 0.8295 - recall_383: 0.8421 - val_loss: 8.0781 - val_accuracy: 0.4858 - val_precision_383: 0.0000e+00 - val_recall_383: 0.0000e+00\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.3620 - accuracy: 0.8329 - precision_383: 0.8272 - recall_383: 0.8427 - val_loss: 6.6718 - val_accuracy: 0.4858 - val_precision_383: 0.0000e+00 - val_recall_383: 0.0000e+00\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3643 - accuracy: 0.8302 - precision_383: 0.8268 - recall_383: 0.8419 - val_loss: 5.5668 - val_accuracy: 0.4858 - val_precision_383: 0.0000e+00 - val_recall_383: 0.0000e+00\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3659 - accuracy: 0.8372 - precision_383: 0.8220 - recall_383: 0.8574 - val_loss: 4.6705 - val_accuracy: 0.4858 - val_precision_383: 0.0000e+00 - val_recall_383: 0.0000e+00\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.3681 - accuracy: 0.8340 - precision_383: 0.8271 - recall_383: 0.8463 - val_loss: 3.9521 - val_accuracy: 0.4858 - val_precision_383: 0.0000e+00 - val_recall_383: 0.0000e+00\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3685 - accuracy: 0.8367 - precision_383: 0.8161 - recall_383: 0.8592 - val_loss: 3.3564 - val_accuracy: 0.4858 - val_precision_383: 0.0000e+00 - val_recall_383: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.3, batch_size=400, activation=relu, AUC=0.359, Accuracy=0.504, f2=0.000, prec=0.000, rec=0.000, total=  16.3s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.3, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 157ms/step - loss: 0.8196 - accuracy: 0.6013 - precision_384: 0.6133 - recall_384: 0.5927 - val_loss: 1718.9091 - val_accuracy: 0.5142 - val_precision_384: 0.5142 - val_recall_384: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.5031 - accuracy: 0.7576 - precision_384: 0.7530 - recall_384: 0.7641 - val_loss: 941.9213 - val_accuracy: 0.5142 - val_precision_384: 0.5142 - val_recall_384: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4825 - accuracy: 0.7684 - precision_384: 0.7743 - recall_384: 0.7603 - val_loss: 467.0734 - val_accuracy: 0.5142 - val_precision_384: 0.5142 - val_recall_384: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4866 - accuracy: 0.7668 - precision_384: 0.7645 - recall_384: 0.7738 - val_loss: 266.4779 - val_accuracy: 0.5142 - val_precision_384: 0.5142 - val_recall_384: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4675 - accuracy: 0.7828 - precision_384: 0.7773 - recall_384: 0.7955 - val_loss: 132.0960 - val_accuracy: 0.5142 - val_precision_384: 0.5142 - val_recall_384: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4585 - accuracy: 0.7851 - precision_384: 0.7636 - recall_384: 0.8077 - val_loss: 51.6227 - val_accuracy: 0.5142 - val_precision_384: 0.5142 - val_recall_384: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4499 - accuracy: 0.7926 - precision_384: 0.7959 - recall_384: 0.7873 - val_loss: 13.8645 - val_accuracy: 0.5142 - val_precision_384: 0.5142 - val_recall_384: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.4243 - accuracy: 0.8089 - precision_384: 0.8015 - recall_384: 0.8169 - val_loss: 2.1046 - val_accuracy: 0.5125 - val_precision_384: 0.5136 - val_recall_384: 0.9822\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4165 - accuracy: 0.8066 - precision_384: 0.8016 - recall_384: 0.8160 - val_loss: 6.3487 - val_accuracy: 0.4858 - val_precision_384: 0.0000e+00 - val_recall_384: 0.0000e+00\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.4032 - accuracy: 0.8181 - precision_384: 0.8119 - recall_384: 0.8272 - val_loss: 7.3451 - val_accuracy: 0.4858 - val_precision_384: 0.0000e+00 - val_recall_384: 0.0000e+00\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4058 - accuracy: 0.8213 - precision_384: 0.8203 - recall_384: 0.8246 - val_loss: 2.9311 - val_accuracy: 0.4858 - val_precision_384: 0.0000e+00 - val_recall_384: 0.0000e+00\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3964 - accuracy: 0.8188 - precision_384: 0.8171 - recall_384: 0.8215 - val_loss: 2.3726 - val_accuracy: 0.4858 - val_precision_384: 0.0000e+00 - val_recall_384: 0.0000e+00\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4003 - accuracy: 0.8262 - precision_384: 0.8130 - recall_384: 0.8402 - val_loss: 1.4329 - val_accuracy: 0.4875 - val_precision_384: 0.6250 - val_recall_384: 0.0081\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3946 - accuracy: 0.8147 - precision_384: 0.7951 - recall_384: 0.8342 - val_loss: 0.9910 - val_accuracy: 0.4925 - val_precision_384: 0.5690 - val_recall_384: 0.0535\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3887 - accuracy: 0.8224 - precision_384: 0.8180 - recall_384: 0.8340 - val_loss: 0.8513 - val_accuracy: 0.5083 - val_precision_384: 0.6098 - val_recall_384: 0.1216\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.3966 - accuracy: 0.8196 - precision_384: 0.8046 - recall_384: 0.8357 - val_loss: 0.7798 - val_accuracy: 0.5267 - val_precision_384: 0.6140 - val_recall_384: 0.2139\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3867 - accuracy: 0.8132 - precision_384: 0.7925 - recall_384: 0.8348 - val_loss: 0.7342 - val_accuracy: 0.5458 - val_precision_384: 0.5973 - val_recall_384: 0.3582\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.4014 - accuracy: 0.8134 - precision_384: 0.8012 - recall_384: 0.8255 - val_loss: 0.7224 - val_accuracy: 0.5592 - val_precision_384: 0.5917 - val_recall_384: 0.4603\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3969 - accuracy: 0.8113 - precision_384: 0.7998 - recall_384: 0.8289 - val_loss: 0.7192 - val_accuracy: 0.5542 - val_precision_384: 0.5553 - val_recall_384: 0.6677\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3925 - accuracy: 0.8147 - precision_384: 0.8054 - recall_384: 0.8219 - val_loss: 0.7355 - val_accuracy: 0.5408 - val_precision_384: 0.5356 - val_recall_384: 0.8039\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3831 - accuracy: 0.8320 - precision_384: 0.8115 - recall_384: 0.8540 - val_loss: 0.7538 - val_accuracy: 0.5150 - val_precision_384: 0.5171 - val_recall_384: 0.8574\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.3915 - accuracy: 0.8233 - precision_384: 0.8141 - recall_384: 0.8389 - val_loss: 0.7890 - val_accuracy: 0.5008 - val_precision_384: 0.5081 - val_recall_384: 0.9206\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3822 - accuracy: 0.8260 - precision_384: 0.8074 - recall_384: 0.8452 - val_loss: 0.8171 - val_accuracy: 0.4992 - val_precision_384: 0.5070 - val_recall_384: 0.9449\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3926 - accuracy: 0.8198 - precision_384: 0.8143 - recall_384: 0.8314 - val_loss: 0.8449 - val_accuracy: 0.5008 - val_precision_384: 0.5077 - val_recall_384: 0.9595\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3937 - accuracy: 0.8289 - precision_384: 0.8148 - recall_384: 0.8503 - val_loss: 0.8690 - val_accuracy: 0.5025 - val_precision_384: 0.5085 - val_recall_384: 0.9708\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.3964 - accuracy: 0.8172 - precision_384: 0.7954 - recall_384: 0.8437 - val_loss: 0.8872 - val_accuracy: 0.5050 - val_precision_384: 0.5097 - val_recall_384: 0.9789\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3845 - accuracy: 0.8247 - precision_384: 0.8205 - recall_384: 0.8249 - val_loss: 0.8998 - val_accuracy: 0.5067 - val_precision_384: 0.5105 - val_recall_384: 0.9822\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3789 - accuracy: 0.8307 - precision_384: 0.8210 - recall_384: 0.8458 - val_loss: 0.9067 - val_accuracy: 0.5092 - val_precision_384: 0.5118 - val_recall_384: 0.9870\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.3803 - accuracy: 0.8278 - precision_384: 0.8110 - recall_384: 0.8478 - val_loss: 0.9103 - val_accuracy: 0.5108 - val_precision_384: 0.5126 - val_recall_384: 0.9919\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3935 - accuracy: 0.8139 - precision_384: 0.8037 - recall_384: 0.8289 - val_loss: 0.9154 - val_accuracy: 0.5125 - val_precision_384: 0.5134 - val_recall_384: 0.9951\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3828 - accuracy: 0.8256 - precision_384: 0.8140 - recall_384: 0.8409 - val_loss: 0.9276 - val_accuracy: 0.5133 - val_precision_384: 0.5138 - val_recall_384: 0.9968\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3881 - accuracy: 0.8168 - precision_384: 0.8026 - recall_384: 0.8329 - val_loss: 0.9541 - val_accuracy: 0.5133 - val_precision_384: 0.5138 - val_recall_384: 0.9968\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3802 - accuracy: 0.8276 - precision_384: 0.8092 - recall_384: 0.8495 - val_loss: 0.9882 - val_accuracy: 0.5133 - val_precision_384: 0.5138 - val_recall_384: 0.9968\n",
      "Epoch 34/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4017 - accuracy: 0.8121 - precision_384: 0.8051 - recall_384: 0.8188 - val_loss: 1.0207 - val_accuracy: 0.5142 - val_precision_384: 0.5142 - val_recall_384: 0.9984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.3, batch_size=400, activation=relu, AUC=0.532, Accuracy=0.498, f2=0.832, prec=0.497, rec=1.000, total=  29.1s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 24ms/step - loss: 0.6942 - accuracy: 0.6984 - precision_385: 0.7054 - recall_385: 0.6823 - val_loss: 6.7742 - val_accuracy: 0.5142 - val_precision_385: 0.5142 - val_recall_385: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.4552 - accuracy: 0.7863 - precision_385: 0.7957 - recall_385: 0.7766 - val_loss: 3.1516 - val_accuracy: 0.5142 - val_precision_385: 0.5142 - val_recall_385: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4524 - accuracy: 0.7910 - precision_385: 0.7913 - recall_385: 0.7909 - val_loss: 9.8104 - val_accuracy: 0.4858 - val_precision_385: 0.0000e+00 - val_recall_385: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4226 - accuracy: 0.8019 - precision_385: 0.7971 - recall_385: 0.8092 - val_loss: 25.4435 - val_accuracy: 0.4858 - val_precision_385: 0.0000e+00 - val_recall_385: 0.0000e+00\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3985 - accuracy: 0.8263 - precision_385: 0.8342 - recall_385: 0.8183 - val_loss: 22.8980 - val_accuracy: 0.4858 - val_precision_385: 0.0000e+00 - val_recall_385: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4000 - accuracy: 0.8156 - precision_385: 0.8135 - recall_385: 0.8104 - val_loss: 13.2887 - val_accuracy: 0.4933 - val_precision_385: 0.8000 - val_recall_385: 0.0194\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3935 - accuracy: 0.8204 - precision_385: 0.8309 - recall_385: 0.8173 - val_loss: 7.6156 - val_accuracy: 0.4858 - val_precision_385: 0.0000e+00 - val_recall_385: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3873 - accuracy: 0.8220 - precision_385: 0.8299 - recall_385: 0.8196 - val_loss: 5.1270 - val_accuracy: 0.4858 - val_precision_385: 0.0000e+00 - val_recall_385: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3612 - accuracy: 0.8407 - precision_385: 0.8388 - recall_385: 0.8475 - val_loss: 3.7050 - val_accuracy: 0.4858 - val_precision_385: 0.0000e+00 - val_recall_385: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3836 - accuracy: 0.8242 - precision_385: 0.8132 - recall_385: 0.8353 - val_loss: 1.3770 - val_accuracy: 0.4983 - val_precision_385: 0.8571 - val_recall_385: 0.0292\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3975 - accuracy: 0.8164 - precision_385: 0.8026 - recall_385: 0.8371 - val_loss: 0.4628 - val_accuracy: 0.7967 - val_precision_385: 0.7311 - val_recall_385: 0.9562\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3875 - accuracy: 0.8117 - precision_385: 0.7956 - recall_385: 0.8230 - val_loss: 0.3906 - val_accuracy: 0.8275 - val_precision_385: 0.7988 - val_recall_385: 0.8882\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3714 - accuracy: 0.8317 - precision_385: 0.8222 - recall_385: 0.8440 - val_loss: 0.4077 - val_accuracy: 0.8200 - val_precision_385: 0.7720 - val_recall_385: 0.9222\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3714 - accuracy: 0.8331 - precision_385: 0.8350 - recall_385: 0.8284 - val_loss: 0.4288 - val_accuracy: 0.8117 - val_precision_385: 0.7529 - val_recall_385: 0.9433\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3692 - accuracy: 0.8375 - precision_385: 0.8320 - recall_385: 0.8439 - val_loss: 0.4502 - val_accuracy: 0.8025 - val_precision_385: 0.7357 - val_recall_385: 0.9611\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3711 - accuracy: 0.8237 - precision_385: 0.8230 - recall_385: 0.8199 - val_loss: 0.4767 - val_accuracy: 0.7842 - val_precision_385: 0.7146 - val_recall_385: 0.9660\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3804 - accuracy: 0.8213 - precision_385: 0.8065 - recall_385: 0.8296 - val_loss: 0.4745 - val_accuracy: 0.7858 - val_precision_385: 0.7163 - val_recall_385: 0.9660\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3728 - accuracy: 0.8279 - precision_385: 0.8251 - recall_385: 0.8279 - val_loss: 0.4625 - val_accuracy: 0.7933 - val_precision_385: 0.7247 - val_recall_385: 0.9643\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3724 - accuracy: 0.8290 - precision_385: 0.8186 - recall_385: 0.8410 - val_loss: 0.4653 - val_accuracy: 0.7917 - val_precision_385: 0.7224 - val_recall_385: 0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=50, activation=elu, AUC=0.919, Accuracy=0.810, f2=0.904, prec=0.738, rec=0.957, total=  23.3s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 23ms/step - loss: 0.6731 - accuracy: 0.7022 - precision_386: 0.6953 - recall_386: 0.7138 - val_loss: 4.0417 - val_accuracy: 0.5142 - val_precision_386: 0.5142 - val_recall_386: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4368 - accuracy: 0.7973 - precision_386: 0.7847 - recall_386: 0.8073 - val_loss: 1.8446 - val_accuracy: 0.5142 - val_precision_386: 0.5142 - val_recall_386: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4037 - accuracy: 0.8184 - precision_386: 0.7973 - recall_386: 0.8361 - val_loss: 4.1889 - val_accuracy: 0.5142 - val_precision_386: 0.5142 - val_recall_386: 1.0000\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3940 - accuracy: 0.8139 - precision_386: 0.8064 - recall_386: 0.8351 - val_loss: 20.1692 - val_accuracy: 0.5142 - val_precision_386: 0.5142 - val_recall_386: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4091 - accuracy: 0.8106 - precision_386: 0.8334 - recall_386: 0.7851 - val_loss: 0.5054 - val_accuracy: 0.7483 - val_precision_386: 0.8777 - val_recall_386: 0.5932\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3655 - accuracy: 0.8324 - precision_386: 0.8317 - recall_386: 0.8325 - val_loss: 13.8188 - val_accuracy: 0.4858 - val_precision_386: 0.0000e+00 - val_recall_386: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3681 - accuracy: 0.8287 - precision_386: 0.8265 - recall_386: 0.8297 - val_loss: 52.9566 - val_accuracy: 0.4858 - val_precision_386: 0.0000e+00 - val_recall_386: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3632 - accuracy: 0.8326 - precision_386: 0.8121 - recall_386: 0.8462 - val_loss: 7.8108 - val_accuracy: 0.4858 - val_precision_386: 0.0000e+00 - val_recall_386: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3573 - accuracy: 0.8402 - precision_386: 0.8438 - recall_386: 0.8426 - val_loss: 4.0022 - val_accuracy: 0.4858 - val_precision_386: 0.0000e+00 - val_recall_386: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3549 - accuracy: 0.8370 - precision_386: 0.8284 - recall_386: 0.8488 - val_loss: 1.4548 - val_accuracy: 0.5692 - val_precision_386: 0.9630 - val_recall_386: 0.1686\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3527 - accuracy: 0.8436 - precision_386: 0.8259 - recall_386: 0.8597 - val_loss: 0.4514 - val_accuracy: 0.7917 - val_precision_386: 0.8799 - val_recall_386: 0.6888\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3685 - accuracy: 0.8289 - precision_386: 0.8072 - recall_386: 0.8546 - val_loss: 0.4162 - val_accuracy: 0.7958 - val_precision_386: 0.8647 - val_recall_386: 0.7147\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3656 - accuracy: 0.8293 - precision_386: 0.8010 - recall_386: 0.8550 - val_loss: 0.4316 - val_accuracy: 0.7958 - val_precision_386: 0.8705 - val_recall_386: 0.7083\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3502 - accuracy: 0.8478 - precision_386: 0.8334 - recall_386: 0.8662 - val_loss: 0.5867 - val_accuracy: 0.7450 - val_precision_386: 0.9103 - val_recall_386: 0.5592\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3486 - accuracy: 0.8436 - precision_386: 0.8231 - recall_386: 0.8690 - val_loss: 0.4056 - val_accuracy: 0.8158 - val_precision_386: 0.8498 - val_recall_386: 0.7796\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3530 - accuracy: 0.8416 - precision_386: 0.8173 - recall_386: 0.8650 - val_loss: 0.3904 - val_accuracy: 0.8317 - val_precision_386: 0.7977 - val_recall_386: 0.9011\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3599 - accuracy: 0.8388 - precision_386: 0.8240 - recall_386: 0.8645 - val_loss: 0.4305 - val_accuracy: 0.8158 - val_precision_386: 0.7578 - val_recall_386: 0.9433\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3443 - accuracy: 0.8474 - precision_386: 0.8330 - recall_386: 0.8667 - val_loss: 0.4181 - val_accuracy: 0.8208 - val_precision_386: 0.7702 - val_recall_386: 0.9287\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3566 - accuracy: 0.8419 - precision_386: 0.8190 - recall_386: 0.8669 - val_loss: 0.4333 - val_accuracy: 0.8158 - val_precision_386: 0.7612 - val_recall_386: 0.9352\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3446 - accuracy: 0.8435 - precision_386: 0.8335 - recall_386: 0.8643 - val_loss: 0.4404 - val_accuracy: 0.8142 - val_precision_386: 0.7585 - val_recall_386: 0.9368\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3429 - accuracy: 0.8435 - precision_386: 0.8192 - recall_386: 0.8728 - val_loss: 0.4548 - val_accuracy: 0.8142 - val_precision_386: 0.7558 - val_recall_386: 0.9433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=50, activation=elu, AUC=0.898, Accuracy=0.784, f2=0.876, prec=0.719, rec=0.927, total=  25.6s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 30ms/step - loss: 0.6875 - accuracy: 0.7090 - precision_387: 0.7048 - recall_387: 0.7119 - val_loss: 7.8249 - val_accuracy: 0.5142 - val_precision_387: 0.5142 - val_recall_387: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4568 - accuracy: 0.7840 - precision_387: 0.7870 - recall_387: 0.7809 - val_loss: 6.5131 - val_accuracy: 0.5142 - val_precision_387: 0.5142 - val_recall_387: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4251 - accuracy: 0.7986 - precision_387: 0.7946 - recall_387: 0.8023 - val_loss: 1.1121 - val_accuracy: 0.5525 - val_precision_387: 0.9651 - val_recall_387: 0.1345\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3847 - accuracy: 0.8268 - precision_387: 0.8301 - recall_387: 0.8281 - val_loss: 4.3614 - val_accuracy: 0.5142 - val_precision_387: 0.5142 - val_recall_387: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3893 - accuracy: 0.8230 - precision_387: 0.8104 - recall_387: 0.8453 - val_loss: 2.6506 - val_accuracy: 0.5142 - val_precision_387: 0.5142 - val_recall_387: 1.0000\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3915 - accuracy: 0.8146 - precision_387: 0.8321 - recall_387: 0.8015 - val_loss: 40.5223 - val_accuracy: 0.4858 - val_precision_387: 0.0000e+00 - val_recall_387: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3699 - accuracy: 0.8330 - precision_387: 0.8271 - recall_387: 0.8415 - val_loss: 3.0417 - val_accuracy: 0.5025 - val_precision_387: 1.0000 - val_recall_387: 0.0324\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3663 - accuracy: 0.8352 - precision_387: 0.8446 - recall_387: 0.8291 - val_loss: 1.9072 - val_accuracy: 0.5683 - val_precision_387: 0.9806 - val_recall_387: 0.1637\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3491 - accuracy: 0.8457 - precision_387: 0.8439 - recall_387: 0.8483 - val_loss: 1.4856 - val_accuracy: 0.5233 - val_precision_387: 0.9412 - val_recall_387: 0.0778\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3578 - accuracy: 0.8407 - precision_387: 0.8269 - recall_387: 0.8556 - val_loss: 0.8921 - val_accuracy: 0.6533 - val_precision_387: 0.9507 - val_recall_387: 0.3436\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3493 - accuracy: 0.8446 - precision_387: 0.8270 - recall_387: 0.8672 - val_loss: 0.7614 - val_accuracy: 0.6800 - val_precision_387: 0.9533 - val_recall_387: 0.3971\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3379 - accuracy: 0.8460 - precision_387: 0.8400 - recall_387: 0.8595 - val_loss: 0.4540 - val_accuracy: 0.7775 - val_precision_387: 0.8977 - val_recall_387: 0.6402\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3503 - accuracy: 0.8456 - precision_387: 0.8459 - recall_387: 0.8540 - val_loss: 0.3958 - val_accuracy: 0.8183 - val_precision_387: 0.8743 - val_recall_387: 0.7553\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3601 - accuracy: 0.8388 - precision_387: 0.8235 - recall_387: 0.8576 - val_loss: 0.3686 - val_accuracy: 0.8367 - val_precision_387: 0.8445 - val_recall_387: 0.8363\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3563 - accuracy: 0.8354 - precision_387: 0.8447 - recall_387: 0.8328 - val_loss: 0.3636 - val_accuracy: 0.8383 - val_precision_387: 0.8289 - val_recall_387: 0.8639\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3560 - accuracy: 0.8385 - precision_387: 0.8350 - recall_387: 0.8473 - val_loss: 0.5589 - val_accuracy: 0.7542 - val_precision_387: 0.9259 - val_recall_387: 0.5673\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3585 - accuracy: 0.8405 - precision_387: 0.8150 - recall_387: 0.8626 - val_loss: 0.3655 - val_accuracy: 0.8367 - val_precision_387: 0.8434 - val_recall_387: 0.8379\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3634 - accuracy: 0.8353 - precision_387: 0.8265 - recall_387: 0.8439 - val_loss: 0.3733 - val_accuracy: 0.8400 - val_precision_387: 0.7989 - val_recall_387: 0.9206\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3505 - accuracy: 0.8363 - precision_387: 0.8405 - recall_387: 0.8399 - val_loss: 0.4129 - val_accuracy: 0.8200 - val_precision_387: 0.7574 - val_recall_387: 0.9562\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3737 - accuracy: 0.8312 - precision_387: 0.8241 - recall_387: 0.8484 - val_loss: 0.3997 - val_accuracy: 0.8242 - val_precision_387: 0.7664 - val_recall_387: 0.9465\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3777 - accuracy: 0.8288 - precision_387: 0.8243 - recall_387: 0.8311 - val_loss: 0.3958 - val_accuracy: 0.8233 - val_precision_387: 0.7682 - val_recall_387: 0.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=50, activation=elu, AUC=0.911, Accuracy=0.814, f2=0.889, prec=0.753, rec=0.931, total=  26.1s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=relu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 25ms/step - loss: 0.5879 - accuracy: 0.7074 - precision_388: 0.7015 - recall_388: 0.6906 - val_loss: 32.1752 - val_accuracy: 0.5142 - val_precision_388: 0.5142 - val_recall_388: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4462 - accuracy: 0.7963 - precision_388: 0.7797 - recall_388: 0.8228 - val_loss: 2.0933 - val_accuracy: 0.5142 - val_precision_388: 0.5142 - val_recall_388: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4255 - accuracy: 0.7981 - precision_388: 0.7968 - recall_388: 0.8126 - val_loss: 13.9874 - val_accuracy: 0.4858 - val_precision_388: 0.0000e+00 - val_recall_388: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4044 - accuracy: 0.8184 - precision_388: 0.8127 - recall_388: 0.8208 - val_loss: 4.6456 - val_accuracy: 0.5075 - val_precision_388: 0.6512 - val_recall_388: 0.0908\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3799 - accuracy: 0.8235 - precision_388: 0.8246 - recall_388: 0.8208 - val_loss: 3.0184 - val_accuracy: 0.6733 - val_precision_388: 0.6180 - val_recall_388: 0.9546\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3860 - accuracy: 0.8204 - precision_388: 0.8070 - recall_388: 0.8354 - val_loss: 1.8534 - val_accuracy: 0.7517 - val_precision_388: 0.7295 - val_recall_388: 0.8217\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3415 - accuracy: 0.8495 - precision_388: 0.8499 - recall_388: 0.8513 - val_loss: 11.7021 - val_accuracy: 0.4758 - val_precision_388: 0.3421 - val_recall_388: 0.0211\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3536 - accuracy: 0.8402 - precision_388: 0.8340 - recall_388: 0.8460 - val_loss: 0.4198 - val_accuracy: 0.8242 - val_precision_388: 0.7758 - val_recall_388: 0.9254\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3290 - accuracy: 0.8593 - precision_388: 0.8433 - recall_388: 0.8802 - val_loss: 5.8312 - val_accuracy: 0.4867 - val_precision_388: 1.0000 - val_recall_388: 0.0016\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3284 - accuracy: 0.8492 - precision_388: 0.8494 - recall_388: 0.8488 - val_loss: 3.2659 - val_accuracy: 0.7758 - val_precision_388: 0.7949 - val_recall_388: 0.7601\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3046 - accuracy: 0.8595 - precision_388: 0.8649 - recall_388: 0.8516 - val_loss: 18.8298 - val_accuracy: 0.5117 - val_precision_388: 0.7627 - val_recall_388: 0.0729\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2839 - accuracy: 0.8725 - precision_388: 0.8772 - recall_388: 0.8676 - val_loss: 15.8597 - val_accuracy: 0.5125 - val_precision_388: 0.7000 - val_recall_388: 0.0908\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2650 - accuracy: 0.8890 - precision_388: 0.8964 - recall_388: 0.8879 - val_loss: 11.7462 - val_accuracy: 0.4817 - val_precision_388: 0.0000e+00 - val_recall_388: 0.0000e+00\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2867 - accuracy: 0.8834 - precision_388: 0.8736 - recall_388: 0.8888 - val_loss: 1.4801 - val_accuracy: 0.5792 - val_precision_388: 0.9828 - val_recall_388: 0.1848\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2988 - accuracy: 0.8654 - precision_388: 0.8732 - recall_388: 0.8598 - val_loss: 0.4862 - val_accuracy: 0.7733 - val_precision_388: 0.8947 - val_recall_388: 0.6337\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2721 - accuracy: 0.8844 - precision_388: 0.8867 - recall_388: 0.8850 - val_loss: 0.4414 - val_accuracy: 0.7883 - val_precision_388: 0.8697 - val_recall_388: 0.6921\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2584 - accuracy: 0.8904 - precision_388: 0.8912 - recall_388: 0.8849 - val_loss: 0.3830 - val_accuracy: 0.8358 - val_precision_388: 0.8608 - val_recall_388: 0.8120\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2662 - accuracy: 0.8899 - precision_388: 0.9004 - recall_388: 0.8823 - val_loss: 0.3735 - val_accuracy: 0.8392 - val_precision_388: 0.8354 - val_recall_388: 0.8558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=relu, AUC=0.919, Accuracy=0.841, f2=0.844, prec=0.835, rec=0.847, total=  23.1s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=relu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 24ms/step - loss: 0.6144 - accuracy: 0.7201 - precision_389: 0.7231 - recall_389: 0.7233 - val_loss: 10.3231 - val_accuracy: 0.5142 - val_precision_389: 0.5142 - val_recall_389: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4393 - accuracy: 0.7980 - precision_389: 0.7919 - recall_389: 0.7945 - val_loss: 3.2485 - val_accuracy: 0.5142 - val_precision_389: 0.5142 - val_recall_389: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3990 - accuracy: 0.8172 - precision_389: 0.8006 - recall_389: 0.8441 - val_loss: 16.7037 - val_accuracy: 0.4858 - val_precision_389: 0.0000e+00 - val_recall_389: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3932 - accuracy: 0.8287 - precision_389: 0.8223 - recall_389: 0.8458 - val_loss: 73.6660 - val_accuracy: 0.4858 - val_precision_389: 0.0000e+00 - val_recall_389: 0.0000e+00\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3855 - accuracy: 0.8275 - precision_389: 0.8241 - recall_389: 0.8342 - val_loss: 68.4736 - val_accuracy: 0.4858 - val_precision_389: 0.0000e+00 - val_recall_389: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3596 - accuracy: 0.8413 - precision_389: 0.8441 - recall_389: 0.8482 - val_loss: 79.0748 - val_accuracy: 0.4858 - val_precision_389: 0.0000e+00 - val_recall_389: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3391 - accuracy: 0.8438 - precision_389: 0.8205 - recall_389: 0.8678 - val_loss: 22.5389 - val_accuracy: 0.4858 - val_precision_389: 0.0000e+00 - val_recall_389: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3373 - accuracy: 0.8550 - precision_389: 0.8527 - recall_389: 0.8625 - val_loss: 20.4234 - val_accuracy: 0.4858 - val_precision_389: 0.0000e+00 - val_recall_389: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3353 - accuracy: 0.8541 - precision_389: 0.8395 - recall_389: 0.8714 - val_loss: 8.9486 - val_accuracy: 0.4858 - val_precision_389: 0.0000e+00 - val_recall_389: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3468 - accuracy: 0.8394 - precision_389: 0.8148 - recall_389: 0.8676 - val_loss: 2.3855 - val_accuracy: 0.4892 - val_precision_389: 1.0000 - val_recall_389: 0.0065\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3552 - accuracy: 0.8326 - precision_389: 0.8187 - recall_389: 0.8493 - val_loss: 2.8742 - val_accuracy: 0.4858 - val_precision_389: 0.0000e+00 - val_recall_389: 0.0000e+00\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3503 - accuracy: 0.8411 - precision_389: 0.8250 - recall_389: 0.8662 - val_loss: 0.9844 - val_accuracy: 0.6167 - val_precision_389: 0.9645 - val_recall_389: 0.2642\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3493 - accuracy: 0.8382 - precision_389: 0.8252 - recall_389: 0.8666 - val_loss: 1.1680 - val_accuracy: 0.5692 - val_precision_389: 0.9808 - val_recall_389: 0.1653\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3362 - accuracy: 0.8429 - precision_389: 0.8296 - recall_389: 0.8630 - val_loss: 0.3885 - val_accuracy: 0.8158 - val_precision_389: 0.8474 - val_recall_389: 0.7828\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3429 - accuracy: 0.8440 - precision_389: 0.8258 - recall_389: 0.8700 - val_loss: 0.3813 - val_accuracy: 0.8233 - val_precision_389: 0.8403 - val_recall_389: 0.8104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=relu, AUC=0.897, Accuracy=0.811, f2=0.797, prec=0.822, rec=0.791, total=  19.6s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=relu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 25ms/step - loss: 0.6003 - accuracy: 0.6991 - precision_390: 0.6909 - recall_390: 0.6981 - val_loss: 18.0547 - val_accuracy: 0.5142 - val_precision_390: 0.5142 - val_recall_390: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4465 - accuracy: 0.7942 - precision_390: 0.7933 - recall_390: 0.7916 - val_loss: 58.2267 - val_accuracy: 0.5142 - val_precision_390: 0.5142 - val_recall_390: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4150 - accuracy: 0.8044 - precision_390: 0.7825 - recall_390: 0.8213 - val_loss: 44.4239 - val_accuracy: 0.4858 - val_precision_390: 0.0000e+00 - val_recall_390: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3843 - accuracy: 0.8184 - precision_390: 0.8010 - recall_390: 0.8399 - val_loss: 126.6255 - val_accuracy: 0.4858 - val_precision_390: 0.0000e+00 - val_recall_390: 0.0000e+00\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3796 - accuracy: 0.8219 - precision_390: 0.8116 - recall_390: 0.8420 - val_loss: 8.2605 - val_accuracy: 0.5142 - val_precision_390: 0.5142 - val_recall_390: 1.0000\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3748 - accuracy: 0.8349 - precision_390: 0.8201 - recall_390: 0.8587 - val_loss: 1.1948 - val_accuracy: 0.5758 - val_precision_390: 0.5480 - val_recall_390: 1.0000\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3701 - accuracy: 0.8290 - precision_390: 0.8271 - recall_390: 0.8422 - val_loss: 117.7524 - val_accuracy: 0.4858 - val_precision_390: 0.0000e+00 - val_recall_390: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3803 - accuracy: 0.8307 - precision_390: 0.8261 - recall_390: 0.8310 - val_loss: 210.3081 - val_accuracy: 0.4858 - val_precision_390: 0.0000e+00 - val_recall_390: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3449 - accuracy: 0.8468 - precision_390: 0.8403 - recall_390: 0.8541 - val_loss: 37.5240 - val_accuracy: 0.4858 - val_precision_390: 0.0000e+00 - val_recall_390: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3307 - accuracy: 0.8540 - precision_390: 0.8493 - recall_390: 0.8644 - val_loss: 158.5509 - val_accuracy: 0.4858 - val_precision_390: 0.0000e+00 - val_recall_390: 0.0000e+00\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3232 - accuracy: 0.8568 - precision_390: 0.8476 - recall_390: 0.8689 - val_loss: 18.1167 - val_accuracy: 0.4858 - val_precision_390: 0.0000e+00 - val_recall_390: 0.0000e+00\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3511 - accuracy: 0.8483 - precision_390: 0.8376 - recall_390: 0.8570 - val_loss: 2.4278 - val_accuracy: 0.4875 - val_precision_390: 1.0000 - val_recall_390: 0.0032\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3359 - accuracy: 0.8470 - precision_390: 0.8345 - recall_390: 0.8624 - val_loss: 1.1727 - val_accuracy: 0.5383 - val_precision_390: 0.9846 - val_recall_390: 0.1037\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3292 - accuracy: 0.8581 - precision_390: 0.8430 - recall_390: 0.8716 - val_loss: 0.5724 - val_accuracy: 0.7175 - val_precision_390: 0.9212 - val_recall_390: 0.4927\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3227 - accuracy: 0.8630 - precision_390: 0.8590 - recall_390: 0.8694 - val_loss: 0.4314 - val_accuracy: 0.7975 - val_precision_390: 0.8896 - val_recall_390: 0.6921\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3333 - accuracy: 0.8565 - precision_390: 0.8466 - recall_390: 0.8681 - val_loss: 0.3913 - val_accuracy: 0.8142 - val_precision_390: 0.8662 - val_recall_390: 0.7553\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3358 - accuracy: 0.8518 - precision_390: 0.8402 - recall_390: 0.8651 - val_loss: 0.3820 - val_accuracy: 0.8233 - val_precision_390: 0.8623 - val_recall_390: 0.7812\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3242 - accuracy: 0.8593 - precision_390: 0.8596 - recall_390: 0.8623 - val_loss: 0.3729 - val_accuracy: 0.8275 - val_precision_390: 0.8361 - val_recall_390: 0.8266\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3364 - accuracy: 0.8465 - precision_390: 0.8227 - recall_390: 0.8659 - val_loss: 0.3734 - val_accuracy: 0.8258 - val_precision_390: 0.8091 - val_recall_390: 0.8655\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3280 - accuracy: 0.8478 - precision_390: 0.8304 - recall_390: 0.8695 - val_loss: 0.3733 - val_accuracy: 0.8283 - val_precision_390: 0.8386 - val_recall_390: 0.8250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=lecun_normal, epochs=500, drop_rate=0.25, batch_size=50, activation=relu, AUC=0.906, Accuracy=0.828, f2=0.825, prec=0.827, rec=0.825, total=  25.6s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 161ms/step - loss: 0.7097 - accuracy: 0.6431 - precision_391: 0.6324 - recall_391: 0.6626 - val_loss: 1.0277 - val_accuracy: 0.4858 - val_precision_391: 0.0000e+00 - val_recall_391: 0.0000e+00\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.5284 - accuracy: 0.7529 - precision_391: 0.7512 - recall_391: 0.7529 - val_loss: 4.4318 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.4871 - accuracy: 0.7612 - precision_391: 0.7682 - recall_391: 0.7527 - val_loss: 7.6801 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4471 - accuracy: 0.7964 - precision_391: 0.7924 - recall_391: 0.8033 - val_loss: 6.2792 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4230 - accuracy: 0.8056 - precision_391: 0.7914 - recall_391: 0.8265 - val_loss: 5.3023 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.4169 - accuracy: 0.8083 - precision_391: 0.7989 - recall_391: 0.8227 - val_loss: 4.5835 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.4292 - accuracy: 0.7961 - precision_391: 0.7843 - recall_391: 0.8089 - val_loss: 4.0541 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4200 - accuracy: 0.8076 - precision_391: 0.7998 - recall_391: 0.8151 - val_loss: 3.6736 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4171 - accuracy: 0.8058 - precision_391: 0.7991 - recall_391: 0.8162 - val_loss: 3.3685 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4233 - accuracy: 0.8037 - precision_391: 0.7996 - recall_391: 0.8083 - val_loss: 3.1246 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4288 - accuracy: 0.8027 - precision_391: 0.7972 - recall_391: 0.8114 - val_loss: 2.9206 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.4328 - accuracy: 0.7891 - precision_391: 0.7783 - recall_391: 0.8057 - val_loss: 2.7432 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4250 - accuracy: 0.8034 - precision_391: 0.7889 - recall_391: 0.8181 - val_loss: 2.5910 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4288 - accuracy: 0.8008 - precision_391: 0.7961 - recall_391: 0.8126 - val_loss: 2.4562 - val_accuracy: 0.5142 - val_precision_391: 0.5142 - val_recall_391: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=400, activation=relu, AUC=0.851, Accuracy=0.497, f2=0.832, prec=0.497, rec=1.000, total=  13.8s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 162ms/step - loss: 0.6301 - accuracy: 0.6668 - precision_392: 0.6538 - recall_392: 0.6591 - val_loss: 0.6216 - val_accuracy: 0.6875 - val_precision_392: 0.6301 - val_recall_392: 0.9498\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4795 - accuracy: 0.7802 - precision_392: 0.7659 - recall_392: 0.7953 - val_loss: 7.6010 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.4371 - accuracy: 0.7918 - precision_392: 0.7844 - recall_392: 0.8123 - val_loss: 9.9941 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4152 - accuracy: 0.8134 - precision_392: 0.7981 - recall_392: 0.8330 - val_loss: 8.0966 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.3982 - accuracy: 0.8168 - precision_392: 0.8053 - recall_392: 0.8339 - val_loss: 6.6174 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4040 - accuracy: 0.8192 - precision_392: 0.8142 - recall_392: 0.8320 - val_loss: 5.5707 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4021 - accuracy: 0.8164 - precision_392: 0.8146 - recall_392: 0.8273 - val_loss: 4.8170 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4008 - accuracy: 0.8128 - precision_392: 0.8088 - recall_392: 0.8255 - val_loss: 4.3211 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4061 - accuracy: 0.8192 - precision_392: 0.8170 - recall_392: 0.8247 - val_loss: 3.9361 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.3913 - accuracy: 0.8172 - precision_392: 0.8060 - recall_392: 0.8367 - val_loss: 3.6196 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4004 - accuracy: 0.8157 - precision_392: 0.8008 - recall_392: 0.8347 - val_loss: 3.3543 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.4002 - accuracy: 0.8190 - precision_392: 0.8030 - recall_392: 0.8373 - val_loss: 3.1302 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4125 - accuracy: 0.8041 - precision_392: 0.7964 - recall_392: 0.8170 - val_loss: 2.9375 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4217 - accuracy: 0.8048 - precision_392: 0.7892 - recall_392: 0.8244 - val_loss: 2.7697 - val_accuracy: 0.5142 - val_precision_392: 0.5142 - val_recall_392: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=400, activation=relu, AUC=0.853, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  13.6s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 156ms/step - loss: 0.6896 - accuracy: 0.6513 - precision_393: 0.6454 - recall_393: 0.6526 - val_loss: 0.7417 - val_accuracy: 0.4858 - val_precision_393: 0.0000e+00 - val_recall_393: 0.0000e+00\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.5364 - accuracy: 0.7435 - precision_393: 0.7397 - recall_393: 0.7441 - val_loss: 6.3411 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4694 - accuracy: 0.7746 - precision_393: 0.7695 - recall_393: 0.7787 - val_loss: 7.9439 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4403 - accuracy: 0.7984 - precision_393: 0.7980 - recall_393: 0.8020 - val_loss: 6.0323 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4226 - accuracy: 0.7952 - precision_393: 0.7930 - recall_393: 0.8008 - val_loss: 4.8508 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4254 - accuracy: 0.7963 - precision_393: 0.7904 - recall_393: 0.8048 - val_loss: 4.1312 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4260 - accuracy: 0.8040 - precision_393: 0.7827 - recall_393: 0.8248 - val_loss: 3.5961 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.4004 - accuracy: 0.8215 - precision_393: 0.8073 - recall_393: 0.8412 - val_loss: 3.2267 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4164 - accuracy: 0.8040 - precision_393: 0.7925 - recall_393: 0.8185 - val_loss: 2.9298 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.4251 - accuracy: 0.7952 - precision_393: 0.7785 - recall_393: 0.8047 - val_loss: 2.6934 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4362 - accuracy: 0.7972 - precision_393: 0.7887 - recall_393: 0.8030 - val_loss: 2.4940 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.4225 - accuracy: 0.8061 - precision_393: 0.8024 - recall_393: 0.8115 - val_loss: 2.3279 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4204 - accuracy: 0.8054 - precision_393: 0.7895 - recall_393: 0.8175 - val_loss: 2.1846 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4290 - accuracy: 0.8058 - precision_393: 0.7960 - recall_393: 0.8134 - val_loss: 2.0615 - val_accuracy: 0.5142 - val_precision_393: 0.5142 - val_recall_393: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=400, activation=relu, AUC=0.815, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  13.1s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.6274 - accuracy: 0.6847 - precision_394: 0.6902 - recall_394: 0.6632 - val_loss: 505.4889 - val_accuracy: 0.5142 - val_precision_394: 0.5142 - val_recall_394: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5079 - accuracy: 0.7467 - precision_394: 0.7363 - recall_394: 0.7569 - val_loss: 135.1235 - val_accuracy: 0.5142 - val_precision_394: 0.5142 - val_recall_394: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4775 - accuracy: 0.7782 - precision_394: 0.7757 - recall_394: 0.7780 - val_loss: 28.1980 - val_accuracy: 0.5142 - val_precision_394: 0.5142 - val_recall_394: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4346 - accuracy: 0.8013 - precision_394: 0.7766 - recall_394: 0.8441 - val_loss: 17.7436 - val_accuracy: 0.5142 - val_precision_394: 0.5142 - val_recall_394: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4435 - accuracy: 0.7843 - precision_394: 0.7779 - recall_394: 0.7898 - val_loss: 51.3758 - val_accuracy: 0.5142 - val_precision_394: 0.5142 - val_recall_394: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4646 - accuracy: 0.7824 - precision_394: 0.7956 - recall_394: 0.7742 - val_loss: 16.0492 - val_accuracy: 0.5142 - val_precision_394: 0.5142 - val_recall_394: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4433 - accuracy: 0.7917 - precision_394: 0.7995 - recall_394: 0.7806 - val_loss: 4.2782 - val_accuracy: 0.5142 - val_precision_394: 0.5142 - val_recall_394: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4080 - accuracy: 0.8181 - precision_394: 0.8098 - recall_394: 0.8247 - val_loss: 1.2759 - val_accuracy: 0.5517 - val_precision_394: 0.9877 - val_recall_394: 0.1297\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4192 - accuracy: 0.8013 - precision_394: 0.7813 - recall_394: 0.8237 - val_loss: 0.6368 - val_accuracy: 0.6692 - val_precision_394: 0.6093 - val_recall_394: 0.9935\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4003 - accuracy: 0.8227 - precision_394: 0.8075 - recall_394: 0.8374 - val_loss: 5.3226 - val_accuracy: 0.5142 - val_precision_394: 0.5142 - val_recall_394: 1.0000\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3914 - accuracy: 0.8211 - precision_394: 0.8123 - recall_394: 0.8268 - val_loss: 10.8462 - val_accuracy: 0.4858 - val_precision_394: 0.0000e+00 - val_recall_394: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3844 - accuracy: 0.8208 - precision_394: 0.8214 - recall_394: 0.8252 - val_loss: 3.3138 - val_accuracy: 0.4858 - val_precision_394: 0.0000e+00 - val_recall_394: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3984 - accuracy: 0.8151 - precision_394: 0.8045 - recall_394: 0.8295 - val_loss: 5.3064 - val_accuracy: 0.4858 - val_precision_394: 0.0000e+00 - val_recall_394: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3852 - accuracy: 0.8219 - precision_394: 0.8104 - recall_394: 0.8416 - val_loss: 2.5621 - val_accuracy: 0.4858 - val_precision_394: 0.0000e+00 - val_recall_394: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3805 - accuracy: 0.8261 - precision_394: 0.8132 - recall_394: 0.8383 - val_loss: 1.4752 - val_accuracy: 0.5075 - val_precision_394: 1.0000 - val_recall_394: 0.0421\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3699 - accuracy: 0.8345 - precision_394: 0.8103 - recall_394: 0.8626 - val_loss: 1.7372 - val_accuracy: 0.5008 - val_precision_394: 1.0000 - val_recall_394: 0.0292\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3773 - accuracy: 0.8214 - precision_394: 0.8130 - recall_394: 0.8343 - val_loss: 1.6067 - val_accuracy: 0.5092 - val_precision_394: 1.0000 - val_recall_394: 0.0454\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3675 - accuracy: 0.8376 - precision_394: 0.8161 - recall_394: 0.8668 - val_loss: 1.2520 - val_accuracy: 0.5592 - val_precision_394: 0.9783 - val_recall_394: 0.1459\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3804 - accuracy: 0.8310 - precision_394: 0.8234 - recall_394: 0.8481 - val_loss: 0.9558 - val_accuracy: 0.6100 - val_precision_394: 0.9306 - val_recall_394: 0.2609\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3571 - accuracy: 0.8468 - precision_394: 0.8371 - recall_394: 0.8606 - val_loss: 0.7336 - val_accuracy: 0.6783 - val_precision_394: 0.9294 - val_recall_394: 0.4052\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3814 - accuracy: 0.8289 - precision_394: 0.8343 - recall_394: 0.8317 - val_loss: 0.5925 - val_accuracy: 0.7308 - val_precision_394: 0.9200 - val_recall_394: 0.5219\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3759 - accuracy: 0.8320 - precision_394: 0.8151 - recall_394: 0.8493 - val_loss: 0.5231 - val_accuracy: 0.7517 - val_precision_394: 0.8919 - val_recall_394: 0.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=relu, AUC=0.911, Accuracy=0.771, f2=0.642, prec=0.910, rec=0.597, total=  23.8s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.6402 - accuracy: 0.6969 - precision_395: 0.7102 - recall_395: 0.6838 - val_loss: 438.4504 - val_accuracy: 0.5142 - val_precision_395: 0.5142 - val_recall_395: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4648 - accuracy: 0.7844 - precision_395: 0.7841 - recall_395: 0.7912 - val_loss: 98.0045 - val_accuracy: 0.5142 - val_precision_395: 0.5142 - val_recall_395: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4291 - accuracy: 0.8035 - precision_395: 0.8017 - recall_395: 0.8081 - val_loss: 25.2584 - val_accuracy: 0.5142 - val_precision_395: 0.5142 - val_recall_395: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4160 - accuracy: 0.8118 - precision_395: 0.8121 - recall_395: 0.8068 - val_loss: 17.2934 - val_accuracy: 0.5142 - val_precision_395: 0.5142 - val_recall_395: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3996 - accuracy: 0.8246 - precision_395: 0.8113 - recall_395: 0.8488 - val_loss: 6.9667 - val_accuracy: 0.4858 - val_precision_395: 0.0000e+00 - val_recall_395: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3791 - accuracy: 0.8304 - precision_395: 0.8162 - recall_395: 0.8527 - val_loss: 2.0245 - val_accuracy: 0.5150 - val_precision_395: 0.5146 - val_recall_395: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3984 - accuracy: 0.8149 - precision_395: 0.7988 - recall_395: 0.8454 - val_loss: 0.5947 - val_accuracy: 0.6933 - val_precision_395: 0.8000 - val_recall_395: 0.5381\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3811 - accuracy: 0.8307 - precision_395: 0.8139 - recall_395: 0.8527 - val_loss: 2.5509 - val_accuracy: 0.5117 - val_precision_395: 1.0000 - val_recall_395: 0.0502\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3892 - accuracy: 0.8319 - precision_395: 0.8068 - recall_395: 0.8437 - val_loss: 3.9800 - val_accuracy: 0.5142 - val_precision_395: 0.5142 - val_recall_395: 1.0000\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3667 - accuracy: 0.8354 - precision_395: 0.7998 - recall_395: 0.8936 - val_loss: 1.8675 - val_accuracy: 0.4858 - val_precision_395: 0.5000 - val_recall_395: 0.1767\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3580 - accuracy: 0.8402 - precision_395: 0.8203 - recall_395: 0.8648 - val_loss: 4.0095 - val_accuracy: 0.4500 - val_precision_395: 0.3193 - val_recall_395: 0.0616\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3669 - accuracy: 0.8397 - precision_395: 0.8140 - recall_395: 0.8700 - val_loss: 4.7550 - val_accuracy: 0.4400 - val_precision_395: 0.3514 - val_recall_395: 0.1053\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3489 - accuracy: 0.8362 - precision_395: 0.8170 - recall_395: 0.8588 - val_loss: 4.8673 - val_accuracy: 0.4708 - val_precision_395: 0.4619 - val_recall_395: 0.1767\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3541 - accuracy: 0.8414 - precision_395: 0.8263 - recall_395: 0.8647 - val_loss: 5.2433 - val_accuracy: 0.3608 - val_precision_395: 0.3026 - val_recall_395: 0.1864\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3643 - accuracy: 0.8412 - precision_395: 0.8365 - recall_395: 0.8569 - val_loss: 5.1895 - val_accuracy: 0.3125 - val_precision_395: 0.2079 - val_recall_395: 0.1199\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3582 - accuracy: 0.8219 - precision_395: 0.8067 - recall_395: 0.8456 - val_loss: 3.7416 - val_accuracy: 0.4150 - val_precision_395: 0.3569 - val_recall_395: 0.1718\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3619 - accuracy: 0.8329 - precision_395: 0.8267 - recall_395: 0.8473 - val_loss: 2.3235 - val_accuracy: 0.5558 - val_precision_395: 0.6280 - val_recall_395: 0.3339\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3538 - accuracy: 0.8451 - precision_395: 0.8326 - recall_395: 0.8621 - val_loss: 1.4386 - val_accuracy: 0.6658 - val_precision_395: 0.7842 - val_recall_395: 0.4830\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3598 - accuracy: 0.8343 - precision_395: 0.8192 - recall_395: 0.8548 - val_loss: 0.9456 - val_accuracy: 0.7192 - val_precision_395: 0.8241 - val_recall_395: 0.5770\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3492 - accuracy: 0.8434 - precision_395: 0.8067 - recall_395: 0.8874 - val_loss: 0.6606 - val_accuracy: 0.7583 - val_precision_395: 0.8413 - val_recall_395: 0.6532\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3558 - accuracy: 0.8299 - precision_395: 0.7979 - recall_395: 0.8738 - val_loss: 0.5163 - val_accuracy: 0.7933 - val_precision_395: 0.8541 - val_recall_395: 0.7212\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3570 - accuracy: 0.8401 - precision_395: 0.8357 - recall_395: 0.8532 - val_loss: 0.4082 - val_accuracy: 0.8117 - val_precision_395: 0.8472 - val_recall_395: 0.7731\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3636 - accuracy: 0.8355 - precision_395: 0.8152 - recall_395: 0.8638 - val_loss: 0.3922 - val_accuracy: 0.8283 - val_precision_395: 0.8419 - val_recall_395: 0.8201\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3591 - accuracy: 0.8276 - precision_395: 0.8070 - recall_395: 0.8529 - val_loss: 0.3860 - val_accuracy: 0.8300 - val_precision_395: 0.8283 - val_recall_395: 0.8444\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3445 - accuracy: 0.8391 - precision_395: 0.8231 - recall_395: 0.8639 - val_loss: 0.3847 - val_accuracy: 0.8333 - val_precision_395: 0.8203 - val_recall_395: 0.8655\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3597 - accuracy: 0.8391 - precision_395: 0.8097 - recall_395: 0.8719 - val_loss: 0.3865 - val_accuracy: 0.8325 - val_precision_395: 0.8104 - val_recall_395: 0.8801\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3582 - accuracy: 0.8341 - precision_395: 0.8208 - recall_395: 0.8509 - val_loss: 0.3901 - val_accuracy: 0.8308 - val_precision_395: 0.8017 - val_recall_395: 0.8914\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3637 - accuracy: 0.8339 - precision_395: 0.8102 - recall_395: 0.8623 - val_loss: 0.3932 - val_accuracy: 0.8292 - val_precision_395: 0.7951 - val_recall_395: 0.8995\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3695 - accuracy: 0.8331 - precision_395: 0.8057 - recall_395: 0.8577 - val_loss: 0.3958 - val_accuracy: 0.8275 - val_precision_395: 0.7920 - val_recall_395: 0.9011\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3648 - accuracy: 0.8394 - precision_395: 0.8206 - recall_395: 0.8606 - val_loss: 0.3995 - val_accuracy: 0.8233 - val_precision_395: 0.7840 - val_recall_395: 0.9060\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3587 - accuracy: 0.8308 - precision_395: 0.8115 - recall_395: 0.8606 - val_loss: 0.4030 - val_accuracy: 0.8233 - val_precision_395: 0.7809 - val_recall_395: 0.9125\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3470 - accuracy: 0.8410 - precision_395: 0.8240 - recall_395: 0.8652 - val_loss: 0.4052 - val_accuracy: 0.8258 - val_precision_395: 0.7810 - val_recall_395: 0.9190\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3561 - accuracy: 0.8346 - precision_395: 0.8184 - recall_395: 0.8590 - val_loss: 0.4071 - val_accuracy: 0.8275 - val_precision_395: 0.7801 - val_recall_395: 0.9254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=relu, AUC=0.894, Accuracy=0.802, f2=0.871, prec=0.747, rec=0.909, total=  34.7s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 46ms/step - loss: 0.6480 - accuracy: 0.6745 - precision_396: 0.6721 - recall_396: 0.6544 - val_loss: 51.7421 - val_accuracy: 0.5142 - val_precision_396: 0.5142 - val_recall_396: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4898 - accuracy: 0.7559 - precision_396: 0.7473 - recall_396: 0.7533 - val_loss: 6.7586 - val_accuracy: 0.5142 - val_precision_396: 0.5142 - val_recall_396: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4556 - accuracy: 0.7893 - precision_396: 0.7829 - recall_396: 0.8011 - val_loss: 0.7914 - val_accuracy: 0.4908 - val_precision_396: 0.5536 - val_recall_396: 0.0502\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4316 - accuracy: 0.8038 - precision_396: 0.8040 - recall_396: 0.8059 - val_loss: 2.4755 - val_accuracy: 0.4858 - val_precision_396: 0.0000e+00 - val_recall_396: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4247 - accuracy: 0.8093 - precision_396: 0.8039 - recall_396: 0.8070 - val_loss: 2.9757 - val_accuracy: 0.4858 - val_precision_396: 0.0000e+00 - val_recall_396: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4094 - accuracy: 0.8167 - precision_396: 0.8004 - recall_396: 0.8444 - val_loss: 13.8587 - val_accuracy: 0.3450 - val_precision_396: 0.4074 - val_recall_396: 0.6029\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3981 - accuracy: 0.8203 - precision_396: 0.8038 - recall_396: 0.8414 - val_loss: 82.3918 - val_accuracy: 0.5142 - val_precision_396: 0.5142 - val_recall_396: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3945 - accuracy: 0.8107 - precision_396: 0.8081 - recall_396: 0.8133 - val_loss: 54.0285 - val_accuracy: 0.5142 - val_precision_396: 0.5142 - val_recall_396: 1.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4075 - accuracy: 0.8101 - precision_396: 0.8054 - recall_396: 0.8180 - val_loss: 52.2584 - val_accuracy: 0.5058 - val_precision_396: 0.5101 - val_recall_396: 0.9838\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3796 - accuracy: 0.8224 - precision_396: 0.8226 - recall_396: 0.8304 - val_loss: 45.5805 - val_accuracy: 0.4525 - val_precision_396: 0.4820 - val_recall_396: 0.8687\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3945 - accuracy: 0.8277 - precision_396: 0.8185 - recall_396: 0.8365 - val_loss: 34.3495 - val_accuracy: 0.3333 - val_precision_396: 0.3980 - val_recall_396: 0.5786\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3958 - accuracy: 0.8264 - precision_396: 0.8240 - recall_396: 0.8331 - val_loss: 23.2488 - val_accuracy: 0.2608 - val_precision_396: 0.2997 - val_recall_396: 0.3274\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4024 - accuracy: 0.8190 - precision_396: 0.7998 - recall_396: 0.8313 - val_loss: 13.5007 - val_accuracy: 0.2850 - val_precision_396: 0.2463 - val_recall_396: 0.1896\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4059 - accuracy: 0.8183 - precision_396: 0.8113 - recall_396: 0.8331 - val_loss: 7.4372 - val_accuracy: 0.3567 - val_precision_396: 0.2373 - val_recall_396: 0.1135\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3800 - accuracy: 0.8303 - precision_396: 0.8266 - recall_396: 0.8379 - val_loss: 4.0229 - val_accuracy: 0.4608 - val_precision_396: 0.4250 - val_recall_396: 0.1378\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3891 - accuracy: 0.8240 - precision_396: 0.8060 - recall_396: 0.8390 - val_loss: 2.1694 - val_accuracy: 0.5617 - val_precision_396: 0.7310 - val_recall_396: 0.2334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.4, batch_size=100, activation=relu, AUC=0.769, Accuracy=0.547, f2=0.249, prec=0.628, rec=0.217, total=  18.5s\n",
      "[CV] lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.7359 - accuracy: 0.6715 - precision_397: 0.6580 - recall_397: 0.6767 - val_loss: 14.9253 - val_accuracy: 0.5142 - val_precision_397: 0.5142 - val_recall_397: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4643 - accuracy: 0.7771 - precision_397: 0.7600 - recall_397: 0.7987 - val_loss: 3.6434 - val_accuracy: 0.5142 - val_precision_397: 0.5142 - val_recall_397: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4619 - accuracy: 0.7751 - precision_397: 0.7901 - recall_397: 0.7486 - val_loss: 1.3534 - val_accuracy: 0.5142 - val_precision_397: 0.5142 - val_recall_397: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4522 - accuracy: 0.7878 - precision_397: 0.7819 - recall_397: 0.7976 - val_loss: 1.0992 - val_accuracy: 0.5142 - val_precision_397: 0.5142 - val_recall_397: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4182 - accuracy: 0.8085 - precision_397: 0.8003 - recall_397: 0.8256 - val_loss: 1.4994 - val_accuracy: 0.4867 - val_precision_397: 1.0000 - val_recall_397: 0.0016\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4331 - accuracy: 0.7884 - precision_397: 0.7876 - recall_397: 0.7841 - val_loss: 1.0094 - val_accuracy: 0.5142 - val_precision_397: 0.5142 - val_recall_397: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4084 - accuracy: 0.8139 - precision_397: 0.8063 - recall_397: 0.8154 - val_loss: 4.2313 - val_accuracy: 0.4917 - val_precision_397: 1.0000 - val_recall_397: 0.0113\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4092 - accuracy: 0.8168 - precision_397: 0.8121 - recall_397: 0.8347 - val_loss: 0.5562 - val_accuracy: 0.7408 - val_precision_397: 0.7304 - val_recall_397: 0.7861\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4066 - accuracy: 0.8182 - precision_397: 0.8040 - recall_397: 0.8402 - val_loss: 0.6360 - val_accuracy: 0.6033 - val_precision_397: 0.8106 - val_recall_397: 0.2982\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3876 - accuracy: 0.8222 - precision_397: 0.8176 - recall_397: 0.8297 - val_loss: 4.7053 - val_accuracy: 0.5125 - val_precision_397: 0.5134 - val_recall_397: 0.9968\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3835 - accuracy: 0.8247 - precision_397: 0.8016 - recall_397: 0.8621 - val_loss: 15.8443 - val_accuracy: 0.5142 - val_precision_397: 0.5142 - val_recall_397: 1.0000\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3918 - accuracy: 0.8256 - precision_397: 0.8145 - recall_397: 0.8490 - val_loss: 1.9393 - val_accuracy: 0.4933 - val_precision_397: 0.9091 - val_recall_397: 0.0162\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3715 - accuracy: 0.8310 - precision_397: 0.8154 - recall_397: 0.8424 - val_loss: 0.4278 - val_accuracy: 0.7892 - val_precision_397: 0.8473 - val_recall_397: 0.7196\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3524 - accuracy: 0.8429 - precision_397: 0.8255 - recall_397: 0.8616 - val_loss: 0.3932 - val_accuracy: 0.8158 - val_precision_397: 0.8333 - val_recall_397: 0.8023\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3630 - accuracy: 0.8329 - precision_397: 0.8093 - recall_397: 0.8541 - val_loss: 0.5953 - val_accuracy: 0.7233 - val_precision_397: 0.6541 - val_recall_397: 0.9806\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3831 - accuracy: 0.8221 - precision_397: 0.8081 - recall_397: 0.8402 - val_loss: 1.9972 - val_accuracy: 0.5675 - val_precision_397: 0.9804 - val_recall_397: 0.1621\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3435 - accuracy: 0.8455 - precision_397: 0.8432 - recall_397: 0.8577 - val_loss: 1.3702 - val_accuracy: 0.6142 - val_precision_397: 0.9278 - val_recall_397: 0.2707\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3680 - accuracy: 0.8331 - precision_397: 0.8240 - recall_397: 0.8506 - val_loss: 0.8146 - val_accuracy: 0.7108 - val_precision_397: 0.9245 - val_recall_397: 0.4765\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3523 - accuracy: 0.8501 - precision_397: 0.8366 - recall_397: 0.8764 - val_loss: 0.5903 - val_accuracy: 0.7550 - val_precision_397: 0.8949 - val_recall_397: 0.5932\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3673 - accuracy: 0.8311 - precision_397: 0.8103 - recall_397: 0.8551 - val_loss: 0.4538 - val_accuracy: 0.7992 - val_precision_397: 0.8760 - val_recall_397: 0.7099\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3680 - accuracy: 0.8282 - precision_397: 0.8215 - recall_397: 0.8447 - val_loss: 0.3978 - val_accuracy: 0.8242 - val_precision_397: 0.8464 - val_recall_397: 0.8039\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3550 - accuracy: 0.8256 - precision_397: 0.8065 - recall_397: 0.8454 - val_loss: 0.3839 - val_accuracy: 0.8308 - val_precision_397: 0.8245 - val_recall_397: 0.8525\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3625 - accuracy: 0.8354 - precision_397: 0.8235 - recall_397: 0.8505 - val_loss: 0.3867 - val_accuracy: 0.8308 - val_precision_397: 0.8053 - val_recall_397: 0.8849\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3578 - accuracy: 0.8431 - precision_397: 0.8336 - recall_397: 0.8602 - val_loss: 0.3939 - val_accuracy: 0.8233 - val_precision_397: 0.7897 - val_recall_397: 0.8947\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3704 - accuracy: 0.8297 - precision_397: 0.8154 - recall_397: 0.8534 - val_loss: 0.4046 - val_accuracy: 0.8308 - val_precision_397: 0.7859 - val_recall_397: 0.9222\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3485 - accuracy: 0.8501 - precision_397: 0.8404 - recall_397: 0.8707 - val_loss: 0.4137 - val_accuracy: 0.8258 - val_precision_397: 0.7720 - val_recall_397: 0.9384\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3450 - accuracy: 0.8444 - precision_397: 0.8271 - recall_397: 0.8687 - val_loss: 0.4231 - val_accuracy: 0.8125 - val_precision_397: 0.7545 - val_recall_397: 0.9417\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3488 - accuracy: 0.8412 - precision_397: 0.8332 - recall_397: 0.8556 - val_loss: 0.4423 - val_accuracy: 0.8067 - val_precision_397: 0.7465 - val_recall_397: 0.9449\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3536 - accuracy: 0.8409 - precision_397: 0.8311 - recall_397: 0.8516 - val_loss: 0.4482 - val_accuracy: 0.8067 - val_precision_397: 0.7446 - val_recall_397: 0.9498\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3792 - accuracy: 0.8310 - precision_397: 0.8250 - recall_397: 0.8455 - val_loss: 0.4546 - val_accuracy: 0.8058 - val_precision_397: 0.7424 - val_recall_397: 0.9530\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3578 - accuracy: 0.8352 - precision_397: 0.8189 - recall_397: 0.8551 - val_loss: 0.4607 - val_accuracy: 0.8017 - val_precision_397: 0.7378 - val_recall_397: 0.9530\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3475 - accuracy: 0.8508 - precision_397: 0.8311 - recall_397: 0.8696 - val_loss: 0.4649 - val_accuracy: 0.7992 - val_precision_397: 0.7350 - val_recall_397: 0.9530\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3594 - accuracy: 0.8367 - precision_397: 0.8265 - recall_397: 0.8499 - val_loss: 0.4692 - val_accuracy: 0.7967 - val_precision_397: 0.7323 - val_recall_397: 0.9530\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3581 - accuracy: 0.8375 - precision_397: 0.8313 - recall_397: 0.8552 - val_loss: 0.4700 - val_accuracy: 0.7975 - val_precision_397: 0.7332 - val_recall_397: 0.9530\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3609 - accuracy: 0.8402 - precision_397: 0.8145 - recall_397: 0.8744 - val_loss: 0.4726 - val_accuracy: 0.7975 - val_precision_397: 0.7320 - val_recall_397: 0.9562\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3647 - accuracy: 0.8346 - precision_397: 0.8297 - recall_397: 0.8457 - val_loss: 0.4832 - val_accuracy: 0.7958 - val_precision_397: 0.7302 - val_recall_397: 0.9562\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3540 - accuracy: 0.8423 - precision_397: 0.8330 - recall_397: 0.8552 - val_loss: 0.4838 - val_accuracy: 0.7958 - val_precision_397: 0.7302 - val_recall_397: 0.9562\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3518 - accuracy: 0.8494 - precision_397: 0.8350 - recall_397: 0.8649 - val_loss: 0.4846 - val_accuracy: 0.7950 - val_precision_397: 0.7293 - val_recall_397: 0.9562\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3705 - accuracy: 0.8277 - precision_397: 0.8209 - recall_397: 0.8434 - val_loss: 0.4868 - val_accuracy: 0.7950 - val_precision_397: 0.7287 - val_recall_397: 0.9579\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3752 - accuracy: 0.8340 - precision_397: 0.8297 - recall_397: 0.8467 - val_loss: 0.4866 - val_accuracy: 0.7933 - val_precision_397: 0.7269 - val_recall_397: 0.9579\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3734 - accuracy: 0.8300 - precision_397: 0.8218 - recall_397: 0.8394 - val_loss: 0.4750 - val_accuracy: 0.7908 - val_precision_397: 0.7243 - val_recall_397: 0.9579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu, AUC=0.913, Accuracy=0.801, f2=0.891, prec=0.734, rec=0.941, total=  42.0s\n",
      "[CV] lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.7336 - accuracy: 0.6667 - precision_398: 0.6695 - recall_398: 0.6703 - val_loss: 197.4276 - val_accuracy: 0.5142 - val_precision_398: 0.5142 - val_recall_398: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4697 - accuracy: 0.7723 - precision_398: 0.7593 - recall_398: 0.7908 - val_loss: 55.8092 - val_accuracy: 0.5142 - val_precision_398: 0.5142 - val_recall_398: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4384 - accuracy: 0.7982 - precision_398: 0.8030 - recall_398: 0.7952 - val_loss: 14.1357 - val_accuracy: 0.5142 - val_precision_398: 0.5142 - val_recall_398: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4253 - accuracy: 0.8013 - precision_398: 0.7972 - recall_398: 0.7946 - val_loss: 7.9604 - val_accuracy: 0.5142 - val_precision_398: 0.5142 - val_recall_398: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4131 - accuracy: 0.8150 - precision_398: 0.8002 - recall_398: 0.8396 - val_loss: 10.7874 - val_accuracy: 0.5142 - val_precision_398: 0.5142 - val_recall_398: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4197 - accuracy: 0.8064 - precision_398: 0.7827 - recall_398: 0.8268 - val_loss: 5.7840 - val_accuracy: 0.5142 - val_precision_398: 0.5142 - val_recall_398: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4025 - accuracy: 0.8092 - precision_398: 0.7852 - recall_398: 0.8380 - val_loss: 9.2437 - val_accuracy: 0.5142 - val_precision_398: 0.5142 - val_recall_398: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3809 - accuracy: 0.8234 - precision_398: 0.8030 - recall_398: 0.8530 - val_loss: 7.9849 - val_accuracy: 0.4858 - val_precision_398: 0.0000e+00 - val_recall_398: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3785 - accuracy: 0.8232 - precision_398: 0.8003 - recall_398: 0.8601 - val_loss: 5.6915 - val_accuracy: 0.4858 - val_precision_398: 0.0000e+00 - val_recall_398: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3599 - accuracy: 0.8431 - precision_398: 0.8362 - recall_398: 0.8603 - val_loss: 0.4308 - val_accuracy: 0.7908 - val_precision_398: 0.8690 - val_recall_398: 0.6985\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3725 - accuracy: 0.8353 - precision_398: 0.8130 - recall_398: 0.8623 - val_loss: 1.1915 - val_accuracy: 0.5733 - val_precision_398: 0.9646 - val_recall_398: 0.1767\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3506 - accuracy: 0.8433 - precision_398: 0.8229 - recall_398: 0.8680 - val_loss: 3.4660 - val_accuracy: 0.5142 - val_precision_398: 0.5142 - val_recall_398: 1.0000\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3553 - accuracy: 0.8352 - precision_398: 0.8374 - recall_398: 0.8419 - val_loss: 2.1700 - val_accuracy: 0.5158 - val_precision_398: 0.5150 - val_recall_398: 1.0000\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3512 - accuracy: 0.8357 - precision_398: 0.8208 - recall_398: 0.8535 - val_loss: 0.3762 - val_accuracy: 0.8358 - val_precision_398: 0.8387 - val_recall_398: 0.8428\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3396 - accuracy: 0.8499 - precision_398: 0.8371 - recall_398: 0.8643 - val_loss: 1.1216 - val_accuracy: 0.5783 - val_precision_398: 0.9744 - val_recall_398: 0.1848\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3555 - accuracy: 0.8369 - precision_398: 0.8127 - recall_398: 0.8633 - val_loss: 0.9441 - val_accuracy: 0.6283 - val_precision_398: 0.9622 - val_recall_398: 0.2885\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3524 - accuracy: 0.8385 - precision_398: 0.8112 - recall_398: 0.8737 - val_loss: 0.6023 - val_accuracy: 0.7242 - val_precision_398: 0.9281 - val_recall_398: 0.5024\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3611 - accuracy: 0.8341 - precision_398: 0.8134 - recall_398: 0.8571 - val_loss: 0.4186 - val_accuracy: 0.8033 - val_precision_398: 0.8944 - val_recall_398: 0.7002\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3316 - accuracy: 0.8484 - precision_398: 0.8428 - recall_398: 0.8613 - val_loss: 0.3925 - val_accuracy: 0.8133 - val_precision_398: 0.8632 - val_recall_398: 0.7569\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3325 - accuracy: 0.8493 - precision_398: 0.8349 - recall_398: 0.8690 - val_loss: 0.3741 - val_accuracy: 0.8400 - val_precision_398: 0.8389 - val_recall_398: 0.8525\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3417 - accuracy: 0.8494 - precision_398: 0.8273 - recall_398: 0.8763 - val_loss: 0.3763 - val_accuracy: 0.8342 - val_precision_398: 0.8138 - val_recall_398: 0.8784\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3540 - accuracy: 0.8372 - precision_398: 0.8329 - recall_398: 0.8476 - val_loss: 0.3827 - val_accuracy: 0.8300 - val_precision_398: 0.7997 - val_recall_398: 0.8930\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3402 - accuracy: 0.8455 - precision_398: 0.8313 - recall_398: 0.8628 - val_loss: 0.3876 - val_accuracy: 0.8292 - val_precision_398: 0.7918 - val_recall_398: 0.9060\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3380 - accuracy: 0.8432 - precision_398: 0.8296 - recall_398: 0.8578 - val_loss: 0.3924 - val_accuracy: 0.8258 - val_precision_398: 0.7849 - val_recall_398: 0.9109\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3471 - accuracy: 0.8378 - precision_398: 0.8285 - recall_398: 0.8506 - val_loss: 0.3966 - val_accuracy: 0.8208 - val_precision_398: 0.7761 - val_recall_398: 0.9157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu, AUC=0.894, Accuracy=0.799, f2=0.867, prec=0.746, rec=0.903, total=  26.5s\n",
      "[CV] lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.7597 - accuracy: 0.6691 - precision_399: 0.6620 - recall_399: 0.6682 - val_loss: 219.5708 - val_accuracy: 0.5142 - val_precision_399: 0.5142 - val_recall_399: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4719 - accuracy: 0.7802 - precision_399: 0.7681 - recall_399: 0.7746 - val_loss: 74.8093 - val_accuracy: 0.5142 - val_precision_399: 0.5142 - val_recall_399: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4562 - accuracy: 0.7957 - precision_399: 0.7899 - recall_399: 0.8035 - val_loss: 32.3657 - val_accuracy: 0.5142 - val_precision_399: 0.5142 - val_recall_399: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4275 - accuracy: 0.8026 - precision_399: 0.7962 - recall_399: 0.8227 - val_loss: 10.9888 - val_accuracy: 0.5142 - val_precision_399: 0.5142 - val_recall_399: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4387 - accuracy: 0.7976 - precision_399: 0.8036 - recall_399: 0.7886 - val_loss: 0.9199 - val_accuracy: 0.6133 - val_precision_399: 0.5851 - val_recall_399: 0.8525\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4479 - accuracy: 0.7967 - precision_399: 0.7806 - recall_399: 0.8069 - val_loss: 8.8478 - val_accuracy: 0.4858 - val_precision_399: 0.0000e+00 - val_recall_399: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4152 - accuracy: 0.8189 - precision_399: 0.8170 - recall_399: 0.8187 - val_loss: 81.9248 - val_accuracy: 0.4858 - val_precision_399: 0.0000e+00 - val_recall_399: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4086 - accuracy: 0.8109 - precision_399: 0.8024 - recall_399: 0.8129 - val_loss: 84.2033 - val_accuracy: 0.4858 - val_precision_399: 0.0000e+00 - val_recall_399: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3796 - accuracy: 0.8181 - precision_399: 0.8121 - recall_399: 0.8258 - val_loss: 121.1226 - val_accuracy: 0.4858 - val_precision_399: 0.0000e+00 - val_recall_399: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3673 - accuracy: 0.8307 - precision_399: 0.8223 - recall_399: 0.8403 - val_loss: 79.7624 - val_accuracy: 0.4900 - val_precision_399: 0.8571 - val_recall_399: 0.0097\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3816 - accuracy: 0.8260 - precision_399: 0.8221 - recall_399: 0.8293 - val_loss: 70.2990 - val_accuracy: 0.4925 - val_precision_399: 0.9000 - val_recall_399: 0.0146\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3758 - accuracy: 0.8236 - precision_399: 0.8036 - recall_399: 0.8463 - val_loss: 31.4598 - val_accuracy: 0.4858 - val_precision_399: 0.5000 - val_recall_399: 0.0032\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3915 - accuracy: 0.8247 - precision_399: 0.8178 - recall_399: 0.8335 - val_loss: 12.0620 - val_accuracy: 0.4858 - val_precision_399: 0.0000e+00 - val_recall_399: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3842 - accuracy: 0.8180 - precision_399: 0.7998 - recall_399: 0.8369 - val_loss: 5.4171 - val_accuracy: 0.4767 - val_precision_399: 0.0000e+00 - val_recall_399: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3647 - accuracy: 0.8376 - precision_399: 0.8209 - recall_399: 0.8579 - val_loss: 3.3565 - val_accuracy: 0.4792 - val_precision_399: 0.3333 - val_recall_399: 0.0130\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3715 - accuracy: 0.8357 - precision_399: 0.8256 - recall_399: 0.8495 - val_loss: 2.0200 - val_accuracy: 0.5283 - val_precision_399: 0.8592 - val_recall_399: 0.0989\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3762 - accuracy: 0.8232 - precision_399: 0.8106 - recall_399: 0.8396 - val_loss: 1.2379 - val_accuracy: 0.6033 - val_precision_399: 0.9548 - val_recall_399: 0.2399\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3762 - accuracy: 0.8305 - precision_399: 0.8063 - recall_399: 0.8466 - val_loss: 0.8159 - val_accuracy: 0.6808 - val_precision_399: 0.9301 - val_recall_399: 0.4100\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3581 - accuracy: 0.8374 - precision_399: 0.8355 - recall_399: 0.8451 - val_loss: 0.5877 - val_accuracy: 0.7392 - val_precision_399: 0.9108 - val_recall_399: 0.5462\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3906 - accuracy: 0.8224 - precision_399: 0.7998 - recall_399: 0.8375 - val_loss: 0.4716 - val_accuracy: 0.7717 - val_precision_399: 0.8871 - val_recall_399: 0.6370\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3584 - accuracy: 0.8424 - precision_399: 0.8398 - recall_399: 0.8434 - val_loss: 0.4146 - val_accuracy: 0.7925 - val_precision_399: 0.8608 - val_recall_399: 0.7115\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3731 - accuracy: 0.8355 - precision_399: 0.8328 - recall_399: 0.8402 - val_loss: 0.3890 - val_accuracy: 0.8183 - val_precision_399: 0.8506 - val_recall_399: 0.7844\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3961 - accuracy: 0.8176 - precision_399: 0.8002 - recall_399: 0.8412 - val_loss: 0.3806 - val_accuracy: 0.8325 - val_precision_399: 0.8366 - val_recall_399: 0.8379\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3654 - accuracy: 0.8369 - precision_399: 0.8294 - recall_399: 0.8463 - val_loss: 0.3808 - val_accuracy: 0.8308 - val_precision_399: 0.8175 - val_recall_399: 0.8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu, AUC=0.908, Accuracy=0.829, f2=0.852, prec=0.805, rec=0.864, total=  25.6s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 58ms/step - loss: 0.7295 - accuracy: 0.6667 - precision_400: 0.6677 - recall_400: 0.6670 - val_loss: 386.7556 - val_accuracy: 0.5142 - val_precision_400: 0.5142 - val_recall_400: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4884 - accuracy: 0.7600 - precision_400: 0.7477 - recall_400: 0.7678 - val_loss: 80.4619 - val_accuracy: 0.5142 - val_precision_400: 0.5142 - val_recall_400: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4988 - accuracy: 0.7559 - precision_400: 0.7412 - recall_400: 0.7546 - val_loss: 30.9719 - val_accuracy: 0.5142 - val_precision_400: 0.5142 - val_recall_400: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4679 - accuracy: 0.7710 - precision_400: 0.7557 - recall_400: 0.7777 - val_loss: 9.1812 - val_accuracy: 0.5142 - val_precision_400: 0.5142 - val_recall_400: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4529 - accuracy: 0.7910 - precision_400: 0.7680 - recall_400: 0.8144 - val_loss: 2.8810 - val_accuracy: 0.5142 - val_precision_400: 0.5142 - val_recall_400: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4247 - accuracy: 0.8125 - precision_400: 0.8060 - recall_400: 0.8092 - val_loss: 21.9265 - val_accuracy: 0.4858 - val_precision_400: 0.0000e+00 - val_recall_400: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4163 - accuracy: 0.8169 - precision_400: 0.7976 - recall_400: 0.8439 - val_loss: 66.2877 - val_accuracy: 0.4858 - val_precision_400: 0.0000e+00 - val_recall_400: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3996 - accuracy: 0.8159 - precision_400: 0.8227 - recall_400: 0.8171 - val_loss: 31.1765 - val_accuracy: 0.4858 - val_precision_400: 0.0000e+00 - val_recall_400: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3945 - accuracy: 0.8177 - precision_400: 0.8003 - recall_400: 0.8311 - val_loss: 107.3880 - val_accuracy: 0.4858 - val_precision_400: 0.0000e+00 - val_recall_400: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4125 - accuracy: 0.8096 - precision_400: 0.7988 - recall_400: 0.8308 - val_loss: 118.5920 - val_accuracy: 0.4858 - val_precision_400: 0.0000e+00 - val_recall_400: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3778 - accuracy: 0.8282 - precision_400: 0.8248 - recall_400: 0.8424 - val_loss: 50.3222 - val_accuracy: 0.4858 - val_precision_400: 0.0000e+00 - val_recall_400: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3630 - accuracy: 0.8374 - precision_400: 0.8257 - recall_400: 0.8506 - val_loss: 22.6891 - val_accuracy: 0.4867 - val_precision_400: 1.0000 - val_recall_400: 0.0016\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3686 - accuracy: 0.8395 - precision_400: 0.8162 - recall_400: 0.8646 - val_loss: 13.9223 - val_accuracy: 0.4908 - val_precision_400: 0.8750 - val_recall_400: 0.0113\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3813 - accuracy: 0.8273 - precision_400: 0.8050 - recall_400: 0.8539 - val_loss: 6.0137 - val_accuracy: 0.4942 - val_precision_400: 0.9167 - val_recall_400: 0.0178\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3761 - accuracy: 0.8257 - precision_400: 0.8183 - recall_400: 0.8394 - val_loss: 3.1965 - val_accuracy: 0.5042 - val_precision_400: 0.9583 - val_recall_400: 0.0373\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3661 - accuracy: 0.8229 - precision_400: 0.8067 - recall_400: 0.8423 - val_loss: 2.0241 - val_accuracy: 0.5500 - val_precision_400: 0.9873 - val_recall_400: 0.1264\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3817 - accuracy: 0.8244 - precision_400: 0.8163 - recall_400: 0.8392 - val_loss: 1.4114 - val_accuracy: 0.5983 - val_precision_400: 0.9470 - val_recall_400: 0.2318\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3842 - accuracy: 0.8198 - precision_400: 0.8178 - recall_400: 0.8306 - val_loss: 1.0423 - val_accuracy: 0.6467 - val_precision_400: 0.9214 - val_recall_400: 0.3420\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3786 - accuracy: 0.8299 - precision_400: 0.8096 - recall_400: 0.8539 - val_loss: 0.8105 - val_accuracy: 0.6975 - val_precision_400: 0.9205 - val_recall_400: 0.4506\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3741 - accuracy: 0.8284 - precision_400: 0.8196 - recall_400: 0.8491 - val_loss: 0.6566 - val_accuracy: 0.7350 - val_precision_400: 0.9141 - val_recall_400: 0.5348\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3973 - accuracy: 0.8176 - precision_400: 0.8069 - recall_400: 0.8396 - val_loss: 0.5503 - val_accuracy: 0.7508 - val_precision_400: 0.8936 - val_recall_400: 0.5851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=relu, AUC=0.907, Accuracy=0.762, f2=0.635, prec=0.894, rec=0.592, total=  23.1s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.7117 - accuracy: 0.6650 - precision_401: 0.6575 - recall_401: 0.6302 - val_loss: 451.0248 - val_accuracy: 0.5142 - val_precision_401: 0.5142 - val_recall_401: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4904 - accuracy: 0.7676 - precision_401: 0.7602 - recall_401: 0.7769 - val_loss: 120.7682 - val_accuracy: 0.5142 - val_precision_401: 0.5142 - val_recall_401: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4649 - accuracy: 0.7749 - precision_401: 0.7719 - recall_401: 0.7766 - val_loss: 35.2577 - val_accuracy: 0.5142 - val_precision_401: 0.5142 - val_recall_401: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4347 - accuracy: 0.7932 - precision_401: 0.7820 - recall_401: 0.8013 - val_loss: 12.6469 - val_accuracy: 0.5142 - val_precision_401: 0.5142 - val_recall_401: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4358 - accuracy: 0.8000 - precision_401: 0.7999 - recall_401: 0.8171 - val_loss: 0.6488 - val_accuracy: 0.6608 - val_precision_401: 0.8596 - val_recall_401: 0.4068\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4267 - accuracy: 0.8005 - precision_401: 0.8117 - recall_401: 0.7801 - val_loss: 1.9407 - val_accuracy: 0.5617 - val_precision_401: 0.8473 - val_recall_401: 0.1799\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4426 - accuracy: 0.7916 - precision_401: 0.7871 - recall_401: 0.8018 - val_loss: 2.3660 - val_accuracy: 0.5142 - val_precision_401: 0.5142 - val_recall_401: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4031 - accuracy: 0.8216 - precision_401: 0.7959 - recall_401: 0.8547 - val_loss: 2.7032 - val_accuracy: 0.5717 - val_precision_401: 0.6625 - val_recall_401: 0.3404\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3811 - accuracy: 0.8261 - precision_401: 0.8074 - recall_401: 0.8494 - val_loss: 8.5995 - val_accuracy: 0.7175 - val_precision_401: 0.6810 - val_recall_401: 0.8476\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3798 - accuracy: 0.8232 - precision_401: 0.8146 - recall_401: 0.8442 - val_loss: 4.2148 - val_accuracy: 0.6825 - val_precision_401: 0.6630 - val_recall_401: 0.7780\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3684 - accuracy: 0.8308 - precision_401: 0.8095 - recall_401: 0.8490 - val_loss: 2.8807 - val_accuracy: 0.5100 - val_precision_401: 0.8222 - val_recall_401: 0.0600\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3609 - accuracy: 0.8317 - precision_401: 0.8142 - recall_401: 0.8554 - val_loss: 2.3598 - val_accuracy: 0.5267 - val_precision_401: 0.9455 - val_recall_401: 0.0843\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3647 - accuracy: 0.8339 - precision_401: 0.8238 - recall_401: 0.8497 - val_loss: 2.1146 - val_accuracy: 0.5475 - val_precision_401: 0.9625 - val_recall_401: 0.1248\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3705 - accuracy: 0.8268 - precision_401: 0.8071 - recall_401: 0.8462 - val_loss: 1.3472 - val_accuracy: 0.6108 - val_precision_401: 0.9630 - val_recall_401: 0.2528\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3738 - accuracy: 0.8274 - precision_401: 0.8136 - recall_401: 0.8442 - val_loss: 0.8849 - val_accuracy: 0.6808 - val_precision_401: 0.9301 - val_recall_401: 0.4100\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3782 - accuracy: 0.8284 - precision_401: 0.8113 - recall_401: 0.8503 - val_loss: 0.6396 - val_accuracy: 0.7433 - val_precision_401: 0.9142 - val_recall_401: 0.5527\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3777 - accuracy: 0.8209 - precision_401: 0.8175 - recall_401: 0.8370 - val_loss: 0.5126 - val_accuracy: 0.7608 - val_precision_401: 0.8802 - val_recall_401: 0.6191\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3564 - accuracy: 0.8386 - precision_401: 0.8259 - recall_401: 0.8564 - val_loss: 0.4447 - val_accuracy: 0.7850 - val_precision_401: 0.8671 - val_recall_401: 0.6872\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3527 - accuracy: 0.8425 - precision_401: 0.8382 - recall_401: 0.8513 - val_loss: 0.4138 - val_accuracy: 0.8125 - val_precision_401: 0.8564 - val_recall_401: 0.7634\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3655 - accuracy: 0.8396 - precision_401: 0.8199 - recall_401: 0.8626 - val_loss: 0.3989 - val_accuracy: 0.8142 - val_precision_401: 0.8328 - val_recall_401: 0.7990\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3901 - accuracy: 0.8225 - precision_401: 0.8157 - recall_401: 0.8456 - val_loss: 0.3937 - val_accuracy: 0.8208 - val_precision_401: 0.8201 - val_recall_401: 0.8347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=relu, AUC=0.891, Accuracy=0.808, f2=0.808, prec=0.806, rec=0.809, total=  22.9s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.6955 - accuracy: 0.6683 - precision_402: 0.6686 - recall_402: 0.6515 - val_loss: 176.1387 - val_accuracy: 0.5142 - val_precision_402: 0.5142 - val_recall_402: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5057 - accuracy: 0.7529 - precision_402: 0.7429 - recall_402: 0.7584 - val_loss: 46.7374 - val_accuracy: 0.5142 - val_precision_402: 0.5142 - val_recall_402: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4785 - accuracy: 0.7677 - precision_402: 0.7571 - recall_402: 0.7735 - val_loss: 15.2557 - val_accuracy: 0.5142 - val_precision_402: 0.5142 - val_recall_402: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4517 - accuracy: 0.7915 - precision_402: 0.7845 - recall_402: 0.8032 - val_loss: 5.7787 - val_accuracy: 0.5142 - val_precision_402: 0.5142 - val_recall_402: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4227 - accuracy: 0.8089 - precision_402: 0.8076 - recall_402: 0.8153 - val_loss: 2.3216 - val_accuracy: 0.5142 - val_precision_402: 0.5142 - val_recall_402: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4447 - accuracy: 0.7887 - precision_402: 0.7884 - recall_402: 0.7940 - val_loss: 2.3501 - val_accuracy: 0.5142 - val_precision_402: 0.5142 - val_recall_402: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4215 - accuracy: 0.8077 - precision_402: 0.8050 - recall_402: 0.8081 - val_loss: 8.5796 - val_accuracy: 0.4858 - val_precision_402: 0.0000e+00 - val_recall_402: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4019 - accuracy: 0.8261 - precision_402: 0.8208 - recall_402: 0.8284 - val_loss: 5.6257 - val_accuracy: 0.4858 - val_precision_402: 0.0000e+00 - val_recall_402: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3829 - accuracy: 0.8267 - precision_402: 0.8216 - recall_402: 0.8402 - val_loss: 1.1800 - val_accuracy: 0.5117 - val_precision_402: 0.9697 - val_recall_402: 0.0519\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3730 - accuracy: 0.8345 - precision_402: 0.8240 - recall_402: 0.8473 - val_loss: 7.1357 - val_accuracy: 0.4858 - val_precision_402: 0.0000e+00 - val_recall_402: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3865 - accuracy: 0.8268 - precision_402: 0.8163 - recall_402: 0.8419 - val_loss: 0.4454 - val_accuracy: 0.8017 - val_precision_402: 0.7490 - val_recall_402: 0.9238\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3712 - accuracy: 0.8291 - precision_402: 0.8252 - recall_402: 0.8329 - val_loss: 2.6156 - val_accuracy: 0.4883 - val_precision_402: 1.0000 - val_recall_402: 0.0049\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3804 - accuracy: 0.8224 - precision_402: 0.8159 - recall_402: 0.8307 - val_loss: 7.2776 - val_accuracy: 0.4858 - val_precision_402: 0.0000e+00 - val_recall_402: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3706 - accuracy: 0.8255 - precision_402: 0.8145 - recall_402: 0.8461 - val_loss: 3.9202 - val_accuracy: 0.4858 - val_precision_402: 0.0000e+00 - val_recall_402: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3764 - accuracy: 0.8341 - precision_402: 0.8287 - recall_402: 0.8433 - val_loss: 3.3003 - val_accuracy: 0.4875 - val_precision_402: 1.0000 - val_recall_402: 0.0032\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3647 - accuracy: 0.8286 - precision_402: 0.8157 - recall_402: 0.8467 - val_loss: 2.8205 - val_accuracy: 0.4942 - val_precision_402: 1.0000 - val_recall_402: 0.0162\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3805 - accuracy: 0.8251 - precision_402: 0.8146 - recall_402: 0.8417 - val_loss: 1.5446 - val_accuracy: 0.5758 - val_precision_402: 0.9737 - val_recall_402: 0.1799\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3622 - accuracy: 0.8347 - precision_402: 0.8280 - recall_402: 0.8532 - val_loss: 0.9949 - val_accuracy: 0.6508 - val_precision_402: 0.9420 - val_recall_402: 0.3420\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3595 - accuracy: 0.8412 - precision_402: 0.8283 - recall_402: 0.8575 - val_loss: 0.7888 - val_accuracy: 0.6958 - val_precision_402: 0.9228 - val_recall_402: 0.4457\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3668 - accuracy: 0.8305 - precision_402: 0.8117 - recall_402: 0.8526 - val_loss: 0.5728 - val_accuracy: 0.7492 - val_precision_402: 0.9093 - val_recall_402: 0.5689\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3791 - accuracy: 0.8277 - precision_402: 0.8091 - recall_402: 0.8459 - val_loss: 0.4769 - val_accuracy: 0.7708 - val_precision_402: 0.8886 - val_recall_402: 0.6337\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3591 - accuracy: 0.8423 - precision_402: 0.8255 - recall_402: 0.8622 - val_loss: 0.4202 - val_accuracy: 0.7967 - val_precision_402: 0.8723 - val_recall_402: 0.7083\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3769 - accuracy: 0.8242 - precision_402: 0.7923 - recall_402: 0.8556 - val_loss: 0.3909 - val_accuracy: 0.8192 - val_precision_402: 0.8559 - val_recall_402: 0.7796\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3762 - accuracy: 0.8230 - precision_402: 0.7956 - recall_402: 0.8532 - val_loss: 0.3801 - val_accuracy: 0.8258 - val_precision_402: 0.8481 - val_recall_402: 0.8055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=relu, AUC=0.912, Accuracy=0.828, f2=0.820, prec=0.832, rec=0.817, total=  25.8s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=200, activation=elu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 83ms/step - loss: 0.8237 - accuracy: 0.6730 - precision_403: 0.6645 - recall_403: 0.6736 - val_loss: 84.8992 - val_accuracy: 0.5142 - val_precision_403: 0.5142 - val_recall_403: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.4880 - accuracy: 0.7580 - precision_403: 0.7665 - recall_403: 0.7293 - val_loss: 78.5768 - val_accuracy: 0.5142 - val_precision_403: 0.5142 - val_recall_403: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.4261 - accuracy: 0.8018 - precision_403: 0.7984 - recall_403: 0.8032 - val_loss: 41.9014 - val_accuracy: 0.5142 - val_precision_403: 0.5142 - val_recall_403: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.4212 - accuracy: 0.8014 - precision_403: 0.7924 - recall_403: 0.8111 - val_loss: 23.6685 - val_accuracy: 0.5142 - val_precision_403: 0.5142 - val_recall_403: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3860 - accuracy: 0.8211 - precision_403: 0.8129 - recall_403: 0.8418 - val_loss: 9.4645 - val_accuracy: 0.5142 - val_precision_403: 0.5142 - val_recall_403: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3802 - accuracy: 0.8306 - precision_403: 0.8147 - recall_403: 0.8385 - val_loss: 21.1849 - val_accuracy: 0.5142 - val_precision_403: 0.5142 - val_recall_403: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3758 - accuracy: 0.8270 - precision_403: 0.8141 - recall_403: 0.8393 - val_loss: 23.2253 - val_accuracy: 0.5142 - val_precision_403: 0.5142 - val_recall_403: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3690 - accuracy: 0.8234 - precision_403: 0.8079 - recall_403: 0.8513 - val_loss: 19.0831 - val_accuracy: 0.5142 - val_precision_403: 0.5142 - val_recall_403: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.3596 - accuracy: 0.8369 - precision_403: 0.8175 - recall_403: 0.8583 - val_loss: 3.2232 - val_accuracy: 0.5142 - val_precision_403: 0.5142 - val_recall_403: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3511 - accuracy: 0.8383 - precision_403: 0.8224 - recall_403: 0.8576 - val_loss: 0.4245 - val_accuracy: 0.8142 - val_precision_403: 0.8137 - val_recall_403: 0.8282\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3496 - accuracy: 0.8386 - precision_403: 0.8183 - recall_403: 0.8595 - val_loss: 7.4428 - val_accuracy: 0.4858 - val_precision_403: 0.0000e+00 - val_recall_403: 0.0000e+00\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3282 - accuracy: 0.8518 - precision_403: 0.8498 - recall_403: 0.8625 - val_loss: 29.7587 - val_accuracy: 0.6117 - val_precision_403: 0.9218 - val_recall_403: 0.2674\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3363 - accuracy: 0.8478 - precision_403: 0.8357 - recall_403: 0.8649 - val_loss: 25.1671 - val_accuracy: 0.5517 - val_precision_403: 0.9540 - val_recall_403: 0.1345\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3194 - accuracy: 0.8600 - precision_403: 0.8521 - recall_403: 0.8749 - val_loss: 51.8682 - val_accuracy: 0.4858 - val_precision_403: 0.0000e+00 - val_recall_403: 0.0000e+00\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3137 - accuracy: 0.8617 - precision_403: 0.8442 - recall_403: 0.8803 - val_loss: 46.1956 - val_accuracy: 0.4858 - val_precision_403: 0.0000e+00 - val_recall_403: 0.0000e+00\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3083 - accuracy: 0.8614 - precision_403: 0.8482 - recall_403: 0.8766 - val_loss: 33.2275 - val_accuracy: 0.4858 - val_precision_403: 0.0000e+00 - val_recall_403: 0.0000e+00\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3117 - accuracy: 0.8575 - precision_403: 0.8498 - recall_403: 0.8701 - val_loss: 25.2916 - val_accuracy: 0.4925 - val_precision_403: 1.0000 - val_recall_403: 0.0130\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3251 - accuracy: 0.8650 - precision_403: 0.8618 - recall_403: 0.8740 - val_loss: 17.6932 - val_accuracy: 0.5158 - val_precision_403: 1.0000 - val_recall_403: 0.0583\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3411 - accuracy: 0.8344 - precision_403: 0.8191 - recall_403: 0.8531 - val_loss: 12.5395 - val_accuracy: 0.5242 - val_precision_403: 0.9792 - val_recall_403: 0.0762\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3041 - accuracy: 0.8731 - precision_403: 0.8561 - recall_403: 0.8929 - val_loss: 8.8940 - val_accuracy: 0.5300 - val_precision_403: 0.9492 - val_recall_403: 0.0908\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3205 - accuracy: 0.8593 - precision_403: 0.8510 - recall_403: 0.8679 - val_loss: 6.2941 - val_accuracy: 0.5300 - val_precision_403: 0.9649 - val_recall_403: 0.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=200, activation=elu, AUC=0.842, Accuracy=0.546, f2=0.112, prec=0.948, rec=0.092, total=  20.8s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=200, activation=elu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 79ms/step - loss: 0.7508 - accuracy: 0.6849 - precision_404: 0.6815 - recall_404: 0.6877 - val_loss: 29.1929 - val_accuracy: 0.5142 - val_precision_404: 0.5142 - val_recall_404: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.4675 - accuracy: 0.7817 - precision_404: 0.7782 - recall_404: 0.7944 - val_loss: 26.6033 - val_accuracy: 0.5142 - val_precision_404: 0.5142 - val_recall_404: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.4334 - accuracy: 0.7923 - precision_404: 0.7785 - recall_404: 0.8137 - val_loss: 14.0526 - val_accuracy: 0.5142 - val_precision_404: 0.5142 - val_recall_404: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3781 - accuracy: 0.8252 - precision_404: 0.8130 - recall_404: 0.8481 - val_loss: 18.4692 - val_accuracy: 0.5142 - val_precision_404: 0.5142 - val_recall_404: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3779 - accuracy: 0.8237 - precision_404: 0.8042 - recall_404: 0.8347 - val_loss: 24.2924 - val_accuracy: 0.5142 - val_precision_404: 0.5142 - val_recall_404: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3659 - accuracy: 0.8330 - precision_404: 0.8077 - recall_404: 0.8638 - val_loss: 11.8390 - val_accuracy: 0.5142 - val_precision_404: 0.5142 - val_recall_404: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3641 - accuracy: 0.8238 - precision_404: 0.8070 - recall_404: 0.8466 - val_loss: 1.5486 - val_accuracy: 0.5267 - val_precision_404: 0.5207 - val_recall_404: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3515 - accuracy: 0.8346 - precision_404: 0.8115 - recall_404: 0.8578 - val_loss: 2.0157 - val_accuracy: 0.5142 - val_precision_404: 0.5142 - val_recall_404: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3479 - accuracy: 0.8358 - precision_404: 0.8152 - recall_404: 0.8683 - val_loss: 4.4408 - val_accuracy: 0.4858 - val_precision_404: 0.0000e+00 - val_recall_404: 0.0000e+00\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3365 - accuracy: 0.8536 - precision_404: 0.8370 - recall_404: 0.8799 - val_loss: 3.5905 - val_accuracy: 0.4858 - val_precision_404: 0.0000e+00 - val_recall_404: 0.0000e+00\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3385 - accuracy: 0.8439 - precision_404: 0.8264 - recall_404: 0.8642 - val_loss: 4.1560 - val_accuracy: 0.4858 - val_precision_404: 0.0000e+00 - val_recall_404: 0.0000e+00\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3384 - accuracy: 0.8484 - precision_404: 0.8359 - recall_404: 0.8644 - val_loss: 3.7251 - val_accuracy: 0.4858 - val_precision_404: 0.0000e+00 - val_recall_404: 0.0000e+00\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3275 - accuracy: 0.8574 - precision_404: 0.8372 - recall_404: 0.8822 - val_loss: 3.8346 - val_accuracy: 0.4858 - val_precision_404: 0.0000e+00 - val_recall_404: 0.0000e+00\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3458 - accuracy: 0.8480 - precision_404: 0.8312 - recall_404: 0.8659 - val_loss: 3.3110 - val_accuracy: 0.4858 - val_precision_404: 0.0000e+00 - val_recall_404: 0.0000e+00\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3397 - accuracy: 0.8438 - precision_404: 0.8251 - recall_404: 0.8673 - val_loss: 2.8288 - val_accuracy: 0.4858 - val_precision_404: 0.0000e+00 - val_recall_404: 0.0000e+00\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3375 - accuracy: 0.8469 - precision_404: 0.8412 - recall_404: 0.8548 - val_loss: 2.4170 - val_accuracy: 0.4858 - val_precision_404: 0.0000e+00 - val_recall_404: 0.0000e+00\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.3461 - accuracy: 0.8413 - precision_404: 0.8320 - recall_404: 0.8584 - val_loss: 2.0580 - val_accuracy: 0.4900 - val_precision_404: 1.0000 - val_recall_404: 0.0081\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3268 - accuracy: 0.8477 - precision_404: 0.8304 - recall_404: 0.8697 - val_loss: 1.7444 - val_accuracy: 0.4967 - val_precision_404: 1.0000 - val_recall_404: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=200, activation=elu, AUC=0.888, Accuracy=0.514, f2=0.027, prec=1.000, rec=0.021, total=  18.1s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=200, activation=elu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 85ms/step - loss: 0.9067 - accuracy: 0.6672 - precision_405: 0.6659 - recall_405: 0.6537 - val_loss: 179.3083 - val_accuracy: 0.5142 - val_precision_405: 0.5142 - val_recall_405: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.4913 - accuracy: 0.7699 - precision_405: 0.7694 - recall_405: 0.7690 - val_loss: 104.2426 - val_accuracy: 0.5142 - val_precision_405: 0.5142 - val_recall_405: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.4323 - accuracy: 0.7999 - precision_405: 0.8021 - recall_405: 0.7913 - val_loss: 59.4019 - val_accuracy: 0.5142 - val_precision_405: 0.5142 - val_recall_405: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.4210 - accuracy: 0.8012 - precision_405: 0.7920 - recall_405: 0.8143 - val_loss: 28.8787 - val_accuracy: 0.5142 - val_precision_405: 0.5142 - val_recall_405: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.4079 - accuracy: 0.8124 - precision_405: 0.8045 - recall_405: 0.8148 - val_loss: 47.8205 - val_accuracy: 0.5142 - val_precision_405: 0.5142 - val_recall_405: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3788 - accuracy: 0.8231 - precision_405: 0.8209 - recall_405: 0.8379 - val_loss: 15.7462 - val_accuracy: 0.5142 - val_precision_405: 0.5142 - val_recall_405: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3878 - accuracy: 0.8193 - precision_405: 0.8172 - recall_405: 0.8171 - val_loss: 31.4941 - val_accuracy: 0.5142 - val_precision_405: 0.5142 - val_recall_405: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3653 - accuracy: 0.8383 - precision_405: 0.8226 - recall_405: 0.8588 - val_loss: 16.4117 - val_accuracy: 0.5142 - val_precision_405: 0.5142 - val_recall_405: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3630 - accuracy: 0.8357 - precision_405: 0.8270 - recall_405: 0.8509 - val_loss: 8.6444 - val_accuracy: 0.5142 - val_precision_405: 0.5142 - val_recall_405: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3435 - accuracy: 0.8422 - precision_405: 0.8200 - recall_405: 0.8635 - val_loss: 4.0036 - val_accuracy: 0.4858 - val_precision_405: 0.0000e+00 - val_recall_405: 0.0000e+00\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3488 - accuracy: 0.8437 - precision_405: 0.8422 - recall_405: 0.8496 - val_loss: 0.8728 - val_accuracy: 0.6100 - val_precision_405: 0.5687 - val_recall_405: 1.0000\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3424 - accuracy: 0.8503 - precision_405: 0.8323 - recall_405: 0.8703 - val_loss: 1.8080 - val_accuracy: 0.4867 - val_precision_405: 1.0000 - val_recall_405: 0.0016\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3289 - accuracy: 0.8508 - precision_405: 0.8421 - recall_405: 0.8589 - val_loss: 19.8637 - val_accuracy: 0.4858 - val_precision_405: 0.0000e+00 - val_recall_405: 0.0000e+00\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3251 - accuracy: 0.8598 - precision_405: 0.8465 - recall_405: 0.8784 - val_loss: 22.3698 - val_accuracy: 0.4858 - val_precision_405: 0.0000e+00 - val_recall_405: 0.0000e+00\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3248 - accuracy: 0.8585 - precision_405: 0.8408 - recall_405: 0.8795 - val_loss: 29.0687 - val_accuracy: 0.4858 - val_precision_405: 0.0000e+00 - val_recall_405: 0.0000e+00\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3260 - accuracy: 0.8542 - precision_405: 0.8468 - recall_405: 0.8659 - val_loss: 25.8804 - val_accuracy: 0.4858 - val_precision_405: 0.0000e+00 - val_recall_405: 0.0000e+00\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3140 - accuracy: 0.8656 - precision_405: 0.8603 - recall_405: 0.8743 - val_loss: 17.8504 - val_accuracy: 0.4858 - val_precision_405: 0.0000e+00 - val_recall_405: 0.0000e+00\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3155 - accuracy: 0.8607 - precision_405: 0.8442 - recall_405: 0.8781 - val_loss: 13.3425 - val_accuracy: 0.4858 - val_precision_405: 0.0000e+00 - val_recall_405: 0.0000e+00\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3189 - accuracy: 0.8571 - precision_405: 0.8406 - recall_405: 0.8759 - val_loss: 10.0261 - val_accuracy: 0.4858 - val_precision_405: 0.0000e+00 - val_recall_405: 0.0000e+00\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3144 - accuracy: 0.8588 - precision_405: 0.8351 - recall_405: 0.8838 - val_loss: 7.0877 - val_accuracy: 0.4858 - val_precision_405: 0.0000e+00 - val_recall_405: 0.0000e+00\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.3317 - accuracy: 0.8568 - precision_405: 0.8408 - recall_405: 0.8786 - val_loss: 4.8958 - val_accuracy: 0.4858 - val_precision_405: 0.0000e+00 - val_recall_405: 0.0000e+00\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.3195 - accuracy: 0.8554 - precision_405: 0.8341 - recall_405: 0.8769 - val_loss: 3.4704 - val_accuracy: 0.4858 - val_precision_405: 0.0000e+00 - val_recall_405: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=200, activation=elu, AUC=0.883, Accuracy=0.503, f2=0.000, prec=0.000, rec=0.000, total=  22.2s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.2, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.5484 - accuracy: 0.7174 - precision_406: 0.7163 - recall_406: 0.7276 - val_loss: 56.6911 - val_accuracy: 0.5142 - val_precision_406: 0.5142 - val_recall_406: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4160 - accuracy: 0.8009 - precision_406: 0.7951 - recall_406: 0.8013 - val_loss: 18.5652 - val_accuracy: 0.5142 - val_precision_406: 0.5142 - val_recall_406: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4389 - accuracy: 0.7935 - precision_406: 0.7830 - recall_406: 0.7958 - val_loss: 1.2448 - val_accuracy: 0.4658 - val_precision_406: 0.3889 - val_recall_406: 0.0681\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3945 - accuracy: 0.8181 - precision_406: 0.8097 - recall_406: 0.8305 - val_loss: 9.9130 - val_accuracy: 0.5142 - val_precision_406: 0.5142 - val_recall_406: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4040 - accuracy: 0.8105 - precision_406: 0.7845 - recall_406: 0.8340 - val_loss: 6.3396 - val_accuracy: 0.5142 - val_precision_406: 0.5142 - val_recall_406: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3640 - accuracy: 0.8422 - precision_406: 0.8293 - recall_406: 0.8743 - val_loss: 1.3960 - val_accuracy: 0.4125 - val_precision_406: 0.4559 - val_recall_406: 0.7374\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3743 - accuracy: 0.8287 - precision_406: 0.8295 - recall_406: 0.8326 - val_loss: 5.1149 - val_accuracy: 0.5142 - val_precision_406: 0.5142 - val_recall_406: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3407 - accuracy: 0.8426 - precision_406: 0.8360 - recall_406: 0.8498 - val_loss: 3.4050 - val_accuracy: 0.5142 - val_precision_406: 0.5142 - val_recall_406: 1.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3417 - accuracy: 0.8450 - precision_406: 0.8375 - recall_406: 0.8595 - val_loss: 2.5433 - val_accuracy: 0.5142 - val_precision_406: 0.5142 - val_recall_406: 1.0000\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3360 - accuracy: 0.8603 - precision_406: 0.8626 - recall_406: 0.8587 - val_loss: 1.7364 - val_accuracy: 0.5150 - val_precision_406: 0.5146 - val_recall_406: 1.0000\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3637 - accuracy: 0.8344 - precision_406: 0.8202 - recall_406: 0.8475 - val_loss: 0.9354 - val_accuracy: 0.6000 - val_precision_406: 0.5624 - val_recall_406: 1.0000\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3296 - accuracy: 0.8513 - precision_406: 0.8516 - recall_406: 0.8465 - val_loss: 0.4148 - val_accuracy: 0.8142 - val_precision_406: 0.7585 - val_recall_406: 0.9368\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3368 - accuracy: 0.8531 - precision_406: 0.8347 - recall_406: 0.8719 - val_loss: 0.3881 - val_accuracy: 0.8233 - val_precision_406: 0.8571 - val_recall_406: 0.7877\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3325 - accuracy: 0.8571 - precision_406: 0.8519 - recall_406: 0.8626 - val_loss: 0.3871 - val_accuracy: 0.8283 - val_precision_406: 0.8513 - val_recall_406: 0.8071\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3249 - accuracy: 0.8557 - precision_406: 0.8399 - recall_406: 0.8725 - val_loss: 0.4626 - val_accuracy: 0.7817 - val_precision_406: 0.8867 - val_recall_406: 0.6596\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3199 - accuracy: 0.8500 - precision_406: 0.8404 - recall_406: 0.8626 - val_loss: 0.5435 - val_accuracy: 0.7567 - val_precision_406: 0.9156 - val_recall_406: 0.5802\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3398 - accuracy: 0.8530 - precision_406: 0.8404 - recall_406: 0.8697 - val_loss: 0.4553 - val_accuracy: 0.7842 - val_precision_406: 0.8874 - val_recall_406: 0.6645\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3307 - accuracy: 0.8427 - precision_406: 0.8351 - recall_406: 0.8515 - val_loss: 0.4039 - val_accuracy: 0.8100 - val_precision_406: 0.8677 - val_recall_406: 0.7439\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3381 - accuracy: 0.8427 - precision_406: 0.8488 - recall_406: 0.8403 - val_loss: 0.3847 - val_accuracy: 0.8258 - val_precision_406: 0.8517 - val_recall_406: 0.8006\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3298 - accuracy: 0.8501 - precision_406: 0.8453 - recall_406: 0.8606 - val_loss: 0.3771 - val_accuracy: 0.8308 - val_precision_406: 0.8393 - val_recall_406: 0.8298\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3332 - accuracy: 0.8444 - precision_406: 0.8426 - recall_406: 0.8483 - val_loss: 0.3749 - val_accuracy: 0.8367 - val_precision_406: 0.8368 - val_recall_406: 0.8476\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3471 - accuracy: 0.8478 - precision_406: 0.8349 - recall_406: 0.8646 - val_loss: 0.3743 - val_accuracy: 0.8392 - val_precision_406: 0.8365 - val_recall_406: 0.8541\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3257 - accuracy: 0.8560 - precision_406: 0.8384 - recall_406: 0.8765 - val_loss: 0.3747 - val_accuracy: 0.8392 - val_precision_406: 0.8282 - val_recall_406: 0.8671\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3399 - accuracy: 0.8490 - precision_406: 0.8542 - recall_406: 0.8491 - val_loss: 0.3749 - val_accuracy: 0.8383 - val_precision_406: 0.8249 - val_recall_406: 0.8703\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3380 - accuracy: 0.8432 - precision_406: 0.8350 - recall_406: 0.8507 - val_loss: 0.3766 - val_accuracy: 0.8350 - val_precision_406: 0.8150 - val_recall_406: 0.8784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.2, batch_size=100, activation=relu, AUC=0.922, Accuracy=0.844, f2=0.867, prec=0.820, rec=0.879, total=  26.6s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.2, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.5541 - accuracy: 0.6973 - precision_407: 0.6846 - recall_407: 0.6939 - val_loss: 68.2472 - val_accuracy: 0.5142 - val_precision_407: 0.5142 - val_recall_407: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4264 - accuracy: 0.7983 - precision_407: 0.7922 - recall_407: 0.8172 - val_loss: 33.7040 - val_accuracy: 0.5142 - val_precision_407: 0.5142 - val_recall_407: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3964 - accuracy: 0.8205 - precision_407: 0.8114 - recall_407: 0.8358 - val_loss: 39.6093 - val_accuracy: 0.5142 - val_precision_407: 0.5142 - val_recall_407: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4057 - accuracy: 0.8151 - precision_407: 0.8052 - recall_407: 0.8269 - val_loss: 95.0724 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3934 - accuracy: 0.8074 - precision_407: 0.7883 - recall_407: 0.8408 - val_loss: 119.6004 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3429 - accuracy: 0.8474 - precision_407: 0.8343 - recall_407: 0.8620 - val_loss: 98.7024 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3577 - accuracy: 0.8375 - precision_407: 0.8335 - recall_407: 0.8436 - val_loss: 116.6357 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3434 - accuracy: 0.8458 - precision_407: 0.8469 - recall_407: 0.8535 - val_loss: 118.1324 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3416 - accuracy: 0.8459 - precision_407: 0.8423 - recall_407: 0.8509 - val_loss: 108.2684 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3320 - accuracy: 0.8549 - precision_407: 0.8538 - recall_407: 0.8640 - val_loss: 95.1847 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3518 - accuracy: 0.8337 - precision_407: 0.8184 - recall_407: 0.8493 - val_loss: 72.6197 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3548 - accuracy: 0.8366 - precision_407: 0.8311 - recall_407: 0.8465 - val_loss: 50.6241 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3379 - accuracy: 0.8474 - precision_407: 0.8316 - recall_407: 0.8630 - val_loss: 31.6905 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3437 - accuracy: 0.8483 - precision_407: 0.8206 - recall_407: 0.8772 - val_loss: 16.7645 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3391 - accuracy: 0.8372 - precision_407: 0.8268 - recall_407: 0.8470 - val_loss: 10.8732 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3519 - accuracy: 0.8366 - precision_407: 0.8304 - recall_407: 0.8462 - val_loss: 8.0201 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3278 - accuracy: 0.8485 - precision_407: 0.8308 - recall_407: 0.8750 - val_loss: 5.8742 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3458 - accuracy: 0.8455 - precision_407: 0.8398 - recall_407: 0.8560 - val_loss: 4.2633 - val_accuracy: 0.4858 - val_precision_407: 0.0000e+00 - val_recall_407: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.2, batch_size=100, activation=relu, AUC=0.869, Accuracy=0.504, f2=0.000, prec=0.000, rec=0.000, total=  19.8s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.2, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 43ms/step - loss: 0.5660 - accuracy: 0.6976 - precision_408: 0.6975 - recall_408: 0.6921 - val_loss: 121.4984 - val_accuracy: 0.5142 - val_precision_408: 0.5142 - val_recall_408: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4200 - accuracy: 0.8063 - precision_408: 0.8057 - recall_408: 0.8072 - val_loss: 44.6902 - val_accuracy: 0.5142 - val_precision_408: 0.5142 - val_recall_408: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3941 - accuracy: 0.8145 - precision_408: 0.8038 - recall_408: 0.8296 - val_loss: 15.5360 - val_accuracy: 0.5142 - val_precision_408: 0.5142 - val_recall_408: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3691 - accuracy: 0.8342 - precision_408: 0.8146 - recall_408: 0.8563 - val_loss: 78.0849 - val_accuracy: 0.5142 - val_precision_408: 0.5142 - val_recall_408: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3679 - accuracy: 0.8244 - precision_408: 0.8192 - recall_408: 0.8358 - val_loss: 71.0914 - val_accuracy: 0.5142 - val_precision_408: 0.5142 - val_recall_408: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3583 - accuracy: 0.8377 - precision_408: 0.8378 - recall_408: 0.8339 - val_loss: 26.5046 - val_accuracy: 0.5142 - val_precision_408: 0.5142 - val_recall_408: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3169 - accuracy: 0.8556 - precision_408: 0.8458 - recall_408: 0.8655 - val_loss: 10.7343 - val_accuracy: 0.4858 - val_precision_408: 0.0000e+00 - val_recall_408: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3286 - accuracy: 0.8583 - precision_408: 0.8507 - recall_408: 0.8724 - val_loss: 7.3095 - val_accuracy: 0.4858 - val_precision_408: 0.0000e+00 - val_recall_408: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3030 - accuracy: 0.8677 - precision_408: 0.8740 - recall_408: 0.8653 - val_loss: 4.3865 - val_accuracy: 0.4942 - val_precision_408: 1.0000 - val_recall_408: 0.0162\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2881 - accuracy: 0.8820 - precision_408: 0.8840 - recall_408: 0.8805 - val_loss: 32.1101 - val_accuracy: 0.4858 - val_precision_408: 0.0000e+00 - val_recall_408: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2691 - accuracy: 0.8873 - precision_408: 0.8746 - recall_408: 0.9001 - val_loss: 27.4594 - val_accuracy: 0.4858 - val_precision_408: 0.0000e+00 - val_recall_408: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2491 - accuracy: 0.8982 - precision_408: 0.8927 - recall_408: 0.8992 - val_loss: 37.2690 - val_accuracy: 0.4858 - val_precision_408: 0.0000e+00 - val_recall_408: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2504 - accuracy: 0.8991 - precision_408: 0.8882 - recall_408: 0.9119 - val_loss: 11.5896 - val_accuracy: 0.4967 - val_precision_408: 0.8824 - val_recall_408: 0.0243\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2357 - accuracy: 0.8936 - precision_408: 0.9028 - recall_408: 0.8876 - val_loss: 4.5649 - val_accuracy: 0.6250 - val_precision_408: 0.7889 - val_recall_408: 0.3695\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2443 - accuracy: 0.8933 - precision_408: 0.8845 - recall_408: 0.9033 - val_loss: 2.7863 - val_accuracy: 0.7008 - val_precision_408: 0.6949 - val_recall_408: 0.7455\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2609 - accuracy: 0.8872 - precision_408: 0.8886 - recall_408: 0.8878 - val_loss: 2.6202 - val_accuracy: 0.6667 - val_precision_408: 0.7692 - val_recall_408: 0.5024\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2147 - accuracy: 0.9082 - precision_408: 0.8867 - recall_408: 0.9311 - val_loss: 2.3612 - val_accuracy: 0.6200 - val_precision_408: 0.8182 - val_recall_408: 0.3355\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2319 - accuracy: 0.8971 - precision_408: 0.8946 - recall_408: 0.8959 - val_loss: 2.4385 - val_accuracy: 0.5392 - val_precision_408: 0.8019 - val_recall_408: 0.1378\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2285 - accuracy: 0.9062 - precision_408: 0.9008 - recall_408: 0.9091 - val_loss: 3.4756 - val_accuracy: 0.4867 - val_precision_408: 0.5455 - val_recall_408: 0.0097\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2436 - accuracy: 0.8925 - precision_408: 0.8817 - recall_408: 0.9069 - val_loss: 2.3685 - val_accuracy: 0.4958 - val_precision_408: 0.8750 - val_recall_408: 0.0227\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2218 - accuracy: 0.9047 - precision_408: 0.8980 - recall_408: 0.9090 - val_loss: 1.6394 - val_accuracy: 0.5325 - val_precision_408: 0.9828 - val_recall_408: 0.0924\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2267 - accuracy: 0.9021 - precision_408: 0.8872 - recall_408: 0.9144 - val_loss: 1.2408 - val_accuracy: 0.5858 - val_precision_408: 0.9615 - val_recall_408: 0.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.2, batch_size=100, activation=relu, AUC=0.904, Accuracy=0.601, f2=0.240, prec=0.976, rec=0.202, total=  23.5s\n",
      "[CV] lr=0.001, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=200, activation=elu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 3s 78ms/step - loss: 0.7690 - accuracy: 0.6384 - precision_409: 0.6202 - recall_409: 0.6424 - val_loss: 6.2414 - val_accuracy: 0.5142 - val_precision_409: 0.5142 - val_recall_409: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.5769 - accuracy: 0.7299 - precision_409: 0.7256 - recall_409: 0.7421 - val_loss: 5.4794 - val_accuracy: 0.5142 - val_precision_409: 0.5142 - val_recall_409: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4774 - accuracy: 0.7716 - precision_409: 0.7737 - recall_409: 0.7594 - val_loss: 3.1833 - val_accuracy: 0.5142 - val_precision_409: 0.5142 - val_recall_409: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4651 - accuracy: 0.7774 - precision_409: 0.7897 - recall_409: 0.7625 - val_loss: 1.4239 - val_accuracy: 0.5142 - val_precision_409: 0.5142 - val_recall_409: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4546 - accuracy: 0.7926 - precision_409: 0.7935 - recall_409: 0.7995 - val_loss: 1.7589 - val_accuracy: 0.5142 - val_precision_409: 0.5142 - val_recall_409: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4134 - accuracy: 0.8094 - precision_409: 0.8052 - recall_409: 0.8169 - val_loss: 3.5682 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4081 - accuracy: 0.8236 - precision_409: 0.8175 - recall_409: 0.8316 - val_loss: 3.8526 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4030 - accuracy: 0.8177 - precision_409: 0.8219 - recall_409: 0.8172 - val_loss: 2.6916 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3914 - accuracy: 0.8182 - precision_409: 0.8047 - recall_409: 0.8263 - val_loss: 3.1005 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4001 - accuracy: 0.8198 - precision_409: 0.8088 - recall_409: 0.8327 - val_loss: 3.5117 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3841 - accuracy: 0.8192 - precision_409: 0.8104 - recall_409: 0.8219 - val_loss: 3.6007 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3945 - accuracy: 0.8256 - precision_409: 0.8052 - recall_409: 0.8440 - val_loss: 3.5848 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3885 - accuracy: 0.8171 - precision_409: 0.7964 - recall_409: 0.8384 - val_loss: 3.3673 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3740 - accuracy: 0.8330 - precision_409: 0.8315 - recall_409: 0.8371 - val_loss: 3.0769 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4088 - accuracy: 0.8225 - precision_409: 0.8162 - recall_409: 0.8358 - val_loss: 2.7447 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3899 - accuracy: 0.8127 - precision_409: 0.7963 - recall_409: 0.8359 - val_loss: 2.4177 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4016 - accuracy: 0.8123 - precision_409: 0.8057 - recall_409: 0.8208 - val_loss: 2.1056 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3878 - accuracy: 0.8229 - precision_409: 0.8249 - recall_409: 0.8247 - val_loss: 1.8246 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3885 - accuracy: 0.8191 - precision_409: 0.8161 - recall_409: 0.8231 - val_loss: 1.5896 - val_accuracy: 0.4858 - val_precision_409: 0.0000e+00 - val_recall_409: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=200, activation=elu, AUC=0.856, Accuracy=0.504, f2=0.003, prec=1.000, rec=0.003, total=  18.3s\n",
      "[CV] lr=0.001, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=200, activation=elu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 80ms/step - loss: 0.8228 - accuracy: 0.6529 - precision_410: 0.6423 - recall_410: 0.6655 - val_loss: 5.5691 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.5186 - accuracy: 0.7655 - precision_410: 0.7619 - recall_410: 0.7681 - val_loss: 14.5869 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4703 - accuracy: 0.7873 - precision_410: 0.7941 - recall_410: 0.7827 - val_loss: 19.9443 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.4558 - accuracy: 0.7891 - precision_410: 0.7792 - recall_410: 0.8047 - val_loss: 19.3645 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4366 - accuracy: 0.7969 - precision_410: 0.7976 - recall_410: 0.8020 - val_loss: 18.3478 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4206 - accuracy: 0.8034 - precision_410: 0.7888 - recall_410: 0.8203 - val_loss: 18.1910 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4302 - accuracy: 0.7986 - precision_410: 0.8015 - recall_410: 0.8044 - val_loss: 17.4652 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4107 - accuracy: 0.8110 - precision_410: 0.8014 - recall_410: 0.8330 - val_loss: 16.8836 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4077 - accuracy: 0.8121 - precision_410: 0.7963 - recall_410: 0.8336 - val_loss: 15.8399 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4376 - accuracy: 0.7891 - precision_410: 0.7751 - recall_410: 0.8078 - val_loss: 14.5701 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4306 - accuracy: 0.7951 - precision_410: 0.7833 - recall_410: 0.8066 - val_loss: 12.8132 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4016 - accuracy: 0.8114 - precision_410: 0.8100 - recall_410: 0.8192 - val_loss: 10.7018 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4077 - accuracy: 0.8104 - precision_410: 0.8090 - recall_410: 0.8148 - val_loss: 8.4103 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4096 - accuracy: 0.8090 - precision_410: 0.8009 - recall_410: 0.8165 - val_loss: 6.1869 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4256 - accuracy: 0.8006 - precision_410: 0.7916 - recall_410: 0.8136 - val_loss: 4.4082 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4092 - accuracy: 0.8171 - precision_410: 0.8010 - recall_410: 0.8375 - val_loss: 3.1225 - val_accuracy: 0.5142 - val_precision_410: 0.5142 - val_recall_410: 1.0000\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4019 - accuracy: 0.8122 - precision_410: 0.7975 - recall_410: 0.8323 - val_loss: 2.2305 - val_accuracy: 0.5183 - val_precision_410: 0.5163 - val_recall_410: 1.0000\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4053 - accuracy: 0.8021 - precision_410: 0.7879 - recall_410: 0.8130 - val_loss: 1.6579 - val_accuracy: 0.5258 - val_precision_410: 0.5202 - val_recall_410: 1.0000\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4230 - accuracy: 0.7988 - precision_410: 0.7847 - recall_410: 0.8092 - val_loss: 1.2968 - val_accuracy: 0.5392 - val_precision_410: 0.5274 - val_recall_410: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=200, activation=elu, AUC=0.851, Accuracy=0.527, f2=0.838, prec=0.512, rec=0.996, total=  17.8s\n",
      "[CV] lr=0.001, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=200, activation=elu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 79ms/step - loss: 0.8613 - accuracy: 0.6326 - precision_411: 0.6271 - recall_411: 0.6291 - val_loss: 10.2994 - val_accuracy: 0.5142 - val_precision_411: 0.5142 - val_recall_411: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.6426 - accuracy: 0.7334 - precision_411: 0.7515 - recall_411: 0.7219 - val_loss: 15.7049 - val_accuracy: 0.5142 - val_precision_411: 0.5142 - val_recall_411: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.5135 - accuracy: 0.7515 - precision_411: 0.7608 - recall_411: 0.7467 - val_loss: 13.3052 - val_accuracy: 0.5142 - val_precision_411: 0.5142 - val_recall_411: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4305 - accuracy: 0.7954 - precision_411: 0.7839 - recall_411: 0.8075 - val_loss: 11.0699 - val_accuracy: 0.5142 - val_precision_411: 0.5142 - val_recall_411: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4533 - accuracy: 0.7926 - precision_411: 0.7845 - recall_411: 0.7951 - val_loss: 9.5001 - val_accuracy: 0.5142 - val_precision_411: 0.5142 - val_recall_411: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4338 - accuracy: 0.7991 - precision_411: 0.8039 - recall_411: 0.8035 - val_loss: 8.2900 - val_accuracy: 0.5142 - val_precision_411: 0.5142 - val_recall_411: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4200 - accuracy: 0.8113 - precision_411: 0.7963 - recall_411: 0.8289 - val_loss: 3.7645 - val_accuracy: 0.5142 - val_precision_411: 0.5142 - val_recall_411: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4168 - accuracy: 0.8072 - precision_411: 0.7899 - recall_411: 0.8264 - val_loss: 1.1828 - val_accuracy: 0.6183 - val_precision_411: 0.5740 - val_recall_411: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4057 - accuracy: 0.8264 - precision_411: 0.7936 - recall_411: 0.8588 - val_loss: 0.7516 - val_accuracy: 0.7417 - val_precision_411: 0.6795 - val_recall_411: 0.9417\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4023 - accuracy: 0.8132 - precision_411: 0.8096 - recall_411: 0.8260 - val_loss: 0.5862 - val_accuracy: 0.7442 - val_precision_411: 0.8429 - val_recall_411: 0.6175\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4053 - accuracy: 0.8171 - precision_411: 0.7982 - recall_411: 0.8328 - val_loss: 2.2345 - val_accuracy: 0.4858 - val_precision_411: 0.0000e+00 - val_recall_411: 0.0000e+00\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3864 - accuracy: 0.8291 - precision_411: 0.8139 - recall_411: 0.8372 - val_loss: 2.9179 - val_accuracy: 0.4858 - val_precision_411: 0.0000e+00 - val_recall_411: 0.0000e+00\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3930 - accuracy: 0.8262 - precision_411: 0.8141 - recall_411: 0.8425 - val_loss: 2.7380 - val_accuracy: 0.4858 - val_precision_411: 0.0000e+00 - val_recall_411: 0.0000e+00\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3964 - accuracy: 0.8179 - precision_411: 0.8146 - recall_411: 0.8251 - val_loss: 1.9356 - val_accuracy: 0.4858 - val_precision_411: 0.0000e+00 - val_recall_411: 0.0000e+00\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3832 - accuracy: 0.8335 - precision_411: 0.8291 - recall_411: 0.8424 - val_loss: 1.6965 - val_accuracy: 0.4858 - val_precision_411: 0.0000e+00 - val_recall_411: 0.0000e+00\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3855 - accuracy: 0.8259 - precision_411: 0.8058 - recall_411: 0.8491 - val_loss: 1.5571 - val_accuracy: 0.4858 - val_precision_411: 0.0000e+00 - val_recall_411: 0.0000e+00\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3778 - accuracy: 0.8277 - precision_411: 0.8171 - recall_411: 0.8411 - val_loss: 1.4363 - val_accuracy: 0.4858 - val_precision_411: 0.0000e+00 - val_recall_411: 0.0000e+00\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3920 - accuracy: 0.8210 - precision_411: 0.8221 - recall_411: 0.8266 - val_loss: 1.3031 - val_accuracy: 0.4883 - val_precision_411: 1.0000 - val_recall_411: 0.0049\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.3820 - accuracy: 0.8230 - precision_411: 0.8137 - recall_411: 0.8323 - val_loss: 1.1899 - val_accuracy: 0.4900 - val_precision_411: 1.0000 - val_recall_411: 0.0081\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.3796 - accuracy: 0.8292 - precision_411: 0.8222 - recall_411: 0.8424 - val_loss: 1.0805 - val_accuracy: 0.4975 - val_precision_411: 0.9375 - val_recall_411: 0.0243\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.3804 - accuracy: 0.8294 - precision_411: 0.8280 - recall_411: 0.8372 - val_loss: 0.9835 - val_accuracy: 0.5067 - val_precision_411: 0.9630 - val_recall_411: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=7, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.5, batch_size=200, activation=elu, AUC=0.879, Accuracy=0.527, f2=0.064, prec=0.932, rec=0.052, total=  19.5s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 46ms/step - loss: 0.9625 - accuracy: 0.6841 - precision_412: 0.6785 - recall_412: 0.6737 - val_loss: 27.8272 - val_accuracy: 0.5142 - val_precision_412: 0.5142 - val_recall_412: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4618 - accuracy: 0.7736 - precision_412: 0.7600 - recall_412: 0.7824 - val_loss: 1.1002 - val_accuracy: 0.5208 - val_precision_412: 0.5176 - val_recall_412: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4079 - accuracy: 0.8132 - precision_412: 0.8005 - recall_412: 0.8303 - val_loss: 1.6322 - val_accuracy: 0.5142 - val_precision_412: 0.5142 - val_recall_412: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4076 - accuracy: 0.8179 - precision_412: 0.8035 - recall_412: 0.8195 - val_loss: 16.4557 - val_accuracy: 0.4858 - val_precision_412: 0.0000e+00 - val_recall_412: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3855 - accuracy: 0.8244 - precision_412: 0.8023 - recall_412: 0.8559 - val_loss: 1.9274 - val_accuracy: 0.4858 - val_precision_412: 0.0000e+00 - val_recall_412: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3882 - accuracy: 0.8235 - precision_412: 0.8123 - recall_412: 0.8368 - val_loss: 11.2507 - val_accuracy: 0.4858 - val_precision_412: 0.0000e+00 - val_recall_412: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3798 - accuracy: 0.8198 - precision_412: 0.8019 - recall_412: 0.8357 - val_loss: 6.4362 - val_accuracy: 0.4858 - val_precision_412: 0.0000e+00 - val_recall_412: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3722 - accuracy: 0.8282 - precision_412: 0.8244 - recall_412: 0.8423 - val_loss: 8.4201 - val_accuracy: 0.4858 - val_precision_412: 0.0000e+00 - val_recall_412: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3930 - accuracy: 0.8071 - precision_412: 0.7791 - recall_412: 0.8290 - val_loss: 4.4498 - val_accuracy: 0.4858 - val_precision_412: 0.0000e+00 - val_recall_412: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3749 - accuracy: 0.8309 - precision_412: 0.8220 - recall_412: 0.8448 - val_loss: 2.1611 - val_accuracy: 0.4858 - val_precision_412: 0.0000e+00 - val_recall_412: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3819 - accuracy: 0.8270 - precision_412: 0.8097 - recall_412: 0.8473 - val_loss: 1.7029 - val_accuracy: 0.4875 - val_precision_412: 1.0000 - val_recall_412: 0.0032\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3908 - accuracy: 0.8121 - precision_412: 0.8067 - recall_412: 0.8220 - val_loss: 1.3619 - val_accuracy: 0.4925 - val_precision_412: 1.0000 - val_recall_412: 0.0130\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3662 - accuracy: 0.8314 - precision_412: 0.8117 - recall_412: 0.8567 - val_loss: 0.9837 - val_accuracy: 0.5342 - val_precision_412: 0.9833 - val_recall_412: 0.0956\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3824 - accuracy: 0.8206 - precision_412: 0.8079 - recall_412: 0.8354 - val_loss: 0.7368 - val_accuracy: 0.6392 - val_precision_412: 0.9600 - val_recall_412: 0.3112\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3743 - accuracy: 0.8191 - precision_412: 0.8036 - recall_412: 0.8391 - val_loss: 0.5710 - val_accuracy: 0.7167 - val_precision_412: 0.9288 - val_recall_412: 0.4862\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3794 - accuracy: 0.8233 - precision_412: 0.8186 - recall_412: 0.8320 - val_loss: 0.4772 - val_accuracy: 0.7633 - val_precision_412: 0.9031 - val_recall_412: 0.6045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=elu, AUC=0.918, Accuracy=0.786, f2=0.670, prec=0.916, rec=0.628, total=  18.7s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 59ms/step - loss: 0.7927 - accuracy: 0.7071 - precision_413: 0.7038 - recall_413: 0.6959 - val_loss: 24.8475 - val_accuracy: 0.5142 - val_precision_413: 0.5142 - val_recall_413: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4311 - accuracy: 0.7949 - precision_413: 0.7714 - recall_413: 0.8331 - val_loss: 11.1777 - val_accuracy: 0.5142 - val_precision_413: 0.5142 - val_recall_413: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4053 - accuracy: 0.8161 - precision_413: 0.8137 - recall_413: 0.8133 - val_loss: 0.4702 - val_accuracy: 0.7800 - val_precision_413: 0.7815 - val_recall_413: 0.7942\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4036 - accuracy: 0.8208 - precision_413: 0.7970 - recall_413: 0.8459 - val_loss: 1.1377 - val_accuracy: 0.5142 - val_precision_413: 0.5142 - val_recall_413: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3771 - accuracy: 0.8255 - precision_413: 0.8082 - recall_413: 0.8470 - val_loss: 2.7586 - val_accuracy: 0.4858 - val_precision_413: 0.0000e+00 - val_recall_413: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3545 - accuracy: 0.8399 - precision_413: 0.8104 - recall_413: 0.8730 - val_loss: 20.0146 - val_accuracy: 0.4858 - val_precision_413: 0.0000e+00 - val_recall_413: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3667 - accuracy: 0.8253 - precision_413: 0.8162 - recall_413: 0.8348 - val_loss: 13.7654 - val_accuracy: 0.4858 - val_precision_413: 0.0000e+00 - val_recall_413: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3462 - accuracy: 0.8365 - precision_413: 0.8128 - recall_413: 0.8654 - val_loss: 9.3945 - val_accuracy: 0.4858 - val_precision_413: 0.0000e+00 - val_recall_413: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3500 - accuracy: 0.8362 - precision_413: 0.8202 - recall_413: 0.8625 - val_loss: 8.0022 - val_accuracy: 0.4867 - val_precision_413: 1.0000 - val_recall_413: 0.0016\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3491 - accuracy: 0.8404 - precision_413: 0.8307 - recall_413: 0.8522 - val_loss: 5.0827 - val_accuracy: 0.4867 - val_precision_413: 1.0000 - val_recall_413: 0.0016\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3497 - accuracy: 0.8414 - precision_413: 0.8315 - recall_413: 0.8623 - val_loss: 3.8572 - val_accuracy: 0.4908 - val_precision_413: 1.0000 - val_recall_413: 0.0097\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3451 - accuracy: 0.8421 - precision_413: 0.8157 - recall_413: 0.8725 - val_loss: 2.0655 - val_accuracy: 0.5492 - val_precision_413: 0.9750 - val_recall_413: 0.1264\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3348 - accuracy: 0.8437 - precision_413: 0.8168 - recall_413: 0.8742 - val_loss: 1.1614 - val_accuracy: 0.6342 - val_precision_413: 0.9495 - val_recall_413: 0.3047\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3394 - accuracy: 0.8482 - precision_413: 0.8287 - recall_413: 0.8735 - val_loss: 0.7263 - val_accuracy: 0.7192 - val_precision_413: 0.9268 - val_recall_413: 0.4927\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3489 - accuracy: 0.8439 - precision_413: 0.8408 - recall_413: 0.8567 - val_loss: 0.5201 - val_accuracy: 0.7617 - val_precision_413: 0.9066 - val_recall_413: 0.5981\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3550 - accuracy: 0.8380 - precision_413: 0.8205 - recall_413: 0.8657 - val_loss: 0.4263 - val_accuracy: 0.8025 - val_precision_413: 0.8755 - val_recall_413: 0.7180\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3528 - accuracy: 0.8336 - precision_413: 0.8065 - recall_413: 0.8629 - val_loss: 0.3875 - val_accuracy: 0.8200 - val_precision_413: 0.8561 - val_recall_413: 0.7812\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3432 - accuracy: 0.8432 - precision_413: 0.8237 - recall_413: 0.8728 - val_loss: 0.3743 - val_accuracy: 0.8283 - val_precision_413: 0.8352 - val_recall_413: 0.8298\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3350 - accuracy: 0.8427 - precision_413: 0.8251 - recall_413: 0.8702 - val_loss: 0.3710 - val_accuracy: 0.8342 - val_precision_413: 0.8215 - val_recall_413: 0.8655\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3370 - accuracy: 0.8513 - precision_413: 0.8318 - recall_413: 0.8759 - val_loss: 0.3724 - val_accuracy: 0.8358 - val_precision_413: 0.8153 - val_recall_413: 0.8801\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3279 - accuracy: 0.8538 - precision_413: 0.8327 - recall_413: 0.8767 - val_loss: 0.3745 - val_accuracy: 0.8358 - val_precision_413: 0.8097 - val_recall_413: 0.8898\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3356 - accuracy: 0.8474 - precision_413: 0.8308 - recall_413: 0.8700 - val_loss: 0.3790 - val_accuracy: 0.8317 - val_precision_413: 0.7969 - val_recall_413: 0.9028\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3316 - accuracy: 0.8544 - precision_413: 0.8413 - recall_413: 0.8691 - val_loss: 0.3813 - val_accuracy: 0.8292 - val_precision_413: 0.7918 - val_recall_413: 0.9060\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3414 - accuracy: 0.8417 - precision_413: 0.8242 - recall_413: 0.8632 - val_loss: 0.3834 - val_accuracy: 0.8317 - val_precision_413: 0.7910 - val_recall_413: 0.9141\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3366 - accuracy: 0.8474 - precision_413: 0.8161 - recall_413: 0.8823 - val_loss: 0.3833 - val_accuracy: 0.8325 - val_precision_413: 0.7921 - val_recall_413: 0.9141\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3471 - accuracy: 0.8437 - precision_413: 0.8226 - recall_413: 0.8696 - val_loss: 0.3853 - val_accuracy: 0.8325 - val_precision_413: 0.7905 - val_recall_413: 0.9173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=elu, AUC=0.896, Accuracy=0.799, f2=0.859, prec=0.750, rec=0.892, total=  29.5s\n",
      "[CV] lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 46ms/step - loss: 0.7534 - accuracy: 0.6906 - precision_414: 0.6838 - recall_414: 0.6810 - val_loss: 128.3679 - val_accuracy: 0.5142 - val_precision_414: 0.5142 - val_recall_414: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.4812 - accuracy: 0.7663 - precision_414: 0.7453 - recall_414: 0.8102 - val_loss: 18.3573 - val_accuracy: 0.5142 - val_precision_414: 0.5142 - val_recall_414: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4576 - accuracy: 0.7856 - precision_414: 0.7854 - recall_414: 0.7887 - val_loss: 1.6246 - val_accuracy: 0.4867 - val_precision_414: 1.0000 - val_recall_414: 0.0016\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4217 - accuracy: 0.8097 - precision_414: 0.7905 - recall_414: 0.8266 - val_loss: 1.2318 - val_accuracy: 0.4842 - val_precision_414: 0.2500 - val_recall_414: 0.0016\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4200 - accuracy: 0.8031 - precision_414: 0.7920 - recall_414: 0.8100 - val_loss: 0.6456 - val_accuracy: 0.6167 - val_precision_414: 0.7060 - val_recall_414: 0.4360\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4091 - accuracy: 0.8180 - precision_414: 0.8059 - recall_414: 0.8327 - val_loss: 3.5936 - val_accuracy: 0.4858 - val_precision_414: 0.0000e+00 - val_recall_414: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3806 - accuracy: 0.8346 - precision_414: 0.8277 - recall_414: 0.8441 - val_loss: 22.8525 - val_accuracy: 0.4858 - val_precision_414: 0.0000e+00 - val_recall_414: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3753 - accuracy: 0.8196 - precision_414: 0.8082 - recall_414: 0.8374 - val_loss: 99.8742 - val_accuracy: 0.4858 - val_precision_414: 0.0000e+00 - val_recall_414: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3613 - accuracy: 0.8409 - precision_414: 0.8272 - recall_414: 0.8537 - val_loss: 69.8497 - val_accuracy: 0.4858 - val_precision_414: 0.0000e+00 - val_recall_414: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3670 - accuracy: 0.8344 - precision_414: 0.8316 - recall_414: 0.8482 - val_loss: 65.7567 - val_accuracy: 0.4858 - val_precision_414: 0.0000e+00 - val_recall_414: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3739 - accuracy: 0.8381 - precision_414: 0.8265 - recall_414: 0.8483 - val_loss: 44.9517 - val_accuracy: 0.4858 - val_precision_414: 0.0000e+00 - val_recall_414: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3366 - accuracy: 0.8511 - precision_414: 0.8326 - recall_414: 0.8730 - val_loss: 19.1687 - val_accuracy: 0.4858 - val_precision_414: 0.0000e+00 - val_recall_414: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3664 - accuracy: 0.8349 - precision_414: 0.8178 - recall_414: 0.8534 - val_loss: 7.2521 - val_accuracy: 0.4858 - val_precision_414: 0.0000e+00 - val_recall_414: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3492 - accuracy: 0.8397 - precision_414: 0.8235 - recall_414: 0.8577 - val_loss: 3.8429 - val_accuracy: 0.4858 - val_precision_414: 0.0000e+00 - val_recall_414: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3565 - accuracy: 0.8385 - precision_414: 0.8205 - recall_414: 0.8591 - val_loss: 2.2508 - val_accuracy: 0.4975 - val_precision_414: 1.0000 - val_recall_414: 0.0227\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3347 - accuracy: 0.8486 - precision_414: 0.8378 - recall_414: 0.8628 - val_loss: 1.3142 - val_accuracy: 0.5733 - val_precision_414: 0.9907 - val_recall_414: 0.1718\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3570 - accuracy: 0.8433 - precision_414: 0.8481 - recall_414: 0.8465 - val_loss: 0.8583 - val_accuracy: 0.6617 - val_precision_414: 0.9648 - val_recall_414: 0.3549\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3597 - accuracy: 0.8366 - precision_414: 0.8359 - recall_414: 0.8474 - val_loss: 0.6107 - val_accuracy: 0.7342 - val_precision_414: 0.9382 - val_recall_414: 0.5170\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3642 - accuracy: 0.8309 - precision_414: 0.8096 - recall_414: 0.8480 - val_loss: 0.4770 - val_accuracy: 0.7642 - val_precision_414: 0.8976 - val_recall_414: 0.6110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=13, kernel_initializer=he_uniform, epochs=500, drop_rate=0.3, batch_size=100, activation=elu, AUC=0.913, Accuracy=0.781, f2=0.667, prec=0.902, rec=0.626, total=  21.9s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 52ms/step - loss: 0.6911 - accuracy: 0.6853 - precision_415: 0.6869 - recall_415: 0.6725 - val_loss: 14.8698 - val_accuracy: 0.5142 - val_precision_415: 0.5142 - val_recall_415: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4605 - accuracy: 0.7851 - precision_415: 0.7701 - recall_415: 0.7957 - val_loss: 6.7145 - val_accuracy: 0.5142 - val_precision_415: 0.5142 - val_recall_415: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3894 - accuracy: 0.8214 - precision_415: 0.8025 - recall_415: 0.8406 - val_loss: 1.7026 - val_accuracy: 0.5142 - val_precision_415: 0.5142 - val_recall_415: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3731 - accuracy: 0.8327 - precision_415: 0.8212 - recall_415: 0.8465 - val_loss: 14.2240 - val_accuracy: 0.4858 - val_precision_415: 0.0000e+00 - val_recall_415: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3674 - accuracy: 0.8368 - precision_415: 0.8328 - recall_415: 0.8383 - val_loss: 11.2809 - val_accuracy: 0.4858 - val_precision_415: 0.0000e+00 - val_recall_415: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3341 - accuracy: 0.8443 - precision_415: 0.8230 - recall_415: 0.8777 - val_loss: 16.7326 - val_accuracy: 0.4858 - val_precision_415: 0.0000e+00 - val_recall_415: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3026 - accuracy: 0.8633 - precision_415: 0.8535 - recall_415: 0.8762 - val_loss: 19.4471 - val_accuracy: 0.4858 - val_precision_415: 0.0000e+00 - val_recall_415: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2704 - accuracy: 0.8867 - precision_415: 0.8708 - recall_415: 0.9034 - val_loss: 18.3440 - val_accuracy: 0.4858 - val_precision_415: 0.0000e+00 - val_recall_415: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2814 - accuracy: 0.8732 - precision_415: 0.8580 - recall_415: 0.8886 - val_loss: 21.7929 - val_accuracy: 0.4858 - val_precision_415: 0.0000e+00 - val_recall_415: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2636 - accuracy: 0.8869 - precision_415: 0.8673 - recall_415: 0.9059 - val_loss: 17.1174 - val_accuracy: 0.4858 - val_precision_415: 0.0000e+00 - val_recall_415: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2721 - accuracy: 0.8863 - precision_415: 0.8786 - recall_415: 0.8994 - val_loss: 13.1709 - val_accuracy: 0.4858 - val_precision_415: 0.0000e+00 - val_recall_415: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2687 - accuracy: 0.8929 - precision_415: 0.8854 - recall_415: 0.9039 - val_loss: 7.9491 - val_accuracy: 0.4858 - val_precision_415: 0.0000e+00 - val_recall_415: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2618 - accuracy: 0.8864 - precision_415: 0.8834 - recall_415: 0.8895 - val_loss: 5.4261 - val_accuracy: 0.4858 - val_precision_415: 0.0000e+00 - val_recall_415: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2782 - accuracy: 0.8772 - precision_415: 0.8780 - recall_415: 0.8815 - val_loss: 3.6122 - val_accuracy: 0.4858 - val_precision_415: 0.0000e+00 - val_recall_415: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2672 - accuracy: 0.8788 - precision_415: 0.8693 - recall_415: 0.8860 - val_loss: 2.3250 - val_accuracy: 0.4925 - val_precision_415: 1.0000 - val_recall_415: 0.0130\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2587 - accuracy: 0.8888 - precision_415: 0.8823 - recall_415: 0.8968 - val_loss: 1.4750 - val_accuracy: 0.5458 - val_precision_415: 0.9737 - val_recall_415: 0.1199\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2636 - accuracy: 0.8878 - precision_415: 0.8841 - recall_415: 0.8935 - val_loss: 0.9483 - val_accuracy: 0.6200 - val_precision_415: 0.9351 - val_recall_415: 0.2804\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2616 - accuracy: 0.8946 - precision_415: 0.8807 - recall_415: 0.9076 - val_loss: 0.6513 - val_accuracy: 0.7192 - val_precision_415: 0.9167 - val_recall_415: 0.4992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=gelu, AUC=0.905, Accuracy=0.730, f2=0.544, prec=0.931, rec=0.493, total=  24.8s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 54ms/step - loss: 0.7522 - accuracy: 0.6830 - precision_416: 0.6926 - recall_416: 0.6735 - val_loss: 12.3186 - val_accuracy: 0.5142 - val_precision_416: 0.5142 - val_recall_416: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4487 - accuracy: 0.7925 - precision_416: 0.7900 - recall_416: 0.7918 - val_loss: 8.6377 - val_accuracy: 0.5142 - val_precision_416: 0.5142 - val_recall_416: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3989 - accuracy: 0.8175 - precision_416: 0.8134 - recall_416: 0.8273 - val_loss: 6.6217 - val_accuracy: 0.5142 - val_precision_416: 0.5142 - val_recall_416: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3685 - accuracy: 0.8322 - precision_416: 0.8171 - recall_416: 0.8564 - val_loss: 4.7949 - val_accuracy: 0.4858 - val_precision_416: 0.0000e+00 - val_recall_416: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3480 - accuracy: 0.8500 - precision_416: 0.8318 - recall_416: 0.8735 - val_loss: 5.6990 - val_accuracy: 0.5142 - val_precision_416: 0.5142 - val_recall_416: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.3296 - accuracy: 0.8531 - precision_416: 0.8460 - recall_416: 0.8603 - val_loss: 5.1902 - val_accuracy: 0.4858 - val_precision_416: 0.0000e+00 - val_recall_416: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.3282 - accuracy: 0.8416 - precision_416: 0.8266 - recall_416: 0.8624 - val_loss: 6.5009 - val_accuracy: 0.4858 - val_precision_416: 0.0000e+00 - val_recall_416: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3115 - accuracy: 0.8554 - precision_416: 0.8469 - recall_416: 0.8706 - val_loss: 12.3864 - val_accuracy: 0.4858 - val_precision_416: 0.0000e+00 - val_recall_416: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2945 - accuracy: 0.8732 - precision_416: 0.8613 - recall_416: 0.8872 - val_loss: 6.3038 - val_accuracy: 0.4858 - val_precision_416: 0.0000e+00 - val_recall_416: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2694 - accuracy: 0.8822 - precision_416: 0.8789 - recall_416: 0.8835 - val_loss: 3.9642 - val_accuracy: 0.4858 - val_precision_416: 0.0000e+00 - val_recall_416: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2676 - accuracy: 0.8900 - precision_416: 0.8788 - recall_416: 0.9014 - val_loss: 3.7203 - val_accuracy: 0.4858 - val_precision_416: 0.0000e+00 - val_recall_416: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2733 - accuracy: 0.8825 - precision_416: 0.8664 - recall_416: 0.9047 - val_loss: 7.1037 - val_accuracy: 0.4858 - val_precision_416: 0.0000e+00 - val_recall_416: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2609 - accuracy: 0.8870 - precision_416: 0.8734 - recall_416: 0.9028 - val_loss: 7.7283 - val_accuracy: 0.4858 - val_precision_416: 0.0000e+00 - val_recall_416: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2730 - accuracy: 0.8822 - precision_416: 0.8742 - recall_416: 0.8934 - val_loss: 5.4840 - val_accuracy: 0.4858 - val_precision_416: 0.0000e+00 - val_recall_416: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2710 - accuracy: 0.8884 - precision_416: 0.8725 - recall_416: 0.9055 - val_loss: 3.6669 - val_accuracy: 0.4858 - val_precision_416: 0.0000e+00 - val_recall_416: 0.0000e+00\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2622 - accuracy: 0.8950 - precision_416: 0.8923 - recall_416: 0.8992 - val_loss: 1.2195 - val_accuracy: 0.5800 - val_precision_416: 0.9520 - val_recall_416: 0.1929\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2582 - accuracy: 0.8906 - precision_416: 0.8741 - recall_416: 0.9075 - val_loss: 1.1325 - val_accuracy: 0.6133 - val_precision_416: 0.9527 - val_recall_416: 0.2609\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2438 - accuracy: 0.9035 - precision_416: 0.8925 - recall_416: 0.9148 - val_loss: 0.8930 - val_accuracy: 0.6700 - val_precision_416: 0.9547 - val_recall_416: 0.3760\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2645 - accuracy: 0.8839 - precision_416: 0.8640 - recall_416: 0.9045 - val_loss: 0.8510 - val_accuracy: 0.6825 - val_precision_416: 0.9470 - val_recall_416: 0.4052\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2698 - accuracy: 0.8847 - precision_416: 0.8736 - recall_416: 0.9012 - val_loss: 0.5826 - val_accuracy: 0.7483 - val_precision_416: 0.9200 - val_recall_416: 0.5592\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2543 - accuracy: 0.8890 - precision_416: 0.8774 - recall_416: 0.9025 - val_loss: 0.4674 - val_accuracy: 0.7817 - val_precision_416: 0.8850 - val_recall_416: 0.6613\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2591 - accuracy: 0.8902 - precision_416: 0.8684 - recall_416: 0.9108 - val_loss: 0.3898 - val_accuracy: 0.8292 - val_precision_416: 0.7934 - val_recall_416: 0.9028\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2578 - accuracy: 0.8898 - precision_416: 0.8692 - recall_416: 0.9106 - val_loss: 0.3783 - val_accuracy: 0.8250 - val_precision_416: 0.8145 - val_recall_416: 0.8541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=gelu, AUC=0.888, Accuracy=0.803, f2=0.816, prec=0.789, rec=0.824, total=  30.9s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=gelu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 52ms/step - loss: 0.6395 - accuracy: 0.7168 - precision_417: 0.7218 - recall_417: 0.7200 - val_loss: 26.5132 - val_accuracy: 0.5142 - val_precision_417: 0.5142 - val_recall_417: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.4513 - accuracy: 0.7852 - precision_417: 0.7858 - recall_417: 0.7901 - val_loss: 14.3106 - val_accuracy: 0.5142 - val_precision_417: 0.5142 - val_recall_417: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.3970 - accuracy: 0.8254 - precision_417: 0.8291 - recall_417: 0.8293 - val_loss: 2.7573 - val_accuracy: 0.4858 - val_precision_417: 0.0000e+00 - val_recall_417: 0.0000e+00\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3929 - accuracy: 0.8212 - precision_417: 0.8171 - recall_417: 0.8274 - val_loss: 3.7032 - val_accuracy: 0.5142 - val_precision_417: 0.5142 - val_recall_417: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3848 - accuracy: 0.8229 - precision_417: 0.8156 - recall_417: 0.8282 - val_loss: 1.2430 - val_accuracy: 0.5142 - val_precision_417: 0.5142 - val_recall_417: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3428 - accuracy: 0.8450 - precision_417: 0.8284 - recall_417: 0.8641 - val_loss: 22.8438 - val_accuracy: 0.4858 - val_precision_417: 0.0000e+00 - val_recall_417: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.3317 - accuracy: 0.8509 - precision_417: 0.8565 - recall_417: 0.8512 - val_loss: 3.8921 - val_accuracy: 0.4858 - val_precision_417: 0.0000e+00 - val_recall_417: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2862 - accuracy: 0.8792 - precision_417: 0.8779 - recall_417: 0.8812 - val_loss: 18.8870 - val_accuracy: 0.4858 - val_precision_417: 0.0000e+00 - val_recall_417: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2826 - accuracy: 0.8758 - precision_417: 0.8678 - recall_417: 0.8885 - val_loss: 13.7038 - val_accuracy: 0.4858 - val_precision_417: 0.0000e+00 - val_recall_417: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2372 - accuracy: 0.9025 - precision_417: 0.9041 - recall_417: 0.8995 - val_loss: 9.3801 - val_accuracy: 0.4858 - val_precision_417: 0.0000e+00 - val_recall_417: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2395 - accuracy: 0.8992 - precision_417: 0.8899 - recall_417: 0.9096 - val_loss: 9.8254 - val_accuracy: 0.4858 - val_precision_417: 0.0000e+00 - val_recall_417: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2337 - accuracy: 0.9030 - precision_417: 0.8878 - recall_417: 0.9165 - val_loss: 7.9062 - val_accuracy: 0.4858 - val_precision_417: 0.0000e+00 - val_recall_417: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 0.2443 - accuracy: 0.8901 - precision_417: 0.8756 - recall_417: 0.9044 - val_loss: 5.9610 - val_accuracy: 0.4858 - val_precision_417: 0.0000e+00 - val_recall_417: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2379 - accuracy: 0.8978 - precision_417: 0.8859 - recall_417: 0.9128 - val_loss: 4.5551 - val_accuracy: 0.4858 - val_precision_417: 0.0000e+00 - val_recall_417: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2439 - accuracy: 0.8930 - precision_417: 0.8888 - recall_417: 0.8972 - val_loss: 3.5712 - val_accuracy: 0.4858 - val_precision_417: 0.0000e+00 - val_recall_417: 0.0000e+00\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2349 - accuracy: 0.9056 - precision_417: 0.8947 - recall_417: 0.9204 - val_loss: 2.6834 - val_accuracy: 0.4892 - val_precision_417: 1.0000 - val_recall_417: 0.0065\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2266 - accuracy: 0.9006 - precision_417: 0.8976 - recall_417: 0.9051 - val_loss: 2.0623 - val_accuracy: 0.5058 - val_precision_417: 0.9615 - val_recall_417: 0.0405\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2289 - accuracy: 0.9024 - precision_417: 0.8880 - recall_417: 0.9208 - val_loss: 1.6274 - val_accuracy: 0.5275 - val_precision_417: 0.9808 - val_recall_417: 0.0827\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2316 - accuracy: 0.9029 - precision_417: 0.8907 - recall_417: 0.9133 - val_loss: 1.2747 - val_accuracy: 0.5733 - val_precision_417: 0.9817 - val_recall_417: 0.1734\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2259 - accuracy: 0.9000 - precision_417: 0.9007 - recall_417: 0.8964 - val_loss: 1.0292 - val_accuracy: 0.6208 - val_precision_417: 0.9551 - val_recall_417: 0.2755\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2251 - accuracy: 0.9102 - precision_417: 0.9153 - recall_417: 0.9074 - val_loss: 0.8524 - val_accuracy: 0.6692 - val_precision_417: 0.9508 - val_recall_417: 0.3760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=gelu, AUC=0.897, Accuracy=0.672, f2=0.421, prec=0.925, rec=0.370, total=  29.0s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.7521 - accuracy: 0.6751 - precision_418: 0.6861 - recall_418: 0.6770 - val_loss: 18.6765 - val_accuracy: 0.5142 - val_precision_418: 0.5142 - val_recall_418: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4401 - accuracy: 0.7916 - precision_418: 0.7831 - recall_418: 0.8113 - val_loss: 9.3494 - val_accuracy: 0.5142 - val_precision_418: 0.5142 - val_recall_418: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4388 - accuracy: 0.7779 - precision_418: 0.7747 - recall_418: 0.7785 - val_loss: 2.6032 - val_accuracy: 0.5142 - val_precision_418: 0.5142 - val_recall_418: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3994 - accuracy: 0.8182 - precision_418: 0.8059 - recall_418: 0.8287 - val_loss: 4.4756 - val_accuracy: 0.5142 - val_precision_418: 0.5142 - val_recall_418: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3981 - accuracy: 0.8247 - precision_418: 0.8251 - recall_418: 0.8283 - val_loss: 1.8554 - val_accuracy: 0.4858 - val_precision_418: 0.0000e+00 - val_recall_418: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3772 - accuracy: 0.8298 - precision_418: 0.8137 - recall_418: 0.8379 - val_loss: 2.9341 - val_accuracy: 0.4858 - val_precision_418: 0.0000e+00 - val_recall_418: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3501 - accuracy: 0.8368 - precision_418: 0.8283 - recall_418: 0.8542 - val_loss: 0.7442 - val_accuracy: 0.5458 - val_precision_418: 0.5310 - val_recall_418: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3580 - accuracy: 0.8436 - precision_418: 0.8434 - recall_418: 0.8433 - val_loss: 2.2643 - val_accuracy: 0.4858 - val_precision_418: 0.0000e+00 - val_recall_418: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3368 - accuracy: 0.8531 - precision_418: 0.8480 - recall_418: 0.8570 - val_loss: 10.4494 - val_accuracy: 0.4858 - val_precision_418: 0.0000e+00 - val_recall_418: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2940 - accuracy: 0.8760 - precision_418: 0.8886 - recall_418: 0.8677 - val_loss: 22.0631 - val_accuracy: 0.4858 - val_precision_418: 0.0000e+00 - val_recall_418: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2623 - accuracy: 0.8848 - precision_418: 0.8754 - recall_418: 0.8965 - val_loss: 19.2528 - val_accuracy: 0.4858 - val_precision_418: 0.0000e+00 - val_recall_418: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2620 - accuracy: 0.8914 - precision_418: 0.8832 - recall_418: 0.9018 - val_loss: 16.2503 - val_accuracy: 0.4858 - val_precision_418: 0.0000e+00 - val_recall_418: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2563 - accuracy: 0.8924 - precision_418: 0.8816 - recall_418: 0.9012 - val_loss: 13.3054 - val_accuracy: 0.4858 - val_precision_418: 0.0000e+00 - val_recall_418: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2526 - accuracy: 0.8934 - precision_418: 0.8749 - recall_418: 0.9143 - val_loss: 7.6702 - val_accuracy: 0.5250 - val_precision_418: 0.9123 - val_recall_418: 0.0843\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2536 - accuracy: 0.8948 - precision_418: 0.8868 - recall_418: 0.9000 - val_loss: 4.2806 - val_accuracy: 0.5825 - val_precision_418: 0.7900 - val_recall_418: 0.2561\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2555 - accuracy: 0.8916 - precision_418: 0.8826 - recall_418: 0.8998 - val_loss: 2.8291 - val_accuracy: 0.5583 - val_precision_418: 0.7208 - val_recall_418: 0.2301\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2444 - accuracy: 0.9005 - precision_418: 0.9028 - recall_418: 0.8986 - val_loss: 2.2055 - val_accuracy: 0.5283 - val_precision_418: 0.7865 - val_recall_418: 0.1135\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2476 - accuracy: 0.8897 - precision_418: 0.8942 - recall_418: 0.8886 - val_loss: 1.7560 - val_accuracy: 0.5342 - val_precision_418: 0.9028 - val_recall_418: 0.1053\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2442 - accuracy: 0.8995 - precision_418: 0.9030 - recall_418: 0.8952 - val_loss: 1.3627 - val_accuracy: 0.5608 - val_precision_418: 0.9327 - val_recall_418: 0.1572\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2581 - accuracy: 0.8908 - precision_418: 0.9024 - recall_418: 0.8823 - val_loss: 1.0358 - val_accuracy: 0.6142 - val_precision_418: 0.9425 - val_recall_418: 0.2658\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2346 - accuracy: 0.9003 - precision_418: 0.9044 - recall_418: 0.8983 - val_loss: 0.8244 - val_accuracy: 0.6575 - val_precision_418: 0.9256 - val_recall_418: 0.3630\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2722 - accuracy: 0.8818 - precision_418: 0.8852 - recall_418: 0.8787 - val_loss: 0.6981 - val_accuracy: 0.7033 - val_precision_418: 0.9223 - val_recall_418: 0.4619\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2477 - accuracy: 0.8904 - precision_418: 0.8968 - recall_418: 0.8847 - val_loss: 0.6091 - val_accuracy: 0.7317 - val_precision_418: 0.9063 - val_recall_418: 0.5332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu, AUC=0.907, Accuracy=0.745, f2=0.586, prec=0.913, rec=0.538, total=  24.7s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 43ms/step - loss: 0.6518 - accuracy: 0.6880 - precision_419: 0.6735 - recall_419: 0.6973 - val_loss: 16.6859 - val_accuracy: 0.5142 - val_precision_419: 0.5142 - val_recall_419: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4242 - accuracy: 0.8037 - precision_419: 0.8015 - recall_419: 0.8045 - val_loss: 7.4100 - val_accuracy: 0.5142 - val_precision_419: 0.5142 - val_recall_419: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3991 - accuracy: 0.8152 - precision_419: 0.8229 - recall_419: 0.8114 - val_loss: 4.0339 - val_accuracy: 0.5142 - val_precision_419: 0.5142 - val_recall_419: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3502 - accuracy: 0.8493 - precision_419: 0.8436 - recall_419: 0.8612 - val_loss: 2.7503 - val_accuracy: 0.4858 - val_precision_419: 0.0000e+00 - val_recall_419: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3425 - accuracy: 0.8505 - precision_419: 0.8330 - recall_419: 0.8671 - val_loss: 8.0870 - val_accuracy: 0.5142 - val_precision_419: 0.5142 - val_recall_419: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3570 - accuracy: 0.8337 - precision_419: 0.8299 - recall_419: 0.8369 - val_loss: 13.2030 - val_accuracy: 0.5142 - val_precision_419: 0.5142 - val_recall_419: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3428 - accuracy: 0.8430 - precision_419: 0.8261 - recall_419: 0.8549 - val_loss: 4.4341 - val_accuracy: 0.5142 - val_precision_419: 0.5142 - val_recall_419: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3093 - accuracy: 0.8631 - precision_419: 0.8521 - recall_419: 0.8800 - val_loss: 1.1562 - val_accuracy: 0.5142 - val_precision_419: 0.5142 - val_recall_419: 1.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3088 - accuracy: 0.8699 - precision_419: 0.8673 - recall_419: 0.8789 - val_loss: 0.8371 - val_accuracy: 0.7292 - val_precision_419: 0.7179 - val_recall_419: 0.7796\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2827 - accuracy: 0.8735 - precision_419: 0.8659 - recall_419: 0.8807 - val_loss: 2.7722 - val_accuracy: 0.6567 - val_precision_419: 0.8596 - val_recall_419: 0.3971\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2827 - accuracy: 0.8819 - precision_419: 0.8669 - recall_419: 0.9008 - val_loss: 23.4218 - val_accuracy: 0.4867 - val_precision_419: 1.0000 - val_recall_419: 0.0016\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2714 - accuracy: 0.8819 - precision_419: 0.8725 - recall_419: 0.8936 - val_loss: 7.2624 - val_accuracy: 0.6500 - val_precision_419: 0.8689 - val_recall_419: 0.3760\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2487 - accuracy: 0.8956 - precision_419: 0.8831 - recall_419: 0.9109 - val_loss: 5.2207 - val_accuracy: 0.6817 - val_precision_419: 0.8036 - val_recall_419: 0.5041\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2530 - accuracy: 0.8953 - precision_419: 0.8819 - recall_419: 0.9071 - val_loss: 3.1969 - val_accuracy: 0.6650 - val_precision_419: 0.8028 - val_recall_419: 0.4619\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2787 - accuracy: 0.8761 - precision_419: 0.8652 - recall_419: 0.8906 - val_loss: 2.9123 - val_accuracy: 0.5725 - val_precision_419: 0.8421 - val_recall_419: 0.2075\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2640 - accuracy: 0.8865 - precision_419: 0.8821 - recall_419: 0.8905 - val_loss: 2.8902 - val_accuracy: 0.5075 - val_precision_419: 0.7708 - val_recall_419: 0.0600\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2571 - accuracy: 0.8970 - precision_419: 0.8825 - recall_419: 0.9132 - val_loss: 2.5539 - val_accuracy: 0.5000 - val_precision_419: 0.7297 - val_recall_419: 0.0438\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2583 - accuracy: 0.8901 - precision_419: 0.8871 - recall_419: 0.8956 - val_loss: 2.0492 - val_accuracy: 0.4925 - val_precision_419: 0.6538 - val_recall_419: 0.0276\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2712 - accuracy: 0.8833 - precision_419: 0.8753 - recall_419: 0.8923 - val_loss: 1.6743 - val_accuracy: 0.5008 - val_precision_419: 0.8750 - val_recall_419: 0.0340\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2702 - accuracy: 0.8778 - precision_419: 0.8594 - recall_419: 0.8990 - val_loss: 1.3637 - val_accuracy: 0.5275 - val_precision_419: 0.9630 - val_recall_419: 0.0843\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2504 - accuracy: 0.8969 - precision_419: 0.8982 - recall_419: 0.8978 - val_loss: 1.1235 - val_accuracy: 0.5700 - val_precision_419: 0.9720 - val_recall_419: 0.1686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu, AUC=0.886, Accuracy=0.580, f2=0.195, prec=0.949, rec=0.162, total=  22.5s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 2s 43ms/step - loss: 0.8532 - accuracy: 0.6492 - precision_420: 0.6404 - recall_420: 0.6544 - val_loss: 8.7045 - val_accuracy: 0.5142 - val_precision_420: 0.5142 - val_recall_420: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4430 - accuracy: 0.8012 - precision_420: 0.8039 - recall_420: 0.7930 - val_loss: 2.5400 - val_accuracy: 0.5142 - val_precision_420: 0.5142 - val_recall_420: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4018 - accuracy: 0.8180 - precision_420: 0.8089 - recall_420: 0.8270 - val_loss: 6.6773 - val_accuracy: 0.4858 - val_precision_420: 0.0000e+00 - val_recall_420: 0.0000e+00\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3953 - accuracy: 0.8119 - precision_420: 0.8035 - recall_420: 0.8143 - val_loss: 2.1585 - val_accuracy: 0.5142 - val_precision_420: 0.5142 - val_recall_420: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3770 - accuracy: 0.8320 - precision_420: 0.8147 - recall_420: 0.8539 - val_loss: 4.3503 - val_accuracy: 0.5142 - val_precision_420: 0.5142 - val_recall_420: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3803 - accuracy: 0.8317 - precision_420: 0.8202 - recall_420: 0.8410 - val_loss: 5.3306 - val_accuracy: 0.4858 - val_precision_420: 0.0000e+00 - val_recall_420: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3400 - accuracy: 0.8373 - precision_420: 0.8183 - recall_420: 0.8626 - val_loss: 5.7849 - val_accuracy: 0.4867 - val_precision_420: 1.0000 - val_recall_420: 0.0016\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3366 - accuracy: 0.8467 - precision_420: 0.8212 - recall_420: 0.8738 - val_loss: 14.5639 - val_accuracy: 0.4858 - val_precision_420: 0.0000e+00 - val_recall_420: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3291 - accuracy: 0.8540 - precision_420: 0.8489 - recall_420: 0.8660 - val_loss: 8.8171 - val_accuracy: 0.5250 - val_precision_420: 0.9273 - val_recall_420: 0.0827\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3081 - accuracy: 0.8577 - precision_420: 0.8372 - recall_420: 0.8811 - val_loss: 9.5824 - val_accuracy: 0.5192 - val_precision_420: 0.9348 - val_recall_420: 0.0697\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2977 - accuracy: 0.8725 - precision_420: 0.8555 - recall_420: 0.8929 - val_loss: 9.1616 - val_accuracy: 0.5275 - val_precision_420: 0.8906 - val_recall_420: 0.0924\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3112 - accuracy: 0.8625 - precision_420: 0.8505 - recall_420: 0.8747 - val_loss: 7.7997 - val_accuracy: 0.5233 - val_precision_420: 0.8358 - val_recall_420: 0.0908\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2982 - accuracy: 0.8749 - precision_420: 0.8662 - recall_420: 0.8849 - val_loss: 5.3149 - val_accuracy: 0.5175 - val_precision_420: 0.8519 - val_recall_420: 0.0746\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3166 - accuracy: 0.8652 - precision_420: 0.8504 - recall_420: 0.8776 - val_loss: 3.5500 - val_accuracy: 0.5108 - val_precision_420: 0.8409 - val_recall_420: 0.0600\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2993 - accuracy: 0.8667 - precision_420: 0.8448 - recall_420: 0.8926 - val_loss: 2.5885 - val_accuracy: 0.5025 - val_precision_420: 0.8125 - val_recall_420: 0.0421\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2925 - accuracy: 0.8708 - precision_420: 0.8646 - recall_420: 0.8753 - val_loss: 1.9570 - val_accuracy: 0.5033 - val_precision_420: 0.8621 - val_recall_420: 0.0405\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2907 - accuracy: 0.8660 - precision_420: 0.8563 - recall_420: 0.8758 - val_loss: 1.5514 - val_accuracy: 0.5108 - val_precision_420: 0.8750 - val_recall_420: 0.0567\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3076 - accuracy: 0.8619 - precision_420: 0.8495 - recall_420: 0.8734 - val_loss: 1.2182 - val_accuracy: 0.5550 - val_precision_420: 0.9663 - val_recall_420: 0.1394\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3011 - accuracy: 0.8692 - precision_420: 0.8578 - recall_420: 0.8829 - val_loss: 0.9869 - val_accuracy: 0.5925 - val_precision_420: 0.9444 - val_recall_420: 0.2204\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2955 - accuracy: 0.8733 - precision_420: 0.8635 - recall_420: 0.8812 - val_loss: 0.7710 - val_accuracy: 0.6575 - val_precision_420: 0.9292 - val_recall_420: 0.3614\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3047 - accuracy: 0.8690 - precision_420: 0.8593 - recall_420: 0.8814 - val_loss: 0.6303 - val_accuracy: 0.7017 - val_precision_420: 0.9060 - val_recall_420: 0.4684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.25, batch_size=100, activation=relu, AUC=0.903, Accuracy=0.713, f2=0.511, prec=0.924, rec=0.460, total=  22.5s\n",
      "[CV] lr=0.005, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.6453 - accuracy: 0.6885 - precision_421: 0.6810 - recall_421: 0.6607 - val_loss: 213.4215 - val_accuracy: 0.5142 - val_precision_421: 0.5142 - val_recall_421: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4922 - accuracy: 0.7666 - precision_421: 0.7573 - recall_421: 0.7785 - val_loss: 65.3229 - val_accuracy: 0.5142 - val_precision_421: 0.5142 - val_recall_421: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4679 - accuracy: 0.7708 - precision_421: 0.7621 - recall_421: 0.7836 - val_loss: 17.4885 - val_accuracy: 0.5142 - val_precision_421: 0.5142 - val_recall_421: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4634 - accuracy: 0.7841 - precision_421: 0.7781 - recall_421: 0.7899 - val_loss: 4.8298 - val_accuracy: 0.5142 - val_precision_421: 0.5142 - val_recall_421: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4493 - accuracy: 0.8019 - precision_421: 0.8209 - recall_421: 0.7733 - val_loss: 1.1366 - val_accuracy: 0.5425 - val_precision_421: 0.8864 - val_recall_421: 0.1264\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4376 - accuracy: 0.7982 - precision_421: 0.7916 - recall_421: 0.7988 - val_loss: 66.9286 - val_accuracy: 0.4858 - val_precision_421: 0.0000e+00 - val_recall_421: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4180 - accuracy: 0.8062 - precision_421: 0.7992 - recall_421: 0.8243 - val_loss: 1.7650 - val_accuracy: 0.4858 - val_precision_421: 0.0000e+00 - val_recall_421: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4221 - accuracy: 0.8017 - precision_421: 0.7996 - recall_421: 0.8113 - val_loss: 28.1866 - val_accuracy: 0.4858 - val_precision_421: 0.0000e+00 - val_recall_421: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3919 - accuracy: 0.8246 - precision_421: 0.8259 - recall_421: 0.8263 - val_loss: 71.0227 - val_accuracy: 0.4858 - val_precision_421: 0.0000e+00 - val_recall_421: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3954 - accuracy: 0.8118 - precision_421: 0.8130 - recall_421: 0.8127 - val_loss: 62.2986 - val_accuracy: 0.4858 - val_precision_421: 0.0000e+00 - val_recall_421: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4059 - accuracy: 0.8149 - precision_421: 0.7918 - recall_421: 0.8391 - val_loss: 21.7470 - val_accuracy: 0.4858 - val_precision_421: 0.0000e+00 - val_recall_421: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3997 - accuracy: 0.8123 - precision_421: 0.7908 - recall_421: 0.8300 - val_loss: 12.3149 - val_accuracy: 0.4858 - val_precision_421: 0.0000e+00 - val_recall_421: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3952 - accuracy: 0.8114 - precision_421: 0.7951 - recall_421: 0.8275 - val_loss: 6.1227 - val_accuracy: 0.4858 - val_precision_421: 0.0000e+00 - val_recall_421: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3913 - accuracy: 0.8234 - precision_421: 0.8130 - recall_421: 0.8353 - val_loss: 3.5167 - val_accuracy: 0.4875 - val_precision_421: 1.0000 - val_recall_421: 0.0032\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3858 - accuracy: 0.8357 - precision_421: 0.8119 - recall_421: 0.8601 - val_loss: 2.3053 - val_accuracy: 0.5058 - val_precision_421: 1.0000 - val_recall_421: 0.0389\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3903 - accuracy: 0.8242 - precision_421: 0.8117 - recall_421: 0.8419 - val_loss: 1.5661 - val_accuracy: 0.5558 - val_precision_421: 0.9773 - val_recall_421: 0.1394\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3986 - accuracy: 0.8107 - precision_421: 0.8190 - recall_421: 0.8136 - val_loss: 1.1283 - val_accuracy: 0.6058 - val_precision_421: 0.9390 - val_recall_421: 0.2496\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4081 - accuracy: 0.8104 - precision_421: 0.7984 - recall_421: 0.8193 - val_loss: 0.8559 - val_accuracy: 0.6625 - val_precision_421: 0.9274 - val_recall_421: 0.3728\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3896 - accuracy: 0.8256 - precision_421: 0.8152 - recall_421: 0.8379 - val_loss: 0.6709 - val_accuracy: 0.7142 - val_precision_421: 0.9255 - val_recall_421: 0.4830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu, AUC=0.902, Accuracy=0.722, f2=0.536, prec=0.915, rec=0.486, total=  21.1s\n",
      "[CV] lr=0.005, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 43ms/step - loss: 0.6539 - accuracy: 0.6820 - precision_422: 0.6764 - recall_422: 0.6709 - val_loss: 203.7867 - val_accuracy: 0.5142 - val_precision_422: 0.5142 - val_recall_422: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4656 - accuracy: 0.7696 - precision_422: 0.7492 - recall_422: 0.7975 - val_loss: 45.0038 - val_accuracy: 0.5142 - val_precision_422: 0.5142 - val_recall_422: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4418 - accuracy: 0.7892 - precision_422: 0.7859 - recall_422: 0.8126 - val_loss: 16.5491 - val_accuracy: 0.5142 - val_precision_422: 0.5142 - val_recall_422: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4325 - accuracy: 0.7993 - precision_422: 0.7917 - recall_422: 0.7964 - val_loss: 30.9524 - val_accuracy: 0.5142 - val_precision_422: 0.5142 - val_recall_422: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4217 - accuracy: 0.8086 - precision_422: 0.7907 - recall_422: 0.8332 - val_loss: 13.3476 - val_accuracy: 0.5142 - val_precision_422: 0.5142 - val_recall_422: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4025 - accuracy: 0.8136 - precision_422: 0.8151 - recall_422: 0.8121 - val_loss: 4.0378 - val_accuracy: 0.5142 - val_precision_422: 0.5142 - val_recall_422: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3908 - accuracy: 0.8226 - precision_422: 0.8154 - recall_422: 0.8483 - val_loss: 90.3749 - val_accuracy: 0.4858 - val_precision_422: 0.0000e+00 - val_recall_422: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3864 - accuracy: 0.8271 - precision_422: 0.8217 - recall_422: 0.8252 - val_loss: 35.4663 - val_accuracy: 0.4933 - val_precision_422: 1.0000 - val_recall_422: 0.0146\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3810 - accuracy: 0.8328 - precision_422: 0.8096 - recall_422: 0.8708 - val_loss: 116.5854 - val_accuracy: 0.4858 - val_precision_422: 0.0000e+00 - val_recall_422: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3600 - accuracy: 0.8384 - precision_422: 0.8108 - recall_422: 0.8700 - val_loss: 89.5541 - val_accuracy: 0.4858 - val_precision_422: 0.0000e+00 - val_recall_422: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3644 - accuracy: 0.8318 - precision_422: 0.8180 - recall_422: 0.8532 - val_loss: 64.3145 - val_accuracy: 0.4958 - val_precision_422: 1.0000 - val_recall_422: 0.0194\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3586 - accuracy: 0.8431 - precision_422: 0.8181 - recall_422: 0.8716 - val_loss: 30.9872 - val_accuracy: 0.5775 - val_precision_422: 0.8986 - val_recall_422: 0.2010\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3623 - accuracy: 0.8438 - precision_422: 0.8163 - recall_422: 0.8764 - val_loss: 17.8538 - val_accuracy: 0.5358 - val_precision_422: 0.9054 - val_recall_422: 0.1086\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3546 - accuracy: 0.8425 - precision_422: 0.8259 - recall_422: 0.8676 - val_loss: 12.4453 - val_accuracy: 0.4975 - val_precision_422: 0.8500 - val_recall_422: 0.0276\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3465 - accuracy: 0.8433 - precision_422: 0.8196 - recall_422: 0.8787 - val_loss: 5.8805 - val_accuracy: 0.5017 - val_precision_422: 1.0000 - val_recall_422: 0.0308\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3409 - accuracy: 0.8471 - precision_422: 0.8250 - recall_422: 0.8696 - val_loss: 3.6158 - val_accuracy: 0.5050 - val_precision_422: 0.9600 - val_recall_422: 0.0389\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3520 - accuracy: 0.8320 - precision_422: 0.8080 - recall_422: 0.8665 - val_loss: 2.3971 - val_accuracy: 0.5142 - val_precision_422: 1.0000 - val_recall_422: 0.0551\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3524 - accuracy: 0.8450 - precision_422: 0.8156 - recall_422: 0.8811 - val_loss: 1.8221 - val_accuracy: 0.5417 - val_precision_422: 0.9855 - val_recall_422: 0.1102\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3580 - accuracy: 0.8379 - precision_422: 0.8126 - recall_422: 0.8689 - val_loss: 1.3402 - val_accuracy: 0.5800 - val_precision_422: 0.9669 - val_recall_422: 0.1896\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3583 - accuracy: 0.8289 - precision_422: 0.7953 - recall_422: 0.8745 - val_loss: 0.9982 - val_accuracy: 0.6400 - val_precision_422: 0.9469 - val_recall_422: 0.3177\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3501 - accuracy: 0.8458 - precision_422: 0.8234 - recall_422: 0.8783 - val_loss: 0.7215 - val_accuracy: 0.7033 - val_precision_422: 0.9307 - val_recall_422: 0.4571\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3560 - accuracy: 0.8460 - precision_422: 0.8283 - recall_422: 0.8738 - val_loss: 0.5690 - val_accuracy: 0.7567 - val_precision_422: 0.9135 - val_recall_422: 0.5818\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3660 - accuracy: 0.8296 - precision_422: 0.8065 - recall_422: 0.8605 - val_loss: 0.4844 - val_accuracy: 0.7742 - val_precision_422: 0.8914 - val_recall_422: 0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu, AUC=0.892, Accuracy=0.778, f2=0.675, prec=0.883, rec=0.637, total=  25.2s\n",
      "[CV] lr=0.005, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.7918 - accuracy: 0.6527 - precision_423: 0.6508 - recall_423: 0.6636 - val_loss: 155.1779 - val_accuracy: 0.5142 - val_precision_423: 0.5142 - val_recall_423: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4954 - accuracy: 0.7566 - precision_423: 0.7668 - recall_423: 0.7514 - val_loss: 41.6178 - val_accuracy: 0.5142 - val_precision_423: 0.5142 - val_recall_423: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4720 - accuracy: 0.7707 - precision_423: 0.7765 - recall_423: 0.7630 - val_loss: 9.2861 - val_accuracy: 0.5142 - val_precision_423: 0.5142 - val_recall_423: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4398 - accuracy: 0.7991 - precision_423: 0.7720 - recall_423: 0.8165 - val_loss: 6.8874 - val_accuracy: 0.5142 - val_precision_423: 0.5142 - val_recall_423: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4210 - accuracy: 0.8114 - precision_423: 0.7906 - recall_423: 0.8484 - val_loss: 15.0988 - val_accuracy: 0.5142 - val_precision_423: 0.5142 - val_recall_423: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4313 - accuracy: 0.8014 - precision_423: 0.7954 - recall_423: 0.8128 - val_loss: 11.6518 - val_accuracy: 0.4858 - val_precision_423: 0.0000e+00 - val_recall_423: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4059 - accuracy: 0.8067 - precision_423: 0.8049 - recall_423: 0.8095 - val_loss: 20.6024 - val_accuracy: 0.4858 - val_precision_423: 0.0000e+00 - val_recall_423: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3884 - accuracy: 0.8184 - precision_423: 0.8076 - recall_423: 0.8362 - val_loss: 14.4087 - val_accuracy: 0.4858 - val_precision_423: 0.0000e+00 - val_recall_423: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3676 - accuracy: 0.8358 - precision_423: 0.8327 - recall_423: 0.8489 - val_loss: 10.4100 - val_accuracy: 0.4858 - val_precision_423: 0.0000e+00 - val_recall_423: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3672 - accuracy: 0.8274 - precision_423: 0.8033 - recall_423: 0.8581 - val_loss: 9.3262 - val_accuracy: 0.4775 - val_precision_423: 0.3684 - val_recall_423: 0.0227\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3785 - accuracy: 0.8210 - precision_423: 0.7957 - recall_423: 0.8465 - val_loss: 9.0558 - val_accuracy: 0.4775 - val_precision_423: 0.2500 - val_recall_423: 0.0081\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3682 - accuracy: 0.8332 - precision_423: 0.8172 - recall_423: 0.8511 - val_loss: 6.7048 - val_accuracy: 0.4833 - val_precision_423: 0.3636 - val_recall_423: 0.0065\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3667 - accuracy: 0.8303 - precision_423: 0.8193 - recall_423: 0.8377 - val_loss: 4.4885 - val_accuracy: 0.4867 - val_precision_423: 0.6667 - val_recall_423: 0.0032\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3729 - accuracy: 0.8301 - precision_423: 0.8274 - recall_423: 0.8316 - val_loss: 3.6699 - val_accuracy: 0.4867 - val_precision_423: 1.0000 - val_recall_423: 0.0016\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3859 - accuracy: 0.8254 - precision_423: 0.8131 - recall_423: 0.8356 - val_loss: 1.9479 - val_accuracy: 0.4950 - val_precision_423: 1.0000 - val_recall_423: 0.0178\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3694 - accuracy: 0.8297 - precision_423: 0.8126 - recall_423: 0.8412 - val_loss: 1.9040 - val_accuracy: 0.4967 - val_precision_423: 1.0000 - val_recall_423: 0.0211\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3789 - accuracy: 0.8272 - precision_423: 0.8245 - recall_423: 0.8360 - val_loss: 1.8337 - val_accuracy: 0.5000 - val_precision_423: 1.0000 - val_recall_423: 0.0276\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3818 - accuracy: 0.8228 - precision_423: 0.8289 - recall_423: 0.8195 - val_loss: 1.2851 - val_accuracy: 0.5725 - val_precision_423: 0.9815 - val_recall_423: 0.1718\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3659 - accuracy: 0.8301 - precision_423: 0.8037 - recall_423: 0.8567 - val_loss: 2.0552 - val_accuracy: 0.5058 - val_precision_423: 0.9615 - val_recall_423: 0.0405\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3654 - accuracy: 0.8383 - precision_423: 0.8362 - recall_423: 0.8445 - val_loss: 1.3001 - val_accuracy: 0.5275 - val_precision_423: 0.9808 - val_recall_423: 0.0827\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3705 - accuracy: 0.8289 - precision_423: 0.8217 - recall_423: 0.8407 - val_loss: 0.7383 - val_accuracy: 0.6525 - val_precision_423: 0.9386 - val_recall_423: 0.3468\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3833 - accuracy: 0.8259 - precision_423: 0.8129 - recall_423: 0.8392 - val_loss: 0.5277 - val_accuracy: 0.7400 - val_precision_423: 0.9155 - val_recall_423: 0.5446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=11, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=100, activation=relu, AUC=0.911, Accuracy=0.743, f2=0.585, prec=0.907, rec=0.538, total=  23.7s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 24ms/step - loss: 0.6352 - accuracy: 0.7162 - precision_424: 0.7078 - recall_424: 0.7145 - val_loss: 8.1875 - val_accuracy: 0.4858 - val_precision_424: 0.0000e+00 - val_recall_424: 0.0000e+00\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4269 - accuracy: 0.8060 - precision_424: 0.7984 - recall_424: 0.8167 - val_loss: 22.0808 - val_accuracy: 0.4858 - val_precision_424: 0.0000e+00 - val_recall_424: 0.0000e+00\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4058 - accuracy: 0.8067 - precision_424: 0.8011 - recall_424: 0.8162 - val_loss: 8.8276 - val_accuracy: 0.4858 - val_precision_424: 0.0000e+00 - val_recall_424: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3766 - accuracy: 0.8349 - precision_424: 0.8312 - recall_424: 0.8387 - val_loss: 22.2614 - val_accuracy: 0.4858 - val_precision_424: 0.0000e+00 - val_recall_424: 0.0000e+00\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3830 - accuracy: 0.8264 - precision_424: 0.8142 - recall_424: 0.8360 - val_loss: 4.7958 - val_accuracy: 0.4875 - val_precision_424: 1.0000 - val_recall_424: 0.0032\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3356 - accuracy: 0.8532 - precision_424: 0.8408 - recall_424: 0.8677 - val_loss: 5.0900 - val_accuracy: 0.4858 - val_precision_424: 0.0000e+00 - val_recall_424: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3511 - accuracy: 0.8433 - precision_424: 0.8173 - recall_424: 0.8670 - val_loss: 7.7863 - val_accuracy: 0.5142 - val_precision_424: 0.5142 - val_recall_424: 1.0000\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3081 - accuracy: 0.8707 - precision_424: 0.8618 - recall_424: 0.8739 - val_loss: 0.9681 - val_accuracy: 0.6383 - val_precision_424: 0.5872 - val_recall_424: 0.9984\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3008 - accuracy: 0.8649 - precision_424: 0.8502 - recall_424: 0.8836 - val_loss: 1.0818 - val_accuracy: 0.6483 - val_precision_424: 0.9221 - val_recall_424: 0.3452\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3019 - accuracy: 0.8641 - precision_424: 0.8595 - recall_424: 0.8726 - val_loss: 0.4559 - val_accuracy: 0.8325 - val_precision_424: 0.8032 - val_recall_424: 0.8930\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2997 - accuracy: 0.8678 - precision_424: 0.8507 - recall_424: 0.8855 - val_loss: 9.1598 - val_accuracy: 0.5200 - val_precision_424: 0.9362 - val_recall_424: 0.0713\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2807 - accuracy: 0.8810 - precision_424: 0.8828 - recall_424: 0.8778 - val_loss: 1.5700 - val_accuracy: 0.5475 - val_precision_424: 0.5319 - val_recall_424: 1.0000\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2587 - accuracy: 0.8912 - precision_424: 0.8780 - recall_424: 0.9038 - val_loss: 0.3800 - val_accuracy: 0.8450 - val_precision_424: 0.8174 - val_recall_424: 0.8995\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2696 - accuracy: 0.8847 - precision_424: 0.8733 - recall_424: 0.8951 - val_loss: 0.4361 - val_accuracy: 0.8183 - val_precision_424: 0.7622 - val_recall_424: 0.9400\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2843 - accuracy: 0.8803 - precision_424: 0.8798 - recall_424: 0.8789 - val_loss: 0.5375 - val_accuracy: 0.7750 - val_precision_424: 0.7025 - val_recall_424: 0.9757\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2758 - accuracy: 0.8882 - precision_424: 0.8859 - recall_424: 0.8879 - val_loss: 0.4665 - val_accuracy: 0.8042 - val_precision_424: 0.7418 - val_recall_424: 0.9498\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2663 - accuracy: 0.8860 - precision_424: 0.8839 - recall_424: 0.8865 - val_loss: 0.3992 - val_accuracy: 0.8392 - val_precision_424: 0.8020 - val_recall_424: 0.9125\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2710 - accuracy: 0.8838 - precision_424: 0.8679 - recall_424: 0.8986 - val_loss: 0.4207 - val_accuracy: 0.8325 - val_precision_424: 0.7865 - val_recall_424: 0.9254\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2772 - accuracy: 0.8789 - precision_424: 0.8801 - recall_424: 0.8763 - val_loss: 0.4366 - val_accuracy: 0.8175 - val_precision_424: 0.7639 - val_recall_424: 0.9335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=50, activation=elu, AUC=0.918, Accuracy=0.828, f2=0.892, prec=0.772, rec=0.928, total=  23.6s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 24ms/step - loss: 0.6945 - accuracy: 0.7168 - precision_425: 0.7106 - recall_425: 0.7249 - val_loss: 10.3710 - val_accuracy: 0.5142 - val_precision_425: 0.5142 - val_recall_425: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4351 - accuracy: 0.7933 - precision_425: 0.7744 - recall_425: 0.8115 - val_loss: 5.7002 - val_accuracy: 0.5142 - val_precision_425: 0.5142 - val_recall_425: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3861 - accuracy: 0.8245 - precision_425: 0.8159 - recall_425: 0.8398 - val_loss: 0.6707 - val_accuracy: 0.6575 - val_precision_425: 0.9292 - val_recall_425: 0.3614\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3559 - accuracy: 0.8386 - precision_425: 0.8190 - recall_425: 0.8626 - val_loss: 4.7181 - val_accuracy: 0.5142 - val_precision_425: 0.5142 - val_recall_425: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3747 - accuracy: 0.8404 - precision_425: 0.8310 - recall_425: 0.8559 - val_loss: 117.8032 - val_accuracy: 0.4858 - val_precision_425: 0.0000e+00 - val_recall_425: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3528 - accuracy: 0.8372 - precision_425: 0.8414 - recall_425: 0.8293 - val_loss: 0.5133 - val_accuracy: 0.7467 - val_precision_425: 0.6741 - val_recall_425: 0.9822\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3134 - accuracy: 0.8675 - precision_425: 0.8476 - recall_425: 0.8885 - val_loss: 19.1205 - val_accuracy: 0.4858 - val_precision_425: 0.0000e+00 - val_recall_425: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3122 - accuracy: 0.8668 - precision_425: 0.8589 - recall_425: 0.8761 - val_loss: 5.1912 - val_accuracy: 0.5142 - val_precision_425: 0.5142 - val_recall_425: 1.0000\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2788 - accuracy: 0.8783 - precision_425: 0.8673 - recall_425: 0.8894 - val_loss: 0.5645 - val_accuracy: 0.7000 - val_precision_425: 0.9186 - val_recall_425: 0.4571\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2887 - accuracy: 0.8807 - precision_425: 0.8801 - recall_425: 0.8814 - val_loss: 3.8113 - val_accuracy: 0.4858 - val_precision_425: 0.0000e+00 - val_recall_425: 0.0000e+00\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2781 - accuracy: 0.8744 - precision_425: 0.8626 - recall_425: 0.8860 - val_loss: 1.0951 - val_accuracy: 0.6000 - val_precision_425: 0.9724 - val_recall_425: 0.2285\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2702 - accuracy: 0.8819 - precision_425: 0.8735 - recall_425: 0.8937 - val_loss: 0.4249 - val_accuracy: 0.8033 - val_precision_425: 0.9097 - val_recall_425: 0.6856\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2498 - accuracy: 0.8909 - precision_425: 0.8748 - recall_425: 0.9094 - val_loss: 0.3665 - val_accuracy: 0.8383 - val_precision_425: 0.8133 - val_recall_425: 0.8898\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2679 - accuracy: 0.8854 - precision_425: 0.8701 - recall_425: 0.9022 - val_loss: 0.3969 - val_accuracy: 0.8258 - val_precision_425: 0.7713 - val_recall_425: 0.9400\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2720 - accuracy: 0.8940 - precision_425: 0.8914 - recall_425: 0.9020 - val_loss: 0.3685 - val_accuracy: 0.8350 - val_precision_425: 0.8085 - val_recall_425: 0.8898\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2875 - accuracy: 0.8803 - precision_425: 0.8653 - recall_425: 0.9007 - val_loss: 0.3620 - val_accuracy: 0.8342 - val_precision_425: 0.8206 - val_recall_425: 0.8671\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2511 - accuracy: 0.8979 - precision_425: 0.8845 - recall_425: 0.9137 - val_loss: 0.3666 - val_accuracy: 0.8350 - val_precision_425: 0.8141 - val_recall_425: 0.8801\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2545 - accuracy: 0.8897 - precision_425: 0.8815 - recall_425: 0.8986 - val_loss: 0.3620 - val_accuracy: 0.8375 - val_precision_425: 0.8371 - val_recall_425: 0.8493\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2621 - accuracy: 0.8896 - precision_425: 0.8771 - recall_425: 0.9022 - val_loss: 0.3625 - val_accuracy: 0.8392 - val_precision_425: 0.8292 - val_recall_425: 0.8655\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2544 - accuracy: 0.9029 - precision_425: 0.8939 - recall_425: 0.9150 - val_loss: 0.3635 - val_accuracy: 0.8350 - val_precision_425: 0.8189 - val_recall_425: 0.8720\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2503 - accuracy: 0.8852 - precision_425: 0.8614 - recall_425: 0.9175 - val_loss: 0.3644 - val_accuracy: 0.8358 - val_precision_425: 0.8182 - val_recall_425: 0.8752\n",
      "Epoch 22/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2620 - accuracy: 0.8908 - precision_425: 0.8697 - recall_425: 0.9149 - val_loss: 0.3646 - val_accuracy: 0.8350 - val_precision_425: 0.8169 - val_recall_425: 0.8752\n",
      "Epoch 23/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2679 - accuracy: 0.8849 - precision_425: 0.8704 - recall_425: 0.9008 - val_loss: 0.3645 - val_accuracy: 0.8358 - val_precision_425: 0.8182 - val_recall_425: 0.8752\n",
      "Epoch 24/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2636 - accuracy: 0.8846 - precision_425: 0.8706 - recall_425: 0.9019 - val_loss: 0.3647 - val_accuracy: 0.8350 - val_precision_425: 0.8169 - val_recall_425: 0.8752\n",
      "Epoch 25/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2529 - accuracy: 0.8904 - precision_425: 0.8779 - recall_425: 0.9048 - val_loss: 0.3647 - val_accuracy: 0.8350 - val_precision_425: 0.8169 - val_recall_425: 0.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=50, activation=elu, AUC=0.895, Accuracy=0.815, f2=0.842, prec=0.789, rec=0.856, total=  30.2s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 31ms/step - loss: 0.6809 - accuracy: 0.7054 - precision_426: 0.7060 - recall_426: 0.7018 - val_loss: 10.3551 - val_accuracy: 0.5142 - val_precision_426: 0.5142 - val_recall_426: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4487 - accuracy: 0.7916 - precision_426: 0.7853 - recall_426: 0.8031 - val_loss: 7.3054 - val_accuracy: 0.4858 - val_precision_426: 0.0000e+00 - val_recall_426: 0.0000e+00\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4074 - accuracy: 0.8125 - precision_426: 0.8045 - recall_426: 0.8168 - val_loss: 3.3266 - val_accuracy: 0.5142 - val_precision_426: 0.5142 - val_recall_426: 1.0000\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.4119 - accuracy: 0.8092 - precision_426: 0.8032 - recall_426: 0.8218 - val_loss: 76.5090 - val_accuracy: 0.4858 - val_precision_426: 0.0000e+00 - val_recall_426: 0.0000e+00\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3599 - accuracy: 0.8394 - precision_426: 0.8289 - recall_426: 0.8511 - val_loss: 18.9826 - val_accuracy: 0.4858 - val_precision_426: 0.0000e+00 - val_recall_426: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3740 - accuracy: 0.8275 - precision_426: 0.8268 - recall_426: 0.8373 - val_loss: 12.3517 - val_accuracy: 0.4858 - val_precision_426: 0.0000e+00 - val_recall_426: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3389 - accuracy: 0.8487 - precision_426: 0.8543 - recall_426: 0.8521 - val_loss: 2.7649 - val_accuracy: 0.4858 - val_precision_426: 0.0000e+00 - val_recall_426: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3322 - accuracy: 0.8440 - precision_426: 0.8349 - recall_426: 0.8526 - val_loss: 9.3787 - val_accuracy: 0.4858 - val_precision_426: 0.0000e+00 - val_recall_426: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3077 - accuracy: 0.8649 - precision_426: 0.8518 - recall_426: 0.8814 - val_loss: 113.2197 - val_accuracy: 0.4858 - val_precision_426: 0.0000e+00 - val_recall_426: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3043 - accuracy: 0.8743 - precision_426: 0.8654 - recall_426: 0.8835 - val_loss: 17.9953 - val_accuracy: 0.4858 - val_precision_426: 0.0000e+00 - val_recall_426: 0.0000e+00\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2880 - accuracy: 0.8761 - precision_426: 0.8579 - recall_426: 0.8871 - val_loss: 2.9423 - val_accuracy: 0.4883 - val_precision_426: 1.0000 - val_recall_426: 0.0049\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2803 - accuracy: 0.8827 - precision_426: 0.8711 - recall_426: 0.8935 - val_loss: 0.7255 - val_accuracy: 0.6850 - val_precision_426: 0.9509 - val_recall_426: 0.4084\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2880 - accuracy: 0.8758 - precision_426: 0.8604 - recall_426: 0.8895 - val_loss: 0.3752 - val_accuracy: 0.8400 - val_precision_426: 0.8120 - val_recall_426: 0.8963\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2448 - accuracy: 0.9017 - precision_426: 0.8991 - recall_426: 0.9042 - val_loss: 0.3965 - val_accuracy: 0.8233 - val_precision_426: 0.7801 - val_recall_426: 0.9141\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2692 - accuracy: 0.8878 - precision_426: 0.8915 - recall_426: 0.8853 - val_loss: 0.4145 - val_accuracy: 0.8167 - val_precision_426: 0.7643 - val_recall_426: 0.9303\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2691 - accuracy: 0.8869 - precision_426: 0.8801 - recall_426: 0.8951 - val_loss: 0.3896 - val_accuracy: 0.8292 - val_precision_426: 0.7918 - val_recall_426: 0.9060\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2595 - accuracy: 0.8917 - precision_426: 0.8984 - recall_426: 0.8852 - val_loss: 0.4042 - val_accuracy: 0.8250 - val_precision_426: 0.7799 - val_recall_426: 0.9190\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2694 - accuracy: 0.8873 - precision_426: 0.8973 - recall_426: 0.8768 - val_loss: 0.3875 - val_accuracy: 0.8317 - val_precision_426: 0.7952 - val_recall_426: 0.9060\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.2569 - accuracy: 0.8915 - precision_426: 0.8798 - recall_426: 0.9043 - val_loss: 0.3832 - val_accuracy: 0.8350 - val_precision_426: 0.8014 - val_recall_426: 0.9028\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2881 - accuracy: 0.8791 - precision_426: 0.8672 - recall_426: 0.8906 - val_loss: 0.3806 - val_accuracy: 0.8383 - val_precision_426: 0.8088 - val_recall_426: 0.8979\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2801 - accuracy: 0.8709 - precision_426: 0.8616 - recall_426: 0.8827 - val_loss: 0.3801 - val_accuracy: 0.8367 - val_precision_426: 0.8082 - val_recall_426: 0.8947\n",
      "Epoch 22/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2540 - accuracy: 0.8907 - precision_426: 0.8992 - recall_426: 0.8846 - val_loss: 0.3798 - val_accuracy: 0.8367 - val_precision_426: 0.8082 - val_recall_426: 0.8947\n",
      "Epoch 23/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2511 - accuracy: 0.9002 - precision_426: 0.8926 - recall_426: 0.9068 - val_loss: 0.3793 - val_accuracy: 0.8383 - val_precision_426: 0.8106 - val_recall_426: 0.8947\n",
      "Epoch 24/500\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.2755 - accuracy: 0.8714 - precision_426: 0.8617 - recall_426: 0.8795 - val_loss: 0.3804 - val_accuracy: 0.8367 - val_precision_426: 0.8082 - val_recall_426: 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=50, activation=elu, AUC=0.900, Accuracy=0.814, f2=0.844, prec=0.785, rec=0.860, total=  29.6s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.25, batch_size=50, activation=relu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 26ms/step - loss: 0.6441 - accuracy: 0.7067 - precision_427: 0.7091 - recall_427: 0.7193 - val_loss: 13.8727 - val_accuracy: 0.5142 - val_precision_427: 0.5142 - val_recall_427: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4531 - accuracy: 0.7831 - precision_427: 0.7766 - recall_427: 0.7828 - val_loss: 5.2384 - val_accuracy: 0.4858 - val_precision_427: 0.0000e+00 - val_recall_427: 0.0000e+00\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4281 - accuracy: 0.7983 - precision_427: 0.7881 - recall_427: 0.8057 - val_loss: 8.3042 - val_accuracy: 0.4858 - val_precision_427: 0.0000e+00 - val_recall_427: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3957 - accuracy: 0.8286 - precision_427: 0.8239 - recall_427: 0.8303 - val_loss: 2.7177 - val_accuracy: 0.4875 - val_precision_427: 1.0000 - val_recall_427: 0.0032\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4078 - accuracy: 0.8212 - precision_427: 0.7971 - recall_427: 0.8491 - val_loss: 110.0216 - val_accuracy: 0.4858 - val_precision_427: 0.0000e+00 - val_recall_427: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4126 - accuracy: 0.8189 - precision_427: 0.8101 - recall_427: 0.8287 - val_loss: 543.9837 - val_accuracy: 0.4858 - val_precision_427: 0.0000e+00 - val_recall_427: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3918 - accuracy: 0.8198 - precision_427: 0.8177 - recall_427: 0.8320 - val_loss: 928.4984 - val_accuracy: 0.4858 - val_precision_427: 0.0000e+00 - val_recall_427: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3823 - accuracy: 0.8235 - precision_427: 0.8106 - recall_427: 0.8403 - val_loss: 168.0581 - val_accuracy: 0.4858 - val_precision_427: 0.0000e+00 - val_recall_427: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3753 - accuracy: 0.8179 - precision_427: 0.7911 - recall_427: 0.8474 - val_loss: 252.7587 - val_accuracy: 0.4858 - val_precision_427: 0.0000e+00 - val_recall_427: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3699 - accuracy: 0.8268 - precision_427: 0.8195 - recall_427: 0.8447 - val_loss: 295.1169 - val_accuracy: 0.4858 - val_precision_427: 0.0000e+00 - val_recall_427: 0.0000e+00\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3644 - accuracy: 0.8244 - precision_427: 0.8148 - recall_427: 0.8364 - val_loss: 58.9149 - val_accuracy: 0.4858 - val_precision_427: 0.0000e+00 - val_recall_427: 0.0000e+00\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3680 - accuracy: 0.8300 - precision_427: 0.8184 - recall_427: 0.8484 - val_loss: 4.9187 - val_accuracy: 0.4858 - val_precision_427: 0.0000e+00 - val_recall_427: 0.0000e+00\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3540 - accuracy: 0.8321 - precision_427: 0.8205 - recall_427: 0.8479 - val_loss: 2.2430 - val_accuracy: 0.4875 - val_precision_427: 1.0000 - val_recall_427: 0.0032\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3534 - accuracy: 0.8466 - precision_427: 0.8437 - recall_427: 0.8533 - val_loss: 1.1003 - val_accuracy: 0.5833 - val_precision_427: 0.9535 - val_recall_427: 0.1994\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3564 - accuracy: 0.8291 - precision_427: 0.8075 - recall_427: 0.8484 - val_loss: 0.6420 - val_accuracy: 0.7067 - val_precision_427: 0.9128 - val_recall_427: 0.4749\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3598 - accuracy: 0.8315 - precision_427: 0.8274 - recall_427: 0.8349 - val_loss: 0.5062 - val_accuracy: 0.7683 - val_precision_427: 0.8933 - val_recall_427: 0.6240\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3509 - accuracy: 0.8369 - precision_427: 0.8181 - recall_427: 0.8590 - val_loss: 0.4590 - val_accuracy: 0.7792 - val_precision_427: 0.8697 - val_recall_427: 0.6710\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3533 - accuracy: 0.8457 - precision_427: 0.8317 - recall_427: 0.8606 - val_loss: 0.4113 - val_accuracy: 0.7983 - val_precision_427: 0.8428 - val_recall_427: 0.7472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.25, batch_size=50, activation=relu, AUC=0.911, Accuracy=0.823, f2=0.785, prec=0.859, rec=0.769, total=  23.9s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.25, batch_size=50, activation=relu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 25ms/step - loss: 0.6307 - accuracy: 0.7240 - precision_428: 0.7130 - recall_428: 0.7306 - val_loss: 7.5514 - val_accuracy: 0.5142 - val_precision_428: 0.5142 - val_recall_428: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4438 - accuracy: 0.7834 - precision_428: 0.7745 - recall_428: 0.7992 - val_loss: 11.5417 - val_accuracy: 0.4858 - val_precision_428: 0.0000e+00 - val_recall_428: 0.0000e+00\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.4156 - accuracy: 0.8158 - precision_428: 0.8070 - recall_428: 0.8173 - val_loss: 1.9024 - val_accuracy: 0.4875 - val_precision_428: 1.0000 - val_recall_428: 0.0032\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3872 - accuracy: 0.8240 - precision_428: 0.8167 - recall_428: 0.8370 - val_loss: 0.5790 - val_accuracy: 0.6850 - val_precision_428: 0.6216 - val_recall_428: 0.9903\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3916 - accuracy: 0.8189 - precision_428: 0.8020 - recall_428: 0.8405 - val_loss: 172.2913 - val_accuracy: 0.4858 - val_precision_428: 0.0000e+00 - val_recall_428: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3660 - accuracy: 0.8356 - precision_428: 0.8225 - recall_428: 0.8499 - val_loss: 257.3191 - val_accuracy: 0.4858 - val_precision_428: 0.0000e+00 - val_recall_428: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3488 - accuracy: 0.8432 - precision_428: 0.8258 - recall_428: 0.8607 - val_loss: 430.5376 - val_accuracy: 0.4858 - val_precision_428: 0.0000e+00 - val_recall_428: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3390 - accuracy: 0.8481 - precision_428: 0.8193 - recall_428: 0.8839 - val_loss: 539.1033 - val_accuracy: 0.4858 - val_precision_428: 0.0000e+00 - val_recall_428: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2976 - accuracy: 0.8735 - precision_428: 0.8736 - recall_428: 0.8780 - val_loss: 494.7274 - val_accuracy: 0.4858 - val_precision_428: 0.0000e+00 - val_recall_428: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2853 - accuracy: 0.8754 - precision_428: 0.8684 - recall_428: 0.8806 - val_loss: 27.8954 - val_accuracy: 0.6758 - val_precision_428: 0.8750 - val_recall_428: 0.4311\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3022 - accuracy: 0.8703 - precision_428: 0.8559 - recall_428: 0.8906 - val_loss: 6.8545 - val_accuracy: 0.6825 - val_precision_428: 0.7950 - val_recall_428: 0.5154\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2930 - accuracy: 0.8668 - precision_428: 0.8496 - recall_428: 0.8881 - val_loss: 2.9549 - val_accuracy: 0.5500 - val_precision_428: 0.8738 - val_recall_428: 0.1459\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2966 - accuracy: 0.8784 - precision_428: 0.8610 - recall_428: 0.8989 - val_loss: 1.3807 - val_accuracy: 0.5475 - val_precision_428: 0.9405 - val_recall_428: 0.1280\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2955 - accuracy: 0.8767 - precision_428: 0.8449 - recall_428: 0.9061 - val_loss: 0.8503 - val_accuracy: 0.6492 - val_precision_428: 0.9414 - val_recall_428: 0.3387\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3056 - accuracy: 0.8585 - precision_428: 0.8477 - recall_428: 0.8673 - val_loss: 0.5307 - val_accuracy: 0.7475 - val_precision_428: 0.9110 - val_recall_428: 0.5640\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2816 - accuracy: 0.8855 - precision_428: 0.8804 - recall_428: 0.8926 - val_loss: 0.4693 - val_accuracy: 0.7858 - val_precision_428: 0.9018 - val_recall_428: 0.6548\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2984 - accuracy: 0.8727 - precision_428: 0.8614 - recall_428: 0.8902 - val_loss: 0.4203 - val_accuracy: 0.8058 - val_precision_428: 0.8707 - val_recall_428: 0.7310\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3045 - accuracy: 0.8707 - precision_428: 0.8466 - recall_428: 0.8972 - val_loss: 0.4039 - val_accuracy: 0.8092 - val_precision_428: 0.8593 - val_recall_428: 0.7520\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2952 - accuracy: 0.8718 - precision_428: 0.8692 - recall_428: 0.8773 - val_loss: 0.3975 - val_accuracy: 0.8092 - val_precision_428: 0.8489 - val_recall_428: 0.7650\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2999 - accuracy: 0.8702 - precision_428: 0.8572 - recall_428: 0.8884 - val_loss: 0.3984 - val_accuracy: 0.8108 - val_precision_428: 0.8520 - val_recall_428: 0.7650\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2973 - accuracy: 0.8642 - precision_428: 0.8512 - recall_428: 0.8814 - val_loss: 0.3935 - val_accuracy: 0.8125 - val_precision_428: 0.8439 - val_recall_428: 0.7796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.25, batch_size=50, activation=relu, AUC=0.888, Accuracy=0.795, f2=0.775, prec=0.810, rec=0.767, total=  27.3s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.25, batch_size=50, activation=relu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 25ms/step - loss: 0.6668 - accuracy: 0.6979 - precision_429: 0.6989 - recall_429: 0.6941 - val_loss: 7.0437 - val_accuracy: 0.5142 - val_precision_429: 0.5142 - val_recall_429: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4589 - accuracy: 0.7817 - precision_429: 0.7676 - recall_429: 0.8065 - val_loss: 1.5324 - val_accuracy: 0.5142 - val_precision_429: 0.5142 - val_recall_429: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4162 - accuracy: 0.8124 - precision_429: 0.8003 - recall_429: 0.8287 - val_loss: 82.3837 - val_accuracy: 0.4858 - val_precision_429: 0.0000e+00 - val_recall_429: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4095 - accuracy: 0.8026 - precision_429: 0.7990 - recall_429: 0.8099 - val_loss: 47.4221 - val_accuracy: 0.4858 - val_precision_429: 0.0000e+00 - val_recall_429: 0.0000e+00\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3885 - accuracy: 0.8197 - precision_429: 0.8187 - recall_429: 0.8299 - val_loss: 202.3816 - val_accuracy: 0.4858 - val_precision_429: 0.0000e+00 - val_recall_429: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3827 - accuracy: 0.8260 - precision_429: 0.8259 - recall_429: 0.8331 - val_loss: 236.6837 - val_accuracy: 0.4858 - val_precision_429: 0.0000e+00 - val_recall_429: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3644 - accuracy: 0.8405 - precision_429: 0.8173 - recall_429: 0.8670 - val_loss: 119.6764 - val_accuracy: 0.4858 - val_precision_429: 0.0000e+00 - val_recall_429: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3551 - accuracy: 0.8403 - precision_429: 0.8398 - recall_429: 0.8445 - val_loss: 103.1677 - val_accuracy: 0.4858 - val_precision_429: 0.0000e+00 - val_recall_429: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3386 - accuracy: 0.8582 - precision_429: 0.8448 - recall_429: 0.8729 - val_loss: 31.8774 - val_accuracy: 0.5167 - val_precision_429: 0.9744 - val_recall_429: 0.0616\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3483 - accuracy: 0.8360 - precision_429: 0.8355 - recall_429: 0.8392 - val_loss: 4.4761 - val_accuracy: 0.5067 - val_precision_429: 1.0000 - val_recall_429: 0.0405\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3412 - accuracy: 0.8504 - precision_429: 0.8426 - recall_429: 0.8646 - val_loss: 1.4626 - val_accuracy: 0.5242 - val_precision_429: 0.9792 - val_recall_429: 0.0762\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3668 - accuracy: 0.8366 - precision_429: 0.8375 - recall_429: 0.8391 - val_loss: 0.7100 - val_accuracy: 0.6742 - val_precision_429: 0.9449 - val_recall_429: 0.3890\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3437 - accuracy: 0.8523 - precision_429: 0.8379 - recall_429: 0.8739 - val_loss: 0.5030 - val_accuracy: 0.7492 - val_precision_429: 0.9010 - val_recall_429: 0.5754\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3540 - accuracy: 0.8493 - precision_429: 0.8422 - recall_429: 0.8634 - val_loss: 0.3895 - val_accuracy: 0.8175 - val_precision_429: 0.8467 - val_recall_429: 0.7877\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3528 - accuracy: 0.8482 - precision_429: 0.8251 - recall_429: 0.8704 - val_loss: 0.4021 - val_accuracy: 0.8017 - val_precision_429: 0.8542 - val_recall_429: 0.7407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=glorot_uniform, epochs=500, drop_rate=0.25, batch_size=50, activation=relu, AUC=0.910, Accuracy=0.818, f2=0.773, prec=0.862, rec=0.753, total=  20.3s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 46ms/step - loss: 0.7563 - accuracy: 0.6744 - precision_430: 0.6666 - recall_430: 0.6743 - val_loss: 90.7293 - val_accuracy: 0.5142 - val_precision_430: 0.5142 - val_recall_430: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4738 - accuracy: 0.7740 - precision_430: 0.7682 - recall_430: 0.7880 - val_loss: 0.6447 - val_accuracy: 0.7167 - val_precision_430: 0.8506 - val_recall_430: 0.5446\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4642 - accuracy: 0.7825 - precision_430: 0.7904 - recall_430: 0.7605 - val_loss: 3.0966 - val_accuracy: 0.4858 - val_precision_430: 0.0000e+00 - val_recall_430: 0.0000e+00\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.4630 - accuracy: 0.7749 - precision_430: 0.7671 - recall_430: 0.7862 - val_loss: 1.6931 - val_accuracy: 0.5142 - val_precision_430: 0.5142 - val_recall_430: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4496 - accuracy: 0.7916 - precision_430: 0.7809 - recall_430: 0.8105 - val_loss: 0.4842 - val_accuracy: 0.7433 - val_precision_430: 0.8239 - val_recall_430: 0.6370\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4111 - accuracy: 0.8103 - precision_430: 0.8005 - recall_430: 0.8315 - val_loss: 1.0203 - val_accuracy: 0.5167 - val_precision_430: 0.5155 - val_recall_430: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3998 - accuracy: 0.8146 - precision_430: 0.8086 - recall_430: 0.8134 - val_loss: 0.4708 - val_accuracy: 0.7808 - val_precision_430: 0.7201 - val_recall_430: 0.9384\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4152 - accuracy: 0.8034 - precision_430: 0.7950 - recall_430: 0.8061 - val_loss: 2.9668 - val_accuracy: 0.4983 - val_precision_430: 1.0000 - val_recall_430: 0.0243\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3961 - accuracy: 0.8256 - precision_430: 0.8197 - recall_430: 0.8327 - val_loss: 0.5065 - val_accuracy: 0.7583 - val_precision_430: 0.8794 - val_recall_430: 0.6143\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3902 - accuracy: 0.8217 - precision_430: 0.8054 - recall_430: 0.8436 - val_loss: 3.7698 - val_accuracy: 0.5008 - val_precision_430: 1.0000 - val_recall_430: 0.0292\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3864 - accuracy: 0.8238 - precision_430: 0.8048 - recall_430: 0.8408 - val_loss: 20.7514 - val_accuracy: 0.4858 - val_precision_430: 0.0000e+00 - val_recall_430: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3852 - accuracy: 0.8146 - precision_430: 0.8067 - recall_430: 0.8236 - val_loss: 6.0564 - val_accuracy: 0.5008 - val_precision_430: 1.0000 - val_recall_430: 0.0292\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3843 - accuracy: 0.8177 - precision_430: 0.8146 - recall_430: 0.8301 - val_loss: 2.2095 - val_accuracy: 0.5758 - val_precision_430: 0.9576 - val_recall_430: 0.1831\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3893 - accuracy: 0.8163 - precision_430: 0.8079 - recall_430: 0.8279 - val_loss: 1.1325 - val_accuracy: 0.6575 - val_precision_430: 0.9221 - val_recall_430: 0.3647\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3678 - accuracy: 0.8378 - precision_430: 0.8372 - recall_430: 0.8457 - val_loss: 0.7645 - val_accuracy: 0.7217 - val_precision_430: 0.9078 - val_recall_430: 0.5105\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3812 - accuracy: 0.8263 - precision_430: 0.8164 - recall_430: 0.8416 - val_loss: 0.5438 - val_accuracy: 0.7608 - val_precision_430: 0.8767 - val_recall_430: 0.6224\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3871 - accuracy: 0.8160 - precision_430: 0.8057 - recall_430: 0.8259 - val_loss: 0.4485 - val_accuracy: 0.7917 - val_precision_430: 0.8536 - val_recall_430: 0.7180\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.4098 - accuracy: 0.8061 - precision_430: 0.7927 - recall_430: 0.8153 - val_loss: 0.4124 - val_accuracy: 0.8183 - val_precision_430: 0.8399 - val_recall_430: 0.7990\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3997 - accuracy: 0.8118 - precision_430: 0.8042 - recall_430: 0.8259 - val_loss: 0.4024 - val_accuracy: 0.8225 - val_precision_430: 0.8156 - val_recall_430: 0.8460\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3910 - accuracy: 0.8262 - precision_430: 0.8195 - recall_430: 0.8402 - val_loss: 0.4037 - val_accuracy: 0.8192 - val_precision_430: 0.7967 - val_recall_430: 0.8703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu, AUC=0.912, Accuracy=0.826, f2=0.849, prec=0.803, rec=0.862, total=  22.8s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 47ms/step - loss: 0.7505 - accuracy: 0.6667 - precision_431: 0.6595 - recall_431: 0.6454 - val_loss: 31.3447 - val_accuracy: 0.5142 - val_precision_431: 0.5142 - val_recall_431: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4652 - accuracy: 0.7738 - precision_431: 0.7602 - recall_431: 0.7878 - val_loss: 0.7958 - val_accuracy: 0.5925 - val_precision_431: 0.8765 - val_recall_431: 0.2415\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.4381 - accuracy: 0.8054 - precision_431: 0.7964 - recall_431: 0.8238 - val_loss: 9.2150 - val_accuracy: 0.4858 - val_precision_431: 0.0000e+00 - val_recall_431: 0.0000e+00\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4292 - accuracy: 0.8046 - precision_431: 0.8035 - recall_431: 0.8034 - val_loss: 4.3218 - val_accuracy: 0.4858 - val_precision_431: 0.0000e+00 - val_recall_431: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3865 - accuracy: 0.8258 - precision_431: 0.8178 - recall_431: 0.8445 - val_loss: 18.3622 - val_accuracy: 0.4858 - val_precision_431: 0.0000e+00 - val_recall_431: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3753 - accuracy: 0.8266 - precision_431: 0.8024 - recall_431: 0.8473 - val_loss: 0.8402 - val_accuracy: 0.5167 - val_precision_431: 0.5979 - val_recall_431: 0.1831\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3814 - accuracy: 0.8180 - precision_431: 0.7845 - recall_431: 0.8621 - val_loss: 0.7421 - val_accuracy: 0.6725 - val_precision_431: 0.9308 - val_recall_431: 0.3922\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3882 - accuracy: 0.8231 - precision_431: 0.8157 - recall_431: 0.8355 - val_loss: 1.1924 - val_accuracy: 0.6125 - val_precision_431: 0.9270 - val_recall_431: 0.2674\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3862 - accuracy: 0.8222 - precision_431: 0.8097 - recall_431: 0.8370 - val_loss: 1.2791 - val_accuracy: 0.6158 - val_precision_431: 0.9333 - val_recall_431: 0.2723\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3784 - accuracy: 0.8378 - precision_431: 0.8269 - recall_431: 0.8531 - val_loss: 0.7912 - val_accuracy: 0.7092 - val_precision_431: 0.9268 - val_recall_431: 0.4716\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3622 - accuracy: 0.8379 - precision_431: 0.8256 - recall_431: 0.8558 - val_loss: 0.6574 - val_accuracy: 0.7383 - val_precision_431: 0.9128 - val_recall_431: 0.5429\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3673 - accuracy: 0.8335 - precision_431: 0.8066 - recall_431: 0.8594 - val_loss: 0.4123 - val_accuracy: 0.8075 - val_precision_431: 0.8509 - val_recall_431: 0.7585\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3655 - accuracy: 0.8326 - precision_431: 0.8232 - recall_431: 0.8450 - val_loss: 0.3929 - val_accuracy: 0.8233 - val_precision_431: 0.8140 - val_recall_431: 0.8509\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3790 - accuracy: 0.8274 - precision_431: 0.8140 - recall_431: 0.8495 - val_loss: 0.4303 - val_accuracy: 0.7967 - val_precision_431: 0.8580 - val_recall_431: 0.7245\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3750 - accuracy: 0.8340 - precision_431: 0.8128 - recall_431: 0.8584 - val_loss: 0.3994 - val_accuracy: 0.8167 - val_precision_431: 0.8428 - val_recall_431: 0.7909\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3645 - accuracy: 0.8242 - precision_431: 0.8056 - recall_431: 0.8468 - val_loss: 0.4001 - val_accuracy: 0.8175 - val_precision_431: 0.8431 - val_recall_431: 0.7925\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3692 - accuracy: 0.8383 - precision_431: 0.8321 - recall_431: 0.8471 - val_loss: 0.3939 - val_accuracy: 0.8225 - val_precision_431: 0.8322 - val_recall_431: 0.8201\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3818 - accuracy: 0.8275 - precision_431: 0.8227 - recall_431: 0.8298 - val_loss: 0.3916 - val_accuracy: 0.8217 - val_precision_431: 0.8105 - val_recall_431: 0.8525\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3657 - accuracy: 0.8361 - precision_431: 0.8158 - recall_431: 0.8614 - val_loss: 0.3945 - val_accuracy: 0.8275 - val_precision_431: 0.8051 - val_recall_431: 0.8768\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3732 - accuracy: 0.8252 - precision_431: 0.8190 - recall_431: 0.8390 - val_loss: 0.3998 - val_accuracy: 0.8267 - val_precision_431: 0.7959 - val_recall_431: 0.8914\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3719 - accuracy: 0.8350 - precision_431: 0.8203 - recall_431: 0.8596 - val_loss: 0.4065 - val_accuracy: 0.8217 - val_precision_431: 0.7834 - val_recall_431: 0.9028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu, AUC=0.889, Accuracy=0.804, f2=0.864, prec=0.754, rec=0.897, total=  24.5s\n",
      "[CV] lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 46ms/step - loss: 0.7333 - accuracy: 0.6941 - precision_432: 0.6898 - recall_432: 0.7163 - val_loss: 1.4101 - val_accuracy: 0.5617 - val_precision_432: 0.5399 - val_recall_432: 0.9968\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.4713 - accuracy: 0.7728 - precision_432: 0.7471 - recall_432: 0.7958 - val_loss: 3.9111 - val_accuracy: 0.4858 - val_precision_432: 0.0000e+00 - val_recall_432: 0.0000e+00\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4239 - accuracy: 0.8095 - precision_432: 0.8005 - recall_432: 0.8093 - val_loss: 1.8525 - val_accuracy: 0.5142 - val_precision_432: 0.5142 - val_recall_432: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3958 - accuracy: 0.8166 - precision_432: 0.7939 - recall_432: 0.8456 - val_loss: 1.9167 - val_accuracy: 0.5025 - val_precision_432: 0.5085 - val_recall_432: 0.9741\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3983 - accuracy: 0.8105 - precision_432: 0.8061 - recall_432: 0.8269 - val_loss: 0.8979 - val_accuracy: 0.5250 - val_precision_432: 0.5202 - val_recall_432: 0.9806\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3863 - accuracy: 0.8276 - precision_432: 0.8183 - recall_432: 0.8454 - val_loss: 7.2068 - val_accuracy: 0.4858 - val_precision_432: 0.0000e+00 - val_recall_432: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3920 - accuracy: 0.8248 - precision_432: 0.8220 - recall_432: 0.8267 - val_loss: 5.9703 - val_accuracy: 0.4858 - val_precision_432: 0.0000e+00 - val_recall_432: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3678 - accuracy: 0.8345 - precision_432: 0.8256 - recall_432: 0.8482 - val_loss: 1.8991 - val_accuracy: 0.5175 - val_precision_432: 0.9750 - val_recall_432: 0.0632\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3665 - accuracy: 0.8331 - precision_432: 0.8117 - recall_432: 0.8533 - val_loss: 2.2893 - val_accuracy: 0.5033 - val_precision_432: 1.0000 - val_recall_432: 0.0340\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3858 - accuracy: 0.8238 - precision_432: 0.8155 - recall_432: 0.8359 - val_loss: 2.8432 - val_accuracy: 0.4950 - val_precision_432: 1.0000 - val_recall_432: 0.0178\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3532 - accuracy: 0.8416 - precision_432: 0.8327 - recall_432: 0.8573 - val_loss: 2.1117 - val_accuracy: 0.5267 - val_precision_432: 0.9804 - val_recall_432: 0.0810\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3532 - accuracy: 0.8458 - precision_432: 0.8278 - recall_432: 0.8691 - val_loss: 1.1960 - val_accuracy: 0.6150 - val_precision_432: 0.9532 - val_recall_432: 0.2642\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3736 - accuracy: 0.8317 - precision_432: 0.8233 - recall_432: 0.8454 - val_loss: 0.9601 - val_accuracy: 0.6625 - val_precision_432: 0.9344 - val_recall_432: 0.3695\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3776 - accuracy: 0.8316 - precision_432: 0.8265 - recall_432: 0.8447 - val_loss: 0.6248 - val_accuracy: 0.7417 - val_precision_432: 0.9137 - val_recall_432: 0.5494\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3644 - accuracy: 0.8438 - precision_432: 0.8174 - recall_432: 0.8730 - val_loss: 0.4799 - val_accuracy: 0.7683 - val_precision_432: 0.8758 - val_recall_432: 0.6402\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.3758 - accuracy: 0.8290 - precision_432: 0.8160 - recall_432: 0.8437 - val_loss: 0.4107 - val_accuracy: 0.7992 - val_precision_432: 0.8534 - val_recall_432: 0.7358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=13, kernel_initializer=he_normal, epochs=500, drop_rate=0.3, batch_size=100, activation=elu, AUC=0.912, Accuracy=0.823, f2=0.777, prec=0.868, rec=0.757, total=  18.9s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=300, activation=elu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 3s 122ms/step - loss: 0.5776 - accuracy: 0.6900 - precision_433: 0.6908 - recall_433: 0.7094 - val_loss: 35.4231 - val_accuracy: 0.5142 - val_precision_433: 0.5142 - val_recall_433: 1.0000\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.4691 - accuracy: 0.7726 - precision_433: 0.7609 - recall_433: 0.7817 - val_loss: 18.2512 - val_accuracy: 0.5142 - val_precision_433: 0.5142 - val_recall_433: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.4219 - accuracy: 0.7979 - precision_433: 0.7780 - recall_433: 0.8046 - val_loss: 13.7409 - val_accuracy: 0.5142 - val_precision_433: 0.5142 - val_recall_433: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 0.3951 - accuracy: 0.8154 - precision_433: 0.8005 - recall_433: 0.8438 - val_loss: 4.6589 - val_accuracy: 0.5142 - val_precision_433: 0.5142 - val_recall_433: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 0.3936 - accuracy: 0.8197 - precision_433: 0.8132 - recall_433: 0.8257 - val_loss: 2.4659 - val_accuracy: 0.4858 - val_precision_433: 0.0000e+00 - val_recall_433: 0.0000e+00\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.3735 - accuracy: 0.8379 - precision_433: 0.8209 - recall_433: 0.8629 - val_loss: 17.9645 - val_accuracy: 0.5142 - val_precision_433: 0.5142 - val_recall_433: 1.0000\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3610 - accuracy: 0.8359 - precision_433: 0.8138 - recall_433: 0.8635 - val_loss: 25.9570 - val_accuracy: 0.4858 - val_precision_433: 0.0000e+00 - val_recall_433: 0.0000e+00\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3263 - accuracy: 0.8545 - precision_433: 0.8566 - recall_433: 0.8521 - val_loss: 21.0560 - val_accuracy: 0.4858 - val_precision_433: 0.0000e+00 - val_recall_433: 0.0000e+00\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3284 - accuracy: 0.8430 - precision_433: 0.8254 - recall_433: 0.8636 - val_loss: 0.5856 - val_accuracy: 0.6908 - val_precision_433: 0.6265 - val_recall_433: 0.9870\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.3184 - accuracy: 0.8547 - precision_433: 0.8456 - recall_433: 0.8671 - val_loss: 0.6889 - val_accuracy: 0.6500 - val_precision_433: 0.5954 - val_recall_433: 0.9968\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3075 - accuracy: 0.8621 - precision_433: 0.8455 - recall_433: 0.8786 - val_loss: 13.3124 - val_accuracy: 0.4858 - val_precision_433: 0.0000e+00 - val_recall_433: 0.0000e+00\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.3004 - accuracy: 0.8631 - precision_433: 0.8519 - recall_433: 0.8673 - val_loss: 3.9230 - val_accuracy: 0.4858 - val_precision_433: 0.0000e+00 - val_recall_433: 0.0000e+00\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.2950 - accuracy: 0.8718 - precision_433: 0.8758 - recall_433: 0.8647 - val_loss: 0.7732 - val_accuracy: 0.5692 - val_precision_433: 0.9717 - val_recall_433: 0.1669\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.2843 - accuracy: 0.8715 - precision_433: 0.8744 - recall_433: 0.8695 - val_loss: 0.9211 - val_accuracy: 0.5333 - val_precision_433: 0.9524 - val_recall_433: 0.0972\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.3080 - accuracy: 0.8617 - precision_433: 0.8542 - recall_433: 0.8710 - val_loss: 0.7787 - val_accuracy: 0.5958 - val_precision_433: 0.9648 - val_recall_433: 0.2220\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.2938 - accuracy: 0.8704 - precision_433: 0.8660 - recall_433: 0.8776 - val_loss: 0.5722 - val_accuracy: 0.6992 - val_precision_433: 0.9267 - val_recall_433: 0.4506\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.2808 - accuracy: 0.8797 - precision_433: 0.8818 - recall_433: 0.8737 - val_loss: 0.4939 - val_accuracy: 0.7458 - val_precision_433: 0.8939 - val_recall_433: 0.5737\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.2867 - accuracy: 0.8675 - precision_433: 0.8547 - recall_433: 0.8813 - val_loss: 0.4442 - val_accuracy: 0.7667 - val_precision_433: 0.8703 - val_recall_433: 0.6418\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.3068 - accuracy: 0.8726 - precision_433: 0.8706 - recall_433: 0.8759 - val_loss: 0.4341 - val_accuracy: 0.7783 - val_precision_433: 0.8726 - val_recall_433: 0.6661\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.2818 - accuracy: 0.8771 - precision_433: 0.8731 - recall_433: 0.8782 - val_loss: 0.4323 - val_accuracy: 0.7817 - val_precision_433: 0.8737 - val_recall_433: 0.6726\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.2876 - accuracy: 0.8730 - precision_433: 0.8644 - recall_433: 0.8816 - val_loss: 0.4431 - val_accuracy: 0.7742 - val_precision_433: 0.8777 - val_recall_433: 0.6515\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.2903 - accuracy: 0.8762 - precision_433: 0.8608 - recall_433: 0.8901 - val_loss: 0.4582 - val_accuracy: 0.7650 - val_precision_433: 0.8798 - val_recall_433: 0.6288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=300, activation=elu, AUC=0.919, Accuracy=0.783, f2=0.670, prec=0.906, rec=0.629, total=  21.4s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=300, activation=elu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 3s 122ms/step - loss: 0.5600 - accuracy: 0.6855 - precision_434: 0.6874 - recall_434: 0.6989 - val_loss: 62.4587 - val_accuracy: 0.5142 - val_precision_434: 0.5142 - val_recall_434: 1.0000\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.4329 - accuracy: 0.7942 - precision_434: 0.7876 - recall_434: 0.8073 - val_loss: 45.0182 - val_accuracy: 0.5142 - val_precision_434: 0.5142 - val_recall_434: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.3884 - accuracy: 0.8198 - precision_434: 0.8070 - recall_434: 0.8401 - val_loss: 32.1473 - val_accuracy: 0.5142 - val_precision_434: 0.5142 - val_recall_434: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.3876 - accuracy: 0.8156 - precision_434: 0.8058 - recall_434: 0.8232 - val_loss: 15.8205 - val_accuracy: 0.5142 - val_precision_434: 0.5142 - val_recall_434: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3616 - accuracy: 0.8289 - precision_434: 0.8105 - recall_434: 0.8486 - val_loss: 20.3889 - val_accuracy: 0.5142 - val_precision_434: 0.5142 - val_recall_434: 1.0000\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3446 - accuracy: 0.8557 - precision_434: 0.8407 - recall_434: 0.8749 - val_loss: 23.5658 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3248 - accuracy: 0.8407 - precision_434: 0.8426 - recall_434: 0.8430 - val_loss: 15.2692 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3162 - accuracy: 0.8588 - precision_434: 0.8489 - recall_434: 0.8673 - val_loss: 10.1708 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.3223 - accuracy: 0.8542 - precision_434: 0.8491 - recall_434: 0.8616 - val_loss: 29.1185 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.3094 - accuracy: 0.8585 - precision_434: 0.8508 - recall_434: 0.8675 - val_loss: 22.7322 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.3016 - accuracy: 0.8640 - precision_434: 0.8579 - recall_434: 0.8697 - val_loss: 20.6576 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.3016 - accuracy: 0.8675 - precision_434: 0.8612 - recall_434: 0.8737 - val_loss: 19.7070 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.2767 - accuracy: 0.8802 - precision_434: 0.8687 - recall_434: 0.8939 - val_loss: 17.9467 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.2838 - accuracy: 0.8700 - precision_434: 0.8524 - recall_434: 0.8884 - val_loss: 16.5129 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3019 - accuracy: 0.8715 - precision_434: 0.8491 - recall_434: 0.8984 - val_loss: 14.9298 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.2959 - accuracy: 0.8665 - precision_434: 0.8559 - recall_434: 0.8809 - val_loss: 13.5956 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.2862 - accuracy: 0.8742 - precision_434: 0.8685 - recall_434: 0.8811 - val_loss: 12.4000 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.2841 - accuracy: 0.8703 - precision_434: 0.8533 - recall_434: 0.8920 - val_loss: 10.9867 - val_accuracy: 0.4858 - val_precision_434: 0.0000e+00 - val_recall_434: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=300, activation=elu, AUC=0.856, Accuracy=0.504, f2=0.000, prec=0.000, rec=0.000, total=  17.9s\n",
      "[CV] lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=300, activation=elu \n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 3s 163ms/step - loss: 0.5906 - accuracy: 0.6739 - precision_435: 0.6696 - recall_435: 0.6763 - val_loss: 41.2809 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.4624 - accuracy: 0.7794 - precision_435: 0.7752 - recall_435: 0.7906 - val_loss: 33.3820 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.4330 - accuracy: 0.8039 - precision_435: 0.7960 - recall_435: 0.8070 - val_loss: 27.2531 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.3967 - accuracy: 0.8216 - precision_435: 0.8181 - recall_435: 0.8286 - val_loss: 29.8210 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.3792 - accuracy: 0.8288 - precision_435: 0.8259 - recall_435: 0.8306 - val_loss: 14.3448 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3664 - accuracy: 0.8354 - precision_435: 0.8334 - recall_435: 0.8390 - val_loss: 13.0668 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.3571 - accuracy: 0.8378 - precision_435: 0.8247 - recall_435: 0.8600 - val_loss: 11.7614 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.3570 - accuracy: 0.8377 - precision_435: 0.8321 - recall_435: 0.8408 - val_loss: 17.3015 - val_accuracy: 0.4858 - val_precision_435: 0.0000e+00 - val_recall_435: 0.0000e+00\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3259 - accuracy: 0.8536 - precision_435: 0.8440 - recall_435: 0.8657 - val_loss: 9.9338 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.3290 - accuracy: 0.8542 - precision_435: 0.8590 - recall_435: 0.8558 - val_loss: 3.6402 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.3054 - accuracy: 0.8646 - precision_435: 0.8531 - recall_435: 0.8687 - val_loss: 10.1992 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.2928 - accuracy: 0.8657 - precision_435: 0.8523 - recall_435: 0.8861 - val_loss: 0.4367 - val_accuracy: 0.7975 - val_precision_435: 0.8351 - val_recall_435: 0.7553\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.2772 - accuracy: 0.8807 - precision_435: 0.8725 - recall_435: 0.8872 - val_loss: 8.9251 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.2649 - accuracy: 0.8843 - precision_435: 0.8804 - recall_435: 0.8891 - val_loss: 4.1135 - val_accuracy: 0.4858 - val_precision_435: 0.0000e+00 - val_recall_435: 0.0000e+00\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.2457 - accuracy: 0.9002 - precision_435: 0.8950 - recall_435: 0.9038 - val_loss: 3.4718 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.2182 - accuracy: 0.9137 - precision_435: 0.9136 - recall_435: 0.9113 - val_loss: 2.7204 - val_accuracy: 0.4858 - val_precision_435: 0.0000e+00 - val_recall_435: 0.0000e+00\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.1990 - accuracy: 0.9136 - precision_435: 0.9073 - recall_435: 0.9178 - val_loss: 0.7897 - val_accuracy: 0.6358 - val_precision_435: 0.5860 - val_recall_435: 0.9935\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.1979 - accuracy: 0.9175 - precision_435: 0.9078 - recall_435: 0.9258 - val_loss: 3.1450 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.1894 - accuracy: 0.9228 - precision_435: 0.9149 - recall_435: 0.9300 - val_loss: 3.0600 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.1900 - accuracy: 0.9229 - precision_435: 0.9204 - recall_435: 0.9241 - val_loss: 2.8302 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.1939 - accuracy: 0.9230 - precision_435: 0.9248 - recall_435: 0.9238 - val_loss: 2.7788 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.1907 - accuracy: 0.9212 - precision_435: 0.9173 - recall_435: 0.9250 - val_loss: 2.8323 - val_accuracy: 0.5142 - val_precision_435: 0.5142 - val_recall_435: 1.0000\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.1955 - accuracy: 0.9179 - precision_435: 0.9128 - recall_435: 0.9226 - val_loss: 2.7758 - val_accuracy: 0.5150 - val_precision_435: 0.5146 - val_recall_435: 1.0000\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.2006 - accuracy: 0.9178 - precision_435: 0.9044 - recall_435: 0.9267 - val_loss: 2.7031 - val_accuracy: 0.5167 - val_precision_435: 0.5155 - val_recall_435: 1.0000\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.1895 - accuracy: 0.9195 - precision_435: 0.9254 - recall_435: 0.9124 - val_loss: 2.6111 - val_accuracy: 0.5175 - val_precision_435: 0.5159 - val_recall_435: 1.0000\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.1932 - accuracy: 0.9204 - precision_435: 0.9137 - recall_435: 0.9291 - val_loss: 2.5060 - val_accuracy: 0.5200 - val_precision_435: 0.5172 - val_recall_435: 1.0000\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.1837 - accuracy: 0.9307 - precision_435: 0.9331 - recall_435: 0.9282 - val_loss: 2.4067 - val_accuracy: 0.5217 - val_precision_435: 0.5181 - val_recall_435: 1.0000\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.1890 - accuracy: 0.9247 - precision_435: 0.9246 - recall_435: 0.9216 - val_loss: 2.2932 - val_accuracy: 0.5267 - val_precision_435: 0.5207 - val_recall_435: 1.0000\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.1966 - accuracy: 0.9178 - precision_435: 0.9158 - recall_435: 0.9190 - val_loss: 2.1924 - val_accuracy: 0.5317 - val_precision_435: 0.5233 - val_recall_435: 1.0000\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.1980 - accuracy: 0.9222 - precision_435: 0.9212 - recall_435: 0.9233 - val_loss: 2.0766 - val_accuracy: 0.5367 - val_precision_435: 0.5260 - val_recall_435: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=9, kernel_initializer=TruncatedNormal, epochs=500, drop_rate=0.3, batch_size=300, activation=elu, AUC=0.892, Accuracy=0.521, f2=0.838, prec=0.509, rec=1.000, total=  28.7s\n",
      "[CV] lr=0.01, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 43ms/step - loss: 0.6517 - accuracy: 0.7094 - precision_436: 0.7103 - recall_436: 0.7349 - val_loss: 32.8442 - val_accuracy: 0.5142 - val_precision_436: 0.5142 - val_recall_436: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4570 - accuracy: 0.7829 - precision_436: 0.7896 - recall_436: 0.7591 - val_loss: 7.8935 - val_accuracy: 0.5142 - val_precision_436: 0.5142 - val_recall_436: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4361 - accuracy: 0.7958 - precision_436: 0.7896 - recall_436: 0.7987 - val_loss: 5.3979 - val_accuracy: 0.5142 - val_precision_436: 0.5142 - val_recall_436: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4143 - accuracy: 0.8154 - precision_436: 0.7901 - recall_436: 0.8336 - val_loss: 9.6525 - val_accuracy: 0.5142 - val_precision_436: 0.5142 - val_recall_436: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3925 - accuracy: 0.8273 - precision_436: 0.8185 - recall_436: 0.8370 - val_loss: 1.1689 - val_accuracy: 0.4833 - val_precision_436: 0.4651 - val_recall_436: 0.0324\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4076 - accuracy: 0.8193 - precision_436: 0.7999 - recall_436: 0.8298 - val_loss: 41.6613 - val_accuracy: 0.4858 - val_precision_436: 0.0000e+00 - val_recall_436: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3785 - accuracy: 0.8325 - precision_436: 0.8317 - recall_436: 0.8247 - val_loss: 15.9871 - val_accuracy: 0.4858 - val_precision_436: 0.0000e+00 - val_recall_436: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3739 - accuracy: 0.8321 - precision_436: 0.8084 - recall_436: 0.8672 - val_loss: 95.0639 - val_accuracy: 0.4858 - val_precision_436: 0.0000e+00 - val_recall_436: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3529 - accuracy: 0.8473 - precision_436: 0.8337 - recall_436: 0.8701 - val_loss: 67.7638 - val_accuracy: 0.4858 - val_precision_436: 0.0000e+00 - val_recall_436: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3685 - accuracy: 0.8276 - precision_436: 0.8205 - recall_436: 0.8341 - val_loss: 54.0754 - val_accuracy: 0.4858 - val_precision_436: 0.0000e+00 - val_recall_436: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3699 - accuracy: 0.8211 - precision_436: 0.8158 - recall_436: 0.8337 - val_loss: 67.3032 - val_accuracy: 0.4858 - val_precision_436: 0.0000e+00 - val_recall_436: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3413 - accuracy: 0.8464 - precision_436: 0.8423 - recall_436: 0.8458 - val_loss: 46.3547 - val_accuracy: 0.4858 - val_precision_436: 0.0000e+00 - val_recall_436: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3507 - accuracy: 0.8413 - precision_436: 0.8316 - recall_436: 0.8502 - val_loss: 51.1464 - val_accuracy: 0.4858 - val_precision_436: 0.0000e+00 - val_recall_436: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3433 - accuracy: 0.8502 - precision_436: 0.8305 - recall_436: 0.8677 - val_loss: 26.2381 - val_accuracy: 0.4858 - val_precision_436: 0.0000e+00 - val_recall_436: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3488 - accuracy: 0.8428 - precision_436: 0.8303 - recall_436: 0.8603 - val_loss: 7.0232 - val_accuracy: 0.5175 - val_precision_436: 1.0000 - val_recall_436: 0.0616\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3613 - accuracy: 0.8383 - precision_436: 0.8415 - recall_436: 0.8402 - val_loss: 2.1623 - val_accuracy: 0.6033 - val_precision_436: 0.9273 - val_recall_436: 0.2480\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3528 - accuracy: 0.8358 - precision_436: 0.8247 - recall_436: 0.8471 - val_loss: 1.2535 - val_accuracy: 0.6825 - val_precision_436: 0.9126 - val_recall_436: 0.4230\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3436 - accuracy: 0.8443 - precision_436: 0.8247 - recall_436: 0.8661 - val_loss: 0.8110 - val_accuracy: 0.7350 - val_precision_436: 0.9074 - val_recall_436: 0.5397\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3305 - accuracy: 0.8589 - precision_436: 0.8561 - recall_436: 0.8642 - val_loss: 0.5716 - val_accuracy: 0.7708 - val_precision_436: 0.8869 - val_recall_436: 0.6353\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3263 - accuracy: 0.8558 - precision_436: 0.8369 - recall_436: 0.8732 - val_loss: 0.4542 - val_accuracy: 0.7983 - val_precision_436: 0.8698 - val_recall_436: 0.7147\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3371 - accuracy: 0.8542 - precision_436: 0.8368 - recall_436: 0.8707 - val_loss: 0.3970 - val_accuracy: 0.8142 - val_precision_436: 0.8569 - val_recall_436: 0.7666\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3411 - accuracy: 0.8410 - precision_436: 0.8308 - recall_436: 0.8508 - val_loss: 0.3747 - val_accuracy: 0.8258 - val_precision_436: 0.8423 - val_recall_436: 0.8136\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3437 - accuracy: 0.8389 - precision_436: 0.8305 - recall_436: 0.8474 - val_loss: 0.3696 - val_accuracy: 0.8350 - val_precision_436: 0.8310 - val_recall_436: 0.8525\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3345 - accuracy: 0.8519 - precision_436: 0.8337 - recall_436: 0.8783 - val_loss: 0.3705 - val_accuracy: 0.8383 - val_precision_436: 0.8219 - val_recall_436: 0.8752\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3411 - accuracy: 0.8471 - precision_436: 0.8344 - recall_436: 0.8649 - val_loss: 0.3731 - val_accuracy: 0.8392 - val_precision_436: 0.8136 - val_recall_436: 0.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=100, activation=elu, AUC=0.919, Accuracy=0.840, f2=0.862, prec=0.817, rec=0.874, total=  25.6s\n",
      "[CV] lr=0.01, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 2s 42ms/step - loss: 0.6328 - accuracy: 0.6915 - precision_437: 0.6863 - recall_437: 0.6865 - val_loss: 11.3843 - val_accuracy: 0.5142 - val_precision_437: 0.5142 - val_recall_437: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4303 - accuracy: 0.8098 - precision_437: 0.8069 - recall_437: 0.8131 - val_loss: 6.9241 - val_accuracy: 0.5142 - val_precision_437: 0.5142 - val_recall_437: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4104 - accuracy: 0.8065 - precision_437: 0.7968 - recall_437: 0.8161 - val_loss: 4.8151 - val_accuracy: 0.5142 - val_precision_437: 0.5142 - val_recall_437: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4046 - accuracy: 0.8045 - precision_437: 0.7828 - recall_437: 0.8261 - val_loss: 6.2628 - val_accuracy: 0.5142 - val_precision_437: 0.5142 - val_recall_437: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3663 - accuracy: 0.8246 - precision_437: 0.8039 - recall_437: 0.8504 - val_loss: 0.7889 - val_accuracy: 0.5383 - val_precision_437: 0.9565 - val_recall_437: 0.1070\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3749 - accuracy: 0.8285 - precision_437: 0.8294 - recall_437: 0.8337 - val_loss: 21.7042 - val_accuracy: 0.4858 - val_precision_437: 0.0000e+00 - val_recall_437: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3956 - accuracy: 0.8233 - precision_437: 0.8266 - recall_437: 0.8204 - val_loss: 1.2635 - val_accuracy: 0.5142 - val_precision_437: 0.5142 - val_recall_437: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3522 - accuracy: 0.8407 - precision_437: 0.8318 - recall_437: 0.8452 - val_loss: 2.4943 - val_accuracy: 0.5142 - val_precision_437: 0.5142 - val_recall_437: 1.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3475 - accuracy: 0.8411 - precision_437: 0.8277 - recall_437: 0.8587 - val_loss: 1.6817 - val_accuracy: 0.5058 - val_precision_437: 0.5101 - val_recall_437: 0.9789\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3335 - accuracy: 0.8565 - precision_437: 0.8567 - recall_437: 0.8560 - val_loss: 2.0473 - val_accuracy: 0.6258 - val_precision_437: 0.7456 - val_recall_437: 0.4133\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3469 - accuracy: 0.8348 - precision_437: 0.8334 - recall_437: 0.8406 - val_loss: 2.9150 - val_accuracy: 0.5717 - val_precision_437: 0.5902 - val_recall_437: 0.5462\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3271 - accuracy: 0.8549 - precision_437: 0.8452 - recall_437: 0.8648 - val_loss: 2.6005 - val_accuracy: 0.6458 - val_precision_437: 0.6727 - val_recall_437: 0.6062\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.3189 - accuracy: 0.8613 - precision_437: 0.8417 - recall_437: 0.8830 - val_loss: 1.7605 - val_accuracy: 0.7083 - val_precision_437: 0.7533 - val_recall_437: 0.6434\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3413 - accuracy: 0.8480 - precision_437: 0.8308 - recall_437: 0.8641 - val_loss: 0.8730 - val_accuracy: 0.7700 - val_precision_437: 0.7809 - val_recall_437: 0.7682\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3301 - accuracy: 0.8529 - precision_437: 0.8439 - recall_437: 0.8612 - val_loss: 0.6342 - val_accuracy: 0.7925 - val_precision_437: 0.8206 - val_recall_437: 0.7634\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3256 - accuracy: 0.8558 - precision_437: 0.8468 - recall_437: 0.8702 - val_loss: 0.4923 - val_accuracy: 0.8125 - val_precision_437: 0.8300 - val_recall_437: 0.7990\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3378 - accuracy: 0.8417 - precision_437: 0.8359 - recall_437: 0.8530 - val_loss: 0.4490 - val_accuracy: 0.8100 - val_precision_437: 0.8280 - val_recall_437: 0.7958\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3477 - accuracy: 0.8467 - precision_437: 0.8315 - recall_437: 0.8694 - val_loss: 0.4195 - val_accuracy: 0.8200 - val_precision_437: 0.8336 - val_recall_437: 0.8120\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3307 - accuracy: 0.8534 - precision_437: 0.8403 - recall_437: 0.8668 - val_loss: 0.4078 - val_accuracy: 0.8233 - val_precision_437: 0.8369 - val_recall_437: 0.8152\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3239 - accuracy: 0.8575 - precision_437: 0.8569 - recall_437: 0.8688 - val_loss: 0.3869 - val_accuracy: 0.8275 - val_precision_437: 0.8275 - val_recall_437: 0.8395\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3251 - accuracy: 0.8594 - precision_437: 0.8447 - recall_437: 0.8804 - val_loss: 0.3798 - val_accuracy: 0.8308 - val_precision_437: 0.8224 - val_recall_437: 0.8558\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3349 - accuracy: 0.8506 - precision_437: 0.8517 - recall_437: 0.8546 - val_loss: 0.3734 - val_accuracy: 0.8358 - val_precision_437: 0.8182 - val_recall_437: 0.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=100, activation=elu, AUC=0.896, Accuracy=0.809, f2=0.836, prec=0.784, rec=0.850, total=  22.8s\n",
      "[CV] lr=0.01, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=100, activation=elu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 43ms/step - loss: 0.6288 - accuracy: 0.7030 - precision_438: 0.7062 - recall_438: 0.6936 - val_loss: 15.6387 - val_accuracy: 0.5142 - val_precision_438: 0.5142 - val_recall_438: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.4592 - accuracy: 0.7873 - precision_438: 0.7674 - recall_438: 0.8063 - val_loss: 10.8834 - val_accuracy: 0.5142 - val_precision_438: 0.5142 - val_recall_438: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4160 - accuracy: 0.8144 - precision_438: 0.7961 - recall_438: 0.8482 - val_loss: 6.5641 - val_accuracy: 0.4858 - val_precision_438: 0.0000e+00 - val_recall_438: 0.0000e+00\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.4292 - accuracy: 0.8089 - precision_438: 0.7866 - recall_438: 0.8284 - val_loss: 22.4871 - val_accuracy: 0.4858 - val_precision_438: 0.0000e+00 - val_recall_438: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.3898 - accuracy: 0.8213 - precision_438: 0.7959 - recall_438: 0.8497 - val_loss: 44.5950 - val_accuracy: 0.4858 - val_precision_438: 0.0000e+00 - val_recall_438: 0.0000e+00\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.3925 - accuracy: 0.8141 - precision_438: 0.8060 - recall_438: 0.8274 - val_loss: 27.0439 - val_accuracy: 0.4858 - val_precision_438: 0.0000e+00 - val_recall_438: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3820 - accuracy: 0.8209 - precision_438: 0.7970 - recall_438: 0.8410 - val_loss: 48.7124 - val_accuracy: 0.4858 - val_precision_438: 0.0000e+00 - val_recall_438: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3728 - accuracy: 0.8272 - precision_438: 0.8297 - recall_438: 0.8301 - val_loss: 22.2230 - val_accuracy: 0.4858 - val_precision_438: 0.0000e+00 - val_recall_438: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3581 - accuracy: 0.8420 - precision_438: 0.8319 - recall_438: 0.8530 - val_loss: 24.4907 - val_accuracy: 0.4858 - val_precision_438: 0.0000e+00 - val_recall_438: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3598 - accuracy: 0.8316 - precision_438: 0.8242 - recall_438: 0.8457 - val_loss: 9.2490 - val_accuracy: 0.4842 - val_precision_438: 0.0000e+00 - val_recall_438: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3678 - accuracy: 0.8368 - precision_438: 0.8299 - recall_438: 0.8465 - val_loss: 4.0347 - val_accuracy: 0.4858 - val_precision_438: 0.0000e+00 - val_recall_438: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3574 - accuracy: 0.8403 - precision_438: 0.8256 - recall_438: 0.8603 - val_loss: 1.9637 - val_accuracy: 0.4742 - val_precision_438: 0.3793 - val_recall_438: 0.0357\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3677 - accuracy: 0.8355 - precision_438: 0.8229 - recall_438: 0.8527 - val_loss: 1.3282 - val_accuracy: 0.5383 - val_precision_438: 0.7442 - val_recall_438: 0.1556\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3710 - accuracy: 0.8284 - precision_438: 0.8187 - recall_438: 0.8456 - val_loss: 0.5760 - val_accuracy: 0.7358 - val_precision_438: 0.8866 - val_recall_438: 0.5575\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3509 - accuracy: 0.8449 - precision_438: 0.8457 - recall_438: 0.8532 - val_loss: 0.4208 - val_accuracy: 0.7925 - val_precision_438: 0.8695 - val_recall_438: 0.7018\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3701 - accuracy: 0.8239 - precision_438: 0.8182 - recall_438: 0.8298 - val_loss: 0.4748 - val_accuracy: 0.7708 - val_precision_438: 0.8767 - val_recall_438: 0.6451\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3822 - accuracy: 0.8311 - precision_438: 0.8144 - recall_438: 0.8475 - val_loss: 0.5127 - val_accuracy: 0.7658 - val_precision_438: 0.8944 - val_recall_438: 0.6175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.01, kernel_size=7, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.5, batch_size=100, activation=elu, AUC=0.900, Accuracy=0.774, f2=0.658, prec=0.896, rec=0.617, total=  17.9s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=200, activation=relu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 3s 82ms/step - loss: 0.7097 - accuracy: 0.6433 - precision_439: 0.6418 - recall_439: 0.6435 - val_loss: 8.4462 - val_accuracy: 0.5142 - val_precision_439: 0.5142 - val_recall_439: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.6011 - accuracy: 0.7371 - precision_439: 0.7325 - recall_439: 0.7243 - val_loss: 14.4362 - val_accuracy: 0.5142 - val_precision_439: 0.5142 - val_recall_439: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4968 - accuracy: 0.7583 - precision_439: 0.7628 - recall_439: 0.7553 - val_loss: 15.4859 - val_accuracy: 0.5142 - val_precision_439: 0.5142 - val_recall_439: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4435 - accuracy: 0.7876 - precision_439: 0.7697 - recall_439: 0.8172 - val_loss: 9.8151 - val_accuracy: 0.5142 - val_precision_439: 0.5142 - val_recall_439: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4346 - accuracy: 0.7983 - precision_439: 0.7847 - recall_439: 0.8086 - val_loss: 6.7003 - val_accuracy: 0.5142 - val_precision_439: 0.5142 - val_recall_439: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4462 - accuracy: 0.7959 - precision_439: 0.7877 - recall_439: 0.8159 - val_loss: 4.8670 - val_accuracy: 0.5142 - val_precision_439: 0.5142 - val_recall_439: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4398 - accuracy: 0.7935 - precision_439: 0.7768 - recall_439: 0.8079 - val_loss: 3.5692 - val_accuracy: 0.5142 - val_precision_439: 0.5142 - val_recall_439: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4326 - accuracy: 0.7932 - precision_439: 0.7843 - recall_439: 0.8007 - val_loss: 2.7698 - val_accuracy: 0.5142 - val_precision_439: 0.5142 - val_recall_439: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4246 - accuracy: 0.8010 - precision_439: 0.7993 - recall_439: 0.8077 - val_loss: 1.7037 - val_accuracy: 0.5142 - val_precision_439: 0.5142 - val_recall_439: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4211 - accuracy: 0.8086 - precision_439: 0.7967 - recall_439: 0.8193 - val_loss: 0.5198 - val_accuracy: 0.7400 - val_precision_439: 0.6739 - val_recall_439: 0.9579\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.4122 - accuracy: 0.8158 - precision_439: 0.8021 - recall_439: 0.8327 - val_loss: 1.4456 - val_accuracy: 0.4925 - val_precision_439: 1.0000 - val_recall_439: 0.0130\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4171 - accuracy: 0.8076 - precision_439: 0.7912 - recall_439: 0.8225 - val_loss: 2.0450 - val_accuracy: 0.4858 - val_precision_439: 0.0000e+00 - val_recall_439: 0.0000e+00\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.4160 - accuracy: 0.8126 - precision_439: 0.8034 - recall_439: 0.8282 - val_loss: 2.2714 - val_accuracy: 0.4858 - val_precision_439: 0.0000e+00 - val_recall_439: 0.0000e+00\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4060 - accuracy: 0.8183 - precision_439: 0.8126 - recall_439: 0.8268 - val_loss: 3.4931 - val_accuracy: 0.4858 - val_precision_439: 0.0000e+00 - val_recall_439: 0.0000e+00\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.3956 - accuracy: 0.8242 - precision_439: 0.8207 - recall_439: 0.8338 - val_loss: 2.7986 - val_accuracy: 0.4858 - val_precision_439: 0.0000e+00 - val_recall_439: 0.0000e+00\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.3993 - accuracy: 0.8155 - precision_439: 0.8026 - recall_439: 0.8368 - val_loss: 2.0467 - val_accuracy: 0.4908 - val_precision_439: 1.0000 - val_recall_439: 0.0097\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.3874 - accuracy: 0.8275 - precision_439: 0.8267 - recall_439: 0.8323 - val_loss: 1.5732 - val_accuracy: 0.5117 - val_precision_439: 0.9697 - val_recall_439: 0.0519\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4009 - accuracy: 0.8210 - precision_439: 0.8095 - recall_439: 0.8342 - val_loss: 1.2413 - val_accuracy: 0.5500 - val_precision_439: 0.9529 - val_recall_439: 0.1313\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.4118 - accuracy: 0.8029 - precision_439: 0.7952 - recall_439: 0.8149 - val_loss: 0.9798 - val_accuracy: 0.6008 - val_precision_439: 0.9481 - val_recall_439: 0.2366\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.3973 - accuracy: 0.8171 - precision_439: 0.8201 - recall_439: 0.8201 - val_loss: 0.8173 - val_accuracy: 0.6317 - val_precision_439: 0.9187 - val_recall_439: 0.3112\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.3950 - accuracy: 0.8258 - precision_439: 0.8138 - recall_439: 0.8423 - val_loss: 0.6924 - val_accuracy: 0.6683 - val_precision_439: 0.9261 - val_recall_439: 0.3857\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.3919 - accuracy: 0.8111 - precision_439: 0.7881 - recall_439: 0.8304 - val_loss: 0.6026 - val_accuracy: 0.7142 - val_precision_439: 0.9177 - val_recall_439: 0.4878\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4053 - accuracy: 0.8159 - precision_439: 0.8079 - recall_439: 0.8285 - val_loss: 0.5323 - val_accuracy: 0.7408 - val_precision_439: 0.8943 - val_recall_439: 0.5624\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.4033 - accuracy: 0.8093 - precision_439: 0.8068 - recall_439: 0.8242 - val_loss: 0.4837 - val_accuracy: 0.7583 - val_precision_439: 0.8776 - val_recall_439: 0.6159\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.3967 - accuracy: 0.8209 - precision_439: 0.8158 - recall_439: 0.8270 - val_loss: 0.4587 - val_accuracy: 0.7742 - val_precision_439: 0.8619 - val_recall_439: 0.6677\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.3972 - accuracy: 0.8190 - precision_439: 0.8103 - recall_439: 0.8344 - val_loss: 0.4416 - val_accuracy: 0.7883 - val_precision_439: 0.8524 - val_recall_439: 0.7115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=200, activation=relu, AUC=0.898, Accuracy=0.800, f2=0.749, prec=0.848, rec=0.728, total=  25.4s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=200, activation=relu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 81ms/step - loss: 0.7380 - accuracy: 0.6469 - precision_440: 0.6411 - recall_440: 0.6488 - val_loss: 1.3904 - val_accuracy: 0.5142 - val_precision_440: 0.5142 - val_recall_440: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.5986 - accuracy: 0.7376 - precision_440: 0.7288 - recall_440: 0.7412 - val_loss: 5.9412 - val_accuracy: 0.5142 - val_precision_440: 0.5142 - val_recall_440: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.4768 - accuracy: 0.7644 - precision_440: 0.7513 - recall_440: 0.7821 - val_loss: 3.3879 - val_accuracy: 0.5142 - val_precision_440: 0.5142 - val_recall_440: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4552 - accuracy: 0.7873 - precision_440: 0.7988 - recall_440: 0.7747 - val_loss: 3.2423 - val_accuracy: 0.5142 - val_precision_440: 0.5142 - val_recall_440: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.4353 - accuracy: 0.7971 - precision_440: 0.7982 - recall_440: 0.7963 - val_loss: 2.0329 - val_accuracy: 0.5142 - val_precision_440: 0.5142 - val_recall_440: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4393 - accuracy: 0.7925 - precision_440: 0.7861 - recall_440: 0.7934 - val_loss: 1.5125 - val_accuracy: 0.5142 - val_precision_440: 0.5142 - val_recall_440: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.4227 - accuracy: 0.7957 - precision_440: 0.7986 - recall_440: 0.7894 - val_loss: 1.1674 - val_accuracy: 0.5142 - val_precision_440: 0.5142 - val_recall_440: 1.0000\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4386 - accuracy: 0.7954 - precision_440: 0.7876 - recall_440: 0.7993 - val_loss: 0.9600 - val_accuracy: 0.5158 - val_precision_440: 0.5150 - val_recall_440: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.4159 - accuracy: 0.8193 - precision_440: 0.8162 - recall_440: 0.8212 - val_loss: 1.0138 - val_accuracy: 0.5150 - val_precision_440: 0.5146 - val_recall_440: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4308 - accuracy: 0.7980 - precision_440: 0.7878 - recall_440: 0.7962 - val_loss: 1.2947 - val_accuracy: 0.5142 - val_precision_440: 0.5142 - val_recall_440: 1.0000\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4152 - accuracy: 0.8018 - precision_440: 0.7966 - recall_440: 0.8047 - val_loss: 1.2585 - val_accuracy: 0.5158 - val_precision_440: 0.5150 - val_recall_440: 1.0000\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.4192 - accuracy: 0.8015 - precision_440: 0.8010 - recall_440: 0.8020 - val_loss: 1.3680 - val_accuracy: 0.5158 - val_precision_440: 0.5150 - val_recall_440: 1.0000\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4146 - accuracy: 0.8075 - precision_440: 0.8164 - recall_440: 0.8056 - val_loss: 1.4102 - val_accuracy: 0.5183 - val_precision_440: 0.5163 - val_recall_440: 1.0000\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4220 - accuracy: 0.8042 - precision_440: 0.7982 - recall_440: 0.8053 - val_loss: 1.3599 - val_accuracy: 0.5267 - val_precision_440: 0.5207 - val_recall_440: 1.0000\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4106 - accuracy: 0.8055 - precision_440: 0.8052 - recall_440: 0.8012 - val_loss: 1.2702 - val_accuracy: 0.5375 - val_precision_440: 0.5265 - val_recall_440: 1.0000\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4184 - accuracy: 0.8047 - precision_440: 0.8013 - recall_440: 0.8093 - val_loss: 1.1569 - val_accuracy: 0.5542 - val_precision_440: 0.5356 - val_recall_440: 1.0000\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4109 - accuracy: 0.8157 - precision_440: 0.8175 - recall_440: 0.8115 - val_loss: 1.0365 - val_accuracy: 0.5683 - val_precision_440: 0.5436 - val_recall_440: 1.0000\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4058 - accuracy: 0.8187 - precision_440: 0.8266 - recall_440: 0.8161 - val_loss: 0.9407 - val_accuracy: 0.5883 - val_precision_440: 0.5554 - val_recall_440: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=200, activation=relu, AUC=0.846, Accuracy=0.578, f2=0.852, prec=0.541, rec=0.995, total=  17.6s\n",
      "[CV] lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=200, activation=relu \n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 80ms/step - loss: 0.7370 - accuracy: 0.6483 - precision_441: 0.6502 - recall_441: 0.6558 - val_loss: 33.6592 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.6058 - accuracy: 0.7262 - precision_441: 0.7283 - recall_441: 0.7221 - val_loss: 30.3271 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4810 - accuracy: 0.7584 - precision_441: 0.7386 - recall_441: 0.7741 - val_loss: 30.4195 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4569 - accuracy: 0.7844 - precision_441: 0.7810 - recall_441: 0.8044 - val_loss: 18.8514 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.4318 - accuracy: 0.7947 - precision_441: 0.7822 - recall_441: 0.8103 - val_loss: 5.1476 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.4141 - accuracy: 0.8034 - precision_441: 0.7993 - recall_441: 0.8165 - val_loss: 3.4044 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4166 - accuracy: 0.8139 - precision_441: 0.8096 - recall_441: 0.8165 - val_loss: 9.3237 - val_accuracy: 0.4858 - val_precision_441: 0.0000e+00 - val_recall_441: 0.0000e+00\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.3946 - accuracy: 0.8099 - precision_441: 0.8095 - recall_441: 0.8163 - val_loss: 8.0243 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4209 - accuracy: 0.7969 - precision_441: 0.7900 - recall_441: 0.7959 - val_loss: 8.6941 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.3876 - accuracy: 0.8192 - precision_441: 0.8216 - recall_441: 0.8117 - val_loss: 5.4511 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.3904 - accuracy: 0.8121 - precision_441: 0.7963 - recall_441: 0.8286 - val_loss: 3.9351 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.3947 - accuracy: 0.8205 - precision_441: 0.8117 - recall_441: 0.8364 - val_loss: 2.9732 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.3866 - accuracy: 0.8225 - precision_441: 0.8075 - recall_441: 0.8433 - val_loss: 2.4183 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.3835 - accuracy: 0.8266 - precision_441: 0.8243 - recall_441: 0.8369 - val_loss: 1.5739 - val_accuracy: 0.5142 - val_precision_441: 0.5142 - val_recall_441: 1.0000\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4034 - accuracy: 0.8076 - precision_441: 0.7915 - recall_441: 0.8294 - val_loss: 0.7467 - val_accuracy: 0.5342 - val_precision_441: 0.5247 - val_recall_441: 1.0000\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.3925 - accuracy: 0.8179 - precision_441: 0.8038 - recall_441: 0.8337 - val_loss: 0.5310 - val_accuracy: 0.7567 - val_precision_441: 0.8378 - val_recall_441: 0.6532\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.4057 - accuracy: 0.8098 - precision_441: 0.7963 - recall_441: 0.8270 - val_loss: 0.8975 - val_accuracy: 0.5700 - val_precision_441: 0.8435 - val_recall_441: 0.2010\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.3944 - accuracy: 0.8110 - precision_441: 0.8021 - recall_441: 0.8227 - val_loss: 1.5113 - val_accuracy: 0.5425 - val_precision_441: 0.8864 - val_recall_441: 0.1264\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.3989 - accuracy: 0.8113 - precision_441: 0.7928 - recall_441: 0.8333 - val_loss: 1.5178 - val_accuracy: 0.5342 - val_precision_441: 0.9028 - val_recall_441: 0.1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=11, kernel_initializer=he_normal, epochs=500, drop_rate=0.5, batch_size=200, activation=relu, AUC=0.882, Accuracy=0.557, f2=0.143, prec=0.922, rec=0.118, total=  18.4s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 190ms/step - loss: 0.7768 - accuracy: 0.6358 - precision_442: 0.6325 - recall_442: 0.6374 - val_loss: 2.7363 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.5917 - accuracy: 0.7510 - precision_442: 0.7471 - recall_442: 0.7584 - val_loss: 7.6635 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.5396 - accuracy: 0.7535 - precision_442: 0.7694 - recall_442: 0.7305 - val_loss: 7.3144 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4691 - accuracy: 0.7809 - precision_442: 0.7885 - recall_442: 0.7746 - val_loss: 5.1945 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.4405 - accuracy: 0.7960 - precision_442: 0.8047 - recall_442: 0.7771 - val_loss: 3.8914 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.4120 - accuracy: 0.8087 - precision_442: 0.8241 - recall_442: 0.7869 - val_loss: 3.0855 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4287 - accuracy: 0.8020 - precision_442: 0.7973 - recall_442: 0.7983 - val_loss: 2.4860 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4333 - accuracy: 0.8036 - precision_442: 0.8009 - recall_442: 0.8018 - val_loss: 1.9884 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.4038 - accuracy: 0.8125 - precision_442: 0.8152 - recall_442: 0.8031 - val_loss: 1.6024 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.4170 - accuracy: 0.8004 - precision_442: 0.7929 - recall_442: 0.8077 - val_loss: 1.7975 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.4155 - accuracy: 0.8142 - precision_442: 0.8122 - recall_442: 0.8086 - val_loss: 2.9601 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4222 - accuracy: 0.8020 - precision_442: 0.8017 - recall_442: 0.7969 - val_loss: 4.2212 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.4052 - accuracy: 0.8124 - precision_442: 0.8045 - recall_442: 0.8213 - val_loss: 5.1809 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.4243 - accuracy: 0.8070 - precision_442: 0.8038 - recall_442: 0.8051 - val_loss: 5.7955 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.4157 - accuracy: 0.8043 - precision_442: 0.7993 - recall_442: 0.8055 - val_loss: 6.2292 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.4260 - accuracy: 0.7979 - precision_442: 0.7961 - recall_442: 0.7907 - val_loss: 6.5602 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4162 - accuracy: 0.8091 - precision_442: 0.8044 - recall_442: 0.8126 - val_loss: 6.8412 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.4321 - accuracy: 0.8014 - precision_442: 0.7962 - recall_442: 0.8017 - val_loss: 7.1137 - val_accuracy: 0.5142 - val_precision_442: 0.5142 - val_recall_442: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=gelu, AUC=0.831, Accuracy=0.497, f2=0.832, prec=0.497, rec=1.000, total=  21.1s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 192ms/step - loss: 0.7665 - accuracy: 0.6450 - precision_443: 0.6440 - recall_443: 0.6441 - val_loss: 6.7288 - val_accuracy: 0.5142 - val_precision_443: 0.5142 - val_recall_443: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.5625 - accuracy: 0.7538 - precision_443: 0.7471 - recall_443: 0.7630 - val_loss: 11.5793 - val_accuracy: 0.5142 - val_precision_443: 0.5142 - val_recall_443: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.4581 - accuracy: 0.7959 - precision_443: 0.7812 - recall_443: 0.8056 - val_loss: 5.8892 - val_accuracy: 0.5142 - val_precision_443: 0.5142 - val_recall_443: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4205 - accuracy: 0.8008 - precision_443: 0.8110 - recall_443: 0.7898 - val_loss: 1.0381 - val_accuracy: 0.5142 - val_precision_443: 0.5142 - val_recall_443: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3901 - accuracy: 0.8193 - precision_443: 0.8205 - recall_443: 0.8254 - val_loss: 3.2021 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3717 - accuracy: 0.8315 - precision_443: 0.8251 - recall_443: 0.8403 - val_loss: 7.0078 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3601 - accuracy: 0.8435 - precision_443: 0.8282 - recall_443: 0.8566 - val_loss: 7.7219 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3577 - accuracy: 0.8399 - precision_443: 0.8355 - recall_443: 0.8512 - val_loss: 7.4715 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.3667 - accuracy: 0.8261 - precision_443: 0.8046 - recall_443: 0.8538 - val_loss: 7.9945 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3577 - accuracy: 0.8322 - precision_443: 0.8257 - recall_443: 0.8430 - val_loss: 8.2096 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3554 - accuracy: 0.8307 - precision_443: 0.8089 - recall_443: 0.8560 - val_loss: 8.5086 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3654 - accuracy: 0.8298 - precision_443: 0.8242 - recall_443: 0.8376 - val_loss: 8.8530 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3538 - accuracy: 0.8372 - precision_443: 0.8198 - recall_443: 0.8600 - val_loss: 9.1215 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3504 - accuracy: 0.8408 - precision_443: 0.8329 - recall_443: 0.8520 - val_loss: 9.3700 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3628 - accuracy: 0.8335 - precision_443: 0.8140 - recall_443: 0.8563 - val_loss: 9.5891 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3697 - accuracy: 0.8287 - precision_443: 0.8120 - recall_443: 0.8500 - val_loss: 9.7918 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3562 - accuracy: 0.8426 - precision_443: 0.8359 - recall_443: 0.8529 - val_loss: 9.9935 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.3611 - accuracy: 0.8295 - precision_443: 0.8248 - recall_443: 0.8370 - val_loss: 10.1717 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.3643 - accuracy: 0.8322 - precision_443: 0.8137 - recall_443: 0.8562 - val_loss: 10.2991 - val_accuracy: 0.4858 - val_precision_443: 0.0000e+00 - val_recall_443: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=gelu, AUC=0.848, Accuracy=0.504, f2=0.000, prec=0.000, rec=0.000, total=  22.0s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=gelu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 193ms/step - loss: 0.7767 - accuracy: 0.6364 - precision_444: 0.6245 - recall_444: 0.6454 - val_loss: 2.2866 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.5622 - accuracy: 0.7443 - precision_444: 0.7452 - recall_444: 0.7493 - val_loss: 5.9801 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.4940 - accuracy: 0.7713 - precision_444: 0.7710 - recall_444: 0.7735 - val_loss: 8.0807 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4535 - accuracy: 0.7909 - precision_444: 0.7820 - recall_444: 0.7904 - val_loss: 5.9627 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4374 - accuracy: 0.8046 - precision_444: 0.7918 - recall_444: 0.8213 - val_loss: 4.3302 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4337 - accuracy: 0.7922 - precision_444: 0.7987 - recall_444: 0.7853 - val_loss: 3.3507 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.4250 - accuracy: 0.8108 - precision_444: 0.8082 - recall_444: 0.8117 - val_loss: 2.6183 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.4372 - accuracy: 0.8004 - precision_444: 0.7822 - recall_444: 0.8155 - val_loss: 2.0483 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.4387 - accuracy: 0.7868 - precision_444: 0.7921 - recall_444: 0.7863 - val_loss: 1.6012 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4269 - accuracy: 0.7974 - precision_444: 0.7920 - recall_444: 0.7982 - val_loss: 1.2865 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4314 - accuracy: 0.7957 - precision_444: 0.7963 - recall_444: 0.8005 - val_loss: 1.1106 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.4359 - accuracy: 0.8021 - precision_444: 0.7885 - recall_444: 0.8082 - val_loss: 1.0845 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4383 - accuracy: 0.7896 - precision_444: 0.7932 - recall_444: 0.7865 - val_loss: 1.2154 - val_accuracy: 0.5142 - val_precision_444: 0.5142 - val_recall_444: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=gelu, AUC=0.836, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  16.4s\n",
      "[CV] lr=0.001, kernel_size=13, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.8331 - accuracy: 0.6397 - precision_445: 0.6318 - recall_445: 0.6372 - val_loss: 10.7098 - val_accuracy: 0.5142 - val_precision_445: 0.5142 - val_recall_445: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5298 - accuracy: 0.7460 - precision_445: 0.7341 - recall_445: 0.7586 - val_loss: 4.4676 - val_accuracy: 0.5142 - val_precision_445: 0.5142 - val_recall_445: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4627 - accuracy: 0.7854 - precision_445: 0.7739 - recall_445: 0.7970 - val_loss: 3.4273 - val_accuracy: 0.5142 - val_precision_445: 0.5142 - val_recall_445: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4491 - accuracy: 0.7955 - precision_445: 0.7753 - recall_445: 0.8270 - val_loss: 1.9501 - val_accuracy: 0.5142 - val_precision_445: 0.5142 - val_recall_445: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4266 - accuracy: 0.8019 - precision_445: 0.8013 - recall_445: 0.8124 - val_loss: 1.4471 - val_accuracy: 0.5142 - val_precision_445: 0.5142 - val_recall_445: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4216 - accuracy: 0.8054 - precision_445: 0.7999 - recall_445: 0.8133 - val_loss: 7.1940 - val_accuracy: 0.4858 - val_precision_445: 0.0000e+00 - val_recall_445: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4243 - accuracy: 0.8025 - precision_445: 0.7995 - recall_445: 0.8075 - val_loss: 2.5360 - val_accuracy: 0.5142 - val_precision_445: 0.5142 - val_recall_445: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4338 - accuracy: 0.8045 - precision_445: 0.7986 - recall_445: 0.8197 - val_loss: 1.9296 - val_accuracy: 0.5142 - val_precision_445: 0.5142 - val_recall_445: 1.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4259 - accuracy: 0.8041 - precision_445: 0.8001 - recall_445: 0.8127 - val_loss: 1.2924 - val_accuracy: 0.5142 - val_precision_445: 0.5142 - val_recall_445: 1.0000\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4094 - accuracy: 0.8114 - precision_445: 0.8141 - recall_445: 0.8161 - val_loss: 0.4637 - val_accuracy: 0.7658 - val_precision_445: 0.8636 - val_recall_445: 0.6467\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4019 - accuracy: 0.8194 - precision_445: 0.8020 - recall_445: 0.8393 - val_loss: 0.6446 - val_accuracy: 0.7075 - val_precision_445: 0.9080 - val_recall_445: 0.4797\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4081 - accuracy: 0.8108 - precision_445: 0.7925 - recall_445: 0.8223 - val_loss: 9.4922 - val_accuracy: 0.4900 - val_precision_445: 1.0000 - val_recall_445: 0.0081\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4051 - accuracy: 0.8185 - precision_445: 0.7990 - recall_445: 0.8446 - val_loss: 14.2507 - val_accuracy: 0.4917 - val_precision_445: 1.0000 - val_recall_445: 0.0113\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.4119 - accuracy: 0.8151 - precision_445: 0.8155 - recall_445: 0.8282 - val_loss: 8.3147 - val_accuracy: 0.4883 - val_precision_445: 1.0000 - val_recall_445: 0.0049\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3751 - accuracy: 0.8375 - precision_445: 0.8166 - recall_445: 0.8586 - val_loss: 4.1172 - val_accuracy: 0.4900 - val_precision_445: 1.0000 - val_recall_445: 0.0081\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3866 - accuracy: 0.8298 - precision_445: 0.8228 - recall_445: 0.8475 - val_loss: 2.4096 - val_accuracy: 0.5408 - val_precision_445: 1.0000 - val_recall_445: 0.1070\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3931 - accuracy: 0.8103 - precision_445: 0.7897 - recall_445: 0.8320 - val_loss: 1.4331 - val_accuracy: 0.6008 - val_precision_445: 0.9259 - val_recall_445: 0.2431\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3741 - accuracy: 0.8389 - precision_445: 0.8251 - recall_445: 0.8580 - val_loss: 0.9471 - val_accuracy: 0.6633 - val_precision_445: 0.9209 - val_recall_445: 0.3776\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3973 - accuracy: 0.8168 - precision_445: 0.8010 - recall_445: 0.8330 - val_loss: 0.6510 - val_accuracy: 0.7267 - val_precision_445: 0.9070 - val_recall_445: 0.5219\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3948 - accuracy: 0.8157 - precision_445: 0.8084 - recall_445: 0.8302 - val_loss: 0.5115 - val_accuracy: 0.7583 - val_precision_445: 0.8724 - val_recall_445: 0.6207\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3996 - accuracy: 0.8170 - precision_445: 0.8155 - recall_445: 0.8267 - val_loss: 0.4431 - val_accuracy: 0.7925 - val_precision_445: 0.8636 - val_recall_445: 0.7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=13, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu, AUC=0.903, Accuracy=0.804, f2=0.751, prec=0.855, rec=0.728, total=  23.2s\n",
      "[CV] lr=0.001, kernel_size=13, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.8061 - accuracy: 0.6363 - precision_446: 0.6350 - recall_446: 0.6300 - val_loss: 56.9321 - val_accuracy: 0.5142 - val_precision_446: 0.5142 - val_recall_446: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5433 - accuracy: 0.7435 - precision_446: 0.7412 - recall_446: 0.7496 - val_loss: 17.4438 - val_accuracy: 0.5142 - val_precision_446: 0.5142 - val_recall_446: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4590 - accuracy: 0.7798 - precision_446: 0.7588 - recall_446: 0.8041 - val_loss: 7.1798 - val_accuracy: 0.5142 - val_precision_446: 0.5142 - val_recall_446: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4322 - accuracy: 0.8043 - precision_446: 0.7943 - recall_446: 0.8164 - val_loss: 2.4488 - val_accuracy: 0.5142 - val_precision_446: 0.5142 - val_recall_446: 1.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4085 - accuracy: 0.8216 - precision_446: 0.8076 - recall_446: 0.8378 - val_loss: 4.3526 - val_accuracy: 0.5142 - val_precision_446: 0.5142 - val_recall_446: 1.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4097 - accuracy: 0.8124 - precision_446: 0.7907 - recall_446: 0.8382 - val_loss: 1.9154 - val_accuracy: 0.5142 - val_precision_446: 0.5142 - val_recall_446: 1.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4034 - accuracy: 0.8235 - precision_446: 0.8072 - recall_446: 0.8535 - val_loss: 6.6160 - val_accuracy: 0.5142 - val_precision_446: 0.5142 - val_recall_446: 1.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4117 - accuracy: 0.8066 - precision_446: 0.7847 - recall_446: 0.8243 - val_loss: 1.1936 - val_accuracy: 0.5142 - val_precision_446: 0.5142 - val_recall_446: 1.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3792 - accuracy: 0.8312 - precision_446: 0.8221 - recall_446: 0.8528 - val_loss: 2.3556 - val_accuracy: 0.5142 - val_precision_446: 0.5142 - val_recall_446: 1.0000\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3820 - accuracy: 0.8249 - precision_446: 0.8092 - recall_446: 0.8417 - val_loss: 0.8686 - val_accuracy: 0.5217 - val_precision_446: 1.0000 - val_recall_446: 0.0697\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3697 - accuracy: 0.8336 - precision_446: 0.8161 - recall_446: 0.8589 - val_loss: 180.5887 - val_accuracy: 0.4858 - val_precision_446: 0.0000e+00 - val_recall_446: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3948 - accuracy: 0.8190 - precision_446: 0.8061 - recall_446: 0.8333 - val_loss: 0.5835 - val_accuracy: 0.7042 - val_precision_446: 0.7519 - val_recall_446: 0.6337\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.3768 - accuracy: 0.8250 - precision_446: 0.8000 - recall_446: 0.8484 - val_loss: 231.6791 - val_accuracy: 0.4858 - val_precision_446: 0.0000e+00 - val_recall_446: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3877 - accuracy: 0.8238 - precision_446: 0.8109 - recall_446: 0.8370 - val_loss: 4.4780 - val_accuracy: 0.5142 - val_precision_446: 0.5142 - val_recall_446: 1.0000\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3602 - accuracy: 0.8353 - precision_446: 0.8120 - recall_446: 0.8688 - val_loss: 0.4630 - val_accuracy: 0.7892 - val_precision_446: 0.8583 - val_recall_446: 0.7066\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3662 - accuracy: 0.8288 - precision_446: 0.8292 - recall_446: 0.8407 - val_loss: 52.9656 - val_accuracy: 0.4858 - val_precision_446: 0.0000e+00 - val_recall_446: 0.0000e+00\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3485 - accuracy: 0.8458 - precision_446: 0.8242 - recall_446: 0.8648 - val_loss: 9.3438 - val_accuracy: 0.4858 - val_precision_446: 0.0000e+00 - val_recall_446: 0.0000e+00\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3522 - accuracy: 0.8400 - precision_446: 0.8293 - recall_446: 0.8584 - val_loss: 14.4792 - val_accuracy: 0.4858 - val_precision_446: 0.0000e+00 - val_recall_446: 0.0000e+00\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3378 - accuracy: 0.8500 - precision_446: 0.8306 - recall_446: 0.8765 - val_loss: 39.3703 - val_accuracy: 0.4858 - val_precision_446: 0.0000e+00 - val_recall_446: 0.0000e+00\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3344 - accuracy: 0.8466 - precision_446: 0.8342 - recall_446: 0.8595 - val_loss: 26.7172 - val_accuracy: 0.4858 - val_precision_446: 0.0000e+00 - val_recall_446: 0.0000e+00\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3584 - accuracy: 0.8263 - precision_446: 0.8175 - recall_446: 0.8372 - val_loss: 16.4242 - val_accuracy: 0.4858 - val_precision_446: 0.0000e+00 - val_recall_446: 0.0000e+00\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3467 - accuracy: 0.8461 - precision_446: 0.8352 - recall_446: 0.8605 - val_loss: 6.6801 - val_accuracy: 0.4867 - val_precision_446: 1.0000 - val_recall_446: 0.0016\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3396 - accuracy: 0.8506 - precision_446: 0.8465 - recall_446: 0.8580 - val_loss: 3.2368 - val_accuracy: 0.4900 - val_precision_446: 1.0000 - val_recall_446: 0.0081\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3232 - accuracy: 0.8658 - precision_446: 0.8470 - recall_446: 0.8903 - val_loss: 2.0935 - val_accuracy: 0.5125 - val_precision_446: 1.0000 - val_recall_446: 0.0519\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3435 - accuracy: 0.8414 - precision_446: 0.8289 - recall_446: 0.8609 - val_loss: 1.3800 - val_accuracy: 0.5700 - val_precision_446: 0.9720 - val_recall_446: 0.1686\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3304 - accuracy: 0.8543 - precision_446: 0.8529 - recall_446: 0.8639 - val_loss: 0.9343 - val_accuracy: 0.6508 - val_precision_446: 0.9500 - val_recall_446: 0.3387\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3400 - accuracy: 0.8450 - precision_446: 0.8490 - recall_446: 0.8475 - val_loss: 0.6576 - val_accuracy: 0.7117 - val_precision_446: 0.9221 - val_recall_446: 0.4797\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3287 - accuracy: 0.8462 - precision_446: 0.8330 - recall_446: 0.8633 - val_loss: 0.5536 - val_accuracy: 0.7425 - val_precision_446: 0.9162 - val_recall_446: 0.5494\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3457 - accuracy: 0.8406 - precision_446: 0.8294 - recall_446: 0.8545 - val_loss: 0.4453 - val_accuracy: 0.7842 - val_precision_446: 0.8943 - val_recall_446: 0.6580\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3469 - accuracy: 0.8483 - precision_446: 0.8317 - recall_446: 0.8649 - val_loss: 0.3993 - val_accuracy: 0.8067 - val_precision_446: 0.8598 - val_recall_446: 0.7455\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3404 - accuracy: 0.8440 - precision_446: 0.8352 - recall_446: 0.8599 - val_loss: 0.3779 - val_accuracy: 0.8267 - val_precision_446: 0.8358 - val_recall_446: 0.8250\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3482 - accuracy: 0.8466 - precision_446: 0.8320 - recall_446: 0.8648 - val_loss: 0.3760 - val_accuracy: 0.8275 - val_precision_446: 0.8275 - val_recall_446: 0.8395\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3527 - accuracy: 0.8488 - precision_446: 0.8360 - recall_446: 0.8614 - val_loss: 0.3796 - val_accuracy: 0.8325 - val_precision_446: 0.8059 - val_recall_446: 0.8882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=13, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu, AUC=0.893, Accuracy=0.801, f2=0.834, prec=0.771, rec=0.851, total=  34.7s\n",
      "[CV] lr=0.001, kernel_size=13, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu \n",
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 44ms/step - loss: 0.8239 - accuracy: 0.6194 - precision_447: 0.6399 - recall_447: 0.6161 - val_loss: 12.8282 - val_accuracy: 0.5142 - val_precision_447: 0.5142 - val_recall_447: 1.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5579 - accuracy: 0.7460 - precision_447: 0.7371 - recall_447: 0.7581 - val_loss: 5.4656 - val_accuracy: 0.5142 - val_precision_447: 0.5142 - val_recall_447: 1.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4808 - accuracy: 0.7781 - precision_447: 0.7640 - recall_447: 0.8064 - val_loss: 2.3059 - val_accuracy: 0.5142 - val_precision_447: 0.5142 - val_recall_447: 1.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4541 - accuracy: 0.7870 - precision_447: 0.7729 - recall_447: 0.8191 - val_loss: 3.0240 - val_accuracy: 0.4858 - val_precision_447: 0.0000e+00 - val_recall_447: 0.0000e+00\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4360 - accuracy: 0.7922 - precision_447: 0.7863 - recall_447: 0.8019 - val_loss: 0.5773 - val_accuracy: 0.6617 - val_precision_447: 0.9203 - val_recall_447: 0.3744\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4132 - accuracy: 0.8024 - precision_447: 0.7871 - recall_447: 0.8269 - val_loss: 24.9466 - val_accuracy: 0.4858 - val_precision_447: 0.0000e+00 - val_recall_447: 0.0000e+00\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4292 - accuracy: 0.7983 - precision_447: 0.7992 - recall_447: 0.7986 - val_loss: 14.3719 - val_accuracy: 0.4858 - val_precision_447: 0.0000e+00 - val_recall_447: 0.0000e+00\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4343 - accuracy: 0.7962 - precision_447: 0.7767 - recall_447: 0.8244 - val_loss: 38.1956 - val_accuracy: 0.4858 - val_precision_447: 0.0000e+00 - val_recall_447: 0.0000e+00\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4089 - accuracy: 0.8047 - precision_447: 0.7970 - recall_447: 0.8222 - val_loss: 59.5325 - val_accuracy: 0.4858 - val_precision_447: 0.0000e+00 - val_recall_447: 0.0000e+00\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4163 - accuracy: 0.8101 - precision_447: 0.8047 - recall_447: 0.8270 - val_loss: 43.8647 - val_accuracy: 0.4858 - val_precision_447: 0.0000e+00 - val_recall_447: 0.0000e+00\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4220 - accuracy: 0.7958 - precision_447: 0.7781 - recall_447: 0.8171 - val_loss: 42.4706 - val_accuracy: 0.4858 - val_precision_447: 0.0000e+00 - val_recall_447: 0.0000e+00\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4015 - accuracy: 0.8211 - precision_447: 0.8210 - recall_447: 0.8271 - val_loss: 31.6034 - val_accuracy: 0.4858 - val_precision_447: 0.0000e+00 - val_recall_447: 0.0000e+00\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4162 - accuracy: 0.8001 - precision_447: 0.7748 - recall_447: 0.8260 - val_loss: 17.5479 - val_accuracy: 0.4858 - val_precision_447: 0.0000e+00 - val_recall_447: 0.0000e+00\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4081 - accuracy: 0.8088 - precision_447: 0.7929 - recall_447: 0.8335 - val_loss: 8.8955 - val_accuracy: 0.4858 - val_precision_447: 0.0000e+00 - val_recall_447: 0.0000e+00\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3834 - accuracy: 0.8189 - precision_447: 0.7993 - recall_447: 0.8425 - val_loss: 5.0528 - val_accuracy: 0.4858 - val_precision_447: 0.0000e+00 - val_recall_447: 0.0000e+00\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4256 - accuracy: 0.7998 - precision_447: 0.7860 - recall_447: 0.8218 - val_loss: 2.8335 - val_accuracy: 0.4942 - val_precision_447: 1.0000 - val_recall_447: 0.0162\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4113 - accuracy: 0.8180 - precision_447: 0.8097 - recall_447: 0.8387 - val_loss: 1.8534 - val_accuracy: 0.5392 - val_precision_447: 0.9848 - val_recall_447: 0.1053\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.4171 - accuracy: 0.8111 - precision_447: 0.8016 - recall_447: 0.8261 - val_loss: 1.2358 - val_accuracy: 0.5917 - val_precision_447: 0.9568 - val_recall_447: 0.2156\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3993 - accuracy: 0.8203 - precision_447: 0.8012 - recall_447: 0.8393 - val_loss: 0.8579 - val_accuracy: 0.6508 - val_precision_447: 0.9195 - val_recall_447: 0.3517\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3998 - accuracy: 0.8225 - precision_447: 0.8140 - recall_447: 0.8337 - val_loss: 0.6179 - val_accuracy: 0.7300 - val_precision_447: 0.9174 - val_recall_447: 0.5219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=13, kernel_initializer=glorot_normal, epochs=500, drop_rate=0.5, batch_size=100, activation=relu, AUC=0.903, Accuracy=0.728, f2=0.547, prec=0.914, rec=0.497, total=  21.7s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 25ms/step - loss: 0.6388 - accuracy: 0.7088 - precision_448: 0.7085 - recall_448: 0.7069 - val_loss: 5.8598 - val_accuracy: 0.5142 - val_precision_448: 0.5142 - val_recall_448: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4248 - accuracy: 0.8023 - precision_448: 0.8004 - recall_448: 0.8079 - val_loss: 5.8498 - val_accuracy: 0.4858 - val_precision_448: 0.0000e+00 - val_recall_448: 0.0000e+00\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3973 - accuracy: 0.8137 - precision_448: 0.8105 - recall_448: 0.8183 - val_loss: 0.6668 - val_accuracy: 0.6433 - val_precision_448: 0.5908 - val_recall_448: 0.9968\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3877 - accuracy: 0.8119 - precision_448: 0.7961 - recall_448: 0.8410 - val_loss: 41.7005 - val_accuracy: 0.4858 - val_precision_448: 0.0000e+00 - val_recall_448: 0.0000e+00\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3437 - accuracy: 0.8455 - precision_448: 0.8410 - recall_448: 0.8440 - val_loss: 0.8833 - val_accuracy: 0.7283 - val_precision_448: 0.6590 - val_recall_448: 0.9773\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2908 - accuracy: 0.8767 - precision_448: 0.8775 - recall_448: 0.8785 - val_loss: 1.2251 - val_accuracy: 0.5800 - val_precision_448: 0.9380 - val_recall_448: 0.1961\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2506 - accuracy: 0.8984 - precision_448: 0.8899 - recall_448: 0.9048 - val_loss: 4.5161 - val_accuracy: 0.4858 - val_precision_448: 0.0000e+00 - val_recall_448: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2172 - accuracy: 0.9156 - precision_448: 0.9210 - recall_448: 0.9088 - val_loss: 4.7918 - val_accuracy: 0.4858 - val_precision_448: 0.0000e+00 - val_recall_448: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2028 - accuracy: 0.9227 - precision_448: 0.9100 - recall_448: 0.9313 - val_loss: 1.9621 - val_accuracy: 0.5017 - val_precision_448: 1.0000 - val_recall_448: 0.0308\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1996 - accuracy: 0.9215 - precision_448: 0.9179 - recall_448: 0.9225 - val_loss: 0.8386 - val_accuracy: 0.6467 - val_precision_448: 0.9289 - val_recall_448: 0.3387\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.2082 - accuracy: 0.9238 - precision_448: 0.9111 - recall_448: 0.9381 - val_loss: 0.9833 - val_accuracy: 0.6233 - val_precision_448: 0.9412 - val_recall_448: 0.2853\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1918 - accuracy: 0.9240 - precision_448: 0.9323 - recall_448: 0.9145 - val_loss: 0.5457 - val_accuracy: 0.7575 - val_precision_448: 0.8808 - val_recall_448: 0.6110\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1951 - accuracy: 0.9264 - precision_448: 0.9172 - recall_448: 0.9344 - val_loss: 0.4298 - val_accuracy: 0.8142 - val_precision_448: 0.8569 - val_recall_448: 0.7666\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1999 - accuracy: 0.9238 - precision_448: 0.9161 - recall_448: 0.9322 - val_loss: 0.4353 - val_accuracy: 0.8108 - val_precision_448: 0.8571 - val_recall_448: 0.7585\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1919 - accuracy: 0.9338 - precision_448: 0.9357 - recall_448: 0.9326 - val_loss: 0.4197 - val_accuracy: 0.8217 - val_precision_448: 0.8444 - val_recall_448: 0.8006\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2095 - accuracy: 0.9210 - precision_448: 0.9184 - recall_448: 0.9260 - val_loss: 0.4206 - val_accuracy: 0.8192 - val_precision_448: 0.8436 - val_recall_448: 0.7958\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1922 - accuracy: 0.9295 - precision_448: 0.9096 - recall_448: 0.9484 - val_loss: 0.4257 - val_accuracy: 0.8167 - val_precision_448: 0.8476 - val_recall_448: 0.7844\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1916 - accuracy: 0.9304 - precision_448: 0.9248 - recall_448: 0.9371 - val_loss: 0.4182 - val_accuracy: 0.8217 - val_precision_448: 0.8375 - val_recall_448: 0.8104\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1902 - accuracy: 0.9289 - precision_448: 0.9340 - recall_448: 0.9244 - val_loss: 0.4214 - val_accuracy: 0.8208 - val_precision_448: 0.8442 - val_recall_448: 0.7990\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1887 - accuracy: 0.9357 - precision_448: 0.9262 - recall_448: 0.9419 - val_loss: 0.4200 - val_accuracy: 0.8217 - val_precision_448: 0.8409 - val_recall_448: 0.8055\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1912 - accuracy: 0.9259 - precision_448: 0.9184 - recall_448: 0.9307 - val_loss: 0.4171 - val_accuracy: 0.8208 - val_precision_448: 0.8274 - val_recall_448: 0.8233\n",
      "Epoch 22/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1837 - accuracy: 0.9360 - precision_448: 0.9268 - recall_448: 0.9424 - val_loss: 0.4181 - val_accuracy: 0.8192 - val_precision_448: 0.8311 - val_recall_448: 0.8136\n",
      "Epoch 23/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1958 - accuracy: 0.9284 - precision_448: 0.9162 - recall_448: 0.9409 - val_loss: 0.4272 - val_accuracy: 0.8167 - val_precision_448: 0.8476 - val_recall_448: 0.7844\n",
      "Epoch 24/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1902 - accuracy: 0.9315 - precision_448: 0.9420 - recall_448: 0.9221 - val_loss: 0.4194 - val_accuracy: 0.8208 - val_precision_448: 0.8384 - val_recall_448: 0.8071\n",
      "Epoch 25/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2003 - accuracy: 0.9235 - precision_448: 0.9109 - recall_448: 0.9386 - val_loss: 0.4195 - val_accuracy: 0.8217 - val_precision_448: 0.8364 - val_recall_448: 0.8120\n",
      "Epoch 26/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1854 - accuracy: 0.9289 - precision_448: 0.9195 - recall_448: 0.9371 - val_loss: 0.4204 - val_accuracy: 0.8208 - val_precision_448: 0.8395 - val_recall_448: 0.8055\n",
      "Epoch 27/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1999 - accuracy: 0.9313 - precision_448: 0.9371 - recall_448: 0.9262 - val_loss: 0.4175 - val_accuracy: 0.8242 - val_precision_448: 0.8264 - val_recall_448: 0.8331\n",
      "Epoch 28/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1808 - accuracy: 0.9384 - precision_448: 0.9350 - recall_448: 0.9418 - val_loss: 0.4198 - val_accuracy: 0.8208 - val_precision_448: 0.8384 - val_recall_448: 0.8071\n",
      "Epoch 29/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1884 - accuracy: 0.9282 - precision_448: 0.9236 - recall_448: 0.9318 - val_loss: 0.4204 - val_accuracy: 0.8200 - val_precision_448: 0.8381 - val_recall_448: 0.8055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu, AUC=0.903, Accuracy=0.818, f2=0.800, prec=0.832, rec=0.792, total=  38.1s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 26ms/step - loss: 0.6615 - accuracy: 0.7206 - precision_449: 0.7065 - recall_449: 0.7219 - val_loss: 6.3613 - val_accuracy: 0.5142 - val_precision_449: 0.5142 - val_recall_449: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4231 - accuracy: 0.8134 - precision_449: 0.7804 - recall_449: 0.8464 - val_loss: 5.2496 - val_accuracy: 0.5142 - val_precision_449: 0.5142 - val_recall_449: 1.0000\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3646 - accuracy: 0.8269 - precision_449: 0.8111 - recall_449: 0.8600 - val_loss: 7.2458 - val_accuracy: 0.4858 - val_precision_449: 0.0000e+00 - val_recall_449: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3305 - accuracy: 0.8519 - precision_449: 0.8415 - recall_449: 0.8568 - val_loss: 25.9380 - val_accuracy: 0.4858 - val_precision_449: 0.0000e+00 - val_recall_449: 0.0000e+00\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3005 - accuracy: 0.8769 - precision_449: 0.8661 - recall_449: 0.8871 - val_loss: 20.4272 - val_accuracy: 0.4858 - val_precision_449: 0.0000e+00 - val_recall_449: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2650 - accuracy: 0.8961 - precision_449: 0.8957 - recall_449: 0.8915 - val_loss: 35.1606 - val_accuracy: 0.4858 - val_precision_449: 0.0000e+00 - val_recall_449: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2318 - accuracy: 0.9044 - precision_449: 0.8847 - recall_449: 0.9317 - val_loss: 13.9836 - val_accuracy: 0.4858 - val_precision_449: 0.0000e+00 - val_recall_449: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2416 - accuracy: 0.9021 - precision_449: 0.8913 - recall_449: 0.9116 - val_loss: 8.3107 - val_accuracy: 0.4858 - val_precision_449: 0.0000e+00 - val_recall_449: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2244 - accuracy: 0.9108 - precision_449: 0.9058 - recall_449: 0.9146 - val_loss: 2.7224 - val_accuracy: 0.4942 - val_precision_449: 1.0000 - val_recall_449: 0.0162\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2232 - accuracy: 0.9119 - precision_449: 0.9075 - recall_449: 0.9137 - val_loss: 1.4013 - val_accuracy: 0.5667 - val_precision_449: 0.9802 - val_recall_449: 0.1605\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2120 - accuracy: 0.9127 - precision_449: 0.9030 - recall_449: 0.9230 - val_loss: 0.6332 - val_accuracy: 0.7408 - val_precision_449: 0.9135 - val_recall_449: 0.5478\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2089 - accuracy: 0.9200 - precision_449: 0.9026 - recall_449: 0.9345 - val_loss: 0.6374 - val_accuracy: 0.7417 - val_precision_449: 0.9160 - val_recall_449: 0.5478\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2104 - accuracy: 0.9120 - precision_449: 0.9111 - recall_449: 0.9137 - val_loss: 0.6430 - val_accuracy: 0.7408 - val_precision_449: 0.9135 - val_recall_449: 0.5478\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2070 - accuracy: 0.9100 - precision_449: 0.9092 - recall_449: 0.9137 - val_loss: 0.4873 - val_accuracy: 0.7925 - val_precision_449: 0.8983 - val_recall_449: 0.6726\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2082 - accuracy: 0.9164 - precision_449: 0.9038 - recall_449: 0.9289 - val_loss: 0.4410 - val_accuracy: 0.8142 - val_precision_449: 0.8848 - val_recall_449: 0.7342\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2118 - accuracy: 0.9168 - precision_449: 0.9146 - recall_449: 0.9199 - val_loss: 0.4259 - val_accuracy: 0.8150 - val_precision_449: 0.8611 - val_recall_449: 0.7634\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2055 - accuracy: 0.9163 - precision_449: 0.9125 - recall_449: 0.9183 - val_loss: 0.4235 - val_accuracy: 0.8192 - val_precision_449: 0.8623 - val_recall_449: 0.7715\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2104 - accuracy: 0.9058 - precision_449: 0.9010 - recall_449: 0.9079 - val_loss: 0.4171 - val_accuracy: 0.8250 - val_precision_449: 0.8589 - val_recall_449: 0.7893\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2120 - accuracy: 0.9168 - precision_449: 0.9166 - recall_449: 0.9159 - val_loss: 0.4098 - val_accuracy: 0.8250 - val_precision_449: 0.8409 - val_recall_449: 0.8136\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2183 - accuracy: 0.9160 - precision_449: 0.9158 - recall_449: 0.9172 - val_loss: 0.4142 - val_accuracy: 0.8217 - val_precision_449: 0.8433 - val_recall_449: 0.8023\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1990 - accuracy: 0.9247 - precision_449: 0.9184 - recall_449: 0.9288 - val_loss: 0.4190 - val_accuracy: 0.8258 - val_precision_449: 0.8592 - val_recall_449: 0.7909\n",
      "Epoch 22/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2058 - accuracy: 0.9177 - precision_449: 0.9144 - recall_449: 0.9221 - val_loss: 0.4133 - val_accuracy: 0.8208 - val_precision_449: 0.8407 - val_recall_449: 0.8039\n",
      "Epoch 23/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2176 - accuracy: 0.9133 - precision_449: 0.9161 - recall_449: 0.9096 - val_loss: 0.4110 - val_accuracy: 0.8250 - val_precision_449: 0.8409 - val_recall_449: 0.8136\n",
      "Epoch 24/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1903 - accuracy: 0.9230 - precision_449: 0.9119 - recall_449: 0.9353 - val_loss: 0.4104 - val_accuracy: 0.8242 - val_precision_449: 0.8372 - val_recall_449: 0.8169\n",
      "Epoch 25/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1953 - accuracy: 0.9243 - precision_449: 0.9195 - recall_449: 0.9285 - val_loss: 0.4105 - val_accuracy: 0.8242 - val_precision_449: 0.8372 - val_recall_449: 0.8169\n",
      "Epoch 26/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2027 - accuracy: 0.9173 - precision_449: 0.9252 - recall_449: 0.9077 - val_loss: 0.4105 - val_accuracy: 0.8258 - val_precision_449: 0.8377 - val_recall_449: 0.8201\n",
      "Epoch 27/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2061 - accuracy: 0.9190 - precision_449: 0.9108 - recall_449: 0.9291 - val_loss: 0.4127 - val_accuracy: 0.8217 - val_precision_449: 0.8398 - val_recall_449: 0.8071\n",
      "Epoch 28/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2053 - accuracy: 0.9228 - precision_449: 0.9254 - recall_449: 0.9231 - val_loss: 0.4108 - val_accuracy: 0.8283 - val_precision_449: 0.8341 - val_recall_449: 0.8314\n",
      "Epoch 29/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2195 - accuracy: 0.9124 - precision_449: 0.9035 - recall_449: 0.9192 - val_loss: 0.4118 - val_accuracy: 0.8233 - val_precision_449: 0.8179 - val_recall_449: 0.8444\n",
      "Epoch 30/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2006 - accuracy: 0.9244 - precision_449: 0.9186 - recall_449: 0.9319 - val_loss: 0.4111 - val_accuracy: 0.8283 - val_precision_449: 0.8341 - val_recall_449: 0.8314\n",
      "Epoch 31/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1997 - accuracy: 0.9248 - precision_449: 0.9274 - recall_449: 0.9235 - val_loss: 0.4113 - val_accuracy: 0.8250 - val_precision_449: 0.8235 - val_recall_449: 0.8395\n",
      "Epoch 32/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2141 - accuracy: 0.9157 - precision_449: 0.9081 - recall_449: 0.9216 - val_loss: 0.4119 - val_accuracy: 0.8242 - val_precision_449: 0.8339 - val_recall_449: 0.8217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu, AUC=0.878, Accuracy=0.797, f2=0.799, prec=0.792, rec=0.801, total=  41.2s\n",
      "[CV] lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu \n",
      "Epoch 1/500\n",
      "64/64 [==============================] - 3s 26ms/step - loss: 0.6387 - accuracy: 0.7170 - precision_450: 0.7234 - recall_450: 0.7058 - val_loss: 5.7939 - val_accuracy: 0.5142 - val_precision_450: 0.5142 - val_recall_450: 1.0000\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4367 - accuracy: 0.7896 - precision_450: 0.7767 - recall_450: 0.8053 - val_loss: 5.3335 - val_accuracy: 0.4858 - val_precision_450: 0.0000e+00 - val_recall_450: 0.0000e+00\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.4196 - accuracy: 0.7982 - precision_450: 0.7922 - recall_450: 0.8051 - val_loss: 17.0692 - val_accuracy: 0.4858 - val_precision_450: 0.0000e+00 - val_recall_450: 0.0000e+00\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3637 - accuracy: 0.8402 - precision_450: 0.8421 - recall_450: 0.8350 - val_loss: 5.2271 - val_accuracy: 0.5142 - val_precision_450: 0.5142 - val_recall_450: 1.0000\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3477 - accuracy: 0.8432 - precision_450: 0.8235 - recall_450: 0.8645 - val_loss: 22.5973 - val_accuracy: 0.4858 - val_precision_450: 0.0000e+00 - val_recall_450: 0.0000e+00\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2735 - accuracy: 0.8856 - precision_450: 0.8825 - recall_450: 0.8892 - val_loss: 22.5701 - val_accuracy: 0.4858 - val_precision_450: 0.0000e+00 - val_recall_450: 0.0000e+00\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2634 - accuracy: 0.8892 - precision_450: 0.8963 - recall_450: 0.8859 - val_loss: 15.3517 - val_accuracy: 0.4858 - val_precision_450: 0.0000e+00 - val_recall_450: 0.0000e+00\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.2063 - accuracy: 0.9175 - precision_450: 0.9226 - recall_450: 0.9124 - val_loss: 12.4874 - val_accuracy: 0.4858 - val_precision_450: 0.0000e+00 - val_recall_450: 0.0000e+00\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1597 - accuracy: 0.9396 - precision_450: 0.9351 - recall_450: 0.9424 - val_loss: 7.0703 - val_accuracy: 0.4858 - val_precision_450: 0.0000e+00 - val_recall_450: 0.0000e+00\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1664 - accuracy: 0.9387 - precision_450: 0.9405 - recall_450: 0.9391 - val_loss: 0.6592 - val_accuracy: 0.7183 - val_precision_450: 0.9020 - val_recall_450: 0.5073\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1442 - accuracy: 0.9535 - precision_450: 0.9587 - recall_450: 0.9496 - val_loss: 1.7623 - val_accuracy: 0.5292 - val_precision_450: 0.9483 - val_recall_450: 0.0891\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1547 - accuracy: 0.9436 - precision_450: 0.9502 - recall_450: 0.9350 - val_loss: 0.5068 - val_accuracy: 0.7917 - val_precision_450: 0.7450 - val_recall_450: 0.9044\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1304 - accuracy: 0.9582 - precision_450: 0.9616 - recall_450: 0.9555 - val_loss: 0.4831 - val_accuracy: 0.7942 - val_precision_450: 0.8280 - val_recall_450: 0.7569\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1238 - accuracy: 0.9612 - precision_450: 0.9602 - recall_450: 0.9606 - val_loss: 0.9989 - val_accuracy: 0.6925 - val_precision_450: 0.6270 - val_recall_450: 0.9919\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1264 - accuracy: 0.9565 - precision_450: 0.9586 - recall_450: 0.9542 - val_loss: 0.5366 - val_accuracy: 0.7883 - val_precision_450: 0.7430 - val_recall_450: 0.8995\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1187 - accuracy: 0.9593 - precision_450: 0.9616 - recall_450: 0.9575 - val_loss: 0.5174 - val_accuracy: 0.7925 - val_precision_450: 0.7548 - val_recall_450: 0.8833\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1206 - accuracy: 0.9580 - precision_450: 0.9595 - recall_450: 0.9566 - val_loss: 0.6266 - val_accuracy: 0.7917 - val_precision_450: 0.7274 - val_recall_450: 0.9514\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1113 - accuracy: 0.9626 - precision_450: 0.9642 - recall_450: 0.9614 - val_loss: 0.5176 - val_accuracy: 0.7958 - val_precision_450: 0.7627 - val_recall_450: 0.8752\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1287 - accuracy: 0.9553 - precision_450: 0.9656 - recall_450: 0.9484 - val_loss: 0.4971 - val_accuracy: 0.7900 - val_precision_450: 0.8007 - val_recall_450: 0.7877\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1165 - accuracy: 0.9579 - precision_450: 0.9592 - recall_450: 0.9570 - val_loss: 0.4983 - val_accuracy: 0.7858 - val_precision_450: 0.7990 - val_recall_450: 0.7796\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1081 - accuracy: 0.9686 - precision_450: 0.9690 - recall_450: 0.9677 - val_loss: 0.5021 - val_accuracy: 0.7883 - val_precision_450: 0.8124 - val_recall_450: 0.7650\n",
      "Epoch 22/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1106 - accuracy: 0.9631 - precision_450: 0.9611 - recall_450: 0.9646 - val_loss: 0.5088 - val_accuracy: 0.7850 - val_precision_450: 0.8155 - val_recall_450: 0.7520\n",
      "Epoch 23/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1085 - accuracy: 0.9663 - precision_450: 0.9675 - recall_450: 0.9642 - val_loss: 0.4994 - val_accuracy: 0.7867 - val_precision_450: 0.8023 - val_recall_450: 0.7763\n",
      "Epoch 24/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1161 - accuracy: 0.9653 - precision_450: 0.9666 - recall_450: 0.9638 - val_loss: 0.4968 - val_accuracy: 0.7883 - val_precision_450: 0.7923 - val_recall_450: 0.7974\n",
      "Epoch 25/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1145 - accuracy: 0.9627 - precision_450: 0.9709 - recall_450: 0.9534 - val_loss: 0.4979 - val_accuracy: 0.7875 - val_precision_450: 0.7919 - val_recall_450: 0.7958\n",
      "Epoch 26/500\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1076 - accuracy: 0.9654 - precision_450: 0.9615 - recall_450: 0.9678 - val_loss: 0.5045 - val_accuracy: 0.7892 - val_precision_450: 0.8138 - val_recall_450: 0.7650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.001, kernel_size=9, kernel_initializer=lecun_uniform, epochs=500, drop_rate=0.2, batch_size=50, activation=elu, AUC=0.883, Accuracy=0.809, f2=0.799, prec=0.815, rec=0.795, total=  33.9s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 147ms/step - loss: 0.8544 - accuracy: 0.6368 - precision_451: 0.6316 - recall_451: 0.6486 - val_loss: 13.1924 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.4754 - accuracy: 0.7732 - precision_451: 0.7832 - recall_451: 0.7454 - val_loss: 16.2787 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.4680 - accuracy: 0.7765 - precision_451: 0.7670 - recall_451: 0.7997 - val_loss: 16.1839 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.4364 - accuracy: 0.7976 - precision_451: 0.7800 - recall_451: 0.8164 - val_loss: 12.4103 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.4294 - accuracy: 0.7932 - precision_451: 0.7802 - recall_451: 0.8113 - val_loss: 10.0543 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.4376 - accuracy: 0.7977 - precision_451: 0.7960 - recall_451: 0.7992 - val_loss: 8.3732 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.4308 - accuracy: 0.7969 - precision_451: 0.7956 - recall_451: 0.7997 - val_loss: 7.1206 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.4257 - accuracy: 0.7996 - precision_451: 0.7967 - recall_451: 0.8042 - val_loss: 6.2894 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.4269 - accuracy: 0.8034 - precision_451: 0.7828 - recall_451: 0.8184 - val_loss: 5.4494 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.4069 - accuracy: 0.8157 - precision_451: 0.8000 - recall_451: 0.8350 - val_loss: 4.7226 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3864 - accuracy: 0.8267 - precision_451: 0.8204 - recall_451: 0.8391 - val_loss: 4.0027 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.4004 - accuracy: 0.8136 - precision_451: 0.8121 - recall_451: 0.8195 - val_loss: 3.0011 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3971 - accuracy: 0.8160 - precision_451: 0.8030 - recall_451: 0.8244 - val_loss: 1.7482 - val_accuracy: 0.5142 - val_precision_451: 0.5142 - val_recall_451: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3836 - accuracy: 0.8279 - precision_451: 0.8196 - recall_451: 0.8344 - val_loss: 0.4645 - val_accuracy: 0.7775 - val_precision_451: 0.7976 - val_recall_451: 0.7601\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3858 - accuracy: 0.8221 - precision_451: 0.8195 - recall_451: 0.8310 - val_loss: 0.6780 - val_accuracy: 0.6417 - val_precision_451: 0.8755 - val_recall_451: 0.3533\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3734 - accuracy: 0.8313 - precision_451: 0.8236 - recall_451: 0.8378 - val_loss: 4.0625 - val_accuracy: 0.4858 - val_precision_451: 0.0000e+00 - val_recall_451: 0.0000e+00\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.3789 - accuracy: 0.8279 - precision_451: 0.8261 - recall_451: 0.8297 - val_loss: 2.1331 - val_accuracy: 0.4875 - val_precision_451: 1.0000 - val_recall_451: 0.0032\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3744 - accuracy: 0.8313 - precision_451: 0.8238 - recall_451: 0.8383 - val_loss: 2.6476 - val_accuracy: 0.4858 - val_precision_451: 0.0000e+00 - val_recall_451: 0.0000e+00\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.3689 - accuracy: 0.8328 - precision_451: 0.8231 - recall_451: 0.8422 - val_loss: 3.1624 - val_accuracy: 0.4858 - val_precision_451: 0.0000e+00 - val_recall_451: 0.0000e+00\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.3702 - accuracy: 0.8311 - precision_451: 0.8258 - recall_451: 0.8394 - val_loss: 3.3113 - val_accuracy: 0.4858 - val_precision_451: 0.0000e+00 - val_recall_451: 0.0000e+00\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3674 - accuracy: 0.8393 - precision_451: 0.8255 - recall_451: 0.8579 - val_loss: 3.0920 - val_accuracy: 0.4858 - val_precision_451: 0.0000e+00 - val_recall_451: 0.0000e+00\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.3676 - accuracy: 0.8311 - precision_451: 0.8333 - recall_451: 0.8300 - val_loss: 2.8204 - val_accuracy: 0.4867 - val_precision_451: 1.0000 - val_recall_451: 0.0016\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3598 - accuracy: 0.8360 - precision_451: 0.8315 - recall_451: 0.8438 - val_loss: 2.5554 - val_accuracy: 0.4867 - val_precision_451: 1.0000 - val_recall_451: 0.0016\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3587 - accuracy: 0.8373 - precision_451: 0.8420 - recall_451: 0.8372 - val_loss: 2.2976 - val_accuracy: 0.4892 - val_precision_451: 1.0000 - val_recall_451: 0.0065\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3593 - accuracy: 0.8450 - precision_451: 0.8421 - recall_451: 0.8542 - val_loss: 2.0433 - val_accuracy: 0.4950 - val_precision_451: 1.0000 - val_recall_451: 0.0178\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.3694 - accuracy: 0.8400 - precision_451: 0.8393 - recall_451: 0.8468 - val_loss: 1.8018 - val_accuracy: 0.5033 - val_precision_451: 0.9565 - val_recall_451: 0.0357\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3750 - accuracy: 0.8296 - precision_451: 0.8180 - recall_451: 0.8337 - val_loss: 1.5808 - val_accuracy: 0.5192 - val_precision_451: 0.9545 - val_recall_451: 0.0681\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3836 - accuracy: 0.8287 - precision_451: 0.8173 - recall_451: 0.8346 - val_loss: 1.3766 - val_accuracy: 0.5450 - val_precision_451: 0.9733 - val_recall_451: 0.1183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=relu, AUC=0.882, Accuracy=0.561, f2=0.151, prec=0.934, rec=0.125, total=  22.6s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 3s 151ms/step - loss: 0.7826 - accuracy: 0.6641 - precision_452: 0.6619 - recall_452: 0.6829 - val_loss: 2.7273 - val_accuracy: 0.4858 - val_precision_452: 0.0000e+00 - val_recall_452: 0.0000e+00\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.5008 - accuracy: 0.7471 - precision_452: 0.7496 - recall_452: 0.7229 - val_loss: 28.8456 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.4331 - accuracy: 0.7991 - precision_452: 0.7905 - recall_452: 0.8063 - val_loss: 35.1404 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.4014 - accuracy: 0.8187 - precision_452: 0.7985 - recall_452: 0.8504 - val_loss: 27.6436 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3913 - accuracy: 0.8209 - precision_452: 0.8061 - recall_452: 0.8477 - val_loss: 22.2135 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3810 - accuracy: 0.8260 - precision_452: 0.8028 - recall_452: 0.8623 - val_loss: 18.5532 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.4060 - accuracy: 0.8230 - precision_452: 0.8058 - recall_452: 0.8458 - val_loss: 15.8061 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.3784 - accuracy: 0.8265 - precision_452: 0.8156 - recall_452: 0.8431 - val_loss: 13.6457 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3951 - accuracy: 0.8100 - precision_452: 0.7829 - recall_452: 0.8453 - val_loss: 11.9412 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.3838 - accuracy: 0.8242 - precision_452: 0.8147 - recall_452: 0.8431 - val_loss: 10.5739 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.3872 - accuracy: 0.8262 - precision_452: 0.8155 - recall_452: 0.8447 - val_loss: 9.4422 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3993 - accuracy: 0.8140 - precision_452: 0.8072 - recall_452: 0.8237 - val_loss: 8.4983 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.3861 - accuracy: 0.8196 - precision_452: 0.8073 - recall_452: 0.8307 - val_loss: 7.7001 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3919 - accuracy: 0.8113 - precision_452: 0.8019 - recall_452: 0.8288 - val_loss: 7.0171 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.4016 - accuracy: 0.8146 - precision_452: 0.7916 - recall_452: 0.8369 - val_loss: 6.4167 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3857 - accuracy: 0.8255 - precision_452: 0.8132 - recall_452: 0.8454 - val_loss: 5.8946 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3825 - accuracy: 0.8205 - precision_452: 0.8051 - recall_452: 0.8407 - val_loss: 5.4337 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3856 - accuracy: 0.8182 - precision_452: 0.7997 - recall_452: 0.8423 - val_loss: 5.0244 - val_accuracy: 0.5142 - val_precision_452: 0.5142 - val_recall_452: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=relu, AUC=0.845, Accuracy=0.496, f2=0.831, prec=0.496, rec=1.000, total=  15.3s\n",
      "[CV] lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=relu \n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 151ms/step - loss: 0.8455 - accuracy: 0.6125 - precision_453: 0.6058 - recall_453: 0.6239 - val_loss: 40.6416 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.4683 - accuracy: 0.7703 - precision_453: 0.7701 - recall_453: 0.7670 - val_loss: 43.9493 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.4171 - accuracy: 0.8076 - precision_453: 0.7995 - recall_453: 0.8152 - val_loss: 27.7401 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.4102 - accuracy: 0.8107 - precision_453: 0.7871 - recall_453: 0.8457 - val_loss: 24.8815 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3811 - accuracy: 0.8264 - precision_453: 0.8192 - recall_453: 0.8317 - val_loss: 23.1735 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3922 - accuracy: 0.8212 - precision_453: 0.8084 - recall_453: 0.8413 - val_loss: 26.5826 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3839 - accuracy: 0.8386 - precision_453: 0.8339 - recall_453: 0.8426 - val_loss: 31.7582 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3552 - accuracy: 0.8376 - precision_453: 0.8292 - recall_453: 0.8490 - val_loss: 27.8987 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3561 - accuracy: 0.8479 - precision_453: 0.8375 - recall_453: 0.8569 - val_loss: 22.0201 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3673 - accuracy: 0.8395 - precision_453: 0.8282 - recall_453: 0.8511 - val_loss: 17.5622 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3582 - accuracy: 0.8352 - precision_453: 0.8243 - recall_453: 0.8462 - val_loss: 12.9668 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3498 - accuracy: 0.8456 - precision_453: 0.8301 - recall_453: 0.8645 - val_loss: 10.4735 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.3474 - accuracy: 0.8452 - precision_453: 0.8372 - recall_453: 0.8542 - val_loss: 4.0106 - val_accuracy: 0.5142 - val_precision_453: 0.5142 - val_recall_453: 1.0000\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3473 - accuracy: 0.8477 - precision_453: 0.8462 - recall_453: 0.8554 - val_loss: 1.7570 - val_accuracy: 0.4917 - val_precision_453: 1.0000 - val_recall_453: 0.0113\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3365 - accuracy: 0.8425 - precision_453: 0.8322 - recall_453: 0.8594 - val_loss: 1.1523 - val_accuracy: 0.5575 - val_precision_453: 0.5375 - val_recall_453: 1.0000\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3282 - accuracy: 0.8575 - precision_453: 0.8501 - recall_453: 0.8650 - val_loss: 2.4160 - val_accuracy: 0.4858 - val_precision_453: 0.0000e+00 - val_recall_453: 0.0000e+00\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3287 - accuracy: 0.8578 - precision_453: 0.8540 - recall_453: 0.8615 - val_loss: 7.3734 - val_accuracy: 0.4858 - val_precision_453: 0.0000e+00 - val_recall_453: 0.0000e+00\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3258 - accuracy: 0.8510 - precision_453: 0.8352 - recall_453: 0.8702 - val_loss: 4.7090 - val_accuracy: 0.4858 - val_precision_453: 0.0000e+00 - val_recall_453: 0.0000e+00\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.3180 - accuracy: 0.8571 - precision_453: 0.8561 - recall_453: 0.8601 - val_loss: 3.3513 - val_accuracy: 0.4858 - val_precision_453: 0.0000e+00 - val_recall_453: 0.0000e+00\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3235 - accuracy: 0.8595 - precision_453: 0.8444 - recall_453: 0.8756 - val_loss: 3.2136 - val_accuracy: 0.4858 - val_precision_453: 0.0000e+00 - val_recall_453: 0.0000e+00\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3317 - accuracy: 0.8552 - precision_453: 0.8471 - recall_453: 0.8615 - val_loss: 2.8920 - val_accuracy: 0.4858 - val_precision_453: 0.0000e+00 - val_recall_453: 0.0000e+00\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.3137 - accuracy: 0.8597 - precision_453: 0.8504 - recall_453: 0.8716 - val_loss: 2.6287 - val_accuracy: 0.4858 - val_precision_453: 0.0000e+00 - val_recall_453: 0.0000e+00\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3202 - accuracy: 0.8508 - precision_453: 0.8423 - recall_453: 0.8624 - val_loss: 2.4566 - val_accuracy: 0.4858 - val_precision_453: 0.0000e+00 - val_recall_453: 0.0000e+00\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.3140 - accuracy: 0.8652 - precision_453: 0.8452 - recall_453: 0.8850 - val_loss: 2.2190 - val_accuracy: 0.4858 - val_precision_453: 0.0000e+00 - val_recall_453: 0.0000e+00\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3072 - accuracy: 0.8711 - precision_453: 0.8562 - recall_453: 0.8868 - val_loss: 2.0039 - val_accuracy: 0.4883 - val_precision_453: 1.0000 - val_recall_453: 0.0049\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3188 - accuracy: 0.8564 - precision_453: 0.8514 - recall_453: 0.8622 - val_loss: 1.7973 - val_accuracy: 0.4933 - val_precision_453: 1.0000 - val_recall_453: 0.0146\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.3170 - accuracy: 0.8547 - precision_453: 0.8505 - recall_453: 0.8577 - val_loss: 1.6065 - val_accuracy: 0.5100 - val_precision_453: 1.0000 - val_recall_453: 0.0470\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3205 - accuracy: 0.8511 - precision_453: 0.8438 - recall_453: 0.8609 - val_loss: 1.4346 - val_accuracy: 0.5250 - val_precision_453: 0.9796 - val_recall_453: 0.0778\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.3259 - accuracy: 0.8540 - precision_453: 0.8372 - recall_453: 0.8683 - val_loss: 1.2797 - val_accuracy: 0.5467 - val_precision_453: 0.9867 - val_recall_453: 0.1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 60.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.005, kernel_size=7, kernel_initializer=he_normal, epochs=500, drop_rate=0.4, batch_size=400, activation=relu, AUC=0.897, Accuracy=0.558, f2=0.138, prec=0.968, rec=0.113, total=  22.9s\n",
      "Epoch 1/500\n",
      "96/96 [==============================] - 3s 21ms/step - loss: 0.6774 - accuracy: 0.7135 - precision_454: 0.7107 - recall_454: 0.7271 - val_loss: 3.1467 - val_accuracy: 0.5142 - val_precision_454: 0.5142 - val_recall_454: 1.0000\n",
      "Epoch 2/500\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 0.4407 - accuracy: 0.7957 - precision_454: 0.7814 - recall_454: 0.8151 - val_loss: 12.7130 - val_accuracy: 0.4858 - val_precision_454: 0.0000e+00 - val_recall_454: 0.0000e+00\n",
      "Epoch 3/500\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 0.4312 - accuracy: 0.7988 - precision_454: 0.7834 - recall_454: 0.8156 - val_loss: 0.5018 - val_accuracy: 0.7333 - val_precision_454: 0.9046 - val_recall_454: 0.5381\n",
      "Epoch 4/500\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 0.3937 - accuracy: 0.8274 - precision_454: 0.8244 - recall_454: 0.8388 - val_loss: 37.4564 - val_accuracy: 0.4858 - val_precision_454: 0.0000e+00 - val_recall_454: 0.0000e+00\n",
      "Epoch 5/500\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 0.3769 - accuracy: 0.8296 - precision_454: 0.8149 - recall_454: 0.8472 - val_loss: 0.5068 - val_accuracy: 0.7300 - val_precision_454: 0.8992 - val_recall_454: 0.5348\n",
      "Epoch 6/500\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 0.3690 - accuracy: 0.8278 - precision_454: 0.8161 - recall_454: 0.8466 - val_loss: 18.7330 - val_accuracy: 0.4858 - val_precision_454: 0.0000e+00 - val_recall_454: 0.0000e+00\n",
      "Epoch 7/500\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 0.3755 - accuracy: 0.8339 - precision_454: 0.8203 - recall_454: 0.8487 - val_loss: 5.2329 - val_accuracy: 0.4858 - val_precision_454: 0.0000e+00 - val_recall_454: 0.0000e+00\n",
      "Epoch 8/500\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 0.3567 - accuracy: 0.8440 - precision_454: 0.8243 - recall_454: 0.8683 - val_loss: 6.8384 - val_accuracy: 0.4858 - val_precision_454: 0.0000e+00 - val_recall_454: 0.0000e+00\n",
      "Epoch 9/500\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 0.3496 - accuracy: 0.8451 - precision_454: 0.8340 - recall_454: 0.8610 - val_loss: 5.0768 - val_accuracy: 0.4858 - val_precision_454: 0.0000e+00 - val_recall_454: 0.0000e+00\n",
      "Epoch 10/500\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 0.3647 - accuracy: 0.8283 - precision_454: 0.8195 - recall_454: 0.8356 - val_loss: 1.7631 - val_accuracy: 0.5117 - val_precision_454: 1.0000 - val_recall_454: 0.0502\n",
      "Epoch 11/500\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 0.3732 - accuracy: 0.8317 - precision_454: 0.8023 - recall_454: 0.8628 - val_loss: 0.3780 - val_accuracy: 0.8192 - val_precision_454: 0.8745 - val_recall_454: 0.7569\n",
      "Epoch 12/500\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 0.3635 - accuracy: 0.8324 - precision_454: 0.8247 - recall_454: 0.8476 - val_loss: 0.3860 - val_accuracy: 0.8333 - val_precision_454: 0.7806 - val_recall_454: 0.9400\n",
      "Epoch 13/500\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 0.3783 - accuracy: 0.8246 - precision_454: 0.8165 - recall_454: 0.8358 - val_loss: 0.3973 - val_accuracy: 0.8017 - val_precision_454: 0.8723 - val_recall_454: 0.7196\n",
      "Epoch 14/500\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 0.3727 - accuracy: 0.8316 - precision_454: 0.8226 - recall_454: 0.8440 - val_loss: 0.3642 - val_accuracy: 0.8350 - val_precision_454: 0.8160 - val_recall_454: 0.8768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=0, shuffle=True),\n",
       "                   error_score=nan,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7faff24ad410>,\n",
       "                   iid='deprecated', n_iter=50, n_jobs=None,\n",
       "                   param_distributions={'activation': ['relu', 'elu', 'gelu'],\n",
       "                                        'batch_size': [50, 100, 200, 300, 400],\n",
       "                                        'drop_rate': [0.2, 0.25, 0.3, 0.4, 0...\n",
       "                                                               'he_normal',\n",
       "                                                               'glorot_normal',\n",
       "                                                               'he_uniform',\n",
       "                                                               'glorot_uniform',\n",
       "                                                               'lecun_uniform'],\n",
       "                                        'kernel_size': [7, 9, 11, 13],\n",
       "                                        'lr': [0.005, 0.001, 0.01]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit='f2',\n",
       "                   return_train_score=False,\n",
       "                   scoring={'AUC': 'roc_auc',\n",
       "                            'Accuracy': make_scorer(accuracy_score),\n",
       "                            'f2': make_scorer(fbeta_score, beta=2),\n",
       "                            'prec': 'precision', 'rec': 'recall'},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'rec' : 'recall', 'prec' : 'precision', 'f2' : make_scorer(fbeta_score, beta=2)}\n",
    "params_to_test_gen = {'epochs':[500], 'batch_size': [50,100,200,300,400], 'lr': [0.005,0.001,0.01], 'activation' : ['relu','elu','gelu'], \n",
    "                      'kernel_size' : [7,9,11,13], \n",
    "                      'kernel_initializer' : ['TruncatedNormal', 'lecun_normal','he_normal','glorot_normal','he_uniform','glorot_uniform','lecun_uniform'],\n",
    "                      'drop_rate' : [0.,0.2,0.25,0.3,0.4,0.5]}\n",
    "rvsearch_0 = RandomizedSearchCV( n_iter = 50,  estimator = estimator, param_distributions = params_to_test_gen, scoring=scoring, refit='f2', cv=StratifiedKFold(n_splits=3, shuffle = True, random_state = 0), verbose = 5)\n",
    "rvsearch_0.fit(x_train, y_train, verbose=1, validation_data=(x_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3150088,
     "status": "ok",
     "timestamp": 1619058992028,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "8JrOcr4mZ72L",
    "outputId": "bebc6e45-365a-41ca-d144-d5c0d9dbecdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'lr': 0.005, 'kernel_size': 7, 'kernel_initializer': 'glorot_uniform', 'epochs': 500, 'drop_rate': 0.5, 'batch_size': 50, 'activation': 'elu'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: \", rvsearch_0.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3146728,
     "status": "ok",
     "timestamp": 1619058992029,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "p6_2HuUobb_F",
    "outputId": "af27b4de-7a3f-428c-f8f5-18269060e8e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvsearch_0.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1619059172251,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "2Ddg5nDKbVHl",
    "outputId": "6ca0b090-edb6-4949-8d45-698d206000b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([19.69554893, 26.50660459, 22.28918592, 19.19447883, 28.51671394,\n",
       "        23.93636243, 23.73331316, 17.49877604, 36.32192135, 24.52136413,\n",
       "        30.32896574, 20.96025332, 22.6051801 , 26.95191455, 24.90107203,\n",
       "        23.47735254, 21.69778204, 20.74819096, 22.29567623, 18.63618644,\n",
       "        27.28520433, 24.00562763, 28.05833769, 26.09096408, 32.32381034,\n",
       "        23.42186316, 23.89161587, 24.62952884, 22.39074198, 13.11348756,\n",
       "        25.28483438, 30.95753074, 23.56391001, 19.96982066, 22.86735241,\n",
       "        18.12899884, 22.95872259, 27.6957802 , 22.86392331, 22.97791139,\n",
       "        27.39834992, 23.44848164, 21.62024252, 22.24164955, 21.69570788,\n",
       "        19.91373555, 19.31343937, 26.16058135, 37.30314525, 19.91342751]),\n",
       " 'mean_score_time': array([0.41061083, 0.41679271, 0.50667453, 0.38945651, 0.49765126,\n",
       "        0.50509453, 0.52495297, 0.36807648, 0.65056094, 0.51178964,\n",
       "        0.49341575, 0.39623443, 0.39094281, 0.41772215, 0.43613823,\n",
       "        0.4028492 , 0.42176501, 0.38652364, 0.38538973, 0.3892862 ,\n",
       "        0.60681788, 0.46863969, 0.43248161, 0.4973863 , 0.49537524,\n",
       "        0.3821222 , 0.38397106, 0.39232318, 0.40329576, 0.38440665,\n",
       "        0.38570913, 0.3912286 , 0.38247315, 0.41661263, 0.39411346,\n",
       "        0.39309645, 0.41711291, 0.51146181, 0.38856578, 0.38467312,\n",
       "        0.3974882 , 0.407679  , 0.42797311, 0.42928282, 0.3930796 ,\n",
       "        0.53670716, 0.49497128, 0.39003714, 0.43691198, 0.36546405]),\n",
       " 'mean_test_AUC': array([0.9064499 , 0.90415139, 0.71489564, 0.90706349, 0.90422477,\n",
       "        0.89925526, 0.84106596, 0.88565104, 0.90842657, 0.7942654 ,\n",
       "        0.66017943, 0.89817966, 0.82815754, 0.89434148, 0.90466386,\n",
       "        0.90720148, 0.90824116, 0.81494138, 0.89727092, 0.89140025,\n",
       "        0.70592811, 0.61520279, 0.904255  , 0.85880373, 0.90885627,\n",
       "        0.85311704, 0.56772051, 0.90918494, 0.90736817, 0.83985565,\n",
       "        0.85799044, 0.90494776, 0.90319249, 0.87122257, 0.89817961,\n",
       "        0.8621639 , 0.9091951 , 0.89694162, 0.89853076, 0.90161586,\n",
       "        0.90464719, 0.90283046, 0.90419408, 0.88923121, 0.90490475,\n",
       "        0.87559254, 0.83847366, 0.89963137, 0.8878729 , 0.87464988]),\n",
       " 'mean_test_Accuracy': array([0.7225    , 0.70854167, 0.55666667, 0.730625  , 0.76895833,\n",
       "        0.69020833, 0.49645833, 0.66083333, 0.81333333, 0.49895833,\n",
       "        0.57104167, 0.57791667, 0.68416667, 0.78895833, 0.80895833,\n",
       "        0.81708333, 0.81395833, 0.57229167, 0.70291667, 0.79270833,\n",
       "        0.62520833, 0.49645833, 0.81770833, 0.51875   , 0.81479167,\n",
       "        0.5675    , 0.54145833, 0.80270833, 0.82645833, 0.49645833,\n",
       "        0.70666667, 0.80979167, 0.799375  , 0.52125   , 0.64979167,\n",
       "        0.51979167, 0.78854167, 0.73520833, 0.679375  , 0.74770833,\n",
       "        0.81895833, 0.81166667, 0.8175    , 0.60270833, 0.80791667,\n",
       "        0.64520833, 0.49895833, 0.77729167, 0.80770833, 0.53833333]),\n",
       " 'mean_test_f2': array([0.55288014, 0.53386632, 0.68557131, 0.66172605, 0.66237947,\n",
       "        0.46051194, 0.83135634, 0.66983985, 0.7901778 , 0.5542765 ,\n",
       "        0.46805721, 0.33293057, 0.49098995, 0.74786827, 0.77439035,\n",
       "        0.86237574, 0.85251188, 0.46865593, 0.50912118, 0.73416066,\n",
       "        0.66464099, 0.83135634, 0.81406689, 0.32157988, 0.80078678,\n",
       "        0.73095331, 0.39421306, 0.88954616, 0.82217062, 0.83135634,\n",
       "        0.58738991, 0.86959915, 0.75450376, 0.04622902, 0.36877881,\n",
       "        0.301577  , 0.73192602, 0.5938313 , 0.43075658, 0.59869091,\n",
       "        0.85940361, 0.7776529 , 0.83006956, 0.50271408, 0.78538575,\n",
       "        0.58154718, 0.5542765 , 0.71064273, 0.79934385, 0.37317846]),\n",
       " 'mean_test_prec': array([0.89359225, 0.54720262, 0.52320974, 0.83287641, 0.87553978,\n",
       "        0.8971612 , 0.49645833, 0.76544437, 0.83799935, 0.33104167,\n",
       "        0.77665433, 0.53587154, 0.7236175 , 0.8280825 , 0.84282432,\n",
       "        0.77816109, 0.78833296, 0.44517857, 0.89620631, 0.84899569,\n",
       "        0.71487823, 0.49645833, 0.82261761, 0.48430632, 0.82981685,\n",
       "        0.62318507, 0.43957701, 0.73672709, 0.82799911, 0.49645833,\n",
       "        0.761446  , 0.76177171, 0.84377004, 0.64935065, 0.59867743,\n",
       "        0.81470796, 0.85586423, 0.88151566, 0.92838667, 0.90144841,\n",
       "        0.78196237, 0.84362164, 0.80859415, 0.47159049, 0.83215121,\n",
       "        0.77000825, 0.33104167, 0.84680172, 0.81316929, 0.79931807]),\n",
       " 'mean_test_rec': array([0.52231199, 0.53148615, 0.76938728, 0.66163416, 0.63189329,\n",
       "        0.43085352, 1.        , 0.69479429, 0.78223257, 0.66666667,\n",
       "        0.50501508, 0.36183853, 0.46134161, 0.73272288, 0.76201437,\n",
       "        0.88712408, 0.87453754, 0.5109152 , 0.49915826, 0.71209702,\n",
       "        0.71986122, 1.        , 0.81450501, 0.36985726, 0.79651368,\n",
       "        0.82745592, 0.43563941, 0.93830511, 0.8208033 , 1.        ,\n",
       "        0.57447629, 0.90262767, 0.7394658 , 0.03774483, 0.36025221,\n",
       "        0.35012489, 0.71510173, 0.56234547, 0.38684368, 0.55353252,\n",
       "        0.88164219, 0.76290153, 0.8384292 , 0.54297694, 0.78048941,\n",
       "        0.613884  , 0.66666667, 0.69238946, 0.7960569 , 0.41262614]),\n",
       " 'param_activation': masked_array(data=['elu', 'elu', 'relu', 'elu', 'gelu', 'gelu', 'gelu',\n",
       "                    'relu', 'gelu', 'gelu', 'gelu', 'elu', 'relu', 'elu',\n",
       "                    'elu', 'elu', 'elu', 'relu', 'relu', 'elu', 'gelu',\n",
       "                    'gelu', 'elu', 'gelu', 'gelu', 'relu', 'relu', 'elu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'elu', 'relu',\n",
       "                    'elu', 'elu', 'gelu', 'relu', 'relu', 'elu', 'relu',\n",
       "                    'elu', 'elu', 'elu', 'relu', 'gelu', 'relu', 'elu',\n",
       "                    'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[100, 100, 300, 200, 100, 100, 300, 200, 50, 300, 400,\n",
       "                    300, 100, 100, 50, 50, 100, 400, 100, 100, 400, 400,\n",
       "                    50, 200, 100, 400, 400, 50, 50, 400, 100, 100, 100,\n",
       "                    200, 100, 200, 100, 100, 100, 100, 50, 50, 100, 300,\n",
       "                    100, 200, 400, 100, 50, 400],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_drop_rate': masked_array(data=[0.3, 0.25, 0.5, 0.4, 0.4, 0.3, 0.5, 0.3, 0.3, 0.5, 0.2,\n",
       "                    0.25, 0.4, 0.2, 0.2, 0.25, 0.5, 0.2, 0.25, 0.5, 0.5,\n",
       "                    0.25, 0.2, 0.2, 0.3, 0.5, 0.3, 0.5, 0.25, 0.4, 0.4,\n",
       "                    0.5, 0.3, 0.4, 0.2, 0.5, 0.3, 0.25, 0.25, 0.4, 0.3,\n",
       "                    0.25, 0.3, 0.3, 0.5, 0.5, 0.4, 0.5, 0.2, 0.4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel_initializer': masked_array(data=['glorot_normal', 'TruncatedNormal', 'he_uniform',\n",
       "                    'lecun_uniform', 'he_uniform', 'glorot_uniform',\n",
       "                    'he_normal', 'he_normal', 'TruncatedNormal',\n",
       "                    'lecun_uniform', 'glorot_normal', 'he_normal',\n",
       "                    'he_normal', 'lecun_uniform', 'he_normal',\n",
       "                    'glorot_normal', 'glorot_normal', 'lecun_normal',\n",
       "                    'he_normal', 'glorot_normal', 'TruncatedNormal',\n",
       "                    'lecun_uniform', 'glorot_uniform', 'he_normal',\n",
       "                    'glorot_uniform', 'he_normal', 'lecun_normal',\n",
       "                    'glorot_uniform', 'lecun_normal', 'lecun_uniform',\n",
       "                    'lecun_uniform', 'glorot_normal', 'glorot_uniform',\n",
       "                    'he_normal', 'TruncatedNormal', 'glorot_uniform',\n",
       "                    'he_uniform', 'he_normal', 'glorot_normal',\n",
       "                    'glorot_normal', 'he_normal', 'glorot_uniform',\n",
       "                    'he_normal', 'TruncatedNormal', 'lecun_uniform',\n",
       "                    'he_normal', 'glorot_normal', 'glorot_normal',\n",
       "                    'lecun_uniform', 'he_normal'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel_size': masked_array(data=[11, 9, 13, 7, 13, 13, 11, 7, 9, 11, 11, 7, 13, 11, 13,\n",
       "                    7, 9, 13, 13, 7, 7, 7, 9, 11, 9, 11, 13, 7, 9, 9, 13,\n",
       "                    9, 13, 9, 9, 7, 13, 11, 9, 11, 7, 11, 13, 9, 7, 11, 9,\n",
       "                    13, 9, 7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_lr': masked_array(data=[0.01, 0.005, 0.005, 0.005, 0.01, 0.01, 0.001, 0.001,\n",
       "                    0.01, 0.005, 0.01, 0.005, 0.005, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.005, 0.005, 0.001, 0.005, 0.005, 0.005, 0.01,\n",
       "                    0.005, 0.005, 0.01, 0.005, 0.005, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.005, 0.005, 0.001, 0.005, 0.001, 0.001, 0.005,\n",
       "                    0.005, 0.001, 0.01, 0.005, 0.01, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.005],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'elu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.3,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_normal',\n",
       "   'kernel_size': 11,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.25,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'TruncatedNormal',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 300,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_uniform',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 200,\n",
       "   'drop_rate': 0.4,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'lecun_uniform',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.4,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_uniform',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.3,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_uniform',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 300,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 11,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 200,\n",
       "   'drop_rate': 0.3,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 50,\n",
       "   'drop_rate': 0.3,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'TruncatedNormal',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 300,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'lecun_uniform',\n",
       "   'kernel_size': 11,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 400,\n",
       "   'drop_rate': 0.2,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_normal',\n",
       "   'kernel_size': 11,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 300,\n",
       "   'drop_rate': 0.25,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.4,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.2,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'lecun_uniform',\n",
       "   'kernel_size': 11,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 50,\n",
       "   'drop_rate': 0.2,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 50,\n",
       "   'drop_rate': 0.25,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_normal',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_normal',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 400,\n",
       "   'drop_rate': 0.2,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'lecun_normal',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.25,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_normal',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 400,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'TruncatedNormal',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 400,\n",
       "   'drop_rate': 0.25,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'lecun_uniform',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 50,\n",
       "   'drop_rate': 0.2,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_uniform',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 200,\n",
       "   'drop_rate': 0.2,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 11,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.3,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_uniform',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 400,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 11,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 400,\n",
       "   'drop_rate': 0.3,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'lecun_normal',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 50,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_uniform',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'drop_rate': 0.25,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'lecun_normal',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 400,\n",
       "   'drop_rate': 0.4,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'lecun_uniform',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.4,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'lecun_uniform',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_normal',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.3,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_uniform',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 200,\n",
       "   'drop_rate': 0.4,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.2,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'TruncatedNormal',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 200,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_uniform',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.3,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_uniform',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.25,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 11,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.25,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_normal',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.4,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_normal',\n",
       "   'kernel_size': 11,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 50,\n",
       "   'drop_rate': 0.3,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'drop_rate': 0.25,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_uniform',\n",
       "   'kernel_size': 11,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.3,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 300,\n",
       "   'drop_rate': 0.3,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'TruncatedNormal',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.005},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'lecun_uniform',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.01},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 200,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 11,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'gelu',\n",
       "   'batch_size': 400,\n",
       "   'drop_rate': 0.4,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_normal',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'drop_rate': 0.5,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'glorot_normal',\n",
       "   'kernel_size': 13,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'elu',\n",
       "   'batch_size': 50,\n",
       "   'drop_rate': 0.2,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'lecun_uniform',\n",
       "   'kernel_size': 9,\n",
       "   'lr': 0.001},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 400,\n",
       "   'drop_rate': 0.4,\n",
       "   'epochs': 500,\n",
       "   'kernel_initializer': 'he_normal',\n",
       "   'kernel_size': 7,\n",
       "   'lr': 0.005}],\n",
       " 'rank_test_AUC': array([ 9, 17, 46,  8, 15, 22, 40, 32,  4, 45, 48, 24, 43, 28, 12,  7,  5,\n",
       "        44, 26, 29, 47, 49, 14, 37,  3, 39, 50,  2,  6, 41, 38, 10, 18, 35,\n",
       "        25, 36,  1, 27, 23, 20, 13, 19, 16, 30, 11, 33, 42, 21, 31, 34],\n",
       "       dtype=int32),\n",
       " 'rank_test_Accuracy': array([24, 25, 40, 23, 20, 28, 48, 31,  8, 46, 38, 36, 29, 17, 11,  5,  7,\n",
       "        37, 27, 16, 34, 48,  3, 45,  6, 39, 41, 14,  1, 48, 26, 10, 15, 43,\n",
       "        32, 44, 18, 22, 30, 21,  2,  9,  4, 35, 12, 33, 46, 19, 13, 42],\n",
       "       dtype=int32),\n",
       " 'rank_test_f2': array([35, 36, 24, 28, 27, 42,  6, 25, 14, 33, 41, 47, 39, 19, 17,  3,  5,\n",
       "        40, 37, 20, 26,  6, 11, 48, 12, 22, 44,  1, 10,  6, 31,  2, 18, 50,\n",
       "        46, 49, 21, 30, 43, 29,  4, 16,  9, 38, 15, 32, 33, 23, 13, 45],\n",
       "       dtype=int32),\n",
       " 'rank_test_prec': array([ 5, 39, 41, 15,  7,  3, 42, 30, 14, 49, 28, 40, 34, 18, 13, 27, 25,\n",
       "        47,  4,  9, 35, 42, 20, 45, 17, 37, 48, 33, 19, 42, 32, 31, 11, 36,\n",
       "        38, 21,  8,  6,  1,  2, 26, 12, 23, 46, 16, 29, 49, 10, 22, 24],\n",
       "       dtype=int32),\n",
       " 'rank_test_rec': array([37, 36, 17, 29, 30, 43,  1, 25, 15, 27, 39, 47, 41, 21, 19,  6,  8,\n",
       "        38, 40, 24, 22,  1, 12, 46, 13, 10, 42,  4, 11,  1, 32,  5, 20, 50,\n",
       "        48, 49, 23, 33, 45, 34,  7, 18,  9, 35, 16, 31, 27, 26, 14, 44],\n",
       "       dtype=int32),\n",
       " 'split0_test_AUC': array([0.91794523, 0.90740732, 0.41680066, 0.91447322, 0.91740302,\n",
       "        0.91124185, 0.83545998, 0.87686863, 0.91729521, 0.70193679,\n",
       "        0.88955194, 0.91476542, 0.67809133, 0.90474472, 0.91667174,\n",
       "        0.92186101, 0.91559827, 0.87030743, 0.88497676, 0.89086917,\n",
       "        0.88813001, 0.41678347, 0.91500137, 0.87152779, 0.91961248,\n",
       "        0.81135513, 0.81157701, 0.91893277, 0.91912809, 0.85115903,\n",
       "        0.9111434 , 0.91307317, 0.90659791, 0.84220712, 0.92211102,\n",
       "        0.85631157, 0.91844525, 0.90502285, 0.90685105, 0.90242275,\n",
       "        0.91832181, 0.91084183, 0.91157623, 0.91928122, 0.91894293,\n",
       "        0.89844603, 0.83063088, 0.90311497, 0.90264463, 0.88155162]),\n",
       " 'split0_test_Accuracy': array([0.83125 , 0.503125, 0.469375, 0.734375, 0.83    , 0.80625 ,\n",
       "        0.496875, 0.496875, 0.815625, 0.496875, 0.53    , 0.553125,\n",
       "        0.48    , 0.78    , 0.833125, 0.84125 , 0.8375  , 0.503125,\n",
       "        0.505625, 0.804375, 0.641875, 0.496875, 0.835   , 0.496875,\n",
       "        0.808125, 0.496875, 0.6225  , 0.81    , 0.840625, 0.496875,\n",
       "        0.770625, 0.80125 , 0.7625  , 0.54625 , 0.844375, 0.504375,\n",
       "        0.78625 , 0.73    , 0.745   , 0.721875, 0.828125, 0.8225  ,\n",
       "        0.82625 , 0.783125, 0.84    , 0.8     , 0.496875, 0.80375 ,\n",
       "        0.8175  , 0.560625]),\n",
       " 'split0_test_f2': array([0.84517577, 0.        , 0.3393907 , 0.89611872, 0.82977118,\n",
       "        0.73579471, 0.83158996, 0.83158996, 0.74973877, 0.83158996,\n",
       "        0.06670804, 0.12269939, 0.09997016, 0.68837702, 0.86457819,\n",
       "        0.86005469, 0.84646162, 0.        , 0.00628141, 0.7906741 ,\n",
       "        0.3377193 , 0.83158996, 0.84396099, 0.83158996, 0.73452256,\n",
       "        0.83158996, 0.35087719, 0.90358585, 0.84420472, 0.83158996,\n",
       "        0.64154511, 0.89068826, 0.6352846 , 0.11206632, 0.86681548,\n",
       "        0.00314268, 0.66979866, 0.54429325, 0.58646204, 0.53581344,\n",
       "        0.89216634, 0.78514521, 0.84924374, 0.6698821 , 0.86206897,\n",
       "        0.74941755, 0.83158996, 0.75058335, 0.8001016 , 0.15063907]),\n",
       " 'split0_test_prec': array([0.81588448, 0.        , 0.4519573 , 0.65416667, 0.8281054 ,\n",
       "        0.87949922, 0.496875  , 0.496875  , 0.88580247, 0.496875  ,\n",
       "        1.        , 1.        , 0.39181287, 0.87102178, 0.8020595 ,\n",
       "        0.82087782, 0.82661783, 0.        , 1.        , 0.81462141,\n",
       "        0.9625    , 0.496875  , 0.82417582, 0.496875  , 0.88607595,\n",
       "        0.496875  , 0.82154882, 0.73811833, 0.83498759, 0.496875  ,\n",
       "        0.90996169, 0.73405299, 0.89373814, 0.94805195, 0.82042254,\n",
       "        1.        , 0.91559633, 0.93111639, 0.91257996, 0.91469194,\n",
       "        0.77196653, 0.85935302, 0.80304807, 0.9057971 , 0.81668625,\n",
       "        0.8477306 , 0.496875  , 0.85524372, 0.8322325 , 0.93396226]),\n",
       " 'split0_test_rec': array([0.85283019, 0.        , 0.31949686, 0.98742138, 0.83018868,\n",
       "        0.70691824, 1.        , 1.        , 0.72201258, 1.        ,\n",
       "        0.05408805, 0.10062893, 0.08427673, 0.65408805, 0.88176101,\n",
       "        0.87044025, 0.85157233, 0.        , 0.00503145, 0.78490566,\n",
       "        0.29056604, 1.        , 0.8490566 , 1.        , 0.70440252,\n",
       "        1.        , 0.30691824, 0.9572327 , 0.84654088, 1.        ,\n",
       "        0.59748428, 0.9408805 , 0.59245283, 0.0918239 , 0.87924528,\n",
       "        0.00251572, 0.62767296, 0.49308176, 0.53836478, 0.48553459,\n",
       "        0.92830189, 0.76855346, 0.86163522, 0.62893082, 0.87421384,\n",
       "        0.72830189, 1.        , 0.72830189, 0.79245283, 0.1245283 ]),\n",
       " 'split1_test_AUC': array([0.89600665, 0.89553475, 0.82910445, 0.89327212, 0.88572482,\n",
       "        0.89009694, 0.82921696, 0.8826559 , 0.8995881 , 0.80157399,\n",
       "        0.83093111, 0.87985418, 0.89313618, 0.88392785, 0.89221581,\n",
       "        0.8948144 , 0.89939903, 0.72143433, 0.89645668, 0.8917861 ,\n",
       "        0.39267912, 0.53596921, 0.8913017 , 0.79386497, 0.89924433,\n",
       "        0.87635789, 0.35913895, 0.89788644, 0.89652387, 0.85345816,\n",
       "        0.89420967, 0.89354245, 0.89117825, 0.88823434, 0.86887856,\n",
       "        0.85082286, 0.89620432, 0.88842029, 0.88569513, 0.89176266,\n",
       "        0.89513785, 0.88792651, 0.8890422 , 0.8560169 , 0.89607853,\n",
       "        0.84619604, 0.84841491, 0.89287835, 0.8781494 , 0.84511785]),\n",
       " 'split1_test_Accuracy': array([0.690625, 0.8075  , 0.521875, 0.675   , 0.705625, 0.735   ,\n",
       "        0.49625 , 0.7475  , 0.803125, 0.49625 , 0.686875, 0.676875,\n",
       "        0.76625 , 0.794375, 0.7975  , 0.80375 , 0.770625, 0.49625 ,\n",
       "        0.813125, 0.766875, 0.49625 , 0.49625 , 0.806875, 0.50375 ,\n",
       "        0.8125  , 0.49625 , 0.50375 , 0.78375 , 0.81125 , 0.49625 ,\n",
       "        0.801875, 0.799375, 0.808125, 0.514375, 0.50375 , 0.5275  ,\n",
       "        0.79875 , 0.803125, 0.58    , 0.778125, 0.815   , 0.795   ,\n",
       "        0.80375 , 0.50375 , 0.809375, 0.578125, 0.50375 , 0.800625,\n",
       "        0.796875, 0.49625 ]),\n",
       " 'split1_test_f2': array([0.45725646, 0.82711443, 0.83773505, 0.41881813, 0.5071249 ,\n",
       "        0.57597367, 0.83123953, 0.60010911, 0.75640031, 0.83123953,\n",
       "        0.50622407, 0.87609231, 0.64685315, 0.81027175, 0.73736321,\n",
       "        0.84641806, 0.88787239, 0.83123953, 0.82730222, 0.65694407,\n",
       "        0.83123953, 0.83123953, 0.84745763, 0.        , 0.83952452,\n",
       "        0.83123953, 0.        , 0.87619048, 0.79695431, 0.83123953,\n",
       "        0.87134926, 0.86656998, 0.80795369, 0.02662073, 0.        ,\n",
       "        0.83792373, 0.8592233 , 0.8164794 , 0.19474638, 0.67484663,\n",
       "        0.84200099, 0.77520367, 0.86407767, 0.        , 0.83601684,\n",
       "        0.85184386, 0.        , 0.83395016, 0.79919578, 0.83123953]),\n",
       " 'split1_test_prec': array([0.93333333, 0.78791469, 0.50931278, 0.94193548, 0.90074442,\n",
       "        0.89361702, 0.49625   , 0.89795918, 0.84659913, 0.49625   ,\n",
       "        0.83371298, 0.60761461, 0.88745387, 0.77844311, 0.85498489,\n",
       "        0.76666667, 0.69641214, 0.49625   , 0.79783394, 0.87522282,\n",
       "        0.49625   , 0.49625   , 0.77094972, 0.        , 0.78654292,\n",
       "        0.49625   , 0.        , 0.71875   , 0.82198953, 0.49625   ,\n",
       "        0.74663909, 0.74609781, 0.8055207 , 1.        , 0.        ,\n",
       "        0.5123057 , 0.75      , 0.78890229, 0.94852941, 0.88307155,\n",
       "        0.78886311, 0.80984043, 0.75423729, 0.        , 0.78397213,\n",
       "        0.54072553, 0.        , 0.77080958, 0.79202989, 0.49625   ]),\n",
       " 'split1_test_rec': array([0.40554156, 0.83753149, 0.99874055, 0.36775819, 0.45717884,\n",
       "        0.52896725, 1.        , 0.55415617, 0.73677582, 1.        ,\n",
       "        0.46095718, 0.98488665, 0.60579345, 0.8186398 , 0.71284635,\n",
       "        0.86901763, 0.9534005 , 1.        , 0.83501259, 0.61838791,\n",
       "        1.        , 1.        , 0.86901763, 0.        , 0.85390428,\n",
       "        1.        , 0.        , 0.92695214, 0.79093199, 1.        ,\n",
       "        0.9093199 , 0.90302267, 0.80856423, 0.02141058, 0.        ,\n",
       "        0.99622166, 0.89168766, 0.82367758, 0.16246851, 0.6372796 ,\n",
       "        0.85642317, 0.76700252, 0.89672544, 0.        , 0.85012594,\n",
       "        0.99496222, 0.        , 0.85138539, 0.80100756, 1.        ]),\n",
       " 'split2_test_AUC': array([0.9053978 , 0.9095121 , 0.89878181, 0.91344513, 0.90954647,\n",
       "        0.89642699, 0.85852095, 0.89742861, 0.90839641, 0.8792854 ,\n",
       "        0.26005525, 0.89991937, 0.91324512, 0.89435187, 0.90510404,\n",
       "        0.90492903, 0.90972617, 0.85308236, 0.91037933, 0.89154546,\n",
       "        0.8369752 , 0.89285569, 0.90646193, 0.91101843, 0.907712  ,\n",
       "        0.87163809, 0.53244558, 0.9107356 , 0.90645255, 0.81494975,\n",
       "        0.76861823, 0.90822765, 0.91180129, 0.88322624, 0.90354926,\n",
       "        0.87935728, 0.91293573, 0.89738173, 0.90304611, 0.91066216,\n",
       "        0.9004819 , 0.90972305, 0.9119638 , 0.89239551, 0.8996928 ,\n",
       "        0.88213556, 0.83637517, 0.90290079, 0.88282466, 0.89728016]),\n",
       " 'split2_test_Accuracy': array([0.645625, 0.815   , 0.67875 , 0.7825  , 0.77125 , 0.529375,\n",
       "        0.49625 , 0.738125, 0.82125 , 0.50375 , 0.49625 , 0.50375 ,\n",
       "        0.80625 , 0.7925  , 0.79625 , 0.80625 , 0.83375 , 0.7175  ,\n",
       "        0.79    , 0.806875, 0.7375  , 0.49625 , 0.81125 , 0.555625,\n",
       "        0.82375 , 0.709375, 0.498125, 0.814375, 0.8275  , 0.49625 ,\n",
       "        0.5475  , 0.82875 , 0.8275  , 0.503125, 0.60125 , 0.5275  ,\n",
       "        0.780625, 0.6725  , 0.713125, 0.743125, 0.81375 , 0.8175  ,\n",
       "        0.8225  , 0.52125 , 0.774375, 0.5575  , 0.49625 , 0.7275  ,\n",
       "        0.80875 , 0.558125]),\n",
       " 'split2_test_f2': array([0.3562082 , 0.77448454, 0.87958818, 0.67024129, 0.65024233,\n",
       "        0.06976744, 0.83123953, 0.57782048, 0.86439431, 0.        ,\n",
       "        0.83123953, 0.        , 0.72614655, 0.74495603, 0.72122964,\n",
       "        0.88065448, 0.82320162, 0.57472826, 0.6937799 , 0.75486381,\n",
       "        0.82496413, 0.83123953, 0.75078206, 0.13314968, 0.82831325,\n",
       "        0.53003045, 0.83176199, 0.88886216, 0.82535282, 0.83123953,\n",
       "        0.24927536, 0.85153923, 0.820273  , 0.        , 0.23952096,\n",
       "        0.0636646 , 0.6667561 , 0.42072124, 0.51106133, 0.58541267,\n",
       "        0.8440435 , 0.77260982, 0.77688728, 0.83826014, 0.65807145,\n",
       "        0.14338011, 0.83123953, 0.54739468, 0.79873418, 0.13765678]),\n",
       " 'split2_test_prec': array([0.93155894, 0.85369318, 0.60835913, 0.90252708, 0.89776952,\n",
       "        0.91836735, 0.49625   , 0.90149893, 0.78159645, 0.        ,\n",
       "        0.49625   , 0.        , 0.89158576, 0.83478261, 0.87142857,\n",
       "        0.74693878, 0.84196891, 0.83928571, 0.89078498, 0.85714286,\n",
       "        0.68588469, 0.49625   , 0.87272727, 0.95604396, 0.81683168,\n",
       "        0.87643021, 0.49718222, 0.75331295, 0.8270202 , 0.49625   ,\n",
       "        0.62773723, 0.80516432, 0.83205128, 0.        , 0.97560976,\n",
       "        0.93181818, 0.90199637, 0.9245283 , 0.92405063, 0.90658174,\n",
       "        0.78505747, 0.86167147, 0.86849711, 0.50897436, 0.89579525,\n",
       "        0.92156863, 0.49625   , 0.91435185, 0.81524548, 0.96774194]),\n",
       " 'split2_test_rec': array([0.30856423, 0.75692695, 0.98992443, 0.62972292, 0.60831234,\n",
       "        0.05667506, 1.        , 0.5302267 , 0.88790932, 0.        ,\n",
       "        1.        , 0.        , 0.69395466, 0.72544081, 0.69143577,\n",
       "        0.92191436, 0.8186398 , 0.53274559, 0.65743073, 0.73299748,\n",
       "        0.86901763, 1.        , 0.72544081, 0.10957179, 0.83123426,\n",
       "        0.48236776, 1.        , 0.93073048, 0.82493703, 1.        ,\n",
       "        0.21662469, 0.86397985, 0.81738035, 0.        , 0.20151134,\n",
       "        0.05163728, 0.62594458, 0.37027708, 0.45969773, 0.53778338,\n",
       "        0.86020151, 0.75314861, 0.75692695, 1.        , 0.61712846,\n",
       "        0.11838791, 1.        , 0.49748111, 0.79471033, 0.11335013]),\n",
       " 'std_fit_time': array([1.53388119, 7.19395178, 5.93846994, 2.13073829, 2.24830525,\n",
       "        0.65236687, 4.44854836, 3.53575244, 1.16156085, 5.23758155,\n",
       "        3.61479635, 3.50990462, 1.17674881, 2.87098676, 0.46712376,\n",
       "        3.40329592, 1.91810973, 3.93142575, 4.21179374, 0.86480973,\n",
       "        5.12214407, 4.71071064, 2.23011262, 0.43480633, 3.5401403 ,\n",
       "        5.6886841 , 5.71114533, 1.22228876, 2.44582872, 0.288872  ,\n",
       "        6.71688163, 7.50923915, 1.34402495, 1.68491352, 2.77774814,\n",
       "        0.69034972, 4.54985539, 2.55266954, 1.04187868, 1.69041265,\n",
       "        2.99119567, 2.85028655, 2.35594678, 4.49292951, 3.14944075,\n",
       "        3.27722075, 2.45946159, 5.8175279 , 2.97763314, 3.48852731]),\n",
       " 'std_score_time': array([0.00731483, 0.00677152, 0.15485131, 0.00818803, 0.00130706,\n",
       "        0.01011823, 0.00094146, 0.0019486 , 0.20309979, 0.00751047,\n",
       "        0.01009721, 0.00572328, 0.00804294, 0.00082597, 0.00653872,\n",
       "        0.00378253, 0.00177928, 0.00581489, 0.00447068, 0.00089914,\n",
       "        0.1886142 , 0.00597452, 0.00544242, 0.00448531, 0.00465668,\n",
       "        0.00385773, 0.00603905, 0.0035092 , 0.00895449, 0.0103631 ,\n",
       "        0.00432813, 0.00368759, 0.00585997, 0.00803799, 0.00466533,\n",
       "        0.00196774, 0.00154236, 0.00489352, 0.00431649, 0.00148886,\n",
       "        0.00334351, 0.00378652, 0.00527475, 0.00288974, 0.00133507,\n",
       "        0.20772449, 0.00352786, 0.0045878 , 0.00456084, 0.00608424]),\n",
       " 'std_test_AUC': array([0.00898723, 0.00615318, 0.21269571, 0.009761  , 0.01346891,\n",
       "        0.008861  , 0.01260294, 0.00865665, 0.00722893, 0.07258647,\n",
       "        0.28394086, 0.01430545, 0.10642992, 0.00849846, 0.00998894,\n",
       "        0.01115804, 0.00669616, 0.06649236, 0.01038653, 0.00038816,\n",
       "        0.22248281, 0.20226989, 0.00980039, 0.04866662, 0.00835454,\n",
       "        0.02959292, 0.18638364, 0.00866181, 0.00925082, 0.01763613,\n",
       "        0.06357269, 0.00830384, 0.00875691, 0.02061864, 0.02206126,\n",
       "        0.01236232, 0.00945724, 0.00678511, 0.00920813, 0.00773676,\n",
       "        0.00991249, 0.01054858, 0.01071517, 0.02592429, 0.01003555,\n",
       "        0.02182695, 0.00741038, 0.00477591, 0.01061815, 0.02184723]),\n",
       " 'std_test_Accuracy': array([0.07906188, 0.14528379, 0.08894687, 0.04396673, 0.05080173,\n",
       "        0.11738728, 0.00029463, 0.11599921, 0.00757486, 0.00339781,\n",
       "        0.08305736, 0.07281958, 0.14528827, 0.00638058, 0.01709603,\n",
       "        0.01711887, 0.03067951, 0.10271615, 0.13982535, 0.01829542,\n",
       "        0.09919249, 0.00029463, 0.01235682, 0.02622519, 0.00658149,\n",
       "        0.1003211 , 0.05735111, 0.01352403, 0.01201489, 0.00029463,\n",
       "        0.11326859, 0.0134274 , 0.0272479 , 0.01826455, 0.14323307,\n",
       "        0.01090123, 0.00757486, 0.05345445, 0.0714635 , 0.02319153,\n",
       "        0.00650187, 0.01196058, 0.00984251, 0.12777374, 0.02681113,\n",
       "        0.10977763, 0.00339781, 0.03523113, 0.00845228, 0.02977491]),\n",
       " 'std_test_f2': array([2.10760902e-01, 3.78111459e-01, 2.45382264e-01, 1.94950157e-01,\n",
       "        1.31999090e-01, 2.83897445e-01, 1.65192952e-04, 1.14735984e-01,\n",
       "        5.25494202e-02, 3.91932695e-01, 3.13283294e-01, 3.87326131e-01,\n",
       "        2.78381297e-01, 4.98059059e-02, 6.41116675e-02, 1.40729896e-02,\n",
       "        2.67461067e-02, 3.47542126e-01, 3.59715562e-01, 5.65237143e-02,\n",
       "        2.31182739e-01, 1.65192952e-04, 4.47718947e-02, 3.64705287e-01,\n",
       "        4.70788905e-02, 1.42073993e-01, 3.40945257e-01, 1.11945663e-02,\n",
       "        1.94206924e-02, 1.65192952e-04, 2.56831428e-01, 1.61254176e-02,\n",
       "        8.44505713e-02, 4.78057079e-02, 3.65488679e-01, 3.80058403e-01,\n",
       "        9.00213397e-02, 1.65321192e-01, 1.69699597e-01, 5.75313867e-02,\n",
       "        2.31817522e-02, 5.40265597e-03, 3.80900493e-02, 3.62057891e-01,\n",
       "        9.06508959e-02, 3.12639910e-01, 3.91932695e-01, 1.20346586e-01,\n",
       "        5.67982289e-04, 3.23941449e-01]),\n",
       " 'std_test_prec': array([5.49524672e-02, 3.87861433e-01, 6.46025167e-02, 1.27386903e-01,\n",
       "        3.35631533e-02, 1.60645313e-02, 2.94627825e-04, 1.89912722e-01,\n",
       "        4.29743385e-02, 2.34081946e-01, 2.09575417e-01, 4.11388139e-01,\n",
       "        2.34627371e-01, 3.80908629e-02, 2.95964727e-02, 3.12605901e-02,\n",
       "        6.52992671e-02, 3.44534803e-01, 8.26229287e-02, 2.54022940e-02,\n",
       "        1.91446659e-01, 2.94627825e-04, 4.15651181e-02, 3.90404483e-01,\n",
       "        4.16586667e-02, 1.79071536e-01, 3.37860313e-01, 1.41445153e-02,\n",
       "        5.35139304e-03, 2.94627825e-04, 1.15692393e-01, 3.10747314e-02,\n",
       "        3.69556137e-02, 4.59649758e-01, 4.28043431e-01, 2.15634777e-01,\n",
       "        7.50629366e-02, 6.55427486e-02, 1.49931476e-02, 1.34095876e-02,\n",
       "        7.23686683e-03, 2.39056705e-02, 4.68109392e-02, 3.70733743e-01,\n",
       "        4.69430597e-02, 1.64905910e-01, 2.34081946e-01, 5.89041406e-02,\n",
       "        1.64781747e-02, 2.14744742e-01]),\n",
       " 'std_test_rec': array([0.23704129, 0.37725536, 0.31814093, 0.25398079, 0.1531908 ,\n",
       "        0.2743766 , 0.        , 0.21603402, 0.07496741, 0.47140452,\n",
       "        0.38742154, 0.4424728 , 0.26904342, 0.06737502, 0.08512362,\n",
       "        0.0246073 , 0.05736237, 0.40854002, 0.35684246, 0.06956849,\n",
       "        0.30823137, 0.        , 0.06350294, 0.44781797, 0.06578669,\n",
       "        0.24401418, 0.41827173, 0.01347243, 0.02288963, 0.        ,\n",
       "        0.28325923, 0.0313958 , 0.10401616, 0.03922595, 0.37609136,\n",
       "        0.45729933, 0.1248671 , 0.19146993, 0.16187503, 0.06294264,\n",
       "        0.03302943, 0.00692536, 0.05938459, 0.41274775, 0.11593147,\n",
       "        0.36689164, 0.47140452, 0.14669546, 0.00361993, 0.41536111])}"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvsearch_0.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 3638,
     "status": "ok",
     "timestamp": 1619134548948,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "hlQ0cW9u_2BF"
   },
   "outputs": [],
   "source": [
    "model = create_model(activation='elu', kernel_size=7, kernel_initializer='glorot_uniform', drop_rate=0.5, lr = 0.005) #'lr': 0.005, 'kernel_size': 7, 'kernel_initializer': 'glorot_uniform', 'epochs': 500, 'drop_rate': 0.5, 'batch_size': 50, 'activation': 'elu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92099,
     "status": "ok",
     "timestamp": 1619134649292,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "rZ2Usgb9BO-L",
    "outputId": "1bd82b65-ff1d-4795-d717-ebaad1c2ea54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "256/256 - 21s - loss: 0.4544 - accuracy: 0.7887 - precision: 0.7829 - recall: 0.8003 - val_loss: 69.8360 - val_accuracy: 0.5044 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/500\n",
      "256/256 - 3s - loss: 0.3978 - accuracy: 0.8145 - precision: 0.8084 - recall: 0.8254 - val_loss: 4.1785 - val_accuracy: 0.4956 - val_precision: 0.4956 - val_recall: 1.0000\n",
      "Epoch 3/500\n",
      "256/256 - 3s - loss: 0.3835 - accuracy: 0.8239 - precision: 0.8152 - recall: 0.8386 - val_loss: 143.2967 - val_accuracy: 0.5044 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/500\n",
      "256/256 - 3s - loss: 0.3768 - accuracy: 0.8267 - precision: 0.8172 - recall: 0.8427 - val_loss: 42.3871 - val_accuracy: 0.5044 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/500\n",
      "256/256 - 3s - loss: 0.3592 - accuracy: 0.8401 - precision: 0.8307 - recall: 0.8552 - val_loss: 2.6000 - val_accuracy: 0.4956 - val_precision: 0.4956 - val_recall: 1.0000\n",
      "Epoch 6/500\n",
      "256/256 - 3s - loss: 0.3485 - accuracy: 0.8429 - precision: 0.8333 - recall: 0.8581 - val_loss: 1.5277 - val_accuracy: 0.4903 - val_precision: 0.4929 - val_recall: 0.9849\n",
      "Epoch 7/500\n",
      "256/256 - 3s - loss: 0.3483 - accuracy: 0.8456 - precision: 0.8362 - recall: 0.8605 - val_loss: 11.7206 - val_accuracy: 0.5044 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/500\n",
      "256/256 - 3s - loss: 0.3417 - accuracy: 0.8480 - precision: 0.8421 - recall: 0.8575 - val_loss: 0.4859 - val_accuracy: 0.7481 - val_precision: 0.8846 - val_recall: 0.5656\n",
      "Epoch 9/500\n",
      "256/256 - 3s - loss: 0.3387 - accuracy: 0.8499 - precision: 0.8385 - recall: 0.8676 - val_loss: 6.7929 - val_accuracy: 0.5044 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/500\n",
      "256/256 - 3s - loss: 0.3332 - accuracy: 0.8524 - precision: 0.8461 - recall: 0.8623 - val_loss: 261.1171 - val_accuracy: 0.5044 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/500\n",
      "256/256 - 3s - loss: 0.3237 - accuracy: 0.8597 - precision: 0.8505 - recall: 0.8736 - val_loss: 0.3582 - val_accuracy: 0.8416 - val_precision: 0.7823 - val_recall: 0.9426\n",
      "Epoch 12/500\n",
      "256/256 - 3s - loss: 0.3190 - accuracy: 0.8595 - precision: 0.8526 - recall: 0.8701 - val_loss: 1.3836 - val_accuracy: 0.7344 - val_precision: 0.7344 - val_recall: 0.7270\n",
      "Epoch 13/500\n",
      "256/256 - 3s - loss: 0.3174 - accuracy: 0.8609 - precision: 0.8540 - recall: 0.8715 - val_loss: 0.8067 - val_accuracy: 0.6350 - val_precision: 0.5761 - val_recall: 0.9981\n",
      "Epoch 14/500\n",
      "256/256 - 3s - loss: 0.3167 - accuracy: 0.8593 - precision: 0.8477 - recall: 0.8767 - val_loss: 0.3217 - val_accuracy: 0.8566 - val_precision: 0.8200 - val_recall: 0.9105\n",
      "Epoch 15/500\n",
      "256/256 - 3s - loss: 0.3149 - accuracy: 0.8599 - precision: 0.8492 - recall: 0.8761 - val_loss: 0.3120 - val_accuracy: 0.8616 - val_precision: 0.8547 - val_recall: 0.8682\n",
      "Epoch 16/500\n",
      "256/256 - 3s - loss: 0.3164 - accuracy: 0.8612 - precision: 0.8517 - recall: 0.8754 - val_loss: 0.5501 - val_accuracy: 0.7522 - val_precision: 0.9637 - val_recall: 0.5195\n",
      "Epoch 17/500\n",
      "256/256 - 3s - loss: 0.3159 - accuracy: 0.8612 - precision: 0.8537 - recall: 0.8726 - val_loss: 0.3295 - val_accuracy: 0.8562 - val_precision: 0.8090 - val_recall: 0.9294\n",
      "Epoch 18/500\n",
      "256/256 - 3s - loss: 0.3151 - accuracy: 0.8613 - precision: 0.8527 - recall: 0.8743 - val_loss: 0.3510 - val_accuracy: 0.8484 - val_precision: 0.7914 - val_recall: 0.9426\n",
      "Epoch 19/500\n",
      "256/256 - 3s - loss: 0.3126 - accuracy: 0.8646 - precision: 0.8569 - recall: 0.8761 - val_loss: 0.4140 - val_accuracy: 0.8166 - val_precision: 0.7403 - val_recall: 0.9704\n",
      "Epoch 20/500\n",
      "256/256 - 3s - loss: 0.3153 - accuracy: 0.8624 - precision: 0.8530 - recall: 0.8765 - val_loss: 0.3753 - val_accuracy: 0.8356 - val_precision: 0.7690 - val_recall: 0.9552\n",
      "Epoch 21/500\n",
      "256/256 - 3s - loss: 0.3148 - accuracy: 0.8630 - precision: 0.8545 - recall: 0.8756 - val_loss: 0.3687 - val_accuracy: 0.8378 - val_precision: 0.7729 - val_recall: 0.9527\n",
      "Epoch 22/500\n",
      "256/256 - 3s - loss: 0.3123 - accuracy: 0.8616 - precision: 0.8537 - recall: 0.8736 - val_loss: 0.3689 - val_accuracy: 0.8375 - val_precision: 0.7725 - val_recall: 0.9527\n",
      "Epoch 23/500\n",
      "256/256 - 3s - loss: 0.3114 - accuracy: 0.8641 - precision: 0.8558 - recall: 0.8764 - val_loss: 0.3640 - val_accuracy: 0.8397 - val_precision: 0.7764 - val_recall: 0.9502\n",
      "Epoch 24/500\n",
      "256/256 - 3s - loss: 0.3195 - accuracy: 0.8605 - precision: 0.8532 - recall: 0.8715 - val_loss: 0.3709 - val_accuracy: 0.8372 - val_precision: 0.7718 - val_recall: 0.9533\n",
      "Epoch 25/500\n",
      "256/256 - 3s - loss: 0.3165 - accuracy: 0.8608 - precision: 0.8511 - recall: 0.8753 - val_loss: 0.3685 - val_accuracy: 0.8378 - val_precision: 0.7732 - val_recall: 0.9521\n",
      "Epoch 26/500\n",
      "256/256 - 3s - loss: 0.3138 - accuracy: 0.8627 - precision: 0.8548 - recall: 0.8746 - val_loss: 0.3698 - val_accuracy: 0.8375 - val_precision: 0.7725 - val_recall: 0.9527\n",
      "Epoch 27/500\n",
      "256/256 - 3s - loss: 0.3159 - accuracy: 0.8622 - precision: 0.8549 - recall: 0.8732 - val_loss: 0.3685 - val_accuracy: 0.8378 - val_precision: 0.7729 - val_recall: 0.9527\n",
      "Epoch 28/500\n",
      "256/256 - 3s - loss: 0.3140 - accuracy: 0.8593 - precision: 0.8507 - recall: 0.8723 - val_loss: 0.3728 - val_accuracy: 0.8375 - val_precision: 0.7717 - val_recall: 0.9546\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,batch_size=50, epochs=500, validation_data=(x_val,y_val),callbacks=callbacks, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "executionInfo": {
     "elapsed": 568,
     "status": "error",
     "timestamp": 1619138909461,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "DZpROzQKWx0O",
    "outputId": "6e139446-bbed-4e1f-bf1f-00354330ab41"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0f1d522d4396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val_recall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#plt.gca().set_ylim(0,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('recall', 'val_recall')"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(history.history['recall']).plot(figsize=(8,6))\n",
    "#plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1619134667198,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "T5JOC_5wSvRG",
    "outputId": "9ba16644-eece-4d04-a66e-0cc4d0604f40"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 2202,
     "status": "ok",
     "timestamp": 1619134680508,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "q5qJClWMDrxb"
   },
   "outputs": [],
   "source": [
    "model.save('CNN_75x75_v1_less_complex_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_dD5FYJdpqa"
   },
   "source": [
    "#Load Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 3238,
     "status": "ok",
     "timestamp": 1619134686879,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "4Ka6Kq27UACi"
   },
   "outputs": [],
   "source": [
    "test_images = load('test_10k.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 913,
     "status": "ok",
     "timestamp": 1619134707558,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "s1DToTD_eWUx"
   },
   "outputs": [],
   "source": [
    "x_test = test_images\n",
    "y_test = load('labels_test10k.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1619134708494,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "p-sUEA2tsngy",
    "outputId": "3404f6d6-d22b-4f3a-a56f-b193351cd749"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2944, 75, 75, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1619134709513,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "CJSIpn9W6ZG_",
    "outputId": "82e621a5-63ae-43a6-92ef-e6a4730f6531"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2944,)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1619134711860,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "dKL5Vaev2MEy"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1766,
     "status": "ok",
     "timestamp": 1619135452863,
     "user": {
      "displayName": "RAFI SAZZAD",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi4U07bmA1TVAm2Vz7vb6dpaOfBcX-d1KLhH4EP8Q=s64",
      "userId": "09687994997096510332"
     },
     "user_tz": 300
    },
    "id": "OpZemf595IoV",
    "outputId": "67fbea2c-b3f8-4e33-9a7e-e5e62e1a3a47"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: f1=0.916 auc=0.9338662\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8804347826086957\n",
      "Average precision: 0.8697477330131765\n",
      "recall: 0.9587884806355511\n",
      "AUC:0.9323543440727162\n",
      "Predicted  0.0   1.0\n",
      "Actual              \n",
      "0.0        661   269\n",
      "1.0         83  1931\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting/Printing Results\n",
    "from keras import backend as K\n",
    "from sklearn import metrics\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "\n",
    "lr_probs = model.predict_proba(x_test)    # Predict probabilities\n",
    "yhat = model.predict(x_test)      # Predict class values\n",
    "yhat = np.round(yhat)\n",
    "#lr_f1, lr_auc = f1_score(y_test, yhat), metrics.auc(lr_recall, lr_precision)\n",
    "lr_f1 = f1_score(y_test, yhat)\n",
    "#lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "print('Logistic: f1=%.3f auc=%.7f' % (lr_f1, lr_auc))   # Summarise scores\n",
    "\n",
    "\n",
    "''' plot the precision-recall curves '''\n",
    "\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "#lr_precision, lr_recall, _ = precision_recall_curve(y_test, yhat)\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "pyplot.plot(lr_recall, lr_precision, 'r-', label='F1 = %0.2f' %(lr_f1))\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "pyplot.legend(loc='lower left')\n",
    "plt.title('Precision-Recall (PR) Curve')\n",
    "pyplot.show()\n",
    "\n",
    "# Save precision and recall data to plot PR curve seperately\n",
    "#np.savetxt(\"/content/drive/My Drive/Colab Notebooks/precision_HP.txt\",lr_precision)\n",
    "#np.savetxt(\"/content/drive/My Drive/Colab Notebooks/recall_HP.txt\",lr_recall)\n",
    "\n",
    "\n",
    "test_predictions = yhat             # Make a prediction on the test set\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy: \" + str(accuracy))\n",
    "average_precision = average_precision_score(y_test, test_predictions)\n",
    "print(\"Average precision: \" + str(average_precision))\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(y_test, test_predictions)\n",
    "auc = metrics.auc(recall, precision)\n",
    "recall1 = recall_score(y_test, np.round(test_predictions))\n",
    "print(\"recall: \" + str(recall1))\n",
    "print('AUC:' +str(auc))\n",
    "\n",
    "\n",
    "# Report Confusion Matrix\n",
    "y_actu = pd.Series(y_test.ravel(), name='Actual')\n",
    "y_pred = pd.Series(np.round(test_predictions.ravel()), name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "print(df_confusion)\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(df_confusion, cmap='YlGn'):\n",
    "    plt.matshow(df_confusion, cmap=cmap) # imshow\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(0,len(df_confusion.columns))\n",
    "    plt.xticks(tick_marks, df_confusion.columns)\n",
    "    plt.yticks(tick_marks, df_confusion.index)\n",
    "    plt.ylabel(df_confusion.index.name)\n",
    "    plt.xlabel(df_confusion.columns.name)\n",
    "    for i in range(len(df_confusion.index)):\n",
    "        for j in range(len(df_confusion.columns)):\n",
    "            plt.text(j,i,str(df_confusion.iloc[i,j]))\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(df_confusion)\n",
    "\n",
    "\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.rcParams['figure.figsize'] = [12, 10]\n",
    "    plt.plot(fpr, tpr, color='darkblue', label='AUC = %0.2f' %(auc))\n",
    "    plt.plot([0, 1], [0, 1], color='orange', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate', fontsize=20)\n",
    "    plt.ylabel('True Positive Rate', fontsize=20)\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=20)\n",
    "    plt.legend(loc='best',numpoints = 1,frameon=False,prop={'size': 20})\n",
    "    plt.gca().tick_params(labelsize=20)\n",
    "    plt.savefig('ROC_AUC.png')\n",
    "  \n",
    "fpr, tpr, thresholds = roc_curve(y_test, lr_probs)\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, yhat)\n",
    "#roc_auc = metrics.auc(fpr, tpr)\n",
    "# Save tpr and fpr to plot seperate ROC curve\n",
    "#np.savetxt(\"/content/drive/My Drive/Colab Notebooks/tpr.txt\",tpr)\n",
    "#np.savetxt(\"/content/drive/My Drive/Colab Notebooks/fpr.txt\",fpr)\n",
    "plot_roc_curve(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_W-4gjlK_k-T"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "MLproject_dark_matter_v5.ipynb",
   "provenance": [
    {
     "file_id": "1d5DDYjw7gpaOwr1Jp9AZ2a2zU5cEdgSo",
     "timestamp": 1618802801794
    },
    {
     "file_id": "1PDp1V116lwqkGZ9Tf-eMw6LdMfy9fe1N",
     "timestamp": 1618205738721
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
